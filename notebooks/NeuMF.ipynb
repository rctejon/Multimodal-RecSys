{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, sys\n",
        "dir2 = os.path.abspath('')\n",
        "dir1 = os.path.dirname(dir2)\n",
        "if not dir1 in sys.path: sys.path.append(dir1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "p1E54ayu9RON"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "import argparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from tensorboardX import SummaryWriter\n",
        "from metrics.metrics import metrics\n",
        "from architectures.NeuMF.neu_mf import NeuMF\n",
        "from loaders.create_dataloader import CreateDataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpBX6rqNfSc9"
      },
      "source": [
        "### Setting Arguments\n",
        "\n",
        "Here is the brief description of important ones:\n",
        "- Learning rate is 0.001\n",
        "- Dropout rate is 0.2\n",
        "- Running for 10 epochs\n",
        "- HitRate@10 and NDCG@10\n",
        "- 4 negative samples for each positive one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATASET_NAME = 'ml-1m'\n",
        "MODEL_NAME = 'NeuMF'\n",
        "DATASET_FILE = 'ratings.dat'\n",
        "MAIN_PATH = f'../data/{DATASET_NAME}/'\n",
        "DATA_PATH = MAIN_PATH + DATASET_FILE\n",
        "MODEL_PATH = f'../models/{DATASET_NAME}/'\n",
        "MODEL = f'{DATASET_NAME}-{MODEL_NAME}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bc5Vg1Ik_gnF",
        "outputId": "084c133e-0b2a-4ccc-f359-7319d904893e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['--out'], dest='out', nargs=None, const=None, default=True, type=None, choices=None, help='save model or not', metavar=None)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--seed\",\n",
        "\ttype=int,\n",
        "\tdefault=51,\n",
        "\thelp=\"Seed\")\n",
        "parser.add_argument(\"--lr\",\n",
        "\ttype=float,\n",
        "\tdefault=0.001,\n",
        "\thelp=\"learning rate\")\n",
        "parser.add_argument(\"--dropout\",\n",
        "\ttype=float,\n",
        "\tdefault=0.2,\n",
        "\thelp=\"dropout rate\")\n",
        "parser.add_argument(\"--batch_size\",\n",
        "\ttype=int,\n",
        "\tdefault=256,\n",
        "\thelp=\"batch size for training\")\n",
        "parser.add_argument(\"--epochs\",\n",
        "\ttype=int,\n",
        "\tdefault=10,\n",
        "\thelp=\"training epoches\")\n",
        "parser.add_argument(\"--top_k\",\n",
        "\ttype=int,\n",
        "\tdefault=10,\n",
        "\thelp=\"compute metrics@top_k\")\n",
        "parser.add_argument(\"--factor_num\",\n",
        "\ttype=int,\n",
        "\tdefault=32,\n",
        "\thelp=\"predictive factors numbers in the model\")\n",
        "parser.add_argument(\"--layers\",\n",
        "    nargs='+',\n",
        "    default=[64,32,16,8],\n",
        "    help=\"MLP layers. Note that the first layer is the concatenation of user \\\n",
        "    and item embeddings. So layers[0]/2 is the embedding size.\")\n",
        "parser.add_argument(\"--num_ng\",\n",
        "\ttype=int,\n",
        "\tdefault=4,\n",
        "\thelp=\"Number of negative samples for training set\")\n",
        "parser.add_argument(\"--num_ng_test\",\n",
        "\ttype=int,\n",
        "\tdefault=100,\n",
        "\thelp=\"Number of negative samples for test set\")\n",
        "parser.add_argument(\"--out\",\n",
        "\tdefault=True,\n",
        "\thelp=\"save model or not\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnaRWy2gg_Nw"
      },
      "source": [
        "## Training NeuMF Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyWquJG893CV",
        "outputId": "79d5472b-75ed-41a8-dab9-cc2db3a885ef"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1193</td>\n",
              "      <td>5</td>\n",
              "      <td>978300760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>661</td>\n",
              "      <td>3</td>\n",
              "      <td>978302109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>914</td>\n",
              "      <td>3</td>\n",
              "      <td>978301968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>3408</td>\n",
              "      <td>4</td>\n",
              "      <td>978300275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2355</td>\n",
              "      <td>5</td>\n",
              "      <td>978824291</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  item_id  rating  timestamp\n",
              "0        1     1193       5  978300760\n",
              "1        1      661       3  978302109\n",
              "2        1      914       3  978301968\n",
              "3        1     3408       4  978300275\n",
              "4        1     2355       5  978824291"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# set device and parameters\n",
        "args = parser.parse_args(\"\")\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "writer = SummaryWriter()\n",
        "\n",
        "# seed for Reproducibility\n",
        "seed_everything(args.seed)\n",
        "\n",
        "# load data\n",
        "ml_1m = pd.read_csv(\n",
        "\tDATA_PATH,\n",
        "\tsep=\"::\",\n",
        "\tnames = ['user_id', 'item_id', 'rating', 'timestamp'],\n",
        "\tengine='python')\n",
        "\n",
        "# set the num_users, items\n",
        "num_users = ml_1m['user_id'].nunique()+1\n",
        "num_items = ml_1m['item_id'].nunique()+1\n",
        "\n",
        "ml_1m.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _reindex(ratings):\n",
        "    \"\"\"\n",
        "    Process dataset to reindex userID and itemID, also set rating as binary feedback\n",
        "    \"\"\"\n",
        "    user_list = list(ratings['user_id'].drop_duplicates())\n",
        "    user2id = {w: i for i, w in enumerate(user_list)}\n",
        "\n",
        "    item_list = list(ratings['item_id'].drop_duplicates())\n",
        "    item2id = {w: i for i, w in enumerate(item_list)}\n",
        "\n",
        "    ratings['user_id'] = ratings['user_id'].apply(lambda x: user2id[x])\n",
        "    ratings['item_id'] = ratings['item_id'].apply(lambda x: item2id[x])\n",
        "    ratings['rating'] = ratings['rating'].apply(lambda x: float(x > 0))\n",
        "    return ratings\n",
        "\n",
        "def _leave_one_out(ratings):\n",
        "    \"\"\"\n",
        "    leave-one-out evaluation protocol in paper https://www.comp.nus.edu.sg/~xiangnan/papers/ncf.pdf\n",
        "    \"\"\"\n",
        "    ratings['rank_latest'] = ratings.groupby(['user_id'])['timestamp'].rank(method='first', ascending=False)\n",
        "    test = ratings.loc[ratings['rank_latest'] == 1]\n",
        "    train = ratings.loc[ratings['rank_latest'] > 1]\n",
        "    assert train['user_id'].nunique()==test['user_id'].nunique(), 'Not Match Train User with Test User'\n",
        "    return train[['user_id', 'item_id', 'rating']], test[['user_id', 'item_id', 'rating']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "ml_1m = _reindex(ml_1m)\n",
        "train_ml_1m, test_ml_1m = _leave_one_out(ml_1m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(994169, 3) (6040, 3) (1000209, 3)\n",
            "cuda:0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rctejon/Documents/tesis/Multimodal-RecSys/venv38/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# construct the train and test datasets\n",
        "data = CreateDataloader(args, train_ml_1m, test_ml_1m, MAIN_PATH)\n",
        "train_loader = data.get_train_instance()\n",
        "test_loader = data.get_test_instance()\n",
        "\n",
        "# set model and loss, optimizer\n",
        "model = NeuMF(args, num_users, num_items)\n",
        "model = model.to(device)\n",
        "print(device)\n",
        "loss_function = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=args.lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19418/19418 [00:58<00:00, 330.03it/s]\n",
            "100%|██████████| 6040/6040 [00:09<00:00, 635.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The time elapse of epoch 001 is: 00: 01: 08\n",
            "HR: 0.736\tNDCG: 0.262\tMRR: 0.739\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19418/19418 [00:59<00:00, 327.05it/s]\n",
            "100%|██████████| 6040/6040 [00:09<00:00, 607.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The time elapse of epoch 002 is: 00: 01: 09\n",
            "HR: 0.851\tNDCG: 0.303\tMRR: 0.853\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19418/19418 [01:01<00:00, 316.85it/s]\n",
            "100%|██████████| 6040/6040 [00:10<00:00, 582.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The time elapse of epoch 003 is: 00: 01: 11\n",
            "HR: 0.873\tNDCG: 0.311\tMRR: 0.875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19418/19418 [01:00<00:00, 319.06it/s]\n",
            "100%|██████████| 6040/6040 [00:09<00:00, 605.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The time elapse of epoch 004 is: 00: 01: 10\n",
            "HR: 0.895\tNDCG: 0.319\tMRR: 0.896\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19418/19418 [01:03<00:00, 303.89it/s]\n",
            "100%|██████████| 6040/6040 [00:10<00:00, 563.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The time elapse of epoch 005 is: 00: 01: 14\n",
            "HR: 0.891\tNDCG: 0.317\tMRR: 0.892\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# train, evaluation\n",
        "best_hr = 0\n",
        "for epoch in range(1, 5+1):\n",
        "\tmodel.train() # Enable dropout (if have).\n",
        "\tstart_time = time.time()\n",
        "\n",
        "\tfor user, item, label, _ in tqdm(train_loader, total=len(train_loader)):\n",
        "\t\tuser = user.to(device)\n",
        "\t\titem = item.to(device)\n",
        "\t\tlabel = label.to(device)\n",
        "\t\t# print(user.shape, item.shape, label.shape)\n",
        "\n",
        "\t\toptimizer.zero_grad()\n",
        "\t\tprediction = model(user, item)\n",
        "\t\t# print(prediction.shape)\n",
        "\t\tloss = loss_function(prediction, label)\n",
        "\t\tloss.backward()\n",
        "\t\toptimizer.step()\n",
        "\t\twriter.add_scalar('loss/Train_loss', loss.item(), epoch)\n",
        "\n",
        "\tmodel.eval()\n",
        "\tHR, NDCG, MRR, RECALL, PRECISION = metrics(model, test_loader, args.top_k, device, args.num_ng_test)\n",
        "\twriter.add_scalar('Perfomance/HR@10', HR, epoch)\n",
        "\twriter.add_scalar('Perfomance/NDCG@10', NDCG, epoch)\n",
        "\n",
        "\telapsed_time = time.time() - start_time\n",
        "\tprint(\"The time elapse of epoch {:03d}\".format(epoch) + \" is: \" +\n",
        "\t\t\ttime.strftime(\"%H: %M: %S\", time.gmtime(elapsed_time)))\n",
        "\tprint(\"HR: {:.3f}\\tNDCG: {:.3f}\\tMRR: {:.3f}\".format(np.mean(HR), np.mean(NDCG), np.mean(MRR)))\n",
        "\n",
        "\tif HR > best_hr:\n",
        "\t\tbest_hr, best_ndcg, best_mrr, best_epoch = HR, NDCG, MRR, epoch\n",
        "\t\tif args.out:\n",
        "\t\t\tif not os.path.exists(MODEL_PATH):\n",
        "\t\t\t\tos.mkdir(MODEL_PATH)\n",
        "\t\t\ttorch.save(model,\n",
        "\t\t\t\t'{}{}.pth'.format(MODEL_PATH, MODEL))\n",
        "\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6040/6040 [00:08<00:00, 701.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The time elapse of epoch 003 is: 00: 00: 08\n",
            "HR: 0.839\tNDCG: 0.299\tMRR: 0.841\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "start_time = time.time()\n",
        "model.eval()\n",
        "HR, NDCG, MRR, RECALL, PRECISION = metrics(model, test_loader, args.top_k, device, args.num_ng_test)\n",
        "writer.add_scalar('Perfomance/HR@10', HR, epoch)\n",
        "writer.add_scalar('Perfomance/NDCG@10', NDCG, epoch)\n",
        "\n",
        "elapsed_time = time.time() - start_time\n",
        "print(\"The time elapse of epoch {:03d}\".format(epoch) + \" is: \" +\n",
        "\t\ttime.strftime(\"%H: %M: %S\", time.gmtime(elapsed_time)))\n",
        "print(\"HR: {:.3f}\\tNDCG: {:.3f}\\tMRR: {:.3f}\".format(np.mean(HR), np.mean(NDCG), np.mean(MRR)))\n",
        "\n",
        "\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbZRS25AhD_p"
      },
      "source": [
        "## Final Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkiRJWeD_trR",
        "outputId": "54fd579b-ad12-42d4-e09e-28289496ee84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best epoch 003: HR@10 = 0.838, NDCG@10 = 0.299, MRR@10 = 0.840\n"
          ]
        }
      ],
      "source": [
        "print(\"Best epoch {:03d}: HR@10 = {:.3f}, NDCG@10 = {:.3f}, MRR@10 = {:.3f}\".format(\n",
        "\t\t\t\t\t\t\t\t\tbest_epoch, best_hr, best_ndcg, best_mrr))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "2020-04-21-rec-algo-ncf-pytorch-pyy0715.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
