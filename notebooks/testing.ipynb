{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>584313</td>\n",
       "      <td>Topic 1: History of\\nTopic 2: Chinese Language...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>584329</td>\n",
       "      <td>Topic 1: Applied Economics\\nTopic 2: Mathemati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>584381</td>\n",
       "      <td>Topic 1: Artistry\\nTopic 2: News Communication...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>597208</td>\n",
       "      <td>Topic 1: Computer Science and Technology\\nDesc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>597225</td>\n",
       "      <td>Description: The university computer program w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3776</th>\n",
       "      <td>2338076</td>\n",
       "      <td>Description: Programme for 2021 [Primary Term ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3777</th>\n",
       "      <td>2341259</td>\n",
       "      <td>Description: Programme for 2021 [Primary Term ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3778</th>\n",
       "      <td>2337996</td>\n",
       "      <td>Description: Programme for 2021 [Primary Term ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3779</th>\n",
       "      <td>1945689</td>\n",
       "      <td>Description: 清华张敏老师带你12 weeks掌握机器学习!8 big clas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3780</th>\n",
       "      <td>2329163</td>\n",
       "      <td>Description: The Creative Writing Case Practic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3781 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     course_id                                               text\n",
       "0       584313  Topic 1: History of\\nTopic 2: Chinese Language...\n",
       "1       584329  Topic 1: Applied Economics\\nTopic 2: Mathemati...\n",
       "2       584381  Topic 1: Artistry\\nTopic 2: News Communication...\n",
       "3       597208  Topic 1: Computer Science and Technology\\nDesc...\n",
       "4       597225  Description: The university computer program w...\n",
       "...        ...                                                ...\n",
       "3776   2338076  Description: Programme for 2021 [Primary Term ...\n",
       "3777   2341259  Description: Programme for 2021 [Primary Term ...\n",
       "3778   2337996  Description: Programme for 2021 [Primary Term ...\n",
       "3779   1945689  Description: 清华张敏老师带你12 weeks掌握机器学习!8 big clas...\n",
       "3780   2329163  Description: The Creative Writing Case Practic...\n",
       "\n",
       "[3781 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "course_texts = pickle.load(open('../pickles/course_texts.pkl', 'rb'))\n",
    "\n",
    "text_df = pd.DataFrame.from_dict(course_texts, orient='index')\n",
    "text_df.reset_index(inplace=True)\n",
    "text_df.columns = ['course_id', 'text']\n",
    "text_df['course_id'] = text_df['course_id'].apply(lambda x: x.split('_')[-1])\n",
    "text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(375629, 0)\n",
      "     id  course_id  rating\n",
      "0  U_24     597214       1\n",
      "1  U_24     605512       1\n",
      "2  U_24     597211       1\n",
      "3  U_24     597314       1\n",
      "4  U_24     597208       1\n",
      "(0, id             U_24\n",
      "course_id    597214\n",
      "rating            1\n",
      "Name: 0, dtype: object)\n",
      "(1, id             U_24\n",
      "course_id    605512\n",
      "rating            1\n",
      "Name: 1, dtype: object)\n",
      "(2, id             U_24\n",
      "course_id    597211\n",
      "rating            1\n",
      "Name: 2, dtype: object)\n",
      "(3, id             U_24\n",
      "course_id    597314\n",
      "rating            1\n",
      "Name: 3, dtype: object)\n",
      "Topic 1: Chinese Language Literature\n",
      "Description: The current data science and artificial intelligence talent gap is unprecedented, and the need for learning of AI-related knowledge is also significantly increased. The course consists mainly of eight lectures and one conversion challenge task, lectures held once a week.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C_597314'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_NAME = 'MOOCCubeX'\n",
    "MODEL_NAME = 'NeuMF'\n",
    "TRAIN_DATASET_FILE = 'train.feather'\n",
    "TEST_DATASET_FILE = 'test.feather'\n",
    "MAIN_PATH = f'../data/{DATASET_NAME}/'\n",
    "TRAIN_DATA_PATH = MAIN_PATH + TRAIN_DATASET_FILE\n",
    "TEST_DATA_PATH = MAIN_PATH + TEST_DATASET_FILE\n",
    "MODEL_PATH = f'./models/{DATASET_NAME}/'\n",
    "MODEL = f'{DATASET_NAME}-{MODEL_NAME}'\n",
    "\n",
    "item2id = pickle.load(open(MAIN_PATH + 'item2id.pkl', 'rb'))\n",
    "\n",
    "for item in item2id.items():\n",
    "    print(item)\n",
    "    break\n",
    "\n",
    "train_rating_data = pd.read_feather(TRAIN_DATA_PATH)\n",
    "test_rating_data = pd.read_feather(TEST_DATA_PATH)\n",
    "print(train_rating_data.head())\n",
    "\n",
    "for rating in train_rating_data.iterrows():\n",
    "    print(rating)\n",
    "    course_id = 'C_' + str(rating[1]['course_id'])\n",
    "    if course_id in course_texts.keys():\n",
    "        print(course_texts[course_id])\n",
    "        break\n",
    "\n",
    "# print(course_texts[course_id])\n",
    "course_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "tokenizations = pickle.load(open(f'../data/MOOCCubeX/train_embeddings_4_64.pkl', 'rb'))\n",
    "a = tokenizations[0]\n",
    "b = tokenizations[1]\n",
    "torch.cat([a,b]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "user = pickle.load(open(f'../data/DBLP_v12/test_users_50.pkl', 'rb'))\n",
    "user = np.array(user)\n",
    "user = user.astype(np.int32)\n",
    "user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2942026"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "item = pickle.load(open(f'../data/DBLP_v12/test_items_50.pkl', 'rb'))\n",
    "item = np.array(item)\n",
    "max(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1388: 'Further Results on Independence in Direct-Product Graphs.\\nYear: 2000\\n#Citations: 1\\nJournal\\n\\nGraph\\nDiscrete mathematics\\nCombinatorics\\nDirect product\\nMathematics',\n",
       " 1688: 'Comparison of GARCH, Neural Network and Support Vector Machine in Financial Time Series Prediction\\nYear: 2009\\n#Citations: 6\\nConference\\nSpringer, Berlin, Heidelberg\\nThis article applied GARCH model instead AR or ARMA model to compare with the standard BP and SVM in forecasting of the four international including two Asian stock markets indices.These models were evaluated on five performance metrics or criteria. Our experimental results showed the superiority of SVM and GARCH models, compared to the standard BP in forecasting of the four international stock markets indices.\\nAutoregressive–moving-average model\\nComputer science\\nSupport vector machine\\nNeural network nn\\nArtificial intelligence\\nFinancial time series prediction\\nAutoregressive conditional heteroskedasticity\\nArtificial neural network\\nMachine learning',\n",
       " 5781: 'Vectorial fast correlation attacks.\\nYear: 2004\\n#Citations: 2\\nRepository\\n\\nPattern recognition\\nComputer science\\nArtificial intelligence\\nCorrelation attack',\n",
       " 6762: 'A Self-Stabilizing Algorithm for Finding the Cutting Center of a Tree.\\nYear: 2003\\n#Citations: 0\\nConference\\n\\nComputer science\\nParallel computing',\n",
       " 8763: 'Fur Visualisation for Computer Game Engines and Real-Time Rendering\\nYear: 2014\\n#Citations: 0\\nConference\\nSpringer, Cham\\nIn this paper there is a method of real-time rendering of fur presented. Physical-based properties of a hair and fur strands are analysed. The work develops shell based method of rendering hair and fur, by new approach to strand modelling and rendering. Thanks to using efficient algorithms the presented method works in interactive, on-line mode and is less demanding in terms of an artist work. Thus it could be used in the production process of real-time rendering applications and computer games of various genres.\\nComputer graphics (images)\\nComputer science\\nVisualization\\nReal-time rendering\\nScheduling (production processes)\\nRendering (computer graphics)',\n",
       " 11068: 'Multisymplectic Spectral Methods for the Gross-Pitaevskii Equation\\nYear: 2002\\n#Citations: 2\\nConference\\nSpringer, Berlin, Heidelberg\\nRecently, Bridges and Reich introduced the concept of multisymplectic spectral discretizations for Hamiltonian wave equations with periodic boundary conditions [5]. In this paper, we show that the ID nonlinear Schrodinger equation and the 2D Gross-Pitaevskii equation are multi-symplectic and derive multi-symplectic spectral discretizations of these systems. The effectiveness of the discretizations is numerically tested using initial data for multi-phase solutions.\\nGross–Pitaevskii equation\\nHamiltonian (quantum mechanics)\\nMathematical analysis\\nSchrödinger equation\\nPeriodic boundary conditions\\nHamiltonian mechanics\\nSpectral method\\nWave equation\\nNonlinear Schrödinger equation\\nMathematics',\n",
       " 11895: 'Speech training systems using lateral shapes of vocal tract and F1-F2 diagram for hearing-impaired children\\nYear: 1979\\n#Citations: 1\\nConference\\nMorgan Kaufmann Publishers Inc.\\nThree speech training systems for hearing-impaired children were designed and constructed using a minicomputer and a microprocessor. The first system displays the lateral shape of the vocal tract for each vowel estimated from the speech sound. In this system, three storages are prepared. One of them can be used to store a reference shape which may be estimated from a teacheru0027s voice or a prepared standard shape. A child can articulate seeing the reference shape and re-articulate comparing his own first articulation with the reference shape. The system can also compare the estimated shape with the reference one and produce instructions with animated cartoons which show where any articulatory defects exist. The second system displays successively the lateral shapes for articulation of any phoneme sequences containing consonants. The third system displays the first two formant frequencies extracted from speech as a spot on the F1-F2 plane, where the regions of vowels are shown in color. Preliminary use of these devices has shown that they complement each other to form a more effective system of speech training.\\nSpeech training\\nComputer science\\nMicroprocessor\\nMinicomputer\\nDiagram\\nSpeech recognition\\nVowel\\nFormant\\nVocal tract',\n",
       " 13070: 'Knowledge Engineering for Affective Bi-Modal Interaction in Mobile Devices\\nYear: 2008\\n#Citations: 2\\nConference\\nIOS Press\\nThis paper focuses on knowledge engineering for the development of a system that provides affective interaction in mobile devices. The system bases its inferences about usersu0027 emotions on user input evidence from the keyboard and the microphone of the mobile device. For this purpose different experimental studies have been conducted with the participation of mobile users and human experts. The experimentsu0027 aim was twofold. They aimed at revealing the criteria that are taken into account in each mode for emotion recognition as well as their weight of importance. The results of the studies are further used for the application of a multi-criteria decision making model.\\nDecision-making models\\nComputer science\\nEmotion recognition\\nMobile device\\nHuman–computer interaction\\nKnowledge engineering\\nAffect (psychology)\\nMultimedia\\nMicrophone\\nModal',\n",
       " 13407: 'A Platform for Disaster Response Planning with Interdependency Simulation Functionality\\nYear: 2013\\n#Citations: 6\\nConference\\nSpringer, Berlin, Heidelberg\\nCatastrophic events can result in great loss of lives and property. Planning an effective disaster response to minimize associated losses is a fundamental challenge for decision makers. The planning process can be improved by simulating interdependent critical infrastructures and evaluating system behavior during disaster scenarios. This paper describes a disaster response planning simulation platform that supports decision making based on the interdependencies existing between a power grid and a supervisory control and data acquisition (SCADA) system. By considering the physical constraints on the power grid and SCADA network, a set of feasible configurations is presented to disaster responders. The utility of the platform is demonstrated using an example scenario involving power distribution to a hospital during a disaster event.\\nInterdependence\\nSystems engineering\\nPlanning process\\nPower grid\\nSCADA\\nEngineering',\n",
       " 15548: 'Cleaneval: a Competition for Cleaning Web Pages\\nYear: 2008\\n#Citations: 66\\nConference\\n\\nCleaneval is a shared task and competitive evaluation on the topic of cleaning arbitrary web pages, with the goal of preparing web data for use as a corpus for linguistic and language technology research and development. The first exercise took place in 2007. We describe how it was set up, results, and lessons learnt.\\nWeb design\\nWeb development\\nWorld Wide Web\\nWeb intelligence\\nWeb page\\nSemantic Web Stack\\nComputer science\\nWeb standards\\nWeb 2.0\\nHTML\\nMultimedia',\n",
       " 15901: 'A pedestrian navigation method for user\\'s safe and easy wayfinding\\nYear: 2013\\n#Citations: 4\\nConference\\nSpringer, Berlin, Heidelberg\\nIn recent years, most of mobile phones have a function of pedestrian navigation guidance. It was reported that users sometimes feel anxiety because of low accuracy of the position estimation especially in urban area and delay of information updating. In order to reduce the anxiety, a route planning algorithm is proposed in this study, which weighs useru0027s difficulty (or easiness) of locating own current position as well as total physical distance of courses. The difficulty is estimated by valuation functions based on the \"recognizability\" and \"visibility\" of landmarks. An experimental study conducted in real situation using a prototype system to examine and refine the model for the optimal route planning. As the result, a modified model is proposed as a promising method of route planning for useru0027s easy wayfinding.\\nVisibility\\nRoute planning\\nComputer science\\nNavigation system\\nPedestrian navigation\\nHuman–computer interaction\\nCognitive model\\nSalience (language)\\nLandmark\\nValuation (finance)',\n",
       " 16160: 'Logical Derivation of a Prolog Interpreter.\\nYear: 1984\\n#Citations: 2\\nJournal\\n\\nProgramming language\\nComputer science\\nTheoretical computer science\\nProlog\\nInterpreter',\n",
       " 21456: 'Leakage-Resilient spatial encryption\\nYear: 2012\\n#Citations: 4\\nConference\\nSpringer, Berlin, Heidelberg\\nSpatial encryption is a generic public-key cryptosystem where vectors play the role of public keys and secret keys are associated to affine spaces. Any secret key associated to a space can decrypt all ciphertexts encrypted for vectors in that space, and the delegation relation is defined by subspace inclusion. Though several constructions of spatial encryption schemes have been proposed in the literature, none of them are known to remain secure in the leakage-resilient setting, in which the adversary may be capable of learning limited additional information about the master secret key and other secret keys in the system. In this paper, we propose the first spatial encryption scheme achieving leakage resilience in the standard model, based on existing static assumptions over bilinear groups of composite order. Our new scheme is based on the leakageresilient HIBE scheme by Lewko, Rouselakis, and Waters in TCC 2011 and can be seen as a generalization of Moriyama-Doi spatial encryption scheme to the leakage-resilient setting.\\nMultiple encryption\\nKey distribution\\nSymmetric-key algorithm\\nComputer security\\nDeterministic encryption\\nAttribute-based encryption\\nEncryption\\nTheoretical computer science\\n40-bit encryption\\nProbabilistic encryption\\nMathematics',\n",
       " 21951: 'Extracted knowledge interpretation in mining biological data: A survey\\nYear: 2007\\n#Citations: 5\\nConference\\n\\nThis paper discusses different approaches for integrating biological knowledge in gene expression analysis. Indeed we are interested in the ﬁfth step of microarray analysis procedure which focuses on knowledge discovery via interpretation of the microarray results. We present a state of the art of methods for processing this step and we propose a classiﬁcation in three facets: prior or knowledge-based, standard or expression-based and co-clustering. First we discuss brieﬂy the purpose and usefulness of our classiﬁcation. Then, following sections give an insight into each facet. We summarize each section with a comparison between remarkable approaches.\\nBiological data\\nData mining\\nComputer science\\nMicroarray analysis techniques\\nKnowledge extraction\\nArtificial intelligence\\nMachine learning',\n",
       " 24781: 'Setting up an Effective Information Security Awareness Programme\\nYear: 2007\\n#Citations: 10\\nJournal\\nVieweg\\nThe security group of a large insurance company in Belgium wanted to set-up and conduct a successful security awareness programme for all employees. Before designing the programme, the group performed field research (including discussing with security peers) into what constitutes a successful awareness programme. The security group also made an inventory of available awareness material, both internally (within the company and the group to which the company belongs) and externally. Based on the various input received a conceptual approach for an effective security awareness programme was drafted on which the insurance information security awareness programme was built. Measuring the results of the programme proved that the approach was effective.\\nSecurity awareness\\nComputer science\\nKnowledge management\\nInformation security\\nInformation security awareness\\nField research',\n",
       " 29332: 'A Clausal Genetic Representation and its Evolutionary Procedures for Satisfiability Problems\\nYear: 1995\\n#Citations: 17\\nConference\\nSpringer, Vienna\\nThis paper presents a clausal genetic representation for the satisfiability problem (SAT). This representation, CR for short, aims to conserve the intrinsic relations between variables for a given SAT instance. Based on CR, a set of evolutionary algorithms (EAs) are defined. In particular, a class of hybrid EAs integrating local search into evolutionary operators are detailed. Various fitness functions for measuring clausal individuals are identified and their relative merits analyzed. Some preliminary results are reported.\\nInteractive evolutionary computation\\nGenetic operator\\nMathematical optimization\\nEvolutionary algorithm\\nComputer science\\nBoolean satisfiability problem\\nFitness approximation\\nGenetic representation\\nLocal search (optimization)\\nEvolutionary programming',\n",
       " 29841: 'Automatic Detection of Annotation Errors in Polish-Language Corpora\\nYear: 2013\\n#Citations: 0\\nConference\\nSpringer, Berlin, Heidelberg\\nIn this article we propose an extension to the variation n-gram based method of detecting annotation errors. We also show an approach to finding anomalies in the morphosyntactic annotation layer by using association rule discovery. As no research has previously been done in the field of morphosyntactic annotation error correction for Polish, we provide novel results based on experiments on the largest available Polish language corpus, the National Corpus of Polish (NCP). We also discuss the differences in the approaches used earlier for English language data and the method proposed in this article, taking into account the characteristics of Polish language.\\nAssociation rule discovery\\nAnnotation\\nEnglish language\\nInformation retrieval\\nComputer science\\nComputational linguistics\\nPolish\\nError detection and correction\\nAssociation rule learning',\n",
       " 35048: 'HyperScout: Linkvorschau im World Wide Web.\\nYear: 2004\\n#Citations: 2\\nConference\\n\\nWeb Accessibility Initiative\\nWorld Wide Web\\nComputer science',\n",
       " 38130: 'On the Universality of Multistage Interconnection Networks.\\nYear: 1986\\n#Citations: 7\\nConference\\n\\nComputer science\\nParallel computing\\nMultistage interconnection networks\\nUniversality (philosophy)\\nDistributed computing',\n",
       " 39294: 'A fuzzy multi criteria approach for evaluating sustainability performance of third –party reverse logistics providers\\nYear: 2014\\n#Citations: 6\\nConference\\nSpringer, Berlin, Heidelberg\\nDue to the complexity and specificity of reverse logistics system, some organizations outsource all or part of the reverse logistics process to third –party provider (3PRLP). The selection of the most efficient 3PRLP is a crucial task in which it is important to take into account environmental and social criteria as well as economic criteria owing to economic interests, stakeholder pressures, and environmental legislations. The tie between all three aspects of sustainability in 3PRLP selection problem has been almost ignored. This research work deals with this issue and develops a new integrated approach for selecting the best sustainable 3PRLP. A hybrid multi-criteria making decision model is structured to assign the priority weights of decision criteria using fuzzy analytic hierarchy process (FAHP) and to get the final ranking of providers using fuzzy preference ranking organization method for enrichment evaluation (F-PROMETHEE). A numerical example is also presented to illustrate the proposed approach.\\nMultiple-criteria decision analysis\\nStakeholder\\nRanking\\nReverse logistics\\nFuzzy logic\\nOperations research\\nOutsourcing\\nDecision model\\nOperations management\\nSustainability\\nBusiness',\n",
       " 40380: 'Face Detection, Recognition in an Image Sequence Using Eigenedginess.\\nYear: 2002\\n#Citations: 17\\nConference\\n\\nThis paper describes a system for face detection and recognition in an image sequence. Motion information is used to find the moving regions, and probable eye region blobs are extracted by thresholding the image. These blobs reduce the search space for face verification, which is done by template matching. Eigen analysis of edginess representation of face is used for face recognition. One dimensional processing is used to extract the edginess image of face. Experimental results for face detection show good performance even across orientation and pose variation to a certain extent. The face recognition is carried out by cumulatively summing up the Euclidean distance between the test face images and the stored database, which shows good discrimination for true and false subjects.\\nTemplate matching\\nComputer vision\\nFacial recognition system\\nPattern recognition\\nThree-dimensional face recognition\\nObject-class detection\\nComputer science\\nEuclidean distance\\nArtificial intelligence\\nFace detection\\nThresholding\\nImage sequence',\n",
       " 41593: 'Towards Increasingly Update Efficient Moving-Object Indexing\\nYear: 2002\\n#Citations: 9\\nJournal\\n\\nCurrent moving-object indexing concentrates on point-objects capable of continuous movement in one-, two-, and three-dimensional Euclidean spaces, and most approaches are based on well-known, conventional spatial indices. Approaches that aim at indexing the current and anticipated future positions of moving objects generally must contend with very large update loads because of the agility of the objects indexed. At the same time, conventional spatial indices were often originally proposed in settings characterized by few updates and focus on query performance. In this paper, we characterize the challenge of moving-object indexing and discuss a range of techniques, the use of which may lead to better update\\nData mining\\nComputer science\\nSearch engine indexing\\nEuclidean geometry',\n",
       " 43929: 'Speech recognition based on the integration of FSVQ and neural network.\\nYear: 1990\\n#Citations: 0\\nConference\\n\\nPattern recognition\\nComputer science\\nSpeech recognition\\nTime delay neural network\\nArtificial intelligence\\nArtificial neural network',\n",
       " 48405: 'Knowledge Flows: Knowledge Transfer, Sharing and Exchange in Organizations: Minitrack Introduction\\nYear: 2004\\n#Citations: 0\\nConference\\nIEEE Computer Society\\nComputer science\\nKnowledge transfer\\nKnowledge management\\nManagement science',\n",
       " 49843: 'Traveling wave solutions of the n-dimensional coupled Yukawa equations\\nYear: 2012\\n#Citations: 7\\nJournal\\nPergamon\\nAbstract   We discuss traveling wave solutions to the Yukawa equations, a system of nonlinear partial differential equations which has applications to meson–nucleon interactions. The Yukawa equations are converted to a six-dimensional dynamical system, which is then studied for various values of the wave speed and mass parameter. The stability of the solutions is discussed, and the methods of competitive modes is used to describe parameter regimes for which chaotic behaviors may appear. Numerical solutions are employed to better demonstrate the dependence of traveling wave solutions on the physical parameters in the Yukawa model. We find a variety of interesting behaviors in the system, a few of which we demonstrate graphically, which depend upon the relative strength of the mass parameter to the wave speed as well as the initial data.\\nNonlinear system\\nTraveling wave\\nMathematical analysis\\nYukawa potential\\nRelative strength\\nChaotic\\nPartial differential equation\\nDynamical system\\nPhysics',\n",
       " 52584: 'A Study on the Development of High Precision Cam Profile CNC Grinding Machine with CAD/CAM System.\\nYear: 2006\\n#Citations: 0\\nConference\\n\\nCAD\\nEngineering drawing\\nComputer science\\nArtificial intelligence\\nGrinding\\nMachine learning',\n",
       " 54153: 'Generating a Business Model Canvas through Elicitation of Business Goals and Rules from Process-Level Use Cases\\nYear: 2014\\n#Citations: 5\\nConference\\nSpringer, Cham\\nBusiness Models play a pivotal role in organizations, especially in building bridges and enabling the dialogue between business and technological worlds. Complementarily, while Use Cases are one of the most popular techniques for eliciting requirements in the design of Information Systems, Business Goals and Business Rules associate with Business Process Use Cases to compose a Business Model base structure. However, methods for relating Business Processes, Goals and Rules (PGR) are scarce, dissonant or highly analyst-dependent. In this sense, we propose a two-step method to help in guiding the elicitation of Business Goals and Rules from Process-level Use Cases, and their mapping to a Business Model representation. As a result, a solution Business Model generated by aligning the resulting trios (PGR) with a Business Model Canvas is presented to the organization stakeholders for review, validation and further negotiation.\\nArtifact-centric business process model\\nSemantics of Business Vocabulary and Business Rules\\nBusiness process\\nComputer science\\nBusiness model\\nBusiness Model Canvas\\nBusiness process modeling\\nBusiness rule\\nBusiness Process Model and Notation\\nManagement science\\nProcess management',\n",
       " 55078: 'Multi-layer topology preserving mapping for K-means clustering\\nYear: 2011\\n#Citations: 5\\nConference\\nSpringer, Berlin, Heidelberg\\nIn this paper, we investigate the multi-layer topology preserving mapping for K-means. We present a Multi-layer Topology Preserving Mapping (MTPM) based on the idea of deep architectures. We demonstrate that the MTPM output can be used to discover the number of clusters for K-means and initialize the prototypes of K-means more reasonably. Also, K-means clusters the data based on the discovered underlying structure of the data by the MTPM. The standard wine data set is used to test our algorithm. We finally analyse a real biological data set with no prior clustering information available.\\nCross entropy\\nBiological data\\nk-means clustering\\nData mining\\nCluster (physics)\\nTopology\\nMulti layer\\nComputer science\\nArtificial intelligence\\nCluster analysis\\nQuantization (signal processing)\\nMachine learning',\n",
       " 57330: 'Spectral Sparsification in Dynamic Graph Streams\\nYear: 2013\\n#Citations: 19\\nConference\\nSpringer, Berlin, Heidelberg\\nWe present a new bound relating edge connectivity in a simple, unweighted graph with effective resistance in the corresponding electrical network. The bound is tight. While we believe the bound is of independent interest, our work is motivated by the problem of constructing combinatorial and spectral sparsifiers of a graph, i.e., sparse, weighted sub-graphs that preserve cut information (in the case of combinatorial sparsifiers) and additional spectral information (in the case of spectral sparsifiers). Recent results by Fung et al. (STOC 2011) and Spielman and Srivastava (SICOMP 2011) show that sampling edges with probability based on edge-connectivity gives rise to a combinatorial sparsifier whereas sampling edges with probability based on effective resistance gives rise to a spectral sparsifier. Our result implies that by simply increasing the sampling probability by a O(n 2/3) factor in the combinatorial sparsifier construction, we also preserve the spectral properties of the graph. Combining this with the algorithms of Ahn et al. (SODA 2012, PODS 2012) gives rise to the first data stream algorithm for the construction of spectral sparsifiers in the dynamic setting where edges can be added or removed from the stream. This was posed as an open question by Kelner and Levin (STACS 2011).\\nSpectral properties\\nGraph\\nDiscrete mathematics\\nElectrical network\\nComputer science\\nData stream\\nTheoretical computer science\\nSampling (statistics)\\nDisjoint path',\n",
       " 59226: 'Interval Abstraction Refinement for Model Checking of Timed-Arc Petri Nets\\nYear: 2014\\n#Citations: 4\\nConference\\nSpringer, Cham\\nState-space explosion is a major obstacle in verification of time-critical distributed systems. An important factor with a negative influence on the tractability of the analysis is the size of constants that clocks are compared to. This problem is particularly accented in explicit state-space exploration techniques. We suggest an approximation method for reducing the size of constants present in the model. The proposed method is developed for Timed-Arc Petri Nets and creates an under-approximation or an over-approximation of the model behaviour. The verification of approximated Petri net models can be considerably faster but it does not in general guarantee conclusive answers. We implement the algorithms within the open-source model checker TAPAAL and demonstrate on a number of experiments that our approximation techniques often result in a significant speed-up of the verification.\\nObstacle\\nDiscrete mathematics\\nModel checking\\nPetri net\\nArc (geometry)\\nAbstraction\\nComputer science\\nTheoretical computer science\\nStochastic Petri net\\nAbstraction refinement',\n",
       " 65220: 'Two notes from experimental study on image steganalysis\\nYear: 2013\\n#Citations: 2\\nConference\\nSpringer Berlin Heidelberg\\nIn recent years, several advanced methods for image steganalysis were proposed. During research process, some concerns are more and more addressed by steganalyzer. In this paper, we focus on several of these concerns. The first one is how to utilize SVM classifier in practical steganalysis, we use clustering analysis to divide training samples and train several SVM for detecting stego image. In this part we also discussed building an image database that can be used for evaluating steganography/steganalysis fairly. The second is how to designed proper classifier for steganalysis, especially how to take information of cover/stego image pair into account. We will discuss several notions regard to these two concerns.\\nSteganography\\nSteganography tools\\nPattern recognition\\nComputer science\\nSupport vector machine\\nArtificial intelligence\\nSteganalysis\\nImage database\\nCluster analysis\\nClassifier (linguistics)\\nMachine learning\\nPattern recognition (psychology)',\n",
       " 67582: 'Near-synonym choice in natural language generation\\nYear: 2003\\n#Citations: 14\\nConference\\nJohn Benjamins Publishing Company\\nWe present Xenon, a natural language generation system capable of distinguishing between nearsynonyms. It integrates a near-synonym choice module with an existing sentence realization module. We evaluate Xenon using English and French nearsynonyms.\\nNatural language generation\\nLexical choice\\nComputer science\\nSynonym\\nNatural language programming\\nNatural language\\nUniversal Networking Language\\nNatural language processing\\nArtificial intelligence\\nLanguage identification\\nSentence',\n",
       " 72095: 'EMR ADOPTION BY SMALL CLINICS IN MALAYSIA: AN EXPLORATORY STUDY AND THEORETICAL EXPLANATION\\nYear: 2014\\n#Citations: 1\\nConference\\n\\nDevelopment of a national health exchange has been the focus of governments in many countries as a means of delivering quality health care at affordable cost. In deployment of a national health exchange, an important facilitator is the adoption and usage of Electronic Medical Record (EMR) systems by primary health care providers such as small clinics, and secondary/tertiary providers such as speciality clinics and hospitals. However, in-spite of expected benefits to physicians, adoption and usage are found to be low, even in some advanced countries. Adoption levels also vary widely across countries. In this research we used the theoretical lens of TPB to conduct four case studies of small clinics in Malaysia to explore their intent to adopt EMR systems. Based on our findings, we develop a theoretical understanding of the small clinics intent towards EMR adoption and propose that the theory of planned behavior (TPB) when integrated with institutional theory serves to provide better explanation of adoption of new technology in situations of low visibility of the technology, as is generally observed in developing countries. The findings have implications for researchers interested in health-care technology diffusion.\\nHealth care\\nInstitutional theory\\nComputer science\\nKnowledge management\\nDeveloping country\\nDeveloped country\\nTheory of planned behavior\\nMedical record\\nExploratory research\\nFacilitator\\nMarketing',\n",
       " 73348: 'Accessibility Issues in E-Government\\nYear: 2014\\n#Citations: 3\\nConference\\nSpringer, Cham\\nGovernment services are almost always monopoly services, and as a result, it is important to maximize inclusion. However, substantial numbers of people are unable or unwilling to use internet services. Usability and accessibility issues are a major deterrent to internet use and are important in users’ perceptions of websites. These are particularly important for older people, many of whom have reduced visual acuity, loss of fine motor control and other disabilities that make it more difficult to deal with poorly designed websites. We undertook two sets of experiments, the first involving an assessment of the accessibility and standards compliance of local and national e-government sites in the UK. The second focuses on sites in several other European countries. Results show significant differences between different levels of government and between standards compliance and accessibility.\\nInternet privacy\\nE-Government\\nUsability\\nMonopoly\\nPerception\\nBusiness\\nReduced visual acuity\\nGovernment\\nThe Internet',\n",
       " 74282: 'CONTEXT AWARENESS OF MOBILE CONTENT DELIVERY BASED ON FINE LOCATION ESTIMATE\\nYear: 2016\\n#Citations: 0\\nConference\\n\\nMobile content\\nInternet privacy\\nWorld Wide Web\\nComputer science\\nKnowledge management\\nContext awareness',\n",
       " 74721: 'Exploring New Care Models in Diabetes Management and Therapy with a Wireless Mobile eHealth Platform\\nYear: 2011\\n#Citations: 5\\nConference\\nSpringer, Berlin, Heidelberg\\nDue to demographic changes, European healthcare systems face two serious challenges: healthcare delivery may become inadequate to perceived needs of the citizens or the cost may spiral out of control. With the decrease in the labour force, there is an urgent need to make more health services mobile allowing citizens with chronic diseases stay longer in the labour markets, reduce the number of lost working days and generally support nomadic working. Mobile technologies have the potential to provide better healthcare while at the same time increasing the working population. However, it calls for dramatic changes of healthcare provisioning and of the care models. The REACTION project develops a mobile, cloud-based platform that provides healthcare services to diabetes patients and caregivers. As part of the project, new chronic care models that support separation of care spaces are proposed.\\nHealth care\\nMobile technology\\nPopulation\\nInternet privacy\\nDiabetes management\\nProvisioning\\nChronic care\\nmHealth\\neHealth\\nMultimedia\\nBusiness',\n",
       " 75756: 'Learning of abstractions from structural descriptions of pictures\\nYear: 1979\\n#Citations: 0\\nConference\\nMorgan Kaufmann Publishers Inc.\\nThe acquisition of concepts induced by structural descriptions of pictures is discussed and a representation scheme is presented which allows the construction of various abstractions based on different points of views and their storage in a simulated associative memory.\\nProgramming language\\nContent-addressable memory\\nAbstraction\\nComputer science\\nArtificial intelligence\\nNatural language processing\\nMachine learning',\n",
       " 80570: 'Hypergraph Transversal Computation with Binary Decision Diagrams\\nYear: 2013\\n#Citations: 14\\nConference\\nSpringer, Berlin, Heidelberg\\nWe study a hypergraph transversal computation: given a hypergraph, the problem is to generate all minimal transversals. This problem is related to many applications in computer science and various algorithms have been proposed. We present a new efficient algorithm using the compressed data structures BDDs and ZDDs, and we analyze the time complexity for it. By conducting computational experiments, we show that our algorithm is highly competitive with existing algorithms.\\nBoolean function\\nData structure\\nComputer science\\nHypergraph\\nBinary decision diagram\\nAlgorithm\\nTransversal (geometry)\\nTheoretical computer science\\nTime complexity\\nComputation',\n",
       " 83404: 'A comparative study of scrum and kanban approaches on a real case study using simulation\\nYear: 2012\\n#Citations: 17\\nConference\\nSpringer, Berlin, Heidelberg\\nWe present the application of software process modeling and simulation using an agent-based approach to a real case study of software maintenance. The original process used PSP/TSP; it spent a large amount of time estimating in advance maintenance requests, and needed to be greatly improved. To this purpose, a Kanban system was successfully implemented, that demonstrated to be able to substantially improve the process without giving up PSP/TSP. We customized the simulator and, using input data with the same characteristics of the real ones, we were able to obtain results very similar to that of the processes of the case study, in particular of the original process. We also simulated, using the same input data, the possible application of the Scrum process to the same data, showing results comparable to the Kanban process.\\nScrum\\nKanban\\nSystems engineering\\nSoftware engineering\\nModeling and simulation\\nLean software development\\nSoftware Process simulation\\nSoftware development process\\nSoftware maintenance\\nEngineering',\n",
       " 86197: 'Securing Mobile Device-Based Machine Interactions with User Location Histories\\nYear: 2012\\n#Citations: 8\\nConference\\nSpringer, Berlin, Heidelberg\\nMobile devices are more and more integrated in workflows, especially when interacting with stationary resources like machines in order to improve productivity or usability, but risk unauthorized access or unwanted unattended operation. Systems for location based access control have been developed to restrict the user to be in specific locations in order to proceed in a workflow. However, these approaches do not consider the movement pattern of a user nor do they distinguish the severity of false-positives that might arise from imperfect location measurements which is crucial in certain workflows. In this paper, focusing on mobile users interacting with stationary machines, an approach for workflow policies is presented using three types of location constraints to enforce movement patterns. The evaluation of these constraints is based on a user’s location history which is generated in a tamper-proof environment on his mobile device and describes his geographical trajectory for a given timespan.\\nImperfect\\nComputer science\\nComputer security\\nUsability\\nComputer network\\nLocation based access control\\nMobile device\\nWorkflow\\nrestrict\\nTrajectory',\n",
       " 89833: 'ADAPTING GRID SERVICES FOR URGENT COMPUTING ENVIRONMENTS\\nYear: 2008\\n#Citations: 4\\nConference\\n\\nDRMAA\\nGrid computing\\nComputer science\\nData grid\\nSemantic grid\\nDatabase\\nGrid\\nDistributed computing',\n",
       " 94238: 'The Year 2000 Problem: Introduction.\\nYear: 1999\\n#Citations: 0\\nJournal\\n\\nYear 2000 problem\\nInternet privacy\\nComputer science',\n",
       " 94630: 'The role of the community in a technical support community: a case study\\nYear: 2013\\n#Citations: 0\\nConference\\nSpringer, Berlin, Heidelberg\\nResource tagging has become an integral and important feature in enabling community users to easily access relevant content in a timely manner. Various methods have been proposed and implemented to optimize the identification of and access to tags used to characterize resources across different types of social web-based communities. While these user-focused tagging methods have shown promise in their limited application, they do not transfer well to internal business applications where the cost, time, tagged content, and user resources needed to implement them is prohibitive. This paper provides a case study of the process, tools, and methods used to engage users in the development and management of a tag taxonomy (folksontology) used to characterize content in an internal technical support community in the Cisco Global Technology Center.\\nWorld Wide Web\\nSocial community\\nSocial web\\nComputer science\\nFolksonomy\\nTechnical support',\n",
       " 95816: 'A possibilistic approach to restore consistency in answer set programming.\\nYear: 2004\\n#Citations: 0\\nConference\\n\\nIn Answer Set Programming it is not possible to deduce any conclusion from an inconsistent program (ie: a program that has no model). The same issue occurs in classical logic where there exist some techniques to handle this inconsistency. In this work, we propose to manage inconsistent logic programs in a similar way as possibilistic logic does for classical logic. We compute a consistent subprogram keeping the most important rules of the original program. This importance is described by a necessity degree assigned to each rule.\\nFunctional logic programming\\nHorn clause\\nComputer science\\nMultimodal logic\\nAlgorithm\\nStable model semantics\\nClassical logic\\nLogic programming\\nAnswer set programming\\nHigher-order logic',\n",
       " 102669: 'Mining Fraudulent Transactions in e-payment Systems.\\nYear: 2007\\n#Citations: 3\\nConference\\n\\nInternet privacy\\nComputer science\\nPayment service provider\\nPayment\\nDatabase',\n",
       " 108831: 'Predictive adaptation and compensation for robust speech recognition.\\nYear: 1998\\n#Citations: 7\\nConference\\n\\nPattern recognition\\nComputer science\\nSpeech recognition\\nSpeaker recognition\\nArtificial intelligence',\n",
       " 111790: 'Context-Aware Staged Configuration of Process Variants@Runtime\\nYear: 2014\\n#Citations: 20\\nConference\\nSpringer, Cham\\nProcess-based context-aware applications are increasingly becoming more complex and dynamic. Besides the large sets of process variants to be managed in such dynamic systems, process variants need to be context sensitive in order to accommodate new user requirements and intrinsic complexity. This paradigm shift forces us to defer decisions to runtime where process variants must be customized and executed based on a recognized context. However, there exists a lack of deferral of the entire process variant configuration and execution to perform an automated decision of subsequent variation points at runtime. In this paper, we present a holistic methodology to automatically resolve process variability at runtime. The proposed solution performs a staged configuration considering static and dynamic context data to accomplish effective decision making. We demonstrate our approach by exemplifying a storage operation process in a smart logistics scenario. Our evaluation demonstrates the performance and scalability results of our methodology.\\nSystems engineering\\nExistential quantification\\nComputer science\\nParadigm shift\\nContext awareness\\nProcess variability\\nUser requirements document\\nScalability',\n",
       " 114370: 'On the Solutions of NP-Complete Problems by Means of jNEP Run on Computers.\\nYear: 2009\\n#Citations: 3\\nConference\\n\\nNP-complete\\nComputer science\\nTheoretical computer science\\nArtificial intelligence\\nMachine learning',\n",
       " 119821: 'The Design and Completion of Jiangsu Tourism Q&A System\\nYear: 2013\\n#Citations: 0\\nConference\\nSpringer, Berlin, Heidelberg\\nBridging the gap between the user’s query and the tourism information has been a major challenge for Qu0026A systems. State-of-the-art approaches address this issue implicitly from an information extraction view. The effectiveness of these Qu0026A systems is highly dependent on the availability of names of tourism sites. Without the name of tourism sites in users’ questions will cause mistakes. Moreover these Qu0026A systems can not deal with real question sentences but only some query words. In this paper we try to solve the above problems by analyzing user’s query sentences and then construct databases of Qu0026A and tourism information. We explore strategies to return precise and appropriate answers. Now Jiangsu Tourism Qu0026A has launched an online service and it will be applied to other areas more widely in the future. Experiments show that the Jiangsu Tourism Qu0026A is feasible and effective.\\nInformation retrieval\\nComputer science\\nBridging (networking)\\nWeb query classification\\nTourism\\nInformation extraction',\n",
       " 120346: 'Color displays for the color blind.\\nYear: 1997\\n#Citations: 31\\nConference\\n\\nComputer vision\\nComputer science\\nArtificial intelligence\\nPrimary color',\n",
       " 121590: 'Simulation-Based Service Process Benchmarking in Product-Service Ecosystems\\nYear: 2013\\n#Citations: 0\\nConference\\nSpringer, Berlin, Heidelberg\\nIncreasing market competition leads to a differentiation of service providers by offering hybrid services as value added services. In product-service ecosystems the effectiveness of cross-company business processes constitutes a major competitive factor. In this paper, we present a procedure model for simulation-based process benchmarking in the domain of industrial service procurement. In focus are cross-company business processes in service networks in bilateral collaboration scenarios of service providers and service consumers. A systematic analysis of performance indicators measures reveals weaknesses and potential for improvement. A set of hands on uses cases realizes validation and evaluation of yielded benchmarking results.\\nService design\\nService level objective\\nBusiness process\\nComputer science\\nKnowledge management\\nService provider\\nService product management\\nService level requirement\\nBenchmarking\\nOperations management\\nService delivery framework\\nProcess management',\n",
       " 122273: 'Electronic Medical Record (EMR) Utilization for Public Health Surveillance\\nYear: 2008\\n#Citations: 8\\nConference\\nAmerican Medical Informatics Association\\nIntroduction: Public health surveillance systems need to be refined. We intend to use a generic approach for early identification of patients with severe influenza-like illness (ILI) by calculating a score that estimates a patient’s disease-severity. Accordingly, we built the Intelligent Severity Score Estimation Model (ISSEM), structured so that the inference process would reflect experts’ decisionmaking logic. Each patient’s disease-severity score is calculated from numbers of respiratory ICD9 encounters, and laboratory, radiologic, and prescription-therapeutic orders in the EMR. Other ISSEM components include chronic disease evidence, probability of immunodeficiency, and the provider’s general practice-behavior patterns. Results: Sensitivity was determined from 200 randomly selected patients with upper- and lowerrespiratory tract ILI; specificity, from 300 randomly selected patients with URI only. For different age groups, ISSEM sensitivity ranged between 90% and 95%; specificity was 72% to 84%. Conclusion: Our preliminary assessment of ISSEM performance demonstrated 93.5% sensitivity and 77.3% specificity across all age groups. Background\\nSeverity of illness\\nData mining\\nPublic health surveillance\\nEmergency medicine\\nAge groups\\nInference\\nImmunodeficiency\\nMedical record\\nChronic disease\\nMedicine',\n",
       " 127103: 'Evolutionary Learning of Basic Functionalities for Snake-Like Robots\\nYear: 2014\\n#Citations: 1\\nJournal\\nSpringer, Cham\\nThe objective of the work presented in this paper is to investigate the optimal learning strategy for snake-like modular robots using a (1+1) Evolutionary Algorithm. We take into account three different but correlated tasks: efficient locomotion, reaching a given point and obstacle avoidance.\\nObstacle avoidance\\nEmbodied evolution\\nEvolutionary algorithm\\nEvolutionary robotics\\nComputer science\\nOptimal learning\\nSelf-reconfiguring modular robot\\nArtificial intelligence\\nRobot\\nEvolutionary learning',\n",
       " 128280: 'Restoration of Images Stained with Waterdrops on a Protection Glass Surface by Using a Stereo Image Pair.\\nYear: 2005\\n#Citations: 2\\nJournal\\n\\nIn this paper, we propose a method for restoration of images stained with waterdrops on a protection glass surface. The method detects positions of waterdrops in images by comparing disparities measured from stereo images with the value calculated from a geometrical relationship of the glass surface and the cameras. Next, it estimates disparities of image regions hidden by waterdrops, based on the property that disparities are generallysimilar with those around waterdrops. Finally, it removes waterdrops from images by replacing the above regions with corresponding image regions obtained by disparityreferring. An experimental result has shown the validity of the proposed method.\\nComputer vision\\nPattern recognition\\nArtificial intelligence\\nMathematics\\nStereo image',\n",
       " 130022: 'WorkCellSimulator: a 3d simulator for intelligent manufacturing\\nYear: 2012\\n#Citations: 4\\nConference\\nSpringer, Berlin, Heidelberg\\nThis paper presents WorkCellSimulator, a software platform that allows to manage an environment for the simulation of robot tasks. It uses the most advanced artificial intelligence algorithms in order to define the production process, by controlling one or more robot manipulators and machineries present in the work cell. The main goal of this software is to assist the user in defining customized production processes which involve specific automated cells. It has been developed by IT+Robotics, a spin-off company of the University of Padua, founded in 2005 from the collaboration between young researchers in the field of Robotics and a group of professors from the Department of Information Engineering, University of Padua.\\nRobot learning\\nGeography of robotics\\nComputer science\\nSimulation\\nScheduling (production processes)\\nSoftware\\nArtificial intelligence\\nInformation engineering\\nRobot\\nRobot manipulator\\nRobotics',\n",
       " 134560: 'Smart Knowledge Capture for Developing Adaptive Management Systems\\nYear: 2008\\n#Citations: 0\\nConference\\n\\nIn this paper we describe how a well\\xaddesigned Spatial Decision Support System (SDSS) may  facilitate  initial  (immediate) decision making, while establishing a robust foundation and framework for improving effectiveness over time as new data and knowledge becomes available. u0027Smart Knowledge Captureu0027 is a set of methods for rapidly developing a strong SDSS for adaptive management. We review some of the MIS tools used in Smart Knowledge Capture: multi\\xadcriteria decision analysis (MCDA) tools, online surveys, online knowledge portals, ontology systems, and describe the architecture of an SDSS  that stores  and  utilizes  this  knowledge.     We  illustrate  these  concepts  using  our  recent work  supporting  the  development of  a revised desert tortoise recovery plan.\\nDecision analysis\\nOntology\\nArchitecture\\nMultiple-criteria decision analysis\\nComputer science\\nKnowledge management\\nSpatial decision support system\\nKnowledge capture\\nAdaptive management',\n",
       " 137780: 'Toward practical application of formal methods in software lifecycle processes\\nYear: 2012\\n#Citations: 0\\nConference\\nSpringer, Berlin, Heidelberg\\nRecent information systems are getting larger and more complex, and are used for a long period of time, continually being modified to meet the unexpected changes of service objectives, usersu0027 requirements, available technologies, standards, and regulations. Such systems usually include externally-developed modules, and are often connected to other systems, which may change occasionally. Thus, todayu0027s software lifecycle processes must be able to cope with such changes.\\nInformation system\\nApplication lifecycle management\\nFormal language\\nSoftware engineering\\nComputer science\\nTheoretical computer science\\nSoftware development process\\nSystem lifecycle\\nFormal methods',\n",
       " 138457: 'Parallel algorithms for deblurring of MR images.\\nYear: 1998\\n#Citations: 3\\nConference\\n\\nDeblurring\\nComputer science\\nParallel algorithm\\nParallel computing',\n",
       " 140204: 'Special issue on causal modeling: Preface.\\nYear: 1989\\n#Citations: 0\\nJournal\\n\\nData science\\nCausal inference\\nComputer science\\nArtificial intelligence\\nMachine learning\\nCausal model',\n",
       " 140362: 'Constructing a Corpus-based Ontology Using Model Bias.\\nYear: 2006\\n#Citations: 17\\nConference\\n\\nRecent work in lexical resource construction has recognized the importance of contextualizing the knowledge in existing resources and ontologies with information derived from text corpora. This paper describes the integration of a corpus-based lexical acquisition process with a large, linguistically motivated lexical ontology. This semi-automatic bootstrapping process is used to produce refinements, additions, and modifications to the type specifications for the arguments to predicates in this ontology. In addition, the procedure is used to verify and modify the lexical extensions of the entity types\\nOntology (information science)\\nOntology\\nInformation retrieval\\nComputer science\\nBootstrapping\\nText corpus\\nNatural language processing\\nArtificial intelligence\\nPredicate (grammar)\\nLexical acquisition',\n",
       " 143119: 'INDOOR NAVIGATION USING APPROXIMATE POSITIONS\\nYear: 2009\\n#Citations: 4\\nConference\\n\\nNavigation aids have usually concentrated on the great outdoors, whether driving on highways or, more recently, walking through cities. These systems use GPS for position information. Indoor navigation cannot rely on GPS. The following presents a indoor system curently being developed, based on a novel technique called\\nComputer science\\nReal-time computing\\nGlobal Positioning System\\nDistributed computing',\n",
       " 148797: 'On the entropy on the Lukasiewicz square.\\nYear: 2005\\n#Citations: 3\\nConference\\n\\nThe unit square is regarded as a special kind of dynamical system. It is proved that the square is an MV-algebra, hence the recent results on MValgebra entropy theory can be applied to it.\\nPure mathematics\\nUnit square\\nEntropy (information theory)\\nDynamical system\\nMathematics',\n",
       " 149844: 'AST Pre-Processing For The Sliding Window Method Using Genetic Algorithms.\\nYear: 2003\\n#Citations: 1\\nJournal\\n\\nModular exponentiation is a cornerstone operation to several public-key cryptography systems such as the RSA. It is performed using successive modular multiplications. The latter is time consuming for large operands. Accelerating public-key cryptography software or hardware needs reducing the total number of modular multiplication needed. This paper introduces a novel idea based on genetic algorithms for evolving an optimal addition chain that allows one to perform precomputations necessary in the window modular exponentiation methods. The obtained addition chain allows one to perform exponentiation with a minimal number of multiplication and hence implementing efficiently the exponentiation operation. We compare our results with those obtained using the algorithm of Brun.\\nSliding window protocol\\nComputer science\\nModular arithmetic\\nOperand\\nArithmetic\\nMultiplication\\nModular design\\nExponentiation\\nAddition chain\\nModular exponentiation',\n",
       " 2431: 'Transaction processing using J2EE application: Performance with tens of millions of users.\\nYear: 2006\\n#Citations: 0\\n\\n\\nTransaction processing\\nComputer science\\nOnline transaction processing\\nExtreme Transaction Processing\\nDatabase\\nTransaction processing system',\n",
       " 3787: 'Reasonig about Set-Oriented Methods in Object Databases.\\nYear: 1998\\n#Citations: 0\\n\\n\\nDeep-sky object\\nDatabase model\\nComputer science\\nDatabase schema\\nDatabase design\\nObject-based spatial database\\nDatabase',\n",
       " 6615: 'Exponential Family of Level Dependent Choquet Integral Based Class-Conditional Probability Functions\\nYear: 2013\\n#Citations: 2\\n\\nSpringer, Berlin, Heidelberg\\nIn a recent paper we introduced two new families of probability-density functions. We introduced first the exponential family of Choquet integral based class-conditional probability-density functions, and second the exponential family of Choquet-Mahalanobis integral based class-conditional probability-density functions. The latter being a generalization of the former, and also a generalization of the normal distribution. In this paper we study some properties of these distributions and define another generalization based on level-dependent Choquet integrals.\\nApplied mathematics\\nNormal distribution\\nConditional probability\\nMathematical analysis\\nExponential family\\nMahalanobis distance\\nMultivariate normal distribution\\nChoquet integral\\nMathematics',\n",
       " 11779: 'Relational Abstract Interpretation of Higher Order Functional Programs (extended abstract)\\nYear: 1991\\n#Citations: 4\\n\\n\\nMost applications of the abstract interpretation framework[2] have been foranalyzing functional programs use functions on abstract values to approxi-mate functions, thus assuming that functions may be called at all arguments.When the abstract domain is ﬁnite, this approach can easily be generalizedto higher order functional languages as shown for example by [1]. In practicethis leads to combinatorial explosion problems as observed, for example, instrictness analysis of higher order functional languages.\\nDiscrete mathematics\\nAlgebra\\nFunctional programming\\nAbstract interpretation\\nCombinatorial explosion\\nMathematics',\n",
       " 17684: \"Word pairs in language modeling for information retrieval\\nYear: 2004\\n#Citations: 18\\n\\nLE CENTRE DE HAUTES ETUDES INTERNATIONALES D'INFORMATIQUE DOCUMENTAIRE\\nPrevious language modeling approaches to information retrieval have focused primarily on single terms. The use of bigram models has been studied, but the restriction on word order and adjacency may not be justified for information retrieval. We propose a new language modeling approach to information retrieval that incorporates lexical affinities, or pairs of words that occur near each other, without a constraint on word order. The use of compound terms in the vector space model has been shown to outperform the vector model with only single terms (Nie u0026 Dufort, 2002). We explore the use of compound terms in a language modeling approach, and compare our results with the vector space model, and unigram and bigram language model approaches.\\nAdjacency list\\nDivergence-from-randomness model\\nComputer science\\nBigram\\nNatural language processing\\nArtificial intelligence\\nTerm Discrimination\\nVector space model\\nLanguage model\\nWord order\\nInformation retrieval\\nSpeech recognition\\nConstructed language\",\n",
       " 19779: 'Sensor-Data-Driven Knowledge Creation Model: A Model and Empirical Test\\nYear: 2014\\n#Citations: 0\\n\\nSpringer, Dordrecht\\nA new knowledge-creation model, called sensor-data-driven knowledge creation (SDD-KC), which utilizes sensor data for discovering tacit knowledge, is proposed and tested. The proposed model utilizes wearable sensors to digitize tacit activities such as location, motion, and social interaction of people. To derive practical knowledge, the obtained data is statistically analyzed and associated with performance outcome. An empirical test at a retail store demonstrated that the SDD-KC model was able to derive a rule that leads to customers’ behavioral change, which contributed to a sales increase. In contrast, the traditional knowledge-creation model, applied in the same setting, failed to identify effective ideas. The proposed SDD-KC model was thus shown to be effective for knowledge creation by overcoming cognitive limitations of people.\\nSocial relation\\nSensor node\\nData-driven\\nWearable computer\\nComputer science\\nHuman–computer interaction\\nKnowledge creation\\nCognition\\nTacit knowledge\\nEmpirical research',\n",
       " 28916: 'Modellierung des Datenverkehrs von WWW-Clienten.\\nYear: 1999\\n#Citations: 0\\n\\n',\n",
       " 31888: 'A Study of the Postgraduate Project Process in a School of Computing.\\nYear: 2004\\n#Citations: 1\\n\\n\\nMedical education\\nProject management process\\nEngineering',\n",
       " 35479: 'Methodology for Development and Objective Comparison of Architectures for Networked RFID\\nYear: 2008\\n#Citations: 0\\n\\nSpringer, Berlin, Heidelberg\\nThe purpose of this paper is to address the problems presented by a heterogeneous environment of networked RFID implementations. These systems have a growing number of applications and these will have varying requirements that need to be modelled and communicated. The use of an ontology-centred methodology is suggested that can represent the entities in the system and also their relationships in a formalized manner. Such a formal methodology can support the planning, design, development, efficient operation and interconnection of various networked architectures.\\nEngineering drawing\\nComputer science\\nOpen Systems Interconnection\\nImplementation\\nInterconnection\\nRDF\\nDistributed computing',\n",
       " 36490: 'Breast Cancer Identification Based on Thermal Analysis and a Clustering and Selection Classification Ensemble\\nYear: 2013\\n#Citations: 7\\n\\nSpringer, Cham\\nBreast cancer is the most common form of cancer in women. Early diagnosis is necessary for effective treatment and therefore of crucial importance. Medical thermography has been demonstrated an effective and inexpensive method for detecting breast cancer, in particular in early stages and in dense tissue. In this paper, we propose a medical decision support system based on analysing bilateral asymmetries in breast thermograms. The underlying data is imbalanced, as the number of benign cases significantly exceeds that of malignant ones, which will lead to problems for conventional pattern recognition algorithms. To address this, we propose an ensemble classifier system which is based on the idea of Clustering and Selection. The feature space, which is derived from a series of image symmetry features, is partitioned in order to decompose the problem into a set of simpler decision areas. We then delegate a locally competent classifier to each of the generated clusters. The set of predictors is composed of both standard models as well as models dedicated to imbalanced classification, so that we are able to employ a specialised classifier to clusters that show high class imbalance, while maintaining a high specificity for other clusters. We demonstrate that our method provides excellent classification performance and that it statistically outperforms several state-of-the-art ensembles dedicated to imbalanced problems.\\nFeature vector\\nPattern recognition\\nBreast cancer\\nDelegate\\nDecision support system\\nArtificial intelligence\\nEngineering\\nCluster analysis\\nClassifier (linguistics)\\nMachine learning',\n",
       " 40845: 'Online discussion boards - friend or foe?\\nYear: 2002\\n#Citations: 22\\n\\n\\nThis paper summarises some of the important features of online discussion boards, and some reflections from my experience in their use as both a graduate student and a staff developer. As a student of the UNITEC Master of Computing programme for the past three years I have experienced the use of discussion boards by a variety of tutors, and have used these experiences to inform my practice as a staff developer in the use of Blackboard at UNITEC. This paper brings these ideas together in a form that will promote better understanding of how effective learning situations can be developed, delivered and assessed.\\nComputer science\\nDiscussion board\\nMultimedia\\nOnline discussion',\n",
       " 43565: 'De-noising and Recovering Images Based on Kernel PCA Theory.\\nYear: 2004\\n#Citations: 0\\n\\n\\nPrincipal Component Analysis (PCA) is a basis transformation to diagonalize an estimate of the covariance matrix of input data and, the new coordinates in the Eigenvector basis are called principal components. Since Kernel PCA is just a PCA in feature space F , the projection of an image in input space can be reconstructed from its principal components in feature space. This enables us to perform several applications concerning de-noising and recovering images. Because of the superiority of Kernel PCA over linear PCA, we also get satisfactory effects of de-noising images using Kernel PCA.\\nSparse PCA\\nFeature vector\\nPattern recognition\\nPrincipal component regression\\nKernel embedding of distributions\\nComputer science\\nKernel principal component analysis\\nArtificial intelligence\\nCovariance matrix\\nEigenvalues and eigenvectors\\nPrincipal component analysis',\n",
       " 45886: 'Accessible Digital Media and Sign Language: Introduction to the Special Thematic Session.\\nYear: 2004\\n#Citations: 0\\n\\n\\nComputer science\\nSign language\\nThematic map\\nMultimedia\\nDigital media',\n",
       " 65230: 'Zur Modellierung in der ordnungssortierten logischen Programmierung.\\nYear: 1994\\n#Citations: 0\\n\\n',\n",
       " 69894: 'Indexing Prolog clauses\\nYear: 1989\\n#Citations: 13\\n\\nDepartment of Computer Science, K.U.Leuven, Leuven, Belgium\\nData mining\\nProgramming language\\nDefinite clause grammar\\nComputer science\\nSearch engine indexing\\nProlog',\n",
       " 78484: 'Collaboration-based verification of Object-Oriented models in HOL.\\nYear: 2004\\n#Citations: 0\\n\\n\\nHOL\\nProgramming language\\nObject-oriented programming\\nComputer science',\n",
       " 88169: 'Organisatorische und technologische Aspekte der CAD/CAM/CIM Systeme\\nYear: 1986\\n#Citations: 0\\n\\nTeubner\\nCAD\\nEngineering drawing\\nEngineering',\n",
       " 93132: 'Telecommunication Information Tracking Application.\\nYear: 2008\\n#Citations: 0\\n\\n\\nTelecommunications\\nComputer science',\n",
       " 95708: 'One for all, all for one: performing citizen driven development of public E-services\\nYear: 2011\\n#Citations: 2\\n\\nSpringer, Berlin, Heidelberg\\nThe notion of citizen driven development of public e-services has been vivid for a number of years in eGovernment research, practice and policies. A variety of expectations are coupled with the idea of citizens participating in the development process; ranging from, roughly outlined, more efficient services (economic gain and customer satisfaction) and enhanced democracy (deliberation and empowerment). There are less conceptual analyses resting on a critical stance analysing how this notion is translated in practical settings, leaving a gap in between for practitioners to solve. This paper presents explorative work made in a Swedish authority, setting out to understand their structure, and the available methods used, in relation to the concept. The results show that besides difficulties in creating systematic work processes, what surfaces is the complex task of estimation.\\nDeliberation\\nCustomer satisfaction\\nPolitical science\\nE-services\\nPublic relations\\nKnowledge management\\nDemocracy\\nEmpowerment',\n",
       " 104967: 'Impact of Microcomputers on Traditional Information Management Resources.\\nYear: 1984\\n#Citations: 0\\n\\n\\nInformation system\\nResource management\\nManagement information systems\\nInformation management\\nComputer science\\nKnowledge management\\nInformation security management\\nRisk management information systems\\nInformation technology management\\nData management',\n",
       " 117599: 'Inserting rhetorical predicates for quasi-abstractive summarization\\nYear: 2010\\n#Citations: 1\\n\\nLE CENTRE DE HAUTES ETUDES INTERNATIONALES D\\'INFORMATIQUE DOCUMENTAIRE\\nWe investigate the problem of inserting rhetorical predicates (e.g. \"to present\", \"to discuss\", \"to indicate\", \"to show\") during non extractive summary generation and compare various algorithms for the task which we trained over a set of human written summaries. The algorithms which use a set of features previously introduced in the summarization literature achieve between 57% to 62% accuracy depending on the machine learning algorithm used. We draw conclusions with respect to the use of context during predicate prediction.\\nMulti-document summarization\\nAutomatic summarization\\nInformation retrieval\\nComputer science\\nRhetorical question\\nNatural language processing\\nArtificial intelligence\\nPredicate (grammar)',\n",
       " 121047: \"Database Interoperability using a Database's own Natural Query Language.\\nYear: 2003\\n#Citations: 0\\n\\n\\nQuery optimization\\nRDF query language\\nDatabase tuning\\nInformation retrieval\\nComputer science\\nView\\nData definition language\\nDatabase schema\\nDatabase design\\nDatabase theory\\nDatabase\",\n",
       " 133150: 'Third-party Multitransfer for the Efficient Distribution and Deployment of High Volume Data in the Grid.\\nYear: 2003\\n#Citations: 0\\n\\n\\nSoftware deployment\\nTelecommunications\\nComputer science\\nThird party\\nGrid',\n",
       " 137649: 'Software Engineering for Ambient Intelligence Systems.\\nYear: 2006\\n#Citations: 0\\n\\n\\nSoftware engineering\\nComputer science\\nAmbient intelligence',\n",
       " 146973: 'Circuit-Based Evaluation of the Arithmetic Transform of Boolean Functions.\\nYear: 2002\\n#Citations: 4\\n\\n\\nBoolean circuit\\nParity function\\nArithmetic\\nProduct term\\nBoolean algebra\\nBoolean expression\\nAnd-inverter graph\\nCircuit minimization for Boolean functions\\nMathematics\\nTwo-element Boolean algebra',\n",
       " 152807: 'INTERNET, WIRELESS AND LEGACY INTEGRATION - Architectural Framework for Testing\\nYear: 2004\\n#Citations: 0\\nConference\\n\\nWireless\\nComputer science\\nComputer network\\nArchitecture framework\\nThe Internet',\n",
       " 153917: 'Robustness of prosodic features to voice imitation\\nYear: 2008\\n#Citations: 6\\nConference\\nInternational Speech Communication Association (ISCA)\\nComunicacio presentada a 9th Annual Conference of the International Speech Communication Association celebrada a Brisbane (Australia) del  22 al 26 de setembre de 2008.\\nSpeech communication\\nComputer science\\nRobustness (computer science)\\nSpeech recognition\\nSpeaker recognition\\nImitation\\nSpeaker diarisation\\nArtificial intelligence\\nNatural language processing',\n",
       " 155019: 'PIQASso: PIsa Question Answering System\\nYear: 2001\\n#Citations: 46\\nConference\\nNIST\\nPiQASso is a Question Answering system based on a combination of modern IR techniques and a series of semantic filters for selecting paragraphs containing a justifiable answer. Semantic filtering is based on several NLP tools, including a dependency-based parser, a POS tagger, a NE tagger and a lexical database. Semantic analysis of questions is performed in order to extract key word used in retrieval queries and to detect the expected answer type. Semantic analysis of retrieved paragraphs includes checking the presence of entities of the expected answer type and extracting logical relations between words. A paragraph is considered to justify an answer if similar relations are present in the question. When no answer passes the filters, the process is repeated applying further levels of query expansions in order to increase recall. We discuss results and limitations of the current implementation.\\nLogical relations\\nData mining\\nComputer science\\nLexical database\\nAutomation\\nParagraph\\nArtificial intelligence\\nNatural language processing\\nQuestion answering\\nInformation retrieval\\nParsing\\nSemantic filtering\\nRecall',\n",
       " 155358: 'A new system for text-to-speech conversion, and its application to Swedish.\\nYear: 1994\\n#Citations: 3\\nConference\\n\\nSpeech synthesis\\nComputer science\\nSpeech recognition\\nNatural language processing\\nArtificial intelligence',\n",
       " 155814: 'A Distributed Dynamic Mobility Architecture with Integral Cross-Layered and Context-Aware Interface for Reliable Provision of High Bitrate mHealth Services\\nYear: 2012\\n#Citations: 11\\nConference\\nSpringer, Berlin, Heidelberg\\nMobile health (mHealth) has been receiving more and more attention recently as an emerging paradigm that brings together the evolution of advanced mobile and wireless communication technologies with the vision of “connected health” aiming to deliver the right care in the right place at the right time. However, there are several cardinal problems hampering the successful and widespread deployment of mHealth services from the mobile networking perspective. On one hand, issues of continuous wireless connectivity and mobility management must be solved in future heterogeneous mobile Internet architectures with ever growing traffic demands. On the other hand, Quality of Service (QoS) and Quality of Experience (QoE) must be guaranteed in a reliable, robust and diagnostically acceptable way. In this paper we propose a context- and content-aware, jointly optimized, distributed dynamic mobility management architecture to cope with the future traffic explosion and meet the medical QoS/QoE requirements in varying environments.\\nWireless\\nConnected health\\nMobility management\\nComputer science\\nComputer network\\nQuality of service\\nContext awareness\\nmHealth\\neHealth\\nQuality of experience',\n",
       " 159256: 'Phoneme recognition by combining Bayesian linear discriminations of selected pairs of classes.\\nYear: 1990\\n#Citations: 5\\nConference\\n\\nPattern recognition\\nComputer science\\nSpeech recognition\\nArtificial intelligence\\nPhoneme recognition\\nBayesian probability',\n",
       " 161312: 'Using pattern-action rules for the generation of GPSG structures from MT-oriented semantics\\nYear: 1991\\n#Citations: 0\\nConference\\nMorgan Kaufmann Publishers Inc.\\nHead-driven phrase structure grammar\\nID/LP grammar\\nComputer science\\nGeneralized phrase structure grammar\\nSynchronous context-free grammar\\nPhrase structure rules\\nNatural language processing\\nArtificial intelligence\\nGenerative grammar\\nSemantics',\n",
       " 161955: 'Multi-Layer Repertory Grid Classification for Increasing Software Reusability.\\nYear: 1993\\n#Citations: 2\\nConference\\n\\nRepertory grid\\nMulti layer\\nSystems engineering\\nComputer science\\nSoftware\\nReusability',\n",
       " 162256: 'Von Mises-Fisher Clustering Models\\nYear: 2014\\n#Citations: 37\\nConference\\nJMLR.org\\nThis paper proposes a suite of models for clustering high-dimensional data on a unit sphere based on von Mises-Fisher (vMF) distribution and for discovering more intuitive clusters than existing approaches. The proposed models include a) A Bayesian formulation of vMF mixture that enables information sharing among clusters, b) a Hierarchical vMF mixture that provides multiscale shrinkage and tree structured view of the data and c) a Temporal vMF mixture that captures evolution of clusters in temporal data. For posterior inference, we develop fast variational methods as well as collapsed Gibbs sampling techniques for all three models. Our experiments on six datasets provide strong empirical support in favour of vMF based clustering models over other popular tools such as K-means, Multinomial Mixtures and Latent Dirichlet Allocation\\nCluster (physics)\\nData mining\\nLatent Dirichlet allocation\\nComputer science\\nMultinomial distribution\\nTemporal database\\nArtificial intelligence\\nCluster analysis\\nGibbs sampling\\nPattern recognition\\nInference\\nMachine learning\\nUnit sphere',\n",
       " 163357: 'Language development after extreme childhood deprivation: a case study.\\nYear: 1998\\n#Citations: 0\\nConference\\n\\nDevelopmental linguistics\\nSecond-language attrition\\nComputer science\\nCognitive psychology\\nSpeech recognition\\nLanguage development',\n",
       " 164367: 'Development of a Training System for Lathe Operation Using a Simulator\\nYear: 2013\\n#Citations: 1\\nConference\\nSpringer, Berlin, Heidelberg\\nRecently, the manufacturing industry in especially Japan has found it difficult to transfer skills from trained workers to inexperienced workers because the former ages and then retires. This is a particular problem for lathe process, as this operation requires explicit and tacit knowledge, and defining the skills clearly in a manual is difficult. This study aimed to develop a training system for lathe operation by using a simulator; this includes formulas that help define the relationship between the speed of tool feed and cutting sound/shape of chips that were proposed in the preceding study. The present study verified the effectiveness of the proposed training system.\\nManufacturing\\nTraining system\\nComputer science\\nSimulation\\nTacit knowledge',\n",
       " 164549: 'Search lessons learned from crossword puzzles\\nYear: 1990\\n#Citations: 66\\nConference\\nAAAI Press\\nThe construction of a program that generates crossword puzzles is discussed. As in a recent paper by Dechter and Meiri, we make an experimental comparison of various search techniques. The conclusions to which we come differ from theirs in some areas - although we agree that directional arc consistency is better than path-consistency or other forms of lookahead, and that backjumping is to be preferred to backtracking, we disagree in that we believe dynamic ordering of the constraints to be necessary in the solution of more difficult problems.\\nLocal consistency\\nComputer science\\nArtificial intelligence\\nBacktracking\\nBackjumping\\nMachine learning',\n",
       " 165983: 'On the structure of recognizable languages of dependence graphs\\nYear: 1993\\n#Citations: 1\\nJournal\\nEDP Sciences\\nDans le cadre de la theorie des traces, un graphe de dependance represente le comportement du0027un systeme distribue (par exemple un reseau de Petri) par analogie avec la relation mot-automate dans le cas sequentiel. Un langage reconnaissable de graphes de dependances represente ainsi lu0027ensemble de tous les comportements du0027un systeme distribue satisfaisant des conditions de regularite. Dans cet article nous caracterisons les languages de graphes obtenus a partir des precedents par suppression des etiquettes sur les sommets\\nGraph\\nCombinatorics\\nGrammar\\nHomomorphism\\nMathematics',\n",
       " 167261: 'All brutes are Subhuman: Aristotle and Ockham on private negation\\nYear: 2003\\n#Citations: 4\\nJournal\\nSpringer\\nThe mediaeval logic of Aristotelian privation, represented by Ockhamu0027s expositionof All A is non-P as All S is of a type T that is naturally P and no S is P, iscritically evaluated as an account of privative negation. It is argued that there aretwo senses of privative negation: (1) an intensifier (as in subhuman), the dualof Neoplatonic hypernegation (superhuman), which is studied in linguistics asan operator on scalar adjectives, and (2) a (often lexicalized) Boolean complementrelative to the extension of a privative negation in sense (1) (e.g., Brute). Thissecond sense, which is the privative negation discussed in modern linguistics, isshown to be Aristotleu0027s. It is argued that Ockhamu0027s exposition fails to capture muchof the logic of Aristotelian privation due to limitations in the expressive power of thesyllogistic.\\nSyllogism\\nPrivative\\nNegation\\nIntensifier\\nPhilosophy\\nEpistemology\\nNeoplatonism\\nLinguistics\\nExpressive power',\n",
       " 170076: 'Farthest Neighbor Voronoi Diagram in the Presence of Rectangular Obstacles.\\nYear: 2005\\n#Citations: 0\\nConference\\n\\nWe propose an implicit representation for the farthest Voronoi diagram of a set P of n points in the plane located outside a set R of m disjoint axes-parallel rectangular obstacles. The distances are measured according to the L1 shortest path (geodesic) metric. In particular, we design a data structure of size O(N) in O(N log N) time that supports O(N logN)time farthest point queries (where N = m + n). We avoid computing the more complicated farthest neighbor Voronoi diagram, whose combinatorial complexity is Θ(mn). This allows one to compute the diameter (and all farthest pairs) of P in O(N log N) time. This improves the previous O(mn logN) bound [1].\\nPower diagram\\nDiscrete mathematics\\nCombinatorics\\nDisjoint sets\\nCentroidal Voronoi tessellation\\nShortest path problem\\nVoronoi diagram\\nWeighted Voronoi diagram\\nTime complexity\\nMathematics\\nGeodesic',\n",
       " 171057: 'An Adaptive Memory Management Protocol for Time Warp Simulation.\\nYear: 1994\\n#Citations: 3\\nConference\\n\\nInterleaved memory\\nComputer science\\nParallel computing\\nAdaptive memory\\nReal-time computing',\n",
       " 176264: 'Receive antenna selection for uplink multiuser MIMO systems over correlated rayleigh fading channels\\nYear: 2011\\n#Citations: 5\\nConference\\nIEEE\\nChannel correlation has the effect to reduce the sum rate and user capacity of multiuser multi-input multi-output (MU-MIMO) systems considerably. In this paper, receive antenna selection is proposed for uplink MU-MIMO system to maximize the sum rate and to maintain high user capacity over correlated Rayleigh fading channel. Two antenna selection criteria are presented to tradeoff the computational complexity and performance. Capacity based selection criterion (CBSC) provides optimal performance at the cost of high complexity compared with the suboptimal norm based selection criterion (NBSC). Simulation results demonstrate and validate the effectiveness of proposed method compared with conventional MU-MIMO systems.\\nRayleigh fading\\nComputer science\\nControl theory\\nFading\\nSignal-to-noise ratio\\nCommunication channel\\nMIMO\\nMultiplexing\\nSpatial multiplexing\\nTelecommunications link',\n",
       " 177064: 'Harmonic filtering for joint estimation of pitch and voiced source with single-microphone input.\\nYear: 2005\\n#Citations: 2\\nConference\\n\\nComputer science\\nHarmonic filtering\\nSpeech recognition\\nMicrophone',\n",
       " 181847: 'Optional finer granularity in an open learner model\\nYear: 2011\\n#Citations: 0\\nConference\\nSpringer, Berlin, Heidelberg\\nOpen learner models (OLMs) available independently from specific tutoring or guidance, such as an intelligent tutoring system may provide, can encourage learners to take greater responsibility for learning., Our results suggest that finer grained OLM information, in this context, can support learners in identifying strengths/weaknesses, planning and focussing learning, when different OLM granularities exist. Learners drew regular comparison between OLM and domain information, showing the flexibility of interaction to be important.\\nIntelligent tutoring system\\nComputer science\\nGranularity\\nMultimedia',\n",
       " 182605: 'Engaging learning groups using Social Interaction Strategies\\nYear: 2010\\n#Citations: 2\\nConference\\nAssociation for Computational Linguistics\\nConversational Agents have been shown to be effective tutors in a wide range of educational domains. However, these agents are often ignored and abused in collaborative learning scenarios involving multiple students. In our work presented here, we design and evaluate interaction strategies motivated from prior research in small group communication. We will discuss how such strategies can be implemented in agents. As a first step towards evaluating agents that can interact socially, we report results showing that human tutors employing these strategies are able to cover more concepts with the students besides being rated as better integrated, likeable and friendlier.\\nSocial relation\\nCollaborative learning\\nComputer science\\nCommunication in small groups\\nKnowledge management',\n",
       " 184619: 'Input sets of strongly connected automata.\\nYear: 1979\\n#Citations: 2\\nConference\\n\\nDiscrete mathematics\\nComputer science\\nAutomaton\\nStrongly connected component',\n",
       " 188435: 'Bridging over problems of learning in finding strongly connected components\\nYear: 2005\\n#Citations: 0\\nConference\\nIADIS (International Association for Development of the Information Society)\\nUnderstanding the processes that takes place inside the human mind-while it is thinking and learning- has remained an elusive exercise mostly because of lack of powerful research tools and techniques. Now because of recent advances in various branches of science dealing with mind and brain, it has become possible to better understand the processes of thinking and learning. For example research from cognitive psychology has considerably increased our understanding of the principles of knowledge organization that govern peopleu0027s abilities to learn, understand and create new knowledge. It is perhaps the right time to apply these developments in the study of learning to help people to think and read critically, to express themselves clearly and persuasively, and to solve complex problems. In this paper we would be applying tools and techniques of science of learning to determine why an algorithm to find Strongly Connected Components (SCC) in a directed graph (in the field of graph algorithms) is particularly hard to understand. We shall try to find why one finds difficulty in learning and fails to find a solution to this problem even if one has all the prerequisite knowledge as well as the motivation to do it. We shall in fact be finding possible missing links in the knowledge map of a learner without which it is almost impossible to find meaning behind the algorithm. We shall substantiate our claims by analyzing student performances in an examination, and also by conducting a number of structured interviews.\\nGraph algorithms\\nStructured interview\\nCognitive science\\nComputer science\\nBridging (networking)\\nDirected graph\\nStrongly connected component\\nKnowledge organization\\nComplex problems\\nDistributed computing',\n",
       " 189951: 'An Extended Web Services Framework.\\nYear: 2002\\n#Citations: 2\\nConference\\n\\nWeb API\\nWorld Wide Web\\nWS-Addressing\\nComputer science\\nWeb standards\\nData Web\\nSemantic Web\\nWeb modeling\\nWeb service\\nWS-Policy',\n",
       " 192821: 'A Scientometrics Study of Rough Sets in Three Decades\\nYear: 2013\\n#Citations: 9\\nConference\\nSpringer, Berlin, Heidelberg\\nRough set theory has been attracting researchers and practitioners over three decades. The theory and its applications experienced unprecedented prosperity especially in the recent ten years. It is essential to explore and review the progress made in the field of rough sets. Mainly based on Web of Science database, we analyze the prolific authors, impact authors, impact groups, and the most impact papers in the past three decades. In addition, we also examine rough set development in the recent five years. One of the goals of this article is to use scientometrics approaches to study three decade research in rough sets. We review the historic growth of rough sets and elaborate on recent development status in this field.\\nIncomplete information system\\nProsperity\\nComputer science\\nRough set\\nGranular computing\\nScientometrics\\nManagement science',\n",
       " 193006: 'Noise Robust Feature Extraction for ASR using the Aurora 2 Database\\nYear: 2001\\n#Citations: 23\\nConference\\n\\nFour front-end processing techniques developed for noise robust speech recognition are tested with the Aurora 2 database. These techniques include three previously published algorithms: variable frame rate analysis [Zhu and Alwan, 2000], peak isolation [Strope and Alwan, 1997], and harmonic demodulation [Zhu and Alwan, 2000], and a new technique for peak-to-valley ratio locking. Our previous work has focused on isolated digit recognition. In this paper, these algorithms are modified for recognition of connected digits. Recognition results with the Aurora 2 database show that a combination of these four techniques results in 40% error rate reduction when compared to the baseline MFCC front-end for the clean training condition, with no significant increase in computational complexity.\\nDemodulation\\nMel-frequency cepstrum\\nComputer science\\nArtificial intelligence\\nDigit recognition\\nPattern recognition\\nWord error rate\\nHarmonic\\nFeature extraction\\nSpeech recognition\\nVariable frame rate\\nDatabase\\nComputational complexity theory',\n",
       " 193554: 'Fully utilize feedbacks: language model based relevance feedback in information retrieval\\nYear: 2011\\n#Citations: 1\\nConference\\nSpringer, Berlin, Heidelberg\\nRelevance feedback algorithm is proposed to be an effective way to improve the precision of information retrieval. However, most researches about relevance feedback are based on vector space model, which canu0027t be used in other more complicated and powerful models, such as language model and logic model. Meanwhile, other researches are conceptually restricted to the view of a query as a set of terms, and so cannot be naturally applied to more general case when the query is considered as a sequence of terms and the frequency information of a query tern is considered. In this paper, we mainly focuses on relevant feedback Algorithm based on language model. We use a mixture model to describe the process of generating document and use EM to solve modelu0027s parameters. Our research also employs semi-supervised learning to calculate collection model and proposes an effective way to obtain feedback from irrelevant documents to improve our algorithm.\\nData mining\\nSemi-supervised learning\\nRelevance feedback\\nComputer science\\nRanking (information retrieval)\\nArtificial intelligence\\nVector space model\\nLanguage model\\nInformation retrieval\\nComputational linguistics\\nSupervised learning\\nMixture model\\nMachine learning',\n",
       " 193936: 'An occam Library for Genetic Programming on Transputer Networks.\\nYear: 1996\\n#Citations: 1\\nConference\\n\\nProgramming language\\nComputer science\\nTransputer\\nParallel computing\\noccam\\nGenetic programming',\n",
       " 198536: '2008 International Conference on Parallel Processing September 8-12, 2008 Portland, Oregon Exploring Parallel I/O Concurrency with Speculative Prefetching.\\nYear: 2008\\n#Citations: 1\\nConference\\n\\nComputer science\\nConcurrency\\nParallel processing\\nParallel computing\\nParallel I/O\\nDistributed computing',\n",
       " 205867: 'On-line Signature Biometrics using Support Vector Machine.\\nYear: 2009\\n#Citations: 3\\nConference\\n\\nStructured support vector machine\\nComputer vision\\nComputer science\\nSupport vector machine\\nArtificial intelligence\\nBiometrics',\n",
       " 208772: 'Editorial - Objects, Databases, and the WWW.\\nYear: 1998\\n#Citations: 0\\nJournal\\n\\nWorld Wide Web\\nInformation retrieval\\nComputer science\\nDatabase',\n",
       " 211926: 'Synthesizing Information Systems: the APIS Project.\\nYear: 2007\\n#Citations: 5\\nConference\\n\\nThis article presents the main features of the APIS project that addresses the rapid development of information systems from formal specifications. Information systems are specified using EB, a trace-based formal language. The sequences of input events accepted by the system are described with a process algebra; they represent the valid traces of the information system. Entity types, associations and attributes are described using a class diagram and computed by means of recursive functions defined on the valid traces of the system. In the APIS framework, three tools have been developed. A first tool, called DCI-WEB, allows the generation of Web interfaces from GUI specifications. To query and/or to update the system, an end-user can trigger an event through the Web interface. This event is then analyzed by EBPAI, an interpreter for EB process expressions. Finally, the tool EBTG generates, for each EB action, a Java program that executes a relational database transaction. The synthesized transactions implement the specification of the information system’s data structure and are used by the interpreter to update or query the database. The article also brings out the main future developments of the project.\\nSpecification language\\nInformation system\\nProgramming language\\nRelational database\\nComputer science\\nFormal specification\\nInterface description language\\nFormal methods\\nData model\\nFormal verification',\n",
       " 212088: 'High dimensional search using polyhedral query\\nYear: 2014\\n#Citations: 0\\nConference\\nSpringer-Verlag\\nIt is well known that, as the dimensionality of a metric space increases, metric search techniques become less effective and the cost of indexing mechanisms becomes greater than the saving they give. This is due to the so-called curse of dimensionality.\\nQuery optimization\\nComputer science\\nBall tree\\nSearch engine indexing\\nHypersphere\\nCurse of dimensionality\\nArtificial intelligence\\nMetric space\\nNearest neighbor search\\nMachine learning',\n",
       " 214894: 'Boolean Analysis of Classifier Sets\\nYear: 1989\\n#Citations: 7\\nConference\\nMorgan Kaufmann Publishers Inc.\\nPattern recognition\\nComputer science\\nBinary decision diagram\\nArtificial intelligence\\nStandard Boolean model\\nMargin classifier\\nClassifier (linguistics)\\nBoolean analysis\\nQuadratic classifier',\n",
       " 215100: \"Multiple-Valued Logic - Guest Editor's Introduction.\\nYear: 1988\\n#Citations: 0\\nJournal\\n\\nSoftware engineering\\nComputer science\",\n",
       " 215364: 'Improving the forward chaining algorithm for conceptual graphs rules\\nYear: 2004\\n#Citations: 30\\nConference\\nNo commercial editor.\\nSimple Conceptual Graphs (SGs) are used to represent entities and relations between these entities: they can be translated into positive, conjunctive, existential first-order logics, without function symbols. Sound and complete reasonings w.r.t. associated logic formulas are obtained through a kind of graph homomorphism called  Graphs :[44],\"Rules (or CG rules) are a standard extension to SGs, keeping sound and complete reasonings w.r.t. associated logic formulas (they have the same form as tuple generating dependencies in database): these graphs represent knowledge of the form \"IF ...  :[85],\"present here an optimization of the natural forward chaining algorithm for CG rules. Generating a graph of rules dependencies makes the following sequences of rule applications far more efficient, and the structure of this graph can be used to obtain new decidability results.\\nGraph operations\\nIndifference graph\\nModular decomposition\\nComputer science\\nGraph homomorphism\\nConceptual graph\\nAlgorithm\\nTheoretical computer science\\nGraph product\\nCograph\\nPathwidth',\n",
       " 215653: 'Sketch-It-Up! Demo\\nYear: 2009\\n#Citations: 5\\nConference\\nSpringer, Berlin, Heidelberg\\nEvery creative project needs to have an ideation process. A good ideation process relies on a simple yet effective way of putting ideas on the table and sorting through them, also discarding them easily if necessary. However, for this ideation to be successful it has to be a process in which cheap and simple ways of exploring ideas are used along with tools that are readily accessible to everyone in the field to use.\\nIdeation\\nSimulation\\nComputer science\\nSorting\\nHuman–computer interaction\\nSketch',\n",
       " 217368: 'Algebraic Formalism over Maps.\\nYear: 2005\\n#Citations: 4\\nConference\\n\\nThis paper describes features of a language approach for map algebra based on the use of algebraic expressions. To be consistent with formal approaches such as geoalgebra and image algebra, the proposed algebraic expressions are suitable for the usual modeling of layers and to represent neighborhoods and zones. A tight compromise between language and implementation issues based on the theory of automata is proposed as the needed support to define or extend coherently operators and grammar rules. This results in an efficient way of implementing map algebra for raster domains that can simplify its coupling to environmental and dynamic models without going too far from its well-known paradigm.\\nData mining\\nDimension of an algebraic variety\\nFunction field of an algebraic variety\\nAlgebraic number\\nAlgebra\\nComputer science\\nDifferential algebraic geometry\\nOperator (computer programming)\\nMap algebra\\nAlgebraic expression\\nReal algebraic geometry\\nCalculus',\n",
       " 220776: 'Approximation in Concept Description Languages.\\nYear: 1992\\n#Citations: 18\\nConference\\n\\nComputer science\\nTheoretical computer science',\n",
       " 221287: 'Solution Proposals for Japan-Oriented Offshore Software Development in China\\nYear: 2009\\n#Citations: 2\\nConference\\nSpringer, Berlin, Heidelberg\\nSurveys on the Japan-oriented vendors in China were conducted twice to find out the existent problems in the Japan-oriented offshore software development. From these survey results, four main problems were found out, which were the frequent requirement changes from the product owner, the misunderstanding of the requirement specification in the vendor side, the heavy overhead of the project management and the low-efficiency communication between the product owner and the vendor. Several solutions are proposed to solve these four problems, which mainly consist of the improvement of the offshore software development process and the development of the offshore development supporting tools. The proposed offshore development process is based on the application of the prototype development, the iteration development and the customer test driven development processes. The proposed offshore development supporting tools include the project management assistant tool and the communication assistant tool.\\nPersonal software process\\nSystems engineering\\nPackage development process\\nLean software development\\nSoftware project management\\nSoftware development process\\nSystems development life cycle\\nEngineering\\nSoftware development\\nGoal-Driven Software Development Process',\n",
       " 222770: 'Platform Substitution and Cannibalization: The Case of Portable Navigation Devices\\nYear: 2012\\n#Citations: 4\\nConference\\nSpringer, Berlin, Heidelberg\\nPlatform competition may engender a substitution process whereby customers and complementors drift from one platform to another. For example, as the aftermath of a competitive race between a general-purpose platform and a single-purpose rival. A case in point is how sales of personal navigation devices (PND) have allegedly been sapped by GPS-enabled smartphones with comparable turn-by-turn navigation functionalities. Using a structural-break unit-root econometric model, the impact of smartphones on the quarterly volume sales of two leading PND manufacturers can be statistically assessed. Such an econometric analysis reveals a significant shift in the level of the underlying stochastic processes and dates the structural change at the third quarter of 2008, when the iOS and Android ecosystems were launched.\\nTelecommunications\\nAndroid (operating system)\\nStructural break\\nCannibalization\\nAdvertising\\nEconometric model\\nEngineering\\nEconometric analysis\\nMarketing',\n",
       " 223055: 'Pedagogical Pattern: Self Test.\\nYear: 2000\\n#Citations: 0\\nConference\\n\\nComputer science\\nKnowledge management\\nMathematics education\\nSelf test',\n",
       " 224561: 'Towards an Organizational MAS Methodology\\nYear: 2005\\n#Citations: 1\\nConference\\nIOS Press\\nOrganizations are a powerful way to coordinate complex behavior in human society. Thus, human organizations can serve as a basis for better understanding and designing open multi-agent systems. Organizational models have been recently used in agent theory for modelling coordination in open systems and to ensure social order in multi-agent system applications. This work discusses several organizational features of organization-oriented multiagent system methodologies and analyzes whether they take into account human organizational designs. Moreover, several guidelines that any organization-oriented MAS methodology must take into account are proposed.\\nSocial order\\nComputer science\\nKnowledge management\\nMulti-agent system\\nOrganizational learning\\nOpen system (systems theory)\\nOrganizational studies',\n",
       " 226082: 'A 2.7 Gcps and 7-Multiplexing CDMA Serial Communication Chip for Real-Time Robot Control with Multiprocessors\\nYear: 2005\\n#Citations: 0\\nJournal\\nFuji Technology Press Ltd.\\nIntelligent robot control using multiprocessors, sensors, and actuators requires real-time flexible networks for communicating various types of real-time data, e.g., sensing data and interrupt signals. Furthermore, serial data transfer is required for implementing the network using a few wiring lines. To meet these requirements, we propose a CDMA serial communication interface utilizing novel two-step synchronization. The transmitter and receiver chip fabricated with 0.25µm digital CMOS technology achieved 2.7Gcps (chips per second) and 7-multiplex communication. The experimental interface board was developed for demonstrating flexible transfer of multiimage data by installing CDMA chips in addition to an FPGA.\\nInterrupt\\nSerial communication\\nRobot control\\nSynchronization\\nComputer science\\nSynchronous serial communication\\nField-programmable gate array\\nChip\\nMultiplexing\\nEmbedded system',\n",
       " 228008: 'Illuminant Estimation: Beyond the Bases.\\nYear: 2000\\n#Citations: 13\\nConference\\n\\nWe describe spectral estimation principles that are useful for color balancing, color conversion, and sensor design. The principles extend conventional estimation methods, which rely on linear models of the input data, by characterizing the distribution or structure of the linear model coefficients. When the linear model coefficients of the input data are highly structured, it is possible to improve the quality of a simple linear model by estimating coefficients that are invisible to the sensors. We illustrate these principles using the synthetic example of estimating blackbody radiator spectral power distributions. Then, we apply the principles to typical daylight illuminants that we measured over the course of twenty days in Stanford, California. We show that the distribution of the daylight linear model coefficients that approximate the daylight spectral power distributions are highly structured. We further show that from knowledge of the coefficient structure, nonlinear algorithms using N sensors estimate the data as well as linear algorithms using N+1 sensors.\\nComputer vision\\nMaximum entropy spectral estimation\\nSpectral density estimation\\nNonlinear algorithms\\nPattern recognition\\nLinear model\\nComputer science\\nDaylight\\nAlgorithm\\nArtificial intelligence\\nStandard illuminant\\nBlack-body radiation',\n",
       " 229287: 'OWL Ontology Development for Destination Marketing\\nYear: 2011\\n#Citations: 0\\nConference\\nSpringer, Berlin, Heidelberg\\nInternet, as a marketing medium in the tourism industry, is a very valuable destination marketing tool. Different tourism authorities and organizations serve as marketing and service providers. They benefit from the use of Internet within the concept of marketing efforts. A new technology, Semantic Web, brought incremental changes by bringing machine-readable descriptions to current web interfaces of these organizations. This paper provides necessary framework for the applicability of Semantic Web technology on Destination Marketing. It creates a methodology on how web pages are created and analyzed with the value-added tourism marketing purposes. Semantic Web technology achieves such interoperability by referring to ontology models. The ontology presented here determines the value of this integration in destination marketing organizations.\\nOntology\\nWorld Wide Web\\nWeb page\\nComputer science\\nSemantic Web\\nKnowledge management\\nTourism\\nService provider\\nOWL-S\\nMarketing\\nWeb Ontology Language\\nThe Internet',\n",
       " 230160: 'Integrating provenance into an operational data product information system\\nYear: 2012\\n#Citations: 0\\nConference\\nSpringer Berlin Heidelberg\\nKnowledge of how a science data product has been generated is a critical component to determining its fitness-for-use for a given analysis. One objective of science information systems is to allow users to search for data products based on a wide range of criteria; spatial and temporal extent, observed parameter, research domain, and organizational project are common search criteria. Currently, science information systems are geared towards helping users find data, but not in helping users determine how the products were generated. An information system that exposes the provenance of available data products, that is what observations, assumptions, and science processing were involved in the generation of the data products, would contribute significant benefit to user fitness-for-use  :[116],\"this work we discuss semantics-driven provenance extensions to the Virtual Solar Terrestrial Observatory (VSTO) information system. The VSTO semantic web portal uses an ontology to provide a unified search and product retrieval interface to data in the fields of solar, solar-terrestrial, and space physics. We have developed an extension to the VSTO ontology that allows it to express item-level data product records. We will show how the Open Provenance Model (OPM) and the Proof Markup Language (PML) can be used to express the provenance of data product records. Additionally, we will discuss ways in which domain semantics can aid in the formulation - and answering - of provenance queries. Our extension to the VSTO ontology has also been integrated with a solar-terrestrial profile of the Observation and Measurement (OM we utilize :[116],\"this integration to connect observation events to the data product record  :[259],\"additions to the VSTO ontology will allow us to extend the VSTO web portal user interface with search criteria based on provenance and observation characteristics. More critically, provenance information will allow the VSTO portal to display important knowledge about selected data records; what science processes and assumptions were applied to generate the record, what observations the record derives from, and the results of quality processing that had been applied to the record and any records it derives from. We conclude by showing our interface for showing record provenance information and discuss how it aids users in determining fitness-for-use of the data.\\nInformation system\\nOntology\\nData mining\\nInformation retrieval\\nComputer science\\nSemantic Web\\nProvenance\\nUser interface\\nDatabase\\nSemantics\\nData records\\nMarkup language',\n",
       " 233935: 'Agricultural Knowledge Management Systems in Practice: The Ability to Support Wereda Knowledge Centers in Ethiopia\\nYear: 2013\\n#Citations: 0\\nConference\\n\\nAgriculture is the dominant sector in the Ethiopian economy but it is characterized by low productivity. Ethiopia is interested in creating access to agricultural knowledge through an agricultural knowledge management system (AKMS). Such a system has been developed using a web-based portal named Ethiopian Agriculture Portal (EAP). It is facilitated through Woreda Knowledge Centers (WKCs) which are in 10 Pilot Learning Woredas (PLW). Providing knowledge in the appropriate format, identification of affordable technological infrastructure, and integrating indigenous agricultural knowledge into the knowledge system is vital to empowering development agents (extension workers) in Ethiopia. This study addresses two research questions: 1)To what extent does the centralized AKMS support WKCs access and utilization of agricultural knowledge? 2) How can the existing AKMS support capturing and sharing of indigenous agricultural knowledge and best practices?\\nTraditional knowledge\\nBest practice\\nIndigenous\\nComputer science\\nKnowledge management\\nAgriculture',\n",
       " 234643: 'Challenges in Fixpoint Computation with Multisets\\nYear: 2004\\n#Citations: 5\\nConference\\nSpringer, Berlin, Heidelberg\\nUncertainty management has been a challenging issue in AI and database research. Logic database programming with its declarative advantage and its top-down and bottom-up query processing techniques has been an attractive formalism for representing and manipulating uncertain information, and numerous frameworks with uncertainty has been proposed. These proposals address fundamental issues of modeling, semantics, query processing and optimization, however, one important issue which remains unaddressed is efficient implementation of such frameworks. In this paper, we illustrate that the standard semi-naive evaluation method does not have a counterpart in general in these frameworks. We then propose a desired semi-naive algorithm, which extends the corresponding standard method, and establish its equivalence with the naive method with uncertainty. We implemented the algorithm and conducted numerous tests. Our experimental results indicate that the proposed technique is practical and supports efficient fixpoint computation with uncertainty. We believe that the method is also useful in a more general context of fixpoint computation with aggregations.\\nData mining\\nComputer science\\nTheoretical computer science\\nEquivalence (measure theory)\\nFixed point\\nFormalism (philosophy)\\nSemantics\\nComputation',\n",
       " 236829: 'Optimizing Network Patching Policy Decisions\\nYear: 2012\\n#Citations: 5\\nConference\\nSpringer, Berlin, Heidelberg\\nPatch management of networks is essential to mitigate the risks from the exploitation of vulnerabilities through malware and other attacks, but by setting too rigorous a patching policy for network devices the IT security team can also create burdens for IT operations or disruptions to the business. Different patch deployment timelines could be adopted with the aim of reducing this operational cost, but care must be taken not to substantially increase the risk of emergency disruption from potential exploits and attacks. In this paper we explore how the IT security policy choices regarding patching timelines can be made in terms of economically-based decisions, in which the aim is to minimize the expected overall costs to the organization from patching-related activity. We introduce a simple cost function that takes into account costs incurred from disruption caused by planned patching and from expected disruption caused by emergency patching. To explore the outcomes under different patching policies we apply a systems modelling approach and Monte Carlo style simulations. The results from the simulations show disruptions caused for a range of patch deployment timelines. These results together with the cost function are then used to identify the optimal patching timelines under different threat environment conditions and taking into account the organization’s risk tolerance.\\nInformation technology operations\\nSoftware deployment\\nComputer science\\nComputer security\\nNetworking hardware\\nTimeline\\nExploit\\nSecurity policy\\nMalware\\nVulnerability',\n",
       " 237528: 'Normalization of place/transition-systems preserves net behaviour\\nYear: 1992\\n#Citations: 2\\nJournal\\nEDP Sciences\\nNous considerons dans cet article des reseaux de Petri etiquetes sans λ. On les appelle normalises si leurs arcs ne sont pas values et si leurs marquages initiaux et finals sont des sous-ensembles de lu0027ensemble des places. Nous prouvons que tout reseau de Petri general peut etre (effectivement) transforme en un reseau de Petri normalise ayant exactement le meme comportement concurrent. Ses comportements sequentiels finis et infinis ainsi que ses suites de pas sont egalement preserves. Ceci permet de toujours considerer des reseaux de Petri sous une forme normalisee quand on travaille sur le comportement des reseaux, sans restreindre la generalite des resultats. Ainsi un bon nombre de recherches futures devrait se trouver facilite\\nCombinatorics\\nPetri net\\nNormalization (statistics)\\nMathematics\\nGraph labelling',\n",
       " 240820: 'Approximation Algorithms for Maximum Cliques in 3D Unit-Disk Graphs.\\nYear: 2005\\n#Citations: 12\\nConference\\n\\nApproximation algorithm\\nDiscrete mathematics\\nIndifference graph\\nCombinatorics\\nComputer science\\nChordal graph\\nClique-sum\\nPathwidth\\nClique problem\\nClique (graph theory)\\nIntersection number (graph theory)',\n",
       " 243668: 'Machine learning for information extraction from XML marked-up text on the semantic web\\nYear: 2001\\n#Citations: 1\\nConference\\nCEUR-WS.org\\nThe last few years have seen an explosion in the amount of text becoming available on the World Wide Web as online communities of users in diverse domains emerge to share documents and other digital resources. In this paper we explore the issue of how to provide a low-level information extraction tool based on hidden Markov models that can identify and classify terminology based on previously marked-up examples. Such a tool should provide the basis for a domain portable information extraction system, that when combined with search technology can help users to access information more effectively within their document collections than todayu0027s information retrieval engines alone. We present results of applying the model in two diverse domains: news and molecular biology and discuss the model and term markup issues that this investigation reveals.\\nData mining\\nWeb intelligence\\nSemantic Web Stack\\nComputer science\\nSemantic Web\\nRelationship extraction\\nMarkup language\\nWorld Wide Web\\nInformation retrieval\\nTerminology\\nXML\\nInformation extraction\\nDatabase',\n",
       " 245881: 'Bounds on 2-Query Locally Testable Codes with Affine Tests.\\nYear: 2009\\n#Citations: 0\\nJournal\\n\\nAffine transformation\\nDiscrete mathematics\\nMathematics',\n",
       " 247967: 'Authentication Services in Mobile Networks\\nYear: 2002\\n#Citations: 2\\nJournal\\nKluwer Academic Publishers\\nAuthentication, Authorization, and Accounting (AAA) technologies are widely considered to be the key to the growth of e-commerce. Mobile network operators may be one of the first to offer such services thanks to a number of advantages. They will face some issues, however, if they attempt to launch AAA services for e-commerce. This paper introduces some of the issues including ID mappings, certificate validation, security awareness, and environments. Some of the solutions for these issues are also discussed.\\nCertificate policy\\nAuthentication\\nX.509\\nComputer science\\nSelf-signed certificate\\nComputer security\\nPublic key certificate\\nComputer network\\nCertificate authority\\nImplicit certificate\\nAuthorization certificate',\n",
       " 249145: 'Computational Metabolism: Towards Biological Geometries for Computing.\\nYear: 1987\\n#Citations: 15\\nJournal\\n\\nComputer science\\nArtificial intelligence\\nMachine learning',\n",
       " 252754: 'The domatic numbers of factors of graphs.\\nYear: 2000\\n#Citations: 1\\nJournal\\n\\nGraph\\nDiscrete mathematics\\nCombinatorics\\nMathematics',\n",
       " 255264: 'Experiments with linear feature extraction in speech recognition.\\nYear: 1995\\n#Citations: 19\\nConference\\n\\nPattern recognition\\nComputer science\\nFeature extraction\\nSpeech recognition\\nArtificial intelligence',\n",
       " 256357: 'Designing Query Support for Multiple Databases\\nYear: 1995\\n#Citations: 8\\nConference\\nSpringer, Boston, MA\\nEven with intelligent query support data retrieval is not always optimal. This is increasingly true as database systems become more complex and powerful. The Intuitive toolset has been developed for use with multimedia, heterogeneous distributed databases, to support query reformulation before or after submission to the database(s). The toolset is reconfigurable to permit optimisation for novice or expert users and to suit specific domain knowledge. The theoretical background to user search difficulties, possible solutions to these difficulties, mixed initiative dialogue and user adaptive systems is discussed.\\nQuery optimization\\nWeb search query\\nRDF query language\\nQuery language\\nQuery expansion\\nComputer science\\nSargable\\nWeb query classification\\nHuman–computer interaction\\nQuery by Example\\nDatabase',\n",
       " 258746: 'Empirical assessment of business model transformations based on model simulation\\nYear: 2012\\n#Citations: 4\\nConference\\nSpringer, Berlin, Heidelberg\\nBusiness processes are recognized by organizations as one of the most important intangible assets, since they let organizations improve their competitiveness. Business processes are supported by enterprise information systems, which can evolve over time and embed particular business rules that are not present anywhere else. Thus, there are many organizations with inaccurate business processes, which prevent the modernization of enterprise information systems in line with the business processes that they support. Therefore, business process mining techniques are often used to retrieve reliable business processes from the event logs recorded during the execution of enterprise systems. Unfortunately, such event logs are represented with purpose-specific notations such as Mining XML and still donu0027t apply the recent software modernization standard: ISO 19506 (KDM, Knowledge Discovery Metamodel). This paper presents an exogenous model transformation between these two notations. The main advantage is that process mining techniques can be effectively reused within software modernization projects according to the standard notation. This paper is particularly focused on the empirical evaluation of this transformation by simulating different kinds of business process models and several event logs with different sizes and configurations from such models. After analyzing all the model transformation executions, the study demonstrates that the transformation can provide suitable KDM models in a linear time in accordance with the size of the input models.\\nArtifact-centric business process model\\nComputer science\\nArtificial intelligence\\nBusiness process modeling\\nBusiness architecture\\nProcess mining\\nBusiness process management\\nPattern recognition\\nSoftware engineering\\nBusiness process discovery\\nBusiness Process Model and Notation\\nBusiness rule\\nProcess management',\n",
       " 260539: 'Reasoning about Array Segments.\\nYear: 1982\\n#Citations: 2\\nConference\\n\\nComputer science\\nArtificial intelligence\\nMachine learning',\n",
       " 267718: 'A type-theoretical approach for ontologies: The case of roles\\nYear: 2012\\n#Citations: 11\\nJournal\\nIOS Press\\nIn the domain of ontology design as well as in Knowledge Representation, modeling universals is a challenging problem. Most approaches that have addressed this problem rely on Description Logics DLs but many difficulties remain, due to under-constrained representation which reduces the inferences that can be drawn and further causes problems in expressiveness. In mathematical logic and program checking, type theories have proved to be appealing but, so far they have not been applied in the formalization of ontologies. To bridge this gap, we present in this paper a theory for representing ontologies in a dependently-typed framework which relies on strong formal foundations including both a constructive logic and a functional type system. The language of this theory defines in a precise way what ontological primitives such as classes, relations, properties, etc., and thereof roles, are. The first part of the paper details how these primitives are defined and used within the theory. In a second part, we focus on the formalization of the role primitive. A review of significant role properties leads to the specification of a role profile and most of the remaining work details through numerous examples, how the proposed theory is able to fully satisfy this profile. It is demonstrated that dependent types can model several non-trivial aspects of roles including a formal solution for generalization hierarchies, identity criteria for roles and other contributions. A discussion is given on how the theory is able to cope with many of the constraints inherent in a good role representation.\\nIntuitionistic logic\\nOntology (information science)\\nOntology\\nData mining\\nKnowledge representation and reasoning\\nProblem of universals\\nComputer science\\nDescription logic\\nTheoretical computer science\\nArtificial intelligence\\nHierarchy\\nMathematical logic',\n",
       " 268777: 'Two Stage Demosaicing Algorithm for Color Filter Arrays\\nYear: 2009\\n#Citations: 0\\nConference\\nSpringer, Berlin, Heidelberg\\nThis paper proposes an efficient two stage demosaicing method to interpolate color filter array images. The proposed method based on the edge sensing technique improves the interpolation performance by adopting the color difference model for a green channel as well as a red/blue channel. In particular, the green channel interpolation method with a new concept includes the gradient operator, which uses the total amount of slope changes in adjacent color information, and the missing green color estimation, which uses Approximated Directional Line Averages. Comparing with various comparative experiments between the conventional results and the proposed ones, the performances of the proposed method in this paper outperform to existing algorithms in terms of visual performance both in numerical and visual aspects. Our method of demosaicing improves the standard performance by8.927dB on the average in comparison of other methods in MSE(Mean square Error).\\nComputer vision\\nInterpolation\\nCommunication channel\\nMean squared error\\nAlgorithm\\nDemosaicing\\nOperator (computer programming)\\nArtificial intelligence\\nColor gel\\nColor filter array\\nColor difference\\nMathematics',\n",
       " 270053: 'Interactive listening to structured speech content on the internet.\\nYear: 1998\\n#Citations: 2\\nConference\\n\\nWeb Accessibility Initiative\\nWeb development\\nWorld Wide Web\\nComputer science\\nActive listening\\nXHTML\\nWeb 2.0\\nMobile Web\\nHTML\\nMultimedia\\nThe Internet',\n",
       " 272511: 'Evaluations of evidence combination rules in terms of statistical sensitivity and divergence\\nYear: 2014\\n#Citations: 6\\nConference\\nIEEE\\nThe theory of belief functions is one of the most important tools in information fusion and uncertainty reasoning. Dempsteru0027s rule of combination and its related modified versions are used to combine independent pieces of evidence. However, until now there is still no solid evaluation criteria and methods for these combination rules. In this paper, we look on the evidence combination as a procedure of estimation and then we propose a set of criteria to evaluate the sensitivity and divergence of different combination rules by using for reference the mean square error (MSE), the bias and the variance. Numerical examples and simulations are used to illustrate our proposed evaluation criteria. Related analyses are also provided.\\nData mining\\nDivergence\\nComputer science\\nMean squared error\\nArtificial intelligence\\nStatistical sensitivity\\nInformation fusion\\nMachine learning',\n",
       " 273782: 'Engineering education: trends and needs (panel).\\nYear: 1992\\n#Citations: 0\\nConference\\n\\nComputer science\\nEngineering management\\nEngineering education',\n",
       " 274954: 'Ultra-loose algebraic specifications.\\nYear: 1988\\n#Citations: 4\\nJournal\\n\\nDiscrete mathematics\\nDimension of an algebraic variety\\nAlgebraic number\\nAlgebra\\nMathematics',\n",
       " 278968: 'Cut-free Systems for some Modal Logics Containing S4.\\nYear: 1992\\n#Citations: 3\\nJournal\\n\\nT-norm fuzzy logics\\nModal μ-calculus\\nNormal modal logic\\nAccessibility relation\\nAlgebra\\nMultimodal logic\\nAxiom S5\\nMathematics\\nDynamic logic (modal logic)\\nModal',\n",
       " 284492: 'Organizational Sustainability and Value Creation in Collaborative Networks\\nYear: 2014\\n#Citations: 0\\nConference\\nSpringer, Berlin, Heidelberg\\nCollaborative Networks are becoming ever more important as a lunchpad for the achievement of competitive advantages and for the creation of socio-economic benefits. According to the relational view theory, joint efforts can indeed generate relational rents. However, task coordination is not a sufficient means for value creation. Indeed, Collaborative Networks have to create a link between several aspects, such as trust, culture of collaboration, knowledge sharing, managerial processes, incentive systems, ethical code and so on in order to create cooperation and, thus, value. Aim of this work is to analyze how these aspects affect each other and how they affect value creation within collaborative networks. In order to do so, we develop a model, based on UML and e3value, in which the main factors impacting on value creation and value exchanges within CNOs are represented. After the description of the model, we analyze a case study of a CNO.\\nIncentive\\nUnified Modeling Language\\nKnowledge sharing\\nComputer science\\nCompetitive advantage\\nKnowledge management\\nSustainability organizations\\nEthical code\\nRelational view\\nSustainability',\n",
       " 287040: 'A tool for solving differential games with co-evolutionary algorithms\\nYear: 1999\\n#Citations: 1\\nConference\\nMorgan Kaufmann Publishers Inc.\\nGame theory is concerned with optimization problems involving several players with conflicting interests. Differential games are an interesting area inside this field in which the problem is formulated by means of dynamical systems. In spite that the theoretical solution of differential games is well known, faced with large-scale, complex systems, analytical or, even, numerical methods are not usually suitable. Genetic algorithms appear to be useful for solving such problems when dealing with nonlinear, large-scale systems. This paper shows how co-evolutionary algorithms can be applied to solve differential games and presents a computer tool to formulate and solve these problems. The differential equations which define the system under study are written in Vensim, a visual modeling tool. The usefulness of the presented tool is shown by means of two examples.\\nDifferential equation\\nMathematical optimization\\nNonlinear system\\nEvolutionary algorithm\\nComputer science\\nDynamical systems theory\\nGame theory\\nNumerical analysis\\nOptimization problem\\nGenetic algorithm',\n",
       " 288456: 'Real-Time Application Domain Visionaries\\nYear: 2000\\n#Citations: 1\\nConference\\nIEEE Computer Society\\nThe gulf separating the real-time research, product development, and application development communities appears to be the largest in the entire computing field. This gulf has an unfortunate tendency to obscure the research opportunities of most value to the real-time application domains. It is an unsurprising consequence of factors historically intrinsic to each of those communities.Almost all academic, and much industrial, research in the area of real-time computing - and especially distributed real-time computing - suffers from two handicaps. First is the necessity for unusually extensive application domain-specific knowledge and understanding compared with what is required in most other computer science and engineering research. Second is the directly contrary reality that few real-time researchers have the option of obtaining such knowledge and understanding, because they lack access to non-trivial, deployed, real-time application environments - particularly to distributed ones (e.g., in process control or discrete manufacturing plants, defense systems, telecommunication intelligent network architectures) - and to the developers and users of those environments.The real-time application domain practitioners (real-time computer product and application developers and users) contribute to this gulf as well. First, the historical focus on traditional small, static, centralized, sampled-data subsystems has often subjected real-time computers to severe constraints on hardware cost, size, weight, and power. And although software development and maintenance costs per line of source code are generally one or two orders of magnitude greater for real-time software than for non-real-time software, the smallest scale instances of these subsystems actually have negligible costs for software compared with hardware. These two factors tend to discourage many of the application developers and users from believing that they need or can afford technology advances from the software and real-time research communities. Second, hardware parsimony makes it necessary, and application simplicity makes it possible, for the application programmers to do the majority of the systemu0027s resource management - most of it au0027 priori, and as little as possible at run time.The increasing importance and deployment of larger scale, more complex, more distributed real-time computer systems makes this gulf an increasingly greater obstacle to their cost-effectiveness and even viability. The purpose of this session is to assist in reducing this gulf by bringing to ISORC2Ku0027s researcher audience some of the most prominent visionaries in some of real-time computingu0027s most important application domains.\\nResource management\\nSoftware deployment\\nComputer science\\nSource code\\nWork in process\\nReal-time computing\\nSoftware\\nApplication domain\\nSoftware development\\nNew product development\\nDistributed computing',\n",
       " 292320: 'Konzepte zum Root-CA Zertifikatswechsel.\\nYear: 2003\\n#Citations: 0\\nJournal\\n\\nDie flachendeckende Einfuhrung von Public-Key-Infrastrukturen (PKI) im Unternehmensbereich, in den offentlichen Behorden sowie uber den Betrieb von Trustcentern fur den breiten Massenmarkt schreitet voran. Dabei entstehen in der Regel hierarchisch strukturierte PKIs, bei denen die Gultigkeitsprufung der Zertifikate von der Gultigkeit des Root CA-Zertifikats abhangt. Sofern dieses Zertifikat auslauft, sich sein Inhalt andert oder es gesperrt werden muss, besteht das Problem, ein neues RootZertifikat auszustellen und authentisch an die Teilnehmer der PKI zu verteilen, ohne dass dabei der Wirkbetrieb beeintrachtigt wird. Viele Losungen sparen die Probleme, die sich aus dem Wechsel des Root CAZertifikats ergeben, aus, verbunden mit der Hoffnung, dass das Problem technisch gelost sein werde, bevor es „in einigen Jahren“ auftritt. Damit gibt es oft keinen wirksamen Notfallplan im Fall, dass ein vorzeitiger Zertifikatswechsel notwendig wird.\\nComputer science\\nComputer security\\nHumanities',\n",
       " 294944: 'Implementing Artificial Immune Systems for the Linear Ordering Problem\\nYear: 2013\\n#Citations: 2\\nJournal\\nSpringer, Berlin, Heidelberg\\nLinear Ordering Problem (LOP) is a well know NP-hard combinatorial optimization problem attractive for its complexity, rich library of test data, and variety of real world applications. This study investigates the bio-inspired Artificial Immune Systems (AIS) as a pure metaheuristic soft computing solver of the LOP. The well known LOP library LOLIB was used to compare the results obtained by AIS and other pure soft computing metaheuristics.\\nArtificial immune system\\nCombinatorial optimization problem\\nLinear ordering\\nComputer science\\nTheoretical computer science\\nTest data\\nSolver\\nSoft computing\\nMetaheuristic',\n",
       " 297098: 'The Challenges of Automated Methods for Integrating Systems\\nYear: 2004\\n#Citations: 4\\nConference\\n\\nOntology-based data integration\\nOntology\\nSystems engineering\\nSoftware engineering\\nComputer science\\nSystem integration',\n",
       " 298915: 'Multilevel Policy Based Security in Distributed Database\\nYear: 2011\\n#Citations: 1\\nConference\\nSpringer, Berlin, Heidelberg\\nAddressing security demands under fixed budgets and tight time constraints are becoming extremely challenging, time consuming and resource intensive. Moreover, securing the distributed database in compliance with several security guidelines makes the system more complex. Mission critical systems, military, government and financial institutions have been under tremendous pressure to secure their databases. Such requirements mandate that each system passes a strict security scan before it is deemed suitable to go into operational mode. This paper presents a framework that embeds security capabilities into distributed database by replicating different predefined security policies at different sites using multilevel secure database management system.\\nSecurity convergence\\nSecurity testing\\nSecurity through obscurity\\nComputer science\\nComputer security\\nSecurity service\\nCloud computing security\\nSecurity information and event management\\nSecurity policy\\nComputer security model',\n",
       " 302370: 'An Evolving Agent with EVOLP.\\nYear: 2003\\n#Citations: 2\\nConference\\n\\nLogic programming has often been considered less than adequate for modelling the dynamics of knowledge changing over time. Evolving Logic Programs (EVOLP) has been recently proposed as a simple though quite powerful extension of logic programming, which allows for modelling the dynamics of knowledge bases expressed by programs, and illustrate its usage in modelling agents whose specifications may dynamically change. From the syntactical point of view, evolving programs are just generalized logic programs (i.e. normal LPs plus default negation in rule heads too), extended with (possibly nested) assertions, whether in heads or bodies of rules. From the semantical point of view, a model-theoretic characterization is offered of the possible evolutions of such programs. These evolutions arise both from self (i.e. internal to the agent) updating, and from external updating originating in the environment. In this paper we illustrate the usage and power of EVOLP, and its ability to model agents’ specifications, by elaborating on variations in the modelling of a Personal Assistant Agent for e-mail management.\\nProgramming language\\nNegation\\nComputer science\\nArtificial intelligence\\nLogic programming',\n",
       " 304184: 'Parallel Thinning on Rmesh.\\nYear: 2004\\n#Citations: 0\\nConference\\n\\nThinning operation is a fundamental operation in image processing. It is a typical preprocessing stage for pattern recognition and data compression. In this report we proposed an algorithm that performs thinning operation by using reconfigurable mesh RMESH multiprocessors. The time and space complexities are both O(1) and therefore optimal.\\nReconfigurable mesh\\nThinning\\nComputer science\\nParallel computing\\nImage processing\\nPreprocessor\\nData compression',\n",
       " 308120: 'Pattern Recognition Using Modular Neural Networks and Genetic Algorithms.\\nYear: 2004\\n#Citations: 15\\nConference\\n\\nNeocognitron\\nPattern recognition\\nComputer science\\nTime delay neural network\\nArtificial intelligence\\nModular design\\nArtificial neural network\\nNeural gas\\nGenetic algorithm',\n",
       " 309476: 'A Multicast Algorithm for Dynamic Closed Groups.\\nYear: 1997\\n#Citations: 0\\nConference\\n\\nComputer science\\nMulticast algorithms\\nXcast\\nComputer network\\nDistributed computing',\n",
       " 309773: 'REAL-TIME ROAD SCENE CLASSIFICATION USING INFRARED IMAGES\\nYear: 2010\\n#Citations: 1\\nConference\\n\\nComputer vision\\nPattern recognition\\nComputer science\\nArtificial intelligence\\nInfrared',\n",
       " 311502: 'The S-Link-S Framework for Reference Linking: Architecture and Implementation.\\nYear: 1999\\n#Citations: 3\\nConference\\n\\nThe Scholarly Link Specification (S-Link-STM) Framework has been proposed as a possible approach towards a solution to the reference linking problem. S-Link-S provides a language for specifying URL generation formulae, and a metadata vocabulary for describing linkable scholarly internet resources. In this paper, I describe the origin of this approach, outline the architecture of the prospective system, and describe the implementation environment.\\nMetadata\\nWorld Wide Web\\nArchitecture\\nThe Open Group Architecture Framework\\nComputer science\\nRM-ODP\\nArchitecture framework\\nReference architecture\\nEnterprise architecture framework\\nView model',\n",
       " 314725: 'Genetic Network Programming with Actor-Critic\\nYear: 2007\\n#Citations: 0\\nJournal\\nFuji Technology Press Ltd.\\nInteractive evolutionary computation\\nComputer science\\nEvolutionary computation\\nGenetic programming\\nArtificial intelligence\\nGenetic representation\\nEvolutionary programming\\nGenetic network\\nMachine learning\\nLearning classifier system\\nReinforcement learning',\n",
       " 316834: 'CONEWS: A COLLABORATIVE APPROACH TO ONLINE NEWS STORIES\\nYear: 2007\\n#Citations: 0\\nConference\\n\\nWorld Wide Web\\nComputer science\\nMultimedia',\n",
       " 320228: 'Key information technologies in the mid-1990s.\\nYear: 1993\\n#Citations: 0\\nConference\\n\\nInformation system\\nManagement information systems\\nInformation technology architecture\\nComputer science\\nInformation technology\\nKnowledge management\\nInformation technology management\\nComputer-aided technologies\\nInformation engineering',\n",
       " 320896: 'Self-Tuning Technology in Microsoft SQL Server.\\nYear: 1999\\n#Citations: 28\\nJournal\\n\\nIdentity column\\nMicrosoft Office Live Meeting\\nBusiness Intelligence Markup Language\\nComputer science\\nLanguage Integrated Query\\nData Transformation Services\\nUser-defined function\\nSQL injection\\nDatabase\\nOperating system\\nSQL/PSM',\n",
       " 326638: 'The Incompleteness Factor Method as a Support of Inference in Decision Support Systems\\nYear: 2014\\n#Citations: 1\\nConference\\nSpringer, Cham\\nThe authors propose the incompleteness factor (IF) method to improve the effectiveness of browsing in knowledge bases with missing data. The paper explains the whole method, which is based on certainty factors and cluster analysis. The experiments’ results conducted to obtain optimal parameters for the algorithm are presented. The evaluation is made by using recall, precision, F-measure and other factors.\\nData mining\\nCertainty\\nIntelligent decision support system\\nInference\\nComputer science\\nDecision support system\\nArtificial intelligence\\nMissing data\\nRecall\\nMachine learning',\n",
       " 329271: 'Some problems on approximation of set of points by polygonal curves.\\nYear: 1998\\n#Citations: 6\\nConference\\n\\nDiscrete mathematics\\nCombinatorics\\nPolygon\\nPolygonal chain\\nMathematics',\n",
       " 161623: 'Aspects of large World Wide Web systems.\\nYear: 1996\\n#Citations: 3\\n\\n\\nWeb Accessibility Initiative\\nWorld Wide Web\\nWeb intelligence\\nComputer science\\nWeb engineering',\n",
       " 172223: 'Designing Reverse Auctions for B-2-B Procurement - Evidence from the German Industry.\\nYear: 2006\\n#Citations: 0\\n\\n\\nUnique bid auction\\nCombinatorial auction\\nEauction\\nAuto auction\\nCommon value auction\\nIndustrial organization\\nProcurement\\nForward auction\\nReverse auction\\nBusiness',\n",
       " 184813: 'An Enhanced Approach for an XML-Database Engine.\\nYear: 2002\\n#Citations: 0\\n\\n\\nEfficient XML Interchange\\nXML framework\\nStreaming XML\\nInformation retrieval\\nXML\\nComputer science\\nDocument Structure Description\\nXML database\\nSimple API for XML\\nDatabase\\nXML Signature',\n",
       " 190289: 'Deliberate Agent Reconcile Reactive and Goal-Oriented Agents.\\nYear: 2000\\n#Citations: 0\\n\\n\\nComputer science\\nGoal orientation\\nKnowledge management',\n",
       " 195760: 'Object Management and Addressing in the MONADS Architecture.\\nYear: 1987\\n#Citations: 28\\n\\n\\nArchitecture\\nComputer science\\nTheoretical computer science\\nMonad (functional programming)',\n",
       " 197896: 'A Survey on Access Control Deployment\\nYear: 2011\\n#Citations: 35\\n\\nSpringer, Berlin, Heidelberg\\nAccess control is a security aspect whose requirements evolve with technology advances and, at the same time, contemporary social contexts. Multitudes of access control models grow out of their respective application domains such as healthcare and collaborative enterprises; and even then, further administering means, human factor considerations, and infringement management are required to effectively deploy the model in the particular usage environment. This paper presents a survey of access control mechanisms along with their deployment issues and solutions available today. We aim to give a comprehensive big picture as well as pragmatic deployment details to guide in understanding, setting up and enforcing access control in its real world application.\\nHealth care\\nSoftware deployment\\nComputer science\\nComputer security\\nAccess control',\n",
       " 214629: 'Lineage Specific Expansion in Vibrio Species.\\nYear: 2007\\n#Citations: 0\\n\\n\\nBiology\\nVibrio species\\nZoology',\n",
       " 217021: 'A Study of the Experimental Validation of Fault-Tolerant Systems Using Different VHDL-Based Fault Injection Techniques.\\nYear: 2001\\n#Citations: 7\\n\\n\\nThree different VHDL-based fault injection techniques have been compared to validate a fault tolerant microcomputer system. We have studied the error pathology, their detection and recovery coverages and their latencies.\\nMicrocomputer system\\nFault coverage\\nComputer science\\nFault (power engineering)\\nFault tolerance\\nVHDL\\nFault injection\\nEmbedded system',\n",
       " 224492: 'Semantic Alliance: a framework for semantic allies\\nYear: 2012\\n#Citations: 12\\n\\nSpringer, Berlin, Heidelberg\\nWe present an architecture and software framework for semantic allies: Semantic systems that complement existing software applications with semantic services and interactions based on a background ontology. On the one hand, our Semantic Alliance framework follows an invasive approach: Users can profit from semantic technology without having to leave their accustomed workflows and tools. On the other hand, Semantic Alliance offers a largely application-independent way of extending existing (open API) applications with MKM technologies. Semantic Alliance framework presented in this paper consists of three components: i.) a universal semantic interaction manager for given abstract document types, ii.) a set of thin APIs realized as invasive extensions to particular applications, and iii.) a set of renderer components for existing semantic services. We validate the Semantic Alliance approach by instantiating it with a spreadsheet-specific interaction manager, thin APIs for LibreOffice Calc 3.4 and MS Excelu002710, and a browser-based renderer.\\nWorld Wide Web\\nSemantic technology\\nSemantic Web Stack\\nComputer science\\nSemantic analytics\\nSemantic interoperability\\nSemantic grid\\nSocial Semantic Web\\nSemantic computing\\nSemantic data model',\n",
       " 245206: 'Ontology-Based Lexicon of Bulgarian.\\nYear: 2009\\n#Citations: 1\\n\\n\\nOntology\\nBulgarian\\nComputer science\\nLexicon\\nNatural language processing\\nArtificial intelligence',\n",
       " 252915: 'An XML-based system for configuration management of telecommunications networks using web-services.\\nYear: 2005\\n#Citations: 0\\n\\n\\nElement management system\\nComputer science\\nComputer network\\nTelecommunications control software\\nConfiguration management\\nWeb service\\nSystems management\\nConfiguration Management (ITSM)\\nOperations support system\\nTelecommunications service',\n",
       " 257391: 'Mapping Requirements to Software Architecture by Feature-Orientation.\\nYear: 2003\\n#Citations: 24\\n\\n\\nRequirements engineering and software architecting are two key activities in software life cycle. Researchers have paid much attention to mapping and transformation from requirements to software architecture, but there’s still lack of effective solutions. In this paper, the inadequacy of traditional mapping approaches (such as approaches in structured method and OO method) for this challenge is analyzed, and further a feature-oriented mapping approach is introduced. The rationale, process and guidelines for this approach are specified, and the approach is illustrated by an example of bank account and transaction (BAT) system.\\nSoftware engineering\\nSystems engineering\\nComputer science\\nArchitecture tradeoff analysis method\\nReference architecture\\nResource-oriented architecture\\nSoftware architecture\\nSoftware requirements specification\\nSoftware construction\\nSoftware development\\nSoftware requirements',\n",
       " 266910: 'Segment-based multiple sequence alignment\\nYear: 2009\\n#Citations: 0\\n\\nUniversität Tübingen\\nComputer science\\nBioinformatics\\nComputational biology\\nMultiple sequence alignment',\n",
       " 269276: 'Assuring Dependability of Software Reuse: An Industrial Standard\\nYear: 2013\\n#Citations: 1\\n\\nSpringer, Berlin, Heidelberg\\nWhereas a software component may be perfectly suited to one application, it may prove to cause severe faults in other applications. The pre-standard IEC/PAS 62814 (Dependability of Software Products Containing Reusable Components – Guidance for Functionality and Tests), which has recently been released, addresses the functionality, testing, and dependability of software components to be reused and products that contain software to be used in more than one application; that is, reused by the same or by another development organization, regardless of whether it belongs to the same or another legal entity than the one that has developed this software. This paper introduces into this pre-standard and give hints how to use it. The author, who chaired its realization that started in 2006, briefly summarizes the difficult process to bring the industrial partners with controversial interests to a consensus.\\nDependability\\nSystems engineering\\nSoftware engineering\\nReuse\\nSoftware\\nComponent-based software engineering\\nEngineering',\n",
       " 277504: 'RC6 as the AES.\\nYear: 2000\\n#Citations: 20\\n\\n\\nEach of the finalist algorithms appears to offer adequate security, and each offers a considerable number of advantages. Any of the finalists could serve admirably as the AES. However, each algorithm also has one or more areas where it does not fare quite as well as some other algorithm; none of the finalists is outstandingly superior to the rest. – Nechvatal, Barker, Bassham, Burr, Dworkin, Foti, Roback [12]\\nComputer science\\nTheoretical computer science\\nAES implementations',\n",
       " 279698: 'A Comparison of Techniques for Specifying Concurrent Systems Using the Object-Oriented Paradigm.\\nYear: 1993\\n#Citations: 1\\n\\n\\nProgramming language\\nObject-oriented programming\\nComputer science',\n",
       " 287008: 'A compiler framework for supporting speculative multicore processors\\nYear: 2007\\n#Citations: 0\\n\\nSpringer, Berlin, Heidelberg\\nAs multi-core technology is currently being deployed in computer industry primarily to limit power consumption and improve throughput, continued performance improvement of a single application on such systems remains an important and challenging task. Because of the shortened on-chip communication latency between cores, using thread-level parallelism (TLP) to improve the number of instructions executed per clock cycle, i.e., to improve ILP performance, has shown to be effective for many general-purpose applications. However, because of the program characteristics of these applications, effective speculative schemes at both thread- and instruction-level are crucial.\\nComputer architecture\\nComputer science\\nLatency (engineering)\\nThread (computing)\\nCompiler\\nThroughput\\nCycles per instruction\\nMulti-core processor\\nPower consumption\\nPerformance improvement',\n",
       " 293295: 'Text Detection from Natural Scene Images Using Scale Space Model\\nYear: 2012\\n#Citations: 2\\n\\nSpringer, Berlin, Heidelberg\\nA scale space based approach is proposed to detect text from natural scene images with complicated background. An edge map containing the edge information of four directions is obtained by Sobel operators. Character areas are detected by connected components analysis and are merged into candidate text regions. We construct a N-level scale space model and compute spatial responses to the Laplacian-of- Gaussian operator at these scale levels. The distribution of some strongest responses obtained from scale space model is employed to verify whether a candidate is a true text region or not. The experimental results demonstrate that the proposed method is able to effectively filter the nontext regions and locate text regions in natural scene images with complicated background.\\nComputer vision\\nPattern recognition\\nEdge detection\\nComputer science\\nScale space\\nSobel operator\\nGaussian\\nOperator (computer programming)\\nConnected component\\nArtificial intelligence\\nText detection',\n",
       " 295139: 'Maximized Modality or constrained consistency\\nYear: 1999\\n#Citations: 34\\n\\n\\nMathematical optimization\\nComputer science',\n",
       " 297283: 'QUANTITATIVE INTERPRETATION OF MAMMOGRAMS BASED ON A PHYSICAL MODEL OF THE IMAGE FORMATION PROCESS\\nYear: 1998\\n#Citations: 1\\n\\nSpringer, Dordrecht\\nThe analysis of a mammography is perturbed by two kinds of degradations : a blur induced by X-rays scattering and a loss of contrast due to beam hardening. Some restorations methods have been proposed for scattering correction [1],[2],[3],[4]. They are based on the low frequency aspect of the scattering map, which is then modeled as a convolution of the observed radiograph. The main issue is the filter determination, which is generally obtained by acquisition of adapted phantoms.\\nMammography\\nLow frequency\\nConvolution\\nOptics\\nImage formation\\nBeam hardening\\nRadiography\\nScattering\\nPhysics',\n",
       " 303506: 'An extremal problem related to biplanes.\\nYear: 1999\\n#Citations: 0\\n\\n\\nCombinatorics',\n",
       " 313502: 'A System for Checking Semi-formal Proofs.\\nYear: 2008\\n#Citations: 1\\n\\n\\nModel checking\\nProgramming language\\nComputer science\\nAutomated proof checking\\nMathematical proof\\nSemi-formal',\n",
       " 320944: 'Another Algorithm for Computing Longest Common Increasing Subsequence for Two Random Input Sequences.\\nYear: 2006\\n#Citations: 0\\n\\n\\nCombinatorics\\nLongest common subsequence problem\\nLongest increasing subsequence\\nLongest alternating subsequence\\nSubsequence\\nMathematics',\n",
       " 326138: 'Qos - based web service description and discovery\\nYear: 2008\\n#Citations: 0\\n\\nΠανεπιστήμιο Κρήτης. Σχολή Θετικών και Τεχνολογικών Επιστημών. Τμήμα Επιστήμης Υπολογιστών\\nOntology alignment\\nWorld Wide Web\\nComputer science\\nConstraint programming\\nQuality of service\\nWeb service\\nService discovery',\n",
       " 330977: 'Ergebnisse einer qualitativen Befragung zur Gestaltung von Nachhaltigkeitsberichten\\nYear: 2013\\n#Citations: 0\\n\\nSpringer Vieweg, Berlin, Heidelberg\\nStakeholder gehen vermehrt dazu uber Informationen hinsichtlich der Nachhaltigkeit der unternehmerischen Aktivitaten einzufordern, was dazu fuhrt, dass die Nachhaltigkeitsberichterstattung, welche bspw. nachweislich das Potenzial besitzt Kauf- oder Investitionsentscheidungen positiv zu beeinflussen, weiter an Bedeutung gewinnt. Die Gestaltung der Berichte variiert stark, daher stellt sich die Frage, welche Merkmale sie aufweisen sollten, um einen moglichst grosen Nutzen fur das berichterstattende Unternehmen zu erzielen. Im Rahmen dieses Beitrags werden anhand der Analyse einer qualitativen Befragung von 260 Teilnehmern Verbesserungspotenziale fur die unternehmerische Nachhaltigkeitsberichterstattung mit dem Nachhaltigkeitsbericht des BASF-Konzerns als Referenz aufgedeckt und diskutiert. Begrundet durch eine Diskussion der bekannten IS-Theorien Cognitive Fit und Task Technology Fit stehen dabei das Verhaltnis von Text, Tabellen und Grafiken, die Bereicherung durch multimediale Inhalte, wie Videos und interaktive Grafiken, sowie generelle Verbesserungsvorschlage im Mittelpunkt der Betrachtung. Die uberwiegende Mehrheit der Befragten war dabei der Ansicht, dass die im untersuchten Nachhaltigkeitsbericht enthaltenen Informationen zu oft in Form von Texten aufbereitet wurden und dass diese besser anschaulich anhand von Grafiken oder Tabellen dargestellt werden sollten.\\nPolitical science\\nHumanities\\nCognitive fit',\n",
       " 331548: 'A Discussion on Process Losses in GSS: Suggested Ground Rules for the Electronic Environment\\nYear: 1999\\n#Citations: 1\\nConference\\nSpringer, London\\nAs research with group support systems (GSS) moves forward, researchers must watch for and identify possible derivative process losses: proposed here as those process losses introduced into the group meeting process while researching a primary dysfunction. This paper reviews a set of GSS literature in order to find support for such derivative process losses. Five such derivative losses are proposed with corresponding ground rules for addressing them. One such loss, “stronger identification with non-consensus”, is discussed in more detail.\\nSystems engineering\\nComputer science\\nSupport system\\nKnowledge management\\nRisk analysis (engineering)',\n",
       " 335626: 'Towards an interactive agent-based approach to real-time feedback (IAARF) in e-learning system\\nYear: 2012\\n#Citations: 2\\nConference\\nSpringer, Berlin, Heidelberg\\nE-learning management systems use an interactive approach that presents the learner with learning objects to interact with during the learning process. Several interactive platforms for sharing learnersu0027 ideas, integrating mutual knowledge or providing feedback have been proposed. However, these approaches have met with limited success. Furthermore, although design education is already taking full advantage of the current state and economy of online information, online teaching materials suffer from scanty content, poor interactivity, and insufficient participation. This paper proposes an interactive agent-based approach to real-time feedback (IAARF) generation in e-learning systems for higher institutions of learning. This approach presents the possible way to use agents in an interactive manner to create learner profiles, guide the learners to set the learning goals, learner activities, and extract learner resources during the learning process. The major strength of this approach is the high level of learner engagement, with real-time feedback (RF) to the learner, shaping and transforming their learning dynamics.\\nExperiential learning\\nInteractivity\\nDesign education\\nMutual knowledge\\nOpen learning\\nE learning\\nComputer science\\nKnowledge management\\nLearning dynamics\\nMultimedia\\nManagement system',\n",
       " 341221: 'A Parallel Programming Approach to Job Shop Scheduling Constrain Satisfaction Problems.\\nYear: 1998\\n#Citations: 0\\nConference\\n\\nMathematical optimization\\nJob shop scheduling\\nFair-share scheduling\\nComputer science\\nFlow shop scheduling\\nOperations research\\nRate-monotonic scheduling\\nDynamic priority scheduling',\n",
       " 344829: 'Comparative Study on the Feature of Kitchen Knife Sharpening Skill between Expert and Non-Expert\\nYear: 2014\\n#Citations: 0\\nConference\\nSpringer, Cham\\nSharpening is one of basic culinary for a cook. In this study, 10 experts and 10 non-experts from Kyoto culinary art college were employed to investigate the gesture of sharpening. The feature of processing was recorded and summarized by a force plate and two cameras. All participants’ main movement elements were counted and summarized. The most representative subjects of expert and non-expert in each type were observed and analyzed by Digital Microscopy. The movement gesture performing with right hand deeply holding the knife was the recommended knife position.\\nSharpening\\nComputer vision\\nDigital microscopy\\nGesture\\nArtificial intelligence\\nEngineering\\nCulinary art',\n",
       " 345707: 'A Study on Guiding Programmers’ Code Navigation with a Graphical Code Recommender\\nYear: 2012\\n#Citations: 5\\nJournal\\nSpringer Berlin Heidelberg\\nWhile performing an evolution task, programmers spend significant time trying to understand a code base. To facilitate programmers’ comprehension of code, researchers have developed software visualization tools. However, those tools have not predicted the information that programmers seek during their program comprehension activities. To responsively provide informative diagrams in a timely manner, we suggest a graphical code recommender and conduct an iterative Wizard of Oz study in order to examine when and what diagrammatic contents should appear in a graphical view to guide a programmer in exploring source code. We found that programmers positively evaluate a graphical code recommender that changes in response to their code navigation. They favored a graphical view that displays the source locations frequently visited by other programmers during the same task. They commented that the graphical code recommender helped in particular when they were uncertain about where to look while exploring the code base.\\nProgramming language\\nProgrammer\\nPair programming\\nDiagrammatic reasoning\\nSource code\\nComputer science\\nInternal documentation\\nHuman–computer interaction\\nProgram comprehension\\nSoftware visualization\\nCode (cryptography)',\n",
       " 348088: 'Using Real Options in ERP-Systems for Improving Delivery Reliability\\nYear: 2011\\n#Citations: 1\\nConference\\nAIS Electronic Library (AISeL)\\nTodayu0027s machinery and equipment industry is a highly volatile market, giving rise to frequently instable and inapprehensible buyer-supplier-relationships and to turbulences with respect to reliability of deliveries. With this paper we propose a minimal invasive approach how to overcome existing capability limitations in production planning, scheduling and procurement of ERP-systems by using real options as means for coordinating the divergent interest of buyers and suppliers. Following the design research paradigm, we first describe how real options can be integrated in a contemporary ERP-system. In a supplemental evaluation, the attitude toward using this approach is discussed. This final discussion provides insights whether companies in the machinery and equipment industry are willing to adopt our real options approach, or if they prefer the use of other, not necessarily IT-enabled, means for handling the poor delivery reliability.\\nInformation management\\nEnterprise resource planning\\nComputer science\\nScheduling (computing)\\nKnowledge management\\nProduction planning\\nDesign research\\nDesign science\\nProcurement',\n",
       " 349990: 'Depicting Diversity in Rules Extracted from Ensembles\\nYear: 2009\\n#Citations: 0\\nConference\\nSpringer, Berlin, Heidelberg\\nEnsembles are committees of neural networks used to achieve better classification and generalization accuracy in contrast to just using a single neural network. Traditionally incomprehensible models such as artificial neural networks presents a problem in its application to safety critical domains where not only accuracy but also model transparency is a requirement. This problem is not only inherited but further multiplied in ensembles. Furthermore, the aspect of diversity by which ensembles achieve improved classification ability cannot be reflected in rule extraction methods designed for single neural networks hence the need for rule extraction methods specifically designed for ensembles. This paper presents a decompositional rule extraction algorithm for ensembles which is able to approximately decompose the neural networks in an ensemble and reflect their collective diversity to identify significantly contributing inputs.\\nTransparency (graphic)\\nPattern recognition\\nExtraction algorithm\\nComputer science\\nArtificial intelligence\\nArtificial neural network\\nMachine learning',\n",
       " 352166: 'Distributed Resolution for ALC\\nYear: 2008\\n#Citations: 16\\nJournal\\nRWTH\\nThe use of Description Logic as the basis for Semantic Web Languages has led to new requirements with respect to scalable and nonstandard reasoning. In this paper, we address the problem of scalable reasoning by proposing a distributed, complete and terminating algorithm that decides satisfiability of terminologies in ALC. The algorithm is based on recent results on applying resolution to description logics. We show that the resolution procedure proposed by Tammet can be distributed amongst multiple resolution solvers by assigning unique sets of literals to individual solvers. This results provides the basis for a highly scalable reasoning infrastructure for Description logics.\\nProgramming language\\nComputer science\\nSatisfiability\\nSemantic Web\\nDescription logic\\nTheoretical computer science\\nScalability',\n",
       " 354571: 'Machine learning for adaptive image interpretation\\nYear: 2004\\n#Citations: 19\\nConference\\nAAAI Press\\nAutomated image interpretation is an important task with numerous applications. Until recently, designing such systems required extensive subject matter and computer vision expertise resulting in poor cross-domain portability and expensive maintenance. Recently, a machine-learned system (ADORE) was successfully applied in an aerial image interpretation domain. Subsequently, it was re-trained for another man-made object recognition task. In this paper we propose and implement several extensions of ADORE addressing its primary limitations. These extensions enable the first successful application of this emerging AI technology to a natural image interpretation domain. The resulting system is shown to be robust with respect to noise in the training data, illumination, and camera angle variations as well as competitively adaptive with respect to novel images.\\nTraining set\\nComputer vision\\nFeature detection (computer vision)\\nComputer science\\nAerial image\\nSoftware portability\\nArtificial intelligence\\nMachine learning\\nCognitive neuroscience of visual object recognition',\n",
       " 355512: 'Visualizing Impression-Based Preferences of Twitter Users\\nYear: 2014\\n#Citations: 1\\nConference\\nSpringer, Cham\\nTwitter is extremely useful for connecting with other users, because, on Twitter, following other users is simple. On the other hand, people are often followed by unknown and anonymous users and are sometimes shown tweets of unknown users through the tweets of the users they follow. In such a situation, they wonder whether they should follow such unknown users. This paper proposes a system for visualizing impression-based preferences of Twitter users to help people select whom to follow. The impression-based preference of a user is derived based on the impressions of the tweets the user has posted and those of the tweets of users followed by the user under consideration. Our proposed system enables people to select whom to follow depending on whether or not another user adheres to the useru0027s own sensibilities, rather than on whether or not another user provides valuable information.\\nWonder\\nInternet privacy\\nWorld Wide Web\\nComputer science\\nSentiment analysis\\nImpression',\n",
       " 356562: 'ACTIVE SECURITY SYSTEM FOR AN INDUSTRIAL ROBOT BASED ON ARTIFICIAL VISION AND FUZZY LOGIC PRINCIPLES\\nYear: 2008\\n#Citations: 0\\nConference\\nINSTICC-INST SYST TECHNOLOGIES INFORMATION CONTROL & COMMUNICATION\\nAn active security system assures that interacting robots donu0027t collide or that a robot operating independently doesnu0027t hit any obstacle that is encountered in the robots workspace. In this paper, an active security system for a FANUC industrial robot is introduced. The active security problem where one robot needs to avoid a moving obstacle in its workspace is considered. An obstacle detection and localization mechanism based on stereoscopic vision methods was successfully developed. To connect the vision system, an operatoru0027s pc and the robot environment a real-time communication is set up over Ethernet using socket messaging. We used fuzzy logic for intelligent trajectory planning. A multitask oriented robot application in the KAREL programming language of FANUC Robotics was implemented and tested.\\nSocial robot\\nRobot control\\nMachine vision\\nPersonal robot\\nControl engineering\\nIndustrial robot\\nArtificial intelligence\\nEngineering\\nRobot\\nRobotics\\nMobile robot',\n",
       " 356711: 'Creating user defined new vocabularies for voice dialing.\\nYear: 1997\\n#Citations: 3\\nConference\\n\\nThis paper introduces a new approach for generation of phonetic transcriptions for voice dialing applications. where on-line construction of user vocabularies is mandatory. The proposed method allows adaptive selection of new transcriptions requiring much less speech utterances for system training than other approaches. The new approach is compared to other classical approaches showing a clear improvement on performance and efficiency.\\nTranscription (linguistics)\\nComputer science\\nAdaptive selection\\nSpeech recognition',\n",
       " 358902: \"The generalization of AQM algorithms for queueing systems with bounded capacity\\nYear: 2011\\n#Citations: 10\\nConference\\nSpringer, Berlin, Heidelberg\\nA queueing system of the M/M/1/(∞,V) type with generally distributed packet volumes and bounded capacity (total packets volume) is considered. The queue length is controlled by means of the accepting function that enqueues the arriving packet with probability depending on the free capacity volume in the system at the pre-arrival epoch. Explicit representations for stationary probabilities are derived via solving the system of differential equations. Sample numerical results are attached in which stationary queue-size distributions with and without dropping packets are compared.\\nM/M/1 queue\\nApplied mathematics\\nDiscrete mathematics\\nM/D/1 queue\\nBulk queue\\nM/M/c queue\\nM/G/1 queue\\nM/G/k queue\\nBurke's theorem\\nTheoretical computer science\\nM/M/∞ queue\\nMathematics\",\n",
       " 360435: 'Agent system for online ticket resale\\nYear: 2008\\n#Citations: 3\\nConference\\nSpringer, Berlin, Heidelberg\\nThis study has tried to suggest a new model that can effectively redistribute the tickets in the online ticket resale market, while suggesting a new allocation mechanism based on an agent negotiation. To this end, this study has analyzed and simulated the secondary ticket market through System dynamics. As a result of these simulations, it has been proved that the price stability of ticket resale market leads to an increase in revenue. An agent negotiation helps to stabilize the ticket prices that are usually inclined to rise at auction, benefiting all the participants in the negotiations, consequently showing a Pareto solution.\\nRevenue\\nData mining\\nComputer science\\nPrice of stability\\nMicroeconomics\\nTicket\\nSystem dynamics\\nPareto solution\\nNegotiation',\n",
       " 361368: 'AN ECONOMIC ANALYSIS OF ONLINE SHARING SYSTEMS´ IMPLICATIONS ON SOCIAL WELFARE\\nYear: 2014\\n#Citations: 5\\nConference\\n\\nThe rise of online sharing systems offers consumers the opportunity to grant other consumers access to infrequent-use goods or spaces they own, or the opportunity to access those they do not. Thereby, consumers’ decision-making and usage behaviors are likely to change, which in turn will affect consumer surplus and thus social welfare. Within this paper, first steps towards understanding the economic implications of online sharing systems upon social welfare are explicated, specifically those relating to consumer decision-making and usage behavior. Preliminary results indicate: (I) The number of uses for consumers (deciding to buy and share) increases in their individual monetary utility per use, increases in aggregate sharing supply, and decreases in aggregate sharing demand. (II) The number of uses for consumers (deciding to share and not buy) increases in their individual monetary utility per use, increases in aggregate sharing supply, and decreases in aggregate sharing demand. Further, a research agenda is presented in order to develop this paper by investigating following steps: (i) how consumers are categorized into different consumer segments; (ii) how sharing system providers set fees for using online sharing systems; and (iii) how online sharing systems affect consumer and producer surplus and how subsequently social welfare is influenced.\\nPublic economics\\nEconomics\\nEconomic analysis\\nEconomic surplus\\nSocial Welfare',\n",
       " 361876: 'Rational and convergent learning in stochastic games\\nYear: 2001\\n#Citations: 215\\nConference\\nMorgan Kaufmann Publishers Inc.\\nThis paper investigates the problem of policy learning in multiagent environments using the stochastic game framework, which we briefly overview. We introduce two properties as desirable for a learning agent when in the presence of other learning agents, namely rationality and convergence. We examine existing reinforcement learning algorithms according to these two properties and notice that they fail to simultaneously meet both criteria. We then contribute a new learning algorithm, WoLF policy hillclimbing, that is based on a simple principle: “learn quickly while losing, slowly while winning.” The algorithm is proven to be rational and we present empirical results for a number of stochastic games showing the algorithm converges.\\nConvergence (routing)\\nLearning agent\\nRationality\\nComputer science\\nPolicy learning\\nNotice\\nArtificial intelligence\\nMachine learning\\nReinforcement learning\\nStochastic game',\n",
       " 363116: 'AR identification of the vocal filter from noisy hyperbaric speech signals.\\nYear: 1995\\n#Citations: 0\\nConference\\n\\nPattern recognition\\nComputer science\\nSpeech recognition\\nArtificial intelligence',\n",
       " 364583: 'Cooperative learning over composite search spaces experiences with a multi-agent design system\\nYear: 1996\\n#Citations: 8\\nConference\\nAAAI Press\\nWe suggest the use of two learning techniques - short term and long term - to enhance search efficiency in a multi-agent design system by letting the agents learn about non-local requirements on the local search process. The first technique allows an agent to accumulate and apply constraining information about global problem solving, gathered as a result of agent communication, to further problem solving within the same problem instance. The second technique is used to classify problem instances and appropriately index and retrieve constraining information to apply to new problem instances. These techniques will be presented within the context of a multi-agent parametric-design application called STEAM. We show that learning conclusively improves solution quality and processing-time results.\\nInstance-based learning\\nComputer science\\nDesign systems\\nArtificial intelligence\\nLocal search (optimization)\\nCooperative learning\\nMachine learning',\n",
       " 368352: 'A new approach to the jeep problem.\\nYear: 1989\\n#Citations: 4\\nJournal\\n\\nJeep problem\\nTheoretical computer science\\nMathematics\\nCalculus',\n",
       " 372956: 'INSERTION ANGLE TEACHING FOR AN ACUPUNCTURE TRAINING SYSTEM\\nYear: 2009\\n#Citations: 2\\nConference\\n\\nMedical education\\nTraining system\\nComputer science\\nAcupuncture\\nPhysical medicine and rehabilitation\\nMultimedia',\n",
       " 374795: 'Integration of Autonomous, Mobile Robots in Flexible Manufacturing Systems\\nYear: 1989\\n#Citations: 9\\nConference\\nIOS Press\\nRobot control\\nManufacturing systems\\nComputer science\\nControl engineering\\nMobile robot',\n",
       " 376474: 'Parallelization of GSL on Clusters of Symmetric Multiprocessors\\nYear: 2005\\n#Citations: 1\\nConference\\n\\nIn this paper we discuss the application of an hybrid programming paradigm that combines message-passing (MPI) with shared memory programming (OpenMP). We apply this model to the parallel solution of two basic problems: the sparse matrix-vector product and the dynamic programming problem. We compare the results of the hybrid model with the application of a pure MPI model on a cluster of dual Intel Xeon processors. The experimental results show that the behavior of both models depend, among other factors, on the application and on the size of the problems. While with the dynamic programming problem we obtain very good speedups, in the case of the matrix-vector product the algorithms do not take very good profit of the dual processors.\\nDynamic programming\\nCluster (physics)\\nShared memory\\nComputer science\\nParallel computing\\nXeon\\nHybrid programming',\n",
       " 380549: 'Evaluating the Use of Project Glossaries in Automated Trace Retrieval.\\nYear: 2008\\n#Citations: 9\\nJournal\\n\\nAutomated traceability methods use information retrieval techniques to dynamically generate traceability links, however they suffer from precision problems. This paper extends our previous work in using a project glossary to improve trace results and presents criteria for evaluating whether an existing project glossary can be used to enhance results in a given project. A new approach for automatically extracting a set of important terms and phrases is also described. Our experimental results suggest that these terms and phrases can be used effectively in lieu of a project glossary to help improve precision of the retrieved traces.\\nInformation retrieval\\nComputer science\\nGlossary\\nTraceability',\n",
       " 382276: 'Word clouds for efficient document labeling\\nYear: 2011\\n#Citations: 5\\nConference\\nSpringer\\nIn text classification the amount and quality of training data is crucial for the performance of the classifier. The generation of training data is done by human labelers - a tedious and time-consuming work. We propose to use condensed representations of text documents instead of the full-text document to reduce the labeling time for single documents. These condensed representations are key sentences and key phrases and can be generated in a fully unsupervised way. The key phrases are presented in a layout similar to a tag cloud. In a user study with 37 participants we evaluated whether document labeling with these condensed representations can be done faster and equally accurate by the human labelers. Our evaluation shows that the users labeled word clouds twice as fast but as accurately as full-text documents. While further investigations for different classification tasks are necessary, this insight could potentially reduce costs for the labeling process of text documents.\\nTraining set\\nInformation retrieval\\nComputer science\\nVisualization\\nDocument layout analysis\\nTag cloud\\nNatural language processing\\nArtificial intelligence\\nClassifier (linguistics)\\nUser interface',\n",
       " 385572: 'A Generic Framework Based on Machine Learning Techniques for Virtual Organization Management\\nYear: 2005\\n#Citations: 1\\nConference\\nSpringer, Boston, MA\\nThe management of Virtual Organization (VO) brings some challenges. One of them is the appropriate and effective coordination and monitoring of distributed businesses processes. It is not easy or trivial to handle the enormous amount of information about and from VOs members. As a direct consequence, decisions are crucial and should be taken not only with agility, but also with intelligence. This paper introduces a framework to support an integrated decision-making environment through which managers will be able to take assisted and smarter decisions. The key element of this framework is the Intelligent Decision Support System, which applies Artificial Intelligence techniques (Data Mining and Machine Learning) to facilitate and to support the decision-making process.\\nData science\\nActive learning (machine learning)\\nIntelligent decision support system\\nComputer science\\nKnowledge management\\nBullwhip effect\\nArtificial intelligence\\nCollaborative network\\nMachine learning\\nVirtual organization',\n",
       " 385951: 'A bimodal Korean address entry/retrieval system.\\nYear: 1998\\n#Citations: 0\\nConference\\n\\nComputer science\\nSpeech recognition',\n",
       " 386281: 'Creation of Hardware Objects in a Reconfigurable Computer\\nYear: 1995\\n#Citations: 4\\nConference\\nSpringer, Berlin, Heidelberg\\nWe define reconfigurable computing systems as those machines that use the reconfigurable aspects of Field Programmable Gate Arrays (FPGA) to implement an algorithm. Researchers throughout the world have shown that computationally intensive software algorithms can be transposed directly into hardware design for extreme performance gain [1,2,3]. Hardware objects are algorithms implemented as dynamically downloadable hardware designs. Hardware objects execute on reconfigurable computing systems based on SRAM-style Field Programmable Gate Arrays (FPGA). A Hardware Object can be created via schematic and VHSIC Hardware Description Language (VHDL) or Verilog hardware description language. To use a hardware design in a software program, it must be converted into a Hardware Object. The Hardware Object can be used over and over or in combination with other Hardware Objects. This H.O.T. (Hardware Object Technology)ℳ method of programming reconfigurable computers is the subject of this paper [4].\\nHardware compatibility list\\nComputer science\\nParallel computing\\nFpgaC\\nField-programmable gate array\\nHardware register\\nHardware acceleration\\nVHDL\\nComputer hardware\\nReconfigurable computing\\nHardware architecture',\n",
       " 388271: 'A Runtime Analysis of Graph-Theoretical Algorithms to Detect Patterns in Process Model Collections\\nYear: 2012\\n#Citations: 5\\nConference\\nSpringer, Berlin, Heidelberg\\nPattern detection serves different purposes in managing large collections of process models, ranging from syntax checking to compliance validation. This paper presents a runtime analysis of four graph-theoretical algorithms for (frequent) pattern detection. We apply these algorithms to large collections of process and data models to demonstrate that, despite their theoretical intractability, they are able to return results within (milli-) seconds. We discuss the relative performance of these algorithms and their applicability in practice.\\nGraph\\nData mining\\nData modeling\\nComputer science\\nWork in process\\nProcess modeling\\nAlgorithm\\nRanging\\nSyntax\\nPattern matching\\nSubgraph isomorphism problem',\n",
       " 389256: 'An Item Bank Calibration Method for a Computer Adaptive Test\\nYear: 2014\\n#Citations: 1\\nConference\\nSpringer, Cham\\nComputer adaptive testing is a form of educational measurement that is adaptable to examineeu0027s proficiency. The usage of a computer adaptive testing brings many benefits but requires creation of a big and a calibrated item bank. The calibration of an item bank made by statistical methods is expensive and time consuming. Therefore, in this paper we worked out an easy item bank calibration method based on expertsu0027 opinions. The proposed algorithm used the Consensus Theory. The researches pointed out that the proposed calibration procedure is efficient. As little as three expertsu0027 opinions were enough to obtain the calibrated item bank where values of itemsu0027 parameters estimated by an expert-based method were not statistically different from values of itemsu0027 parameter estimated by a statistical calibration method. The statistical calibration method required engaging over 50 persons.\\nData mining\\nEducational measurement\\nComputer science\\nArtificial intelligence\\nComputerized adaptive testing\\nItem bank\\nConsensus theory\\nItem response theory\\nMachine learning\\nCalibration',\n",
       " 392408: 'Dynamic integration of multiple feature streams for robust real-time LVCSR\\nYear: 2007\\n#Citations: 1\\nConference\\n\\nPattern recognition\\nComputer science\\nSpeech recognition\\nMutual information\\nArtificial intelligence\\nSTREAMS',\n",
       " 395173: 'Improving Spelling Skills for Blind Language Learners - Orthographic Feedback in an Auditory Vocabulary Trainer.\\nYear: 2010\\n#Citations: 1\\nConference\\n\\nTrainer\\nOrthographic projection\\nComputer science\\nSpelling\\nNatural language processing\\nArtificial intelligence\\nVocabulary',\n",
       " 398077: 'Panel: The impact of IT on accounting and auditing.\\nYear: 2002\\n#Citations: 0\\nConference\\n\\nFinancial accounting\\nAccounting\\nAudit\\nComparison of management accounting and financial accounting\\nAccounting information system\\nComputer science\\nManagement accounting',\n",
       " 399837: 'B. Haverkort: Performance of computer communication systems.\\nYear: 1999\\n#Citations: 0\\nJournal\\n\\nComputer science\\nComputer network\\nCommunications system',\n",
       " 401217: 'Code Mobility in Open Systems: A Formal Approach.\\nYear: 2000\\n#Citations: 1\\nConference\\n\\nComputer science\\nCode mobility\\nOpen system (systems theory)\\nDistributed computing',\n",
       " 402670: 'Optimal Code Scheduling for Multiple-Pipeline Processors\\nYear: 1990\\n#Citations: 4\\nConference\\n\\nMultiprocessor scheduling\\nFair-share scheduling\\nComputer science\\nParallel computing\\nGang scheduling\\nTwo-level scheduling\\nRate-monotonic scheduling\\nEarliest deadline first scheduling\\nDynamic priority scheduling\\nRound-robin scheduling',\n",
       " 403334: 'Explore the operational problems of FMSs through analytical hierarchy process and simulation approach\\nYear: 1996\\n#Citations: 0\\nConference\\nGordon and Breach Science Publishers, Inc.\\nIndustrial engineering\\nComputer science\\nAnalytic network process\\nArtificial intelligence\\nManagement science\\nMachine learning\\nAnalytic hierarchy process',\n",
       " 404804: 'Speaker weighted training of HMM using multiple reference speakers.\\nYear: 1990\\n#Citations: 0\\nConference\\n\\nPattern recognition\\nComputer science\\nSpeech recognition\\nArtificial intelligence\\nHidden Markov model',\n",
       " 405103: 'Parallel Simulation of Atmospheric Gas Dispersion.\\nYear: 2006\\n#Citations: 0\\nConference\\n\\nDispersion (optics)\\nParallel simulation\\nComputer science\\nParallel computing',\n",
       " 407825: 'SimSaaS: simulation software-as-a-service\\nYear: 2011\\n#Citations: 28\\nConference\\nSociety for Computer Simulation International\\nSimulation can benefit from cloud computing that often comes with thousands of processors and its software is structured as Software-as-a-Service (SaaS) with its multi-tenancy architecture (MTA). This paper proposes Simulation Software-as-a-Service (SimSaaS) with a MTA configuration model and a cloud-based runtime to support rapid simulation development to be run in an elastic cloud environment.\\nArchitecture\\nSimulation software\\nComputer science\\nSoftware as a service\\nReal-time computing\\nElastic cloud\\nSoftware\\nOperating system\\nDistributed computing\\nCloud computing',\n",
       " 414512: 'MLB: multilevel load balancing for structured grid applications\\nYear: 1997\\n#Citations: 4\\nConference\\nLos Alamos National Laboratory\\nThe Multilevel Load Balancing algorithm (MLB) is a parallel algorithm that determines the communication schedule that is necessary to balance a distributed discrete load function. The MLB algorithm focuses on structured grid computations and their load balancing requirements, which we feel are largely unsupported within the load balancing community. The interface to MLB is inherently simple; a distributed discrete load function is provided by the user and a communication schedule is returned. The load function can, for example, map to one or more distributed arrays. So far the implementation includes a parallel version of only the one dimensional MLB algorithm and produces a communication schedule that requires at most log(p) communication steps, where p is the number of processors (log() stands for the logarithm of base two). This work forms just one of the object-oriented class libraries within the OVERTURE Framework, an object-oriented environment for the numerical solution of partial differential equations in serial and parallel environments.\\nLoad balancing (computing)\\nComputer science\\nParallel algorithm\\nParallel processing\\nParallel computing\\nNumerical partial differential equations\\nLogarithm\\nPartial differential equation\\nGrid\\nDistributed computing\\nComputation',\n",
       " 418632: 'TICC, Technology for Integrated Computation and Communication.\\nYear: 2003\\n#Citations: 0\\nConference\\n\\nComputer science\\nParallel computing\\nTheoretical computer science\\nComputational science\\nComputation',\n",
       " 421533: 'Model of Fuzzy Comprehension Evaluation of Traffic Operations Safety on Urban Ice and Snow Road\\nYear: 2011\\n#Citations: 0\\nConference\\nSpringer, Berlin, Heidelberg\\nIn order to evaluate traffic operation safety of urban ice and snow road objectively, ice and snow pavement friction coefficient, visibility, following distance and snow-accumulated depth are chosen as evaluation indexes and their criteria are established. Evaluation indexes are weighted by using the improved entropy weight coefficient method, and then the model of fuzzy comprehension evaluation of traffic operation safety on urban ice and snow road is constructed. It is demonstrated through an example that the model has strong operability, and its result is relatively accurate. This model provides a theoretical basis for judging road traffic safety ranks objectively and formulating scientific policies and measures which can improve road traffic safety under ice and snow condition.\\nVisibility\\nSimulation\\nComputer science\\nFuzzy logic\\nOperability\\nWeight coefficient\\nFriction coefficient\\nCivil engineering\\nSnow\\nComprehension\\nRoad traffic safety',\n",
       " 423216: 'Design and Implementation of a Software Configuration Management Tool.\\nYear: 2008\\n#Citations: 0\\nJournal\\n\\nApplication lifecycle management\\nSoftware design\\nSoftware configuration management\\nSoftware engineering\\nSoftware system\\nSoftware project management\\nControl engineering\\nEngineering\\nSoftware construction\\nSoftware verification and validation\\nSoftware development',\n",
       " 425490: 'A approach to clinical proteomics data quality control and import\\nYear: 2011\\n#Citations: 1\\nConference\\nSpringer, Berlin, Heidelberg\\nBiomedical domain and proteomics in particular are faced with an increasing volume of data. The heterogeneity of data sources implies heterogeneity in the representation and in the content of data. Data may also be incorrect, implicate errors and can compromise the analysis of experiments results. Our approach aims to ensure the initial quality of data during import into an information system dedicated to proteomics. It is based on the joint use of models, which represent the system sources, and ontologies, which are use as mediators between them. The controls, we propose, ensure the validity of values, semantics and data consistency during import process.\\nData science\\nOntology (information science)\\nInformation system\\nOntology\\nData quality\\nProteomics\\nComputer science\\nCompromise\\nSemantics\\nData consistency',\n",
       " 430170: 'Robust fin control for ship roll stabilization by using functional-link neural networks\\nYear: 2013\\n#Citations: 2\\nConference\\nSpringer, Berlin, Heidelberg\\nTo reduce the roll of a surface ship, a robust fin controller based on functional-link neural networks is proposed. The plant consists of the ship roll dynamics and that of the fin actuators. Modeling errors and the environmental disturbance induced by waves are considered in the cascaded roll system, which are identified by the neural networks. Lyapunov function is employed in the controller design, which guarantees the stability of the fin stabilizer. Numerical simulation demonstrates the good performance of the roll reduction based on the controller proposed.\\nSurface ship\\nLyapunov function\\nControl theory\\nFin\\nComputer simulation\\nComputer science\\nController design\\nControl theory\\nArtificial neural network\\nActuator',\n",
       " 432350: 'A fragile watermarking scheme based CRC checksum and public key cryptosystem for RGB color image authentication\\nYear: 2012\\n#Citations: 0\\nConference\\nSpringer Berlin Heidelberg\\nThe increased use of multimedia applications pose more problems concerning the preservation of confidentiality and authenticity of the transmission of digital data. These data, in particular the images should be protected from tampering. The solution is the use of fragile watermarking. Fragile watermarking can be modeled as a problem of communication of a signal over a noisy and hostile channel, where the attack takes place. Indeed, the use of error checking algorithms appear natural. . Cyclic redundancy check (CRC) code provides a simple, yet powerful, method for the detection of burst errors during digital data transmission and storage. CRC is one of the most versatile error checking algorithm used in various digital communication systems. In this paper, we propose a novel fragile watermarking scheme based CRC checksum and public key cryptosystem for RGB color image authentication.\\nComputer vision\\nDigital watermarking\\nAuthentication\\nConfidentiality\\nComputer science\\nCyclic redundancy check\\nCommunication channel\\nCommunications system\\nArtificial intelligence\\nRGB color model\\nDigital data',\n",
       " 434796: 'Lessons Learned from an e-Government Implementation: The Case of Ethiopia\\nYear: 2012\\n#Citations: 0\\nConference\\n\\nE-Government implementation failure in low-income countries is reported to be as high as 85% where 35% being classified as total failures, the project never started or was started but immediately abandoned, and 50% are partial failures, major project goals are not attained or there were undesirable outcomes (Heeks, 2003). Given this rate of failure we wanted to investigate a successful project and draw lessons learned that can be replicated in other projects. We use Design-Reality gap model as a theoretical framework to assess the project status. Primary data were collected from four different groups involved in the project. Our analysis shows lower gaps in ‘process’; ‘management systems and structures’ dimensions; and higher gaps in ‘information’, ‘technology’, ‘staffing and skills’, ‘objectives and values’, and ‘other resources’ dimensions. Based on the implementation experiences of this project, list of recommendations are provided for successful execution of possible related initiatives in the future.\\nE-Government\\nStaffing\\nComputer science\\nKnowledge management\\nManagement system\\nProcess management',\n",
       " 439701: 'A microphone array Interface for Real-Time Interactive Music Performance.\\nYear: 2012\\n#Citations: 3\\nConference\\nMichigan Publishing, University of Michigan Library\\nInteractive music\\nNoise-canceling microphone\\nMicrophone array\\nSpeech recognition\\nAcoustics\\nEngineering',\n",
       " 444267: 'Smoke Detection for Early Fire-Alarming System Based on Video Processing\\nYear: 2008\\n#Citations: 4\\nJournal\\nDigital Information Research Foundation\\nVideo processing\\nInformation retrieval\\nComputer science\\nSmoke\\nMultimedia',\n",
       " 444896: 'Annotation for the Semantic Web During Website Development\\nYear: 2004\\n#Citations: 7\\nConference\\nSpringer, Berlin, Heidelberg\\nWhile introducing the HTML standard to present information on the World Wide Web, the importance of being able to express the deep structure and meaning of the information was neglected. This has lead to some of the limitations of the current web (e.g. its restricted query possibilities). Work has started in the domain of the semantic web which tries to solve this problem by annotating web pages with semantic information. A crucial aspect to the success of the semantic web is that we have methods available to create, integrate and use this semantic information. In this paper, we present a new approach to generate semantic information by taking the annotation process to a conceptual level and by integrating it into an existing website design method.\\nWorld Wide Web\\nWeb intelligence\\nInformation retrieval\\nSemantic Web Stack\\nComputer science\\nWeb standards\\nData Web\\nSemantic Web\\nSemantic analytics\\nSocial Semantic Web\\nSemantic computing',\n",
       " 445523: 'Describing speech styles using prosody: a pilot study.\\nYear: 1995\\n#Citations: 1\\nConference\\n\\nProsody\\nComputer science\\nSpeech recognition',\n",
       " 446831: 'Spectral clustering as an automated SOM segmentation tool\\nYear: 2011\\n#Citations: 5\\nConference\\nSpringer, Berlin, Heidelberg\\nA powerful method in knowledge discovery and cluster extraction is the use of self-organizing maps (SOMs), which provide adaptive quantization of the data together with its topologically ordered lower-dimensional representation on a rigid lattice. The knowledge extraction from SOMs is often performed interactively from informative visualizations. Even though interactive cluster extraction is successful, it is often time consuming and usually not straightforward for inexperienced users. In order to cope with the need of fast and accurate analysis of increasing amount of data, automated methods for SOM clustering have been popular. In this study, we use spectral clustering, a graph partitioning method based on eigenvector decomposition, for automated clustering of the SOM. Experimental results based on seven real data sets indicate that spectral clustering can successfully be used as an automated SOM segmentation tool, and it outperforms hierarchical clustering methods with distance based similarity measures.\\nHierarchical clustering\\nCanopy clustering algorithm\\nFuzzy clustering\\nData mining\\nClustering high-dimensional data\\nData stream clustering\\nCorrelation clustering\\nComputer science\\nConsensus clustering\\nCluster analysis',\n",
       " 449364: 'Optimal Link Bombs are Uncoordinated.\\nYear: 2005\\n#Citations: 33\\nConference\\n\\nComputer science\\nDistributed computing',\n",
       " 450079: 'Automatic Generation of Robot Applications Using a Knowledge Integration Framework\\nYear: 2010\\n#Citations: 9\\nConference\\nVDE\\nThis article describes an integrated approach for the handling and modeling of knowledge for assembly processes in an automated production environment. High-level information on the process provided by the user needs to be transferred into executable code. This is informal information and might be even available in natural language. With the help of several information sources like CAD or sensor data, device and skill descriptions, planning algorithms, process knowledge and finally domain knowledge the Knowledge Integration Framework derives a formal application description. Therefore, the user input is parsed and analyzed with all the relevant knowledge made available in a formal representation beforehand. With the help of computer-based reasoning and inference algorithms the input is evaluated and enhancements for missing information are requested from the user. The core part of the implementation is to capture and to enable access to the available knowledge. Without a proper representation of all process and operation details the Knowledge Integration Framework cannot perform this challenging work. The formal application description is fed into the code generator where device-specific code together with the execution sequence is created. On runtime these executable programs - after deployment to the physical devices - are iteratively readapted taking strategies for safety and error recovery into account. This work promises a strong potential for realizing future robot installations in a robust and efficient way, taking into account a dynamic environment and human robot cooperation with respect to safe task execution and human injury prevention.\\nKnowledge integration\\nDomain knowledge\\nSoftware engineering\\nInference\\nComputer science\\nCode generation\\nTheoretical computer science\\nNatural language\\nParsing\\nRobot\\nExecutable',\n",
       " 451916: 'Coordinating Self Interested Autonomous Planning Agents.\\nYear: 2005\\n#Citations: 2\\nConference\\n\\nComputer science\\nHuman–computer interaction\\nArtificial intelligence\\nMachine learning',\n",
       " 456073: 'Interpreting Specialization in Type Theory.\\nYear: 1999\\n#Citations: 1\\nConference\\n\\nHindley–Milner type system\\nSimply typed lambda calculus\\nTyped lambda calculus\\nComputer science\\nAlgorithm\\nType theory\\nTheoretical computer science\\nEpistemology\\nPure type system\\nDependent type\\nType constructor\\nCurry–Howard correspondence',\n",
       " 458772: 'Understanding Collaborations in Virtual World\\nYear: 2010\\n#Citations: 3\\nConference\\n\\nVirtual worlds (VW) have paved a new and important channel for workplace collaborations. However, analysts have noted that several organizations that made a strong entrance into using VW as a nouveau channel for communication and collaboration are stepping back due to limited user response. Motivated by this fact, we propose a trust-theoretic ‘virtual world collaboration model’ for collaborations in virtual worlds. The model, grounded in literature on ‘technology adoption’ and ‘trust’, theoretically examines the role of trust in motivating users for using this rich virtual communication medium for collaborations. Results establish the important roles of perceived social presence and perceived structural assurance for fostering user trust in VW. Further, results also indicate that user trust is significantly related to both extrinsic and intrinsic motivations, which in turn influence the behavioural intention to use the VW. Implications for research and practice are discussed.\\nMetaverse\\nComputer science\\nKnowledge management\\nCommunication channel\\nVirtual communication\\nInstrumental and intrinsic value',\n",
       " 460272: 'Application of Modal Analysis for Extraction of Geometrical Features of Biological Objects Set.\\nYear: 2008\\n#Citations: 4\\nConference\\n\\nGeometric data analysis\\nComputer vision\\nPattern recognition\\nBiological objects\\nArtificial intelligence\\nEngineering\\nModal analysis',\n",
       " 463804: 'RP is Small in SUBEXP else ZPP equals PSPACE and NP equals EXP\\nYear: 2003\\n#Citations: 0\\nJournal\\nElectronic Colloquium on Computational Complexity\\nWe use recent results on the hardness of  :[8],\"random strings, to prove that RP is small in  :[18],\"ZPP=PSPACE and  :[21],\"also prove that if NP is not small in SUBEXP,  :[32],\"improving a former result which held for the measure on E.\\nDiscrete mathematics\\nCombinatorics\\nPSPACE\\nMathematics',\n",
       " 465329: 'Key requirements for integrating usability engineering and software engineering\\nYear: 2011\\n#Citations: 5\\nConference\\nSpringer, Berlin, Heidelberg\\nTo improve the integration between Software Engineering (SE) and Usability Engineering (UE) this paper identifies areas of overlap and develops proposals for their integration. The focus is on key requirements that were derived using semi-structured interviews and questionnaires. The principles and activities in the standards ISO 13407 and ISO/PAS 18152 were concretized to establish specific quality aspects. The identified requirements provide a foundation for systematic modification of existing development processes with established best practices from both disciplines.\\nProcess definition\\nBest practice\\nQuality of analytical results\\nSoftware engineering\\nComputer science\\nUsability engineering\\nProcess modeling\\nRequirements engineering',\n",
       " 469256: 'On Enumerating All Maximal Bicliques of Bipartite Graphs.\\nYear: 2010\\n#Citations: 8\\nConference\\n\\nDiscrete mathematics\\nComplete bipartite graph\\nCombinatorics\\nForbidden graph characterization\\nComputer science\\nBipartite graph\\nCograph\\nPathwidth\\nTriangle-free graph\\nDense graph\\nMaximal independent set',\n",
       " 471352: 'A note on the tree graph of a set of points in the plane.\\nYear: 1997\\n#Citations: 1\\nConference\\n\\nGeometric graph theory\\nDiscrete mathematics\\nIncidence structure\\nCombinatorics\\nK-ary tree\\nTree decomposition\\nEuclidean minimum spanning tree\\nSPQR tree\\nGomory–Hu tree\\nPlanar graph\\nMathematics',\n",
       " 475113: 'P2P Systems in Legal Networks: Another \"Small World\" Case\\nYear: 2007\\n#Citations: 7\\nConference\\nACM Press\\nThe “small world”-paradigm oers a new interesting viewpoint for the analysis of contemporary legal networks and artificial intelligence. This topological approach sheds further light on such dierent fields as case-based legal reasoning, knowledge discovery in legal databases, or legal ontologies, as far as clustering coecients, diameter and hubs of the network are involved. Moreover, empirical evidence shows that even P2P systems as Gnutella present small world-features. So it becomes possible to deepen our understanding of how spontaneous communities organize themselves in the network. While opening new horizons in the field of recommender systems, it also widens our perspective in dealing with such important issues as privacy and digital copyright.\\nRecommender system\\nData science\\nOntology (information science)\\nLegal reasoning\\nData mining\\nEmpirical evidence\\nComputer science\\nKnowledge management\\nKnowledge extraction\\nCluster analysis',\n",
       " 480214: 'Improving content management: a semantic approach\\nYear: 2008\\n#Citations: 1\\nJournal\\nActa Cybernetica\\nPublic administration institutions - as well as citizens and businesses - have to meet challenges of the constantly changing business and legal environment. The complexity and quantity of information to be faced with by these actors is increasing at an alarming rate. Research and development projects must turn to the development of innovative, modern technologies which enable citizens and businesses to access, understand and apply complex information easily. Ontology-based content management systems can contribute to the improvement of quality and effectiveness of significant processes, requiring the application of complex information, within the public administration or in a corporation. Compared to traditional content management systems, these systems can support further functions, such as semantic enabled search, explication of relations between documents, drafting of new documents, and version management, as well. Ontologies, in addition to the definition of concepts, support the most detailed and complete exploration of semantic relations between the concepts of a given domain.\\nOntology (information science)\\nOntology\\nCorporation\\nSemantic technology\\nComputer science\\nDocument management system\\nKnowledge management\\nContent management\\nContent management system\\nExplication',\n",
       " 482782: 'Antenna Array Receiver Using Channel Estimation in an M-ary Orthogonal DS/CDMA System.\\nYear: 2000\\n#Citations: 0\\nConference\\n\\nAntenna measurement\\nComputer science\\nSensor array\\nCommunication channel\\nAntenna array\\nReal-time computing\\nElectronic engineering\\nCode division multiple access',\n",
       " 487783: 'TOWARDS AN EXTENDED ALIGNMENT MODEL FOR A COMPLETE ALIGNMENT OF MANUFACTURING INFORMATION SYSTEMS\\nYear: 2008\\n#Citations: 2\\nConference\\n\\nInformation system\\nData mining\\nSoftware engineering\\nComputer science',\n",
       " 489504: 'Research of Intelligent Evacuation System\\nYear: 2013\\n#Citations: 0\\nConference\\nSpringer Berlin Heidelberg\\nDesign a system that combines the professional intelligent evacuation system and GIS (Geographic Information Systems), which can dynamically guide people to leave the fire site in the shortest time through a safe route according to instantaneity situation.\\nGeographic information system\\nComputer science\\nComputer security',\n",
       " 490186: 'A Survey on Reduction of Load on the Network\\nYear: 2015\\n#Citations: 0\\nJournal\\nSpringer, Cham\\nThe following research paper emphasizes on ever increasing load on networks vitally due to the presence of web crawlers and inefficient search mechanisms. Consequently, a lot of research has been done already but no feasible solution has been found yet. The following research paper tries to find out the possible loopholes by surveying previous researches so that one can come up with a more practicable and workable approach to lessen the load on the network.\\nHypertext\\nAnalytical chemistry\\nSoftware engineering\\nComputer science\\nSoftware agent\\nWeb crawler',\n",
       " 490876: 'Computing the Split Points for Learning Decision Tree in MapReduce\\nYear: 2013\\n#Citations: 4\\nConference\\nSpringer, Berlin, Heidelberg\\nThe explosive growth of Data is bringing more and more challenges and opportunities to data mining. In data mining, learning decision tree is a common method, in which determining split points is the key problem. Existing methods of calculating split points in the distributed setting on large data either (1) cause high communication overhead or (2) are not universal for different levels of skewness of data distribution. In this paper, we study the properties of Gini impurity, which is a measure for determining split points, and design new algorithms for calculating split points in MapReduce. Empirical evaluation demonstrates that our method outperforms existing state-of-the-art techniques on communication cost and universality.\\nDecision tree\\nData mining\\nSkewness\\nComputer science\\nExplosive material\\nArtificial intelligence\\nID3 algorithm\\nUniversality (philosophy)\\nDecision tree learning\\nMachine learning\\nIncremental decision tree',\n",
       " 493721: 'On mining closed sets in multi-relational data\\nYear: 2007\\n#Citations: 28\\nConference\\nMorgan Kaufmann Publishers Inc.\\nWe investigate the problem of mining closed sets in multi-relational databases. Previous work introduced different semantics and associated algorithms for mining closed sets in multirelational databases. However, insight into the implications of semantic choices and the relationships among them was still lacking. Our investigation shows that the semantic choices are important because they imply different properties, which in turn affect the range of algorithms that can mine for such sets. Of particular interest is the question whether the seminal LCM algorithm by Uno et al. can be upgraded towards multi-relational problems. LCM is attractive since its run time is linear in the number of closed sets and it does not need to store outputs in order to avoid duplicates. We provide a positive answer to this question for some of the semantic choices, and report on experiments that evaluate the scalability and applicability of the upgraded algorithm on benchmark problems.\\nRelational database\\nComputer science\\nClosed set\\nArtificial intelligence\\nMachine learning\\nSemantics\\nScalability',\n",
       " 499447: 'An Empirical Analysis of the Complexity of Model-Based Diagnosis\\nYear: 2006\\n#Citations: 2\\nConference\\nIOS Press\\nWe empirically study the computational complexity of diagnosing systems with real-world structure. We adopt the structure specified by a small-world network, which is a graphical structure that is common to a wide variety of naturally-occurring systems, ranging from biological systems, the WWW, to human-designed mechanical systems. We randomly generate a suite of digital circuit models with small-world network structure, and show that diagnosing these models is computationally hard.\\nData mining\\nDigital electronics\\nSuite\\nComputer science\\nRanging\\nArtificial intelligence\\nMachine learning\\nMechanical system\\nComputational complexity theory\\nNetwork structure',\n",
       " 502452: 'A search-engine concept based on multi-feature vectors and spatial relationship\\nYear: 2011\\n#Citations: 10\\nConference\\nSpringer, Berlin, Heidelberg\\nAt present a great deal of research is being done in different aspects of Content-Based Image Retrieval System (CBIR). Unfortunately, these aspects are mostly analysed separately. We propose how to put together vectors of features for segmented objects and a spatial relationship of the objects. To achieve this goal we have constructed a search engine taking into account multi-set data mining and object spatial relationship. Additionally, we have constructed a graphical user interface (GUI) to enable the user to build a query by image. The efficiency of our system will be evaluated in the near future. In this paper we present the search engine for our CBIR.\\nData mining\\nFeature vector\\nSearch engine\\nInformation retrieval\\nComputer science\\nSpatial relationship\\nImage retrieval\\nGraphical user interface',\n",
       " 335544: 'Elementary coupled cellular automata with memory\\nYear: 2008\\n#Citations: 3\\n\\n\\nCellular automaton\\nMobile automaton\\nComputer science\\nTheoretical computer science\\nStochastic cellular automaton',\n",
       " 336255: 'Discovering Inclusion and Approximate Dependencies in Relational Databases.\\nYear: 1999\\n#Citations: 0\\n\\n\\nRelational calculus\\nConjunctive query\\nInformation retrieval\\nRelational database\\nComputer science\\nFunctional dependency\\nDatabase theory\\nRelational model\\nCandidate key\\nDependency theory (database theory)',\n",
       " 337358: 'Farming als Methode zur Parallelisierung komplexer Algorithmen auf Transputer- und Workstation-Cluster\\nYear: 1994\\n#Citations: 0\\n\\nSpringer, Berlin, Heidelberg\\nDie Extrahierung der wesentlichen Informationen aus einem Grauwertbild mit Hilfe eines Neuronalen Netzes ist ein Beispiel aus der Klasse der komplexen Algorithmen [5]. Dieser Algorithmus besteht im wesentlichen aus Matrizen- und Vektor Operationen, deren sequentielle Abarbeitung sehr zeitaufwendig, die Parallelisierung jedoch recht einfach moglich ist.\\nTransputer\\nComputer science\\nOperating system',\n",
       " 341064: 'Functional Compatibility and the Law: From the Necessity of Clean Room Development of Computer Software to the Copyrightability of Computer Hardware.\\nYear: 1988\\n#Citations: 0\\n\\n\\nComputer software\\nCompatibility (mechanics)\\nHardware compatibility list\\nSoftware engineering\\nEngineering',\n",
       " 344196: 'Algebraic, Operational and Denotational Semantics of the Lambda Calculus.\\nYear: 1984\\n#Citations: 1\\n\\n\\nDenotational semantics of the Actor model\\nOperational semantics\\nProgramming language\\nNormalisation by evaluation\\nSimply typed lambda calculus\\nAlgebra\\nTyped lambda calculus\\nComputer science\\nAction semantics\\nDenotational semantics\\nChurch encoding',\n",
       " 350626: 'Organizando Processos de Requisitos.\\nYear: 1998\\n#Citations: 3\\n\\n\\nResumo Considerando que a definicao e a documentacao de processos e um ponto importante para a gerencia de requisitos o presente artigo propoe um esquema basico para organizacao de processos de requisitos, cuja enfase esta na descricao de padroes. Organizando os processos em tres tipos (padrao de processo, processo padrao e processo solucao) procuramos fornecer informacoes sob tres pontos de vista, de modo a facilitar a aplicacao e adaptacao de processos. Como damos enfase nas descricoes de padroes de processo, os apresentamos em diferentes niveis de abstracao (padrao individuo, padrao em familia e padrao em comunidade). Nas descricoes de processos utiliza-se a ideia do LAL; a ideia de hipertexto; e estrutura-se mais a linguagem natural que descreve os padroes. Palavras-chave: padroes de processo, processo, requisitos, padroes.',\n",
       " 378968: 'Stable sorting and merging with optimal space and time bounds.\\nYear: 1974\\n#Citations: 1\\n\\nStanford University\\nThis work introduces two algorithms for stable merging and stable sorting of files. The algorithms have optimal worst case time bounds, the merge is linear and the sort is of order n log n. Extra storage requirements are also optimal, since both algorithms make use of a fixed number of pointers. Files are handled only by means of the primitives exchange and comparison of records and basic pointer transformations.\\nMerge algorithm\\nPointer (computer programming)\\nTimsort\\nComputer science\\nsort\\nSpacetime\\nTheoretical computer science\\nSorting\\nExternal sorting\\nBlock sort',\n",
       " 384603: 'QoS Guaranteed SIP Communication Service by Bandwidth Reservation At Edge.\\nYear: 2004\\n#Citations: 0\\n\\n\\nMobile QoS\\nComputer science\\nComputer network\\nQuality of service\\nBandwidth reservation\\nDistributed computing',\n",
       " 392052: 'An Approach to Reduce False Alarms in an Intrusion Detection System.\\nYear: 2005\\n#Citations: 0\\n\\n\\nComputer science\\nReal-time computing\\nAnomaly-based intrusion detection system\\nIntrusion detection system',\n",
       " 396995: 'Statistical Information Resource Discovery and Retrieval Using Statistical Metadata.\\nYear: 1998\\n#Citations: 0\\n\\n\\nData science\\nMetadata\\nInformation retrieval\\nComputer science',\n",
       " 406557: 'Tight integration on one document: the programming environment\\nYear: 1996\\n#Citations: 0\\n\\nSpringer-Verlag New York, Inc.\\nInformation retrieval\\nComputer science',\n",
       " 408374: 'Fuzzy-based Adaptive Replication Mechanism in Desktop Grid Systems.\\nYear: 2008\\n#Citations: 0\\n\\n\\nComputer science\\nFuzzy logic\\nGrid system\\nDistributed computing',\n",
       " 415342: 'Integration von Legacy-Anwendungen durch eine Beobachter-Architektur.\\nYear: 2009\\n#Citations: 0\\n\\n',\n",
       " 419665: 'Non-Linear 2D and 3D Registration Using Block-Matching and B-Splines\\nYear: 2005\\n#Citations: 7\\n\\nSpringer, Berlin, Heidelberg\\nWe developed a non-linear registration technique to align images that feature anatomical variabilities. The algorithm is based on a block-matching technique that identifies a sparse displacement vector field from the iconic features of two images. Subsequently, the displacement vectors are used as sampling points to estimate a parametric non-linear transformation that is represented by a tensor product of B-Splines. The B-Spline transformation estimation approximates the correspondences while minimizing the second order derivatives in the transformation function. The block-matching and the transformation estimation are then iterated in a multiscale framework to improve robustness and accuracy. Experiments on 2D histological slices and 3D MR images show qualitatively good results.\\nSpline (mathematics)\\nTensor product\\nComputer vision\\nTransformation (function)\\nComputer science\\nAlgorithm\\nRobustness (computer science)\\nParametric statistics\\nSampling (statistics)\\nArtificial intelligence\\nIterated function\\nDisplacement (vector)',\n",
       " 427331: 'A systematic review on metrics for usability evaluation.\\nYear: 2009\\n#Citations: 0\\n\\n\\nSoftware engineering\\nUsability engineering\\nComputer science\\nUsability',\n",
       " 433966: 'LogicSQL: Augmenting SQL with Logic.\\nYear: 1994\\n#Citations: 1\\n\\n\\nSQL\\nPL/SQL\\nProgramming language\\nComputer science\\nLanguage Integrated Query\\nDatabase',\n",
       " 440308: 'An Introduction to Time Series Forecasting for CPE.\\nYear: 1991\\n#Citations: 1\\n\\n\\nEconometrics\\nTime series\\nComputer science',\n",
       " 441923: 'MVS/ESA SMF & RMF Measurements: What are they Good for?\\nYear: 1991\\n#Citations: 0\\n\\n\\nRemote sensing\\nPhysics',\n",
       " 449591: 'Implementing Tuple Space with Threads.\\nYear: 1997\\n#Citations: 4\\n\\n\\nThe development of efficient and portable parallel programming systems can be a complex and troublesome task. Although there are several portable environments that are meant to be used as a support layer for higher level programming systems, they all provide different features and different levels of functionality to the system programmer. In this paper we report on our experience implementing a tuple space library, called OpenTS, on top of two portable environments: the MPI message passing interface and the Panda virtual machine. We discuss the difficulties encountered when implementing OpenTS on both systems, and how the availability/lack of some features affected the flexibility, elegance, and refinement of the overall tuple space implementation. In particular, we focus on the system support that is required to build the sophisticated OpenTS run-time system module that supports different tuple distribution policies based on programmer annotations. Experimental results of OpenTS collected on a cluster of workstations using Panda and MPI are presented. The comparison of these performance numbers shows the practical impact of both environments on the overall performance of a higher level programming system.\\nTuple space\\nProgramming language\\nProgrammer\\nVirtual machine\\nComputer science\\nTuple\\nWorkstation\\nThread (computing)\\nMessage Passing Interface',\n",
       " 461413: 'Beyond user acceptance: The determinants of the intention to produce user created contents on the internet\\nYear: 2009\\n#Citations: 0\\n\\n\\nThis paper summarizes an empirical investigation that explored biased project reporting by Information Systems (IS) professionals. The study is based on a survey of 91 professionals who were involved with system implementations in various governmental agencies. Our investigation assessed the impact of project importance, control, structure, and size on biasing behaviors. To formulate the research hypotheses for our study, we adopted a Message Exchange Perspective. The results reveal that IS professionals are more likely to bias their project status communications when working in projects that are (1) large, (2) important, and (3) lack controls. The practical and research implications of our findings are discussed.\\nInformation system\\nKnowledge management\\nImplementation\\nBusiness\\nThe Internet',\n",
       " 473870: 'Software Architectures Supporting Tailor-Made Look and Feel of Customized Applications\\nYear: 1991\\n#Citations: 0\\n\\nNorth-Holland Publishing Co.\\nComputer architecture\\nLook and feel\\nSoftware engineering\\nSoftware architecture description\\nComputer science\\nResource-oriented architecture\\nComponent-based software engineering\\nSoftware construction\\nSoftware development\\nSoftware framework\\nSocial software engineering',\n",
       " 477134: 'Partial order reduction: linear and branching temporal logics and process algebras\\nYear: 1997\\n#Citations: 45\\n\\nAMS Press, Inc.\\nAlgebra\\nAbsorption law\\nPartial order reduction\\nMathematics\\nBranching (version control)',\n",
       " 496663: 'Modeling and Control of DSTATCOM for Voltage Sag.\\nYear: 2003\\n#Citations: 2\\n\\n\\nControl theory\\nComputer science\\nVoltage sag',\n",
       " 499848: 'Ripple Effects: Small-Scale Investigations into the Sustainability of Ocean Science Education Networks\\nYear: 2013\\n#Citations: 0\\n\\nSpringer Berlin Heidelberg\\nEducation Networks are an important way for educational institutions to develop and share knowledge and resources. Yet, methods of evaluating what makes them successful have been elusive. Here, we present a network analysis of the New England Ocean Science Education Collaborative (NEOSEC), a successful ocean science literacy collaborative and an effort to reveal characteristics inherent to successful education networks. NEOSEC is a network comprised of more than 40 institutions, with a stated goal of advancing ocean literacy in the region. Analysis of the evolution of this network suggests that network analysis adds an important dimension to evaluating education networks, and that successful educational networks may exhibit network characteristics that could aid in understanding their functionality and sustainability. Preliminary results also indicate that as these networks increase in complexity they may exhibit characteristics of other kinds of complex networks.\\nLiteracy\\nData science\\nEnvironmental resource management\\nEigenvector centrality\\nEnvironmental science\\nComplex network\\nNetwork analysis\\nOcean science\\nSustainability',\n",
       " 503857: 'Utility function induced by fuzzy target in probabilistic decision making\\nYear: 2006\\n#Citations: 1\\n\\nSpringer, Berlin, Heidelberg\\nIt is widely accepted that a common precept for the choice under uncertainty is to use the expected utility maximization principle, which was established axiomatically. Recently, a formal equivalence between this principle of choice and the target-based principle, that suggests that one should select an action which maximizes the (expected) probability of meeting a (probabilistic) uncertain target, has been established and extensively discussed. In this paper, we discuss the issue of how to bring fuzzy targets within the reach of the target-based model for a class of decision making under uncertainty problems. Two methods for inducing utility functions from fuzzy targets are discussed and illustrated with an example taken from the literature.\\nMathematical economics\\nEquivalence principle\\nExpected utility hypothesis\\nFuzzy logic\\nRough set\\nProbabilistic logic\\nDynamic and formal equivalence\\nMathematics\\nMaximization\\nPrecept',\n",
       " 505292: 'Product of Gaussians as a distributed representation for speech recognition\\nYear: 2003\\n#Citations: 0\\nConference\\nISCA\\nPattern recognition\\nComputer science\\nSpeech recognition\\nSpeaker recognition\\nNatural language processing\\nArtificial intelligence\\nDistributed representation',\n",
       " 505803: 'Impact of Admission and Discharge Peak Times on Hospital Overcrowding\\nYear: 2011\\n#Citations: 18\\nJournal\\nIOS Press BV\\nThe ability of hospital staff to get a patient to the right bed at the right time is dependent on bed occupancy, and is a key issue in all acute hospitals. This paper seeks to identify the impact of admission and discharge timing on hospital occupancy with reference to the peak in daily admissions and discharges. Patient admissions data from 23 Queensland public hospitals was classified into categories based on the relative timing of daily admission and discharge curves. We found statistically significant differences in mean and peak occupancy and patient length of stay between categories (one-way univariate ANOVA p0.0001). The results support early patient discharge initiatives to reduce hospital occupancy rates.\\nOvercrowding\\nOccupancy\\nMedical emergency\\nUnivariate\\nBed Occupancy\\nMedicine',\n",
       " 506156: 'Support for guideline development through error classification and constraint checking.\\nYear: 2002\\n#Citations: 21\\nConference\\nAmerican Medical Informatics Association\\n :[0],\"guidelines aim to eliminate clinician errors, reduce practice variation, and promote best medical practices. Computer-interpretable :[0],\"guidelines (CIGs) can deliver patient-specific advice during clinical encounters, which makes them more likely to affect clinician behavior than narrative guidelines. To reduce the number of errors that are introduced while developing narrative :[0],\"guidelines and CIGs, we studied the process used by the ACP-ASIM to develop clinical algorithms from narrative guidelines. We analyzed how changes progressed between subsequent versions of an algorithm and between a narrative guideline and its derived clinical algorithm. We recommend procedures that could limit the number of errors produced when generating clinical algorithms. In addition, we developed a tool for authoring CIGs in GLIF3 format and validating their syntax, data type matches, cardinality constraints, and structural integrity constraints. We used this tool to author :[0],\"guidelines and to check them for errors.\\nData mining\\nComputer science\\nCardinality\\nNarrative\\nData type\\nNatural language processing\\nArtificial intelligence\\nGuideline\\nSyntax\\nStructural integrity',\n",
       " 510479: 'Modeling technological limitations in all-optical networks.\\nYear: 2001\\n#Citations: 0\\nConference\\n\\nAll optical\\nComputer science\\nDistributed computing',\n",
       " 511318: 'Social Media Strategy and Capacity for Consumer Co-Creation Among Destination Marketing Organizations\\nYear: 2013\\n#Citations: 19\\nConference\\nSpringer, Berlin, Heidelberg\\nApplying the concept of absorptive capacity in the context of consumer integration for new product development in tourism, this study provided empirical support for the multidimensionality of capacity for consumer co-creation. Co-creation capacity consists of lower level capabilities, including explorative, transformative and exploitative capacity to turn consumer knowledge into consumer-centric products/services. It was identified that social media, in which consumers are increasingly participating in the knowledge exchange processes, is an important avenue for tourism organizations to nurture relationships with consumers that drive participation and integration. Social media strategy is shown to have a positive effect on capacity for co-creation, specifically the capability to process consumer knowledge into valuable assets. Finally, it was also identified that capacity for co-creation among tourism organizations has a positive impact on their performance.\\nCo-creation\\nSocial media\\nTransformative learning\\nNature versus nurture\\nTourism\\nAbsorptive capacity\\nMarketing\\nEmpirical research\\nNew product development\\nBusiness',\n",
       " 515036: 'Where are the really hard manipulation problems? the phase transition in manipulating the veto rule\\nYear: 2009\\n#Citations: 58\\nConference\\nMorgan Kaufmann Publishers Inc.\\nVoting is a simple mechanism to aggregate the preferences of agents. Many voting rules have been shown to be NP-hard to manipulate. However, a number of recent theoretical results suggest that this complexity may only be in the worst-case since manipulation is often easy in practice. In this paper, we show that empirical studies are useful in improving our understanding of this issue. We demonstrate that there is a smooth transition in the probability that a coalition can elect a desired candidate using the veto rule as the size of the manipulating coalition increases. We show that a rescaled probability curve displays a simple and universal form independent of the size of the problem. We argue that manipulation of the veto rule is asymptotically easy for many independent and identically distributed votes even when the coalition of manipulators is critical in size. Based on this argument, we identify a situation in which manipulation is computationally hard. This is when votes are highly correlated and the election is \"hung\". We show, however, that even a single uncorrelated voter is enough to make manipulation easy again.\\nPhase transition\\nVoting\\nComputer science\\nUncorrelated\\nIndependent and identically distributed random variables\\nArtificial intelligence\\nEmpirical research\\nMachine learning\\nVeto',\n",
       " 518915: 'OpenMP extensions for heterogeneous architectures\\nYear: 2011\\n#Citations: 5\\nConference\\nSpringer, Berlin, Heidelberg\\nModern architectures are becoming more heterogeneous. OpenMP currently has no mechanism for assigning work to specific parts of these heterogeneous architectures.We propose a combination of thread mapping and subteams as a means to give programmers control over how work is allocated on these architectures. Experiments with a prototype implementation on the Cell Broadband Engine show the benefit of allowing OpenMP teams to be created across the different elements of a heterogeneous architecture.\\nComputer architecture\\nThread mapping\\nArchitecture\\nComputer science\\nParallel computing\\nBroadband',\n",
       " 521312: 'DELTA - A Bottom-up Preprocessor for Top-Down Theorem Provers - System Abstract\\nYear: 1994\\n#Citations: 25\\nConference\\nSpringer-Verlag\\nTheorem provers\\nDiscrete mathematics\\nComputer science\\nTop-down and bottom-up design\\nAlgorithm\\nPreprocessor',\n",
       " 526827: 'On weight distributions of codes of planes of order 9.\\nYear: 2002\\n#Citations: 8\\nJournal\\n\\nDiscrete mathematics\\nMathematics',\n",
       " 529478: 'AN APPROACH FOR CLASS MODEL DEVELOPMENT\\nYear: 2010\\n#Citations: 1\\nConference\\n\\nThis paper aims to introduce an approach that can be used by both students and practitioners to develop a class model by analysing users’ documents. The approach is based on the concept of functional dependence and enables the use of the normalization technique in the field of object-oriented modelling. We believe that the normalization technique is applicable, useful and even essential in this field. The approach consists of six steps that lead the analyst through identifying identity attributes, determining functional dependences, defining associations between identity attributes, integrating the analyses, developing an initial class model, and completing the class model by using inheritance. Two documents of a hospitalization process are used as an example to implement the steps of this approach.\\nData mining\\nNormalization (statistics)\\nComputer science\\nArtificial intelligence\\nMachine learning',\n",
       " 531080: 'BOUNDS FOR THE RANGE OF A BIVARIATE POLYNOMIAL OVER A TRIANGLE\\nYear: 1998\\n#Citations: 11\\nJournal\\nSpringer\\nThe problem of finding an enclosure for the range of a bivariate polynomial p over the unit triangle is considered. The polynomial p is expanded into Bernstein polynomials. If p has only real coefficients the coefficients of this expansion, the so-called Bernstein coefficients, provide lower and upper bounds for the range. In the case that p has complex coefficients the convex hull of the Bernstein coefficients encloses the range. The enclosure is improved by subdividing the unit triangle into squares and triangles and computing enclosures for the range of p over these regions. It is shown that the sequence of enclosures obtained in this way converges to the convex hull of the range in the Hausdorff distance. Furthermore, it is described how the Bernstein coefficients on these regions can be computed economically.\\nDiscrete mathematics\\nMathematical optimization\\nCombinatorics\\nEnclosure\\nPolynomial\\nConvex hull\\nBernstein polynomial\\nHausdorff distance\\nMathematics\\nBivariate polynomials',\n",
       " 533918: 'SketchyDynamics: A Sketch-Based Library for the Development of Physics Simulation Applications\\nYear: 2013\\n#Citations: 0\\nConference\\nSpringer, Berlin, Heidelberg\\nSketch-based interfaces provide a powerful, natural and intuitive way for users to interact with an application. By combining a sketch-based interface with a physically simulated environment, an application offers the means for users to rapidly sketch a set of objects, like if they are doing it on piece of paper, and see how these objects behave in a simulation. In this paper we present SketchyDynamics, a library that intends to facilitate the creation of applications by rapidly providing them a sketch-based interface and physics simulation capabilities. SketchyDynamics was designed to be versatile and customizable but also simple. In fact, a simple application where the user draws objects and they are immediately simulated, colliding with each other and reacting to the specified forces, can be created with only 3 lines of code.\\nDynamical simulation\\nEntertainment\\nComputer science\\nGesture recognition\\nHuman–computer interaction\\nRigid body dynamics\\nSketch\\nSource lines of code',\n",
       " 537828: 'Inline evaluation of hybrid knowledge bases PhD description\\nYear: 2011\\n#Citations: 2\\nConference\\nSpringer-Verlag\\nThe deployment of knowledge representation formalisms to the Web has created the need for hybrid formalisms that combine heterogeneous knowledge bases. The aim of this research is to improve the reasoning efficiency over hybrid knowledge bases (KBs). The traditional way of reasoning over hybrid KBs is to use different underlying reasoners to access the different data sources, which causes overhead. To remedy this, we propose a new strategy, called inline evaluation, which compiles the whole hybrid KB into a new KB using only one single formalism. Hence we can use a single reasoner to do the reasoning tasks, and improve the efficiency of hybrid reasoning.\\nKnowledge representation and reasoning\\nSoftware deployment\\nSemantic reasoner\\nComputer science\\nDescription logic\\nTheoretical computer science\\nHybrid reasoning\\nArtificial intelligence\\nFormalism (philosophy)\\nLogic programming\\nRotation formalisms in three dimensions',\n",
       " 539049: 'Qualitative Reasoning about Perception and Belief.\\nYear: 1997\\n#Citations: 7\\nConference\\n\\nCognitive science\\nComputer science\\nArtificial intelligence\\nPerception\\nMachine learning\\nQualitative reasoning',\n",
       " 541011: 'Target Monitoring in Wireless Sensor Networks: A Localized Approach.\\nYear: 2010\\n#Citations: 7\\nJournal\\n\\nFixed wireless\\nSensor node\\nWireless network\\nKey distribution in wireless sensor networks\\nComputer science\\nComputer network\\nMobile wireless sensor network\\nElectro-optical sensor\\nWi-Fi array\\nWireless sensor network',\n",
       " 545983: 'Detection of vortical structures in 4D velocity encoded phase contrast MRI data using vector template matching\\nYear: 2013\\n#Citations: 2\\nConference\\nSpringer, Berlin, Heidelberg\\nWe present the Adaptive Vector Pattern Matching (AVPM) method, a novel method for the detection of vortical structures specifically designed for velocity encoded 4D PCMRI datasets. AVPM is based on vector pattern matching combined with robust orientation estimation. This combination provides for a simple yet robust algorithm, which is a priori axial flow invariant. We demonstrate these properties by comparing the performance of AVPM with Heibergu0027s Vector Pattern Matching algorithm.\\nString searching algorithm\\nPhase contrast microscopy\\nTemplate matching\\nPattern recognition\\nA priori and a posteriori\\nInvariant (mathematics)\\nArtificial intelligence\\nPattern matching\\nMathematics',\n",
       " 549212: 'The game ontology project: supporting learning while contributing authentically to game studies\\nYear: 2008\\n#Citations: 22\\nConference\\nInternational Society of the Learning Sciences\\nLearning research has argued the importance of providing authentic contexts for learning. However, traditional learning environments are often disconnected from external communities of practice. For example, students might design and carry out scientific experiments that are valuable pedagogically, but do not contribute to science itself. In this study, we used the Game Ontology Project (GOP), a wiki-enabled hierarchy of elements of gameplay used by games studies researchers, in a game design class. Students found it useful for learning. However, encouraging sustained participation was challenging because students tended to view the GOP as a static source, rather than a participatory and editable resource. Expert analysis of the studentu0027s contributions to the ontology found them to be useful and significant. We conclude with thoughts on the importance of these kinds of authentic environments in traditional learning.\\nExperiential learning\\nOntology\\nComputer science\\nKnowledge management\\nGame design\\nCitizen journalism\\nGame studies\\nHierarchy',\n",
       " 557224: 'On Efficient Distributed Elections in Clustered Chordal Rings.\\nYear: 1992\\n#Citations: 1\\nConference\\n\\nComputer science\\nChordal graph\\nParallel computing',\n",
       " 558092: 'Cryptanalysis of a New Efficient MAKEP for Wireless Communications\\nYear: 2005\\n#Citations: 4\\nJournal\\n\\nIn 2001, Wong and Chan proposed two mutual authentication and key exchange protocols (MAKEP) for low power wireless communications, which were suitable for establishing secure communications between a low-power wireless device and a powerful base station. Unfortunately, Shim pointed out Wong and Chan’s schemes were incurred the unknown key-shared attack, then he proposed an improved scheme to overcome this weakness. Later, Jan and Chen found that the improved scheme was vulnerable to the man-in-the-middle attack. Then, they also proposed a new efficient MAKEP in spirit of Girault’s method to withstand the above weakness. However, in this paper, we shall show that Jan and Chen’s scheme suffered from the forgery attack and the man-inthe-middle attack.\\nBase station\\nMutual authentication\\nWireless\\nKey exchange\\nComputer science\\nComputer security\\nComputer network\\nCryptanalysis',\n",
       " 558617: 'Methoden zu Unternehmensmodellierung\\nYear: 2007\\n#Citations: 0\\nJournal\\nVieweg Verlag\\nComputer science\\nKnowledge management',\n",
       " 562589: 'Ninth International Conference on Concurrency Theory 1998 - Editorial.\\nYear: 2002\\n#Citations: 0\\nJournal\\n\\nDiscrete mathematics\\nConcurrency\\nComputer science\\nOperations research\\nNinth\\nMathematics education',\n",
       " 562991: 'Datenverwaltung im Fertigungsbereich.\\nYear: 1980\\n#Citations: 3\\nJournal\\n\\nWorld Wide Web\\nSoftware engineering\\nComputer science',\n",
       " 563542: 'Prosody for Mandarin speech recognition: a comparative study of read and spontaneous speech.\\nYear: 2008\\n#Citations: 2\\nConference\\n\\nSpeech corpus\\nProsody\\nComputer science\\nViseme\\nChinese speech synthesis\\nMotor theory of speech perception\\nSpeech recognition\\nSpeech production\\nSpeech shadowing\\nSpeech technology',\n",
       " 567418: 'Design and Performance Analysis of a Simple OXC\\nYear: 2003\\n#Citations: 6\\nJournal\\n\\nOptical cross-connects are expected to be the key element in future optical transport networks. In this paper, a simple OXC architecture is proposed and its performance evaluated by means of simulations. The main advantage of the proposed design in front of previously reported structures consists in the absence of any tunable component. Obtained results show that the proposed device performance is close to that given by an OXC with full wavelength conversion capability.\\nWavelength-division multiplexing\\nOptical switch\\nComputer science\\nSimulation\\nElectronic engineering\\nWavelength conversion\\nDistributed computing',\n",
       " 570361: 'Colour laser scanner characterisation by enhanced LUT\\nYear: 2012\\n#Citations: 0\\nConference\\n\\nThis study investigated how to improve the accuracy of colour characterisation for a three-colour laser scanner, implemented by a lookup table (LUT) with interpolation. The transfer function was trained on a huge number of real and synthetic reflectance spectra, refined through statistical analysis. The lookup table enabled a u0027baselineu0027 matrix fitting to be enhanced through local deformations of 3D colour space to give optimal colorimetric performance.\\nLookup table\\nLaser scanning\\nComputer graphics (images)\\nComputer science\\nMatrix (mathematics)\\nInterpolation\\nTransfer function\\nReflectivity\\nStatistical analysis',\n",
       " 572518: 'Concurrent Engineering Tools for Product and Process Improvement in an Electronic Industry.\\nYear: 2003\\n#Citations: 1\\nConference\\n\\nConcurrent engineering\\nElectronic industry\\nComputer science\\nManufacturing engineering',\n",
       " 573701: 'Purpose-based access control policies and conflicting analysis\\nYear: 2010\\n#Citations: 3\\nConference\\nSpringer, Berlin, Heidelberg\\nThis paper proposes a purpose-based framework for supporting privacy preserving access control policies and mechanisms. The mechanism enforces access policy to data containing personally identifiable information. The key component of the framework is purpose involved access control models (PAC) that provide full support for expressing highly complex privacy-related policies, taking into account features like purposes and conditions. A policy refers to an access right that a subject can have on an object, based on attribute predicates, obligation actions, and system conditions. Policy conflicting problems may arise when new access policies are generated. The structure of purpose involved access control policy is studied, and efficient conflict-checking algorithms are developed. Finally a discussion of our work in comparison with other access control and frameworks such as EPAL is presented.\\nObligation\\nComputer science\\nComputer security\\nRole-based access control\\nAccess control\\nPersonally identifiable information\\nPredicate (grammar)',\n",
       " 574966: 'Organizational issues arising from the integration of the lexicon and concept network in a text understanding system\\nYear: 1991\\n#Citations: 10\\nConference\\nMorgan Kaufmann Publishers Inc.\\nA knowledge based system for text understanding will incorporate both lexical and encyclopaedic information. The lexical information is the basis of the parsing process while the encyclopaedic information forms the target representation and is used in the knowledge acquisition process. This paper describes TWIG, a text understanding system where these two knowledge bases arc integrated into one representation. There is some theoretical justification for this and it has the advantage of reducing duplication of information in the system. This integration also has the advantage of making conceptual information available during the parsing process. Most of all this integration of diverse information forms a natural basis for a blackboard architecture.\\nKnowledge integration\\nComputer science\\nBlackboard system\\nKnowledge-based systems\\nLexicon\\nArtificial intelligence\\nNatural language processing\\nParsing\\nKnowledge acquisition',\n",
       " 578238: 'Applying Information Retrieval for Market Basket Recommender Systems.\\nYear: 2009\\n#Citations: 0\\nConference\\n\\nRecommender system\\nData mining\\nWorld Wide Web\\nHuman–computer information retrieval\\nMarket basket\\nInformation retrieval\\nComputer science',\n",
       " 581576: 'A modified real AdaBoost algorithm to discover intensive care unit subgroups with a poor outcome.\\nYear: 2013\\n#Citations: 1\\nConference\\nAmerican Medical Informatics Association\\nThe Intensive Care Unit (ICU) population is heterogeneous. At individual ICUs, the quality of care may vary within subgroups. We investigate whether poor outcomes of an ICU can be traced back to excess deaths in specific patient subgroups, by discovering candidate subgroups, with a modified adaptive decision tree boosting algorithm applied to 80 Dutch ICUs. Genuine subgroups were selected from candidate subgroups when the case-mix adjusted outcomes were poorer than those of the five top performing ICUs. For 59 ICUs we discovered 122 genuine subgroups and most were defined by one to four variables, with a median of three [2–4]. Variables Glasgow Coma Scale and age were used most. There were 29 ICUs with overall poor outcomes, and for 22 our algorithm found all excess deaths. A new method based on adaptive decision tree boosting discovered many subgroups of ICU patients for which there is potentially room for outcomes improvement.\\nAdaboost algorithm\\nIntensive care unit\\nDecision tree\\nPopulation\\nBoosting (machine learning)\\nQuality of care\\nMedical emergency\\nGlasgow Coma Scale\\nMedicine',\n",
       " 582745: 'User Profiling Based on Keyword Clusters for Improved Recommendations\\nYear: 2014\\n#Citations: 1\\nConference\\nSpringer, Cham\\nRecommender Systems RS have risen in popularity over the years, and their ability to ease decision-making for the user in various domains has made them ubiquitous. However, the sparsity of data continues to be one of the biggest shortcomings of the suggestions offered. Recommendation algorithms typically model user preferences in the form of a profile, which is then used to match user preferences to items of their interest. Consequently, the quality of recommendations is directly related to the level of detail contained in these profiles. Several attempts at enriching the user profiles leveraging both user preference data and item content details have been explored in the past. We propose a method of constructing a user profile, specifically for the movie domain, based on user preference for keyword clusters, which indirectly captures preferences for various narrative styles. These profiles are then utilized to perform both content-based CB filtering as well as collaborative filtering CF. The proposed approach scores over the direct keyword-matching, genre-based user profiling and the traditional CF methods under sparse data scenarios as established by various experiments. It has the advantage of a compact user model representation, while at the same time capturing the essence of the styles or genres preferred by the user. The identification of implicit genres is captured effectively through clustering without requiring labeled data for training.\\nRecommender system\\nData mining\\nCollaborative filtering\\nUser profile\\nInformation retrieval\\nProfiling (computer programming)\\nComputer science\\nLevel of detail\\nUser modeling\\nCluster analysis\\nComputer user satisfaction\\nDistributed computing',\n",
       " 584704: 'Graph automata: the algebraic properties of abelian relational graphoids\\nYear: 2011\\n#Citations: 5\\nConference\\nSpringer Berlin Heidelberg\\nAutomata operating on arbitrary graphs were introduced in a previous paper by virtue of a particular instance of an abelian relational graphoid. As it is indicated in the same paper, in order to construct a graph automaton it is necessary and sufficient that the relations over the Kleene star of the state set constitute a graphoid. In this respect, various different versions of graph automata arise corresponding to the specific relational graphoid that is employed. We prove that the generation of an abelian graphoid by a set Q implies the partitioning of Q into disjoint abelian groups and vise versa.\\nGraph\\nDiscrete mathematics\\nAbelian group\\nCombinatorics\\nKleene star\\nDisjoint sets\\nAutomaton\\nAlgebraic properties\\nGraphoid\\nMathematics',\n",
       " 585590: 'Opportunistic, receiver-initiated data-collection protocol\\nYear: 2012\\n#Citations: 18\\nConference\\nSpringer, Berlin, Heidelberg\\nThis paper presents and evaluates ORiNoCo, a novel data-collection and event-reporting protocol for sensor networks. ORiNoCo is built upon the asynchronous duty-cycle protocol RI-MAC and breaks with the tradition of exchanging extensive neighborhood information, a cornerstone of many competing collection protocols and one of their major source of communication overhead and energy expenditure. The merit of this venture is an opportunistic, energy-efficient, latency-reducing, and self-stabilizing protocol. ORiNoCo comes at virtually no extra costs in terms of memory demand and communication overhead compared to RI-MAC. We derive theoretical boundaries for the improvements in radio efficiency, latency, and energy-consumption. ORiNoCo is verified with these findings via simulation and compared with CTP. ORiNoCo achieves lower energy-consumption while reducing end-to-end delays.\\nSensor node\\nData collection\\nAsynchronous communication\\nComputer science\\nLatency (engineering)\\nComputer network\\nCommunication source\\nEnergy expenditure\\nPacket loss\\nWireless sensor network',\n",
       " 591848: \"JSTOR: The Andrew W. Mellon Foundation's Journal Storage Project.\\nYear: 1996\\n#Citations: 0\\nConference\\n\\nOperations research\\nEngineering\\nLibrary science\",\n",
       " 598832: 'Cognitive modelling of event ordering reasoning in imagistic domains\\nYear: 2005\\n#Citations: 8\\nConference\\nMorgan Kaufmann Publishers Inc.\\nThe inference of temporal information from past event occurences in imagistic domains is relevant in several applications in knowledge engineering. In such applications, the order in which events have happened is imprinted in the domain as visual-spatial relations among its elements. Therefore, the interpretation of the relative ordering in which those events have occured is essential for understanding the domain evolution. We propose a cognitive model for event ordering reasoning within domains whose elements have been modified by past events. From the analysis of cognitive abilities of experts we propose new ontology constructs for knowledge modelling associated to Problem-Solving Methods. We illustrate the effectiveness of the model by means of an applications to an imagistic domain.\\nOntology\\nKnowledge modelling\\nInference\\nComputer science\\nArtificial intelligence\\nKnowledge engineering\\nCognitive model\\nCognition\\nMachine learning',\n",
       " 600256: 'Computing with planar toppling domino arrangements\\nYear: 2012\\n#Citations: 2\\nJournal\\nSpringer Netherlands\\nA method for implementing Boolean logic functions using arrangements of toppling dominoes is described. Logic functions are implemented using only lines of dominoes and fork junctions. Using a dual-rail representation for Boolean values, any desired combinational function can be implemented. Circuits constructed using this method have no timing or order constraints on their inputs and require no out-of-plane bridges for passing one line of dominoes over another. Since they are built using toppling dominoes, circuits can be used only once.\\nDomino logic\\nDiscrete mathematics\\nBoolean circuit\\nLogic gate\\nSequential logic\\nLogic optimization\\nAlgorithm\\nArithmetic\\nCombinational logic\\nBoolean algebra\\nLogic family\\nMathematics',\n",
       " 601150: 'Making Sense of Software Project Management: A case of knowledge sharing in software development\\nYear: 2010\\n#Citations: 8\\nJournal\\nDepartment of Mathematical Sciences, Aalborg University\\n�������� �������� �������� �������� ��������������� ���� ���� ���� ���������������� ���������� ��������� ������� ���������� �������� ������� ����� ������� �������� ������� ����� ������ ������� �������� �������� ����������� ����������� ��������� �������� �������� ��������� ��������� ���� �� �� � � � � � � � � � ��!�\"�!$ ��!� ������!���� ��!������$ � � ��� ���� ������ ����� ���� ������ �#���� ��������������\\nKnowledge sharing\\nKnowledge management\\nSoftware project management\\nEngineering\\nManagement science\\nSoftware development',\n",
       " 603151: 'A Teleo-Reactive Architecture for Fast, Reactive and Robust Control of Mobile Robots\\nYear: 2008\\n#Citations: 18\\nConference\\nSpringer, Berlin, Heidelberg\\nOne of the elementary tasks of an autonomous mobile robot is the execution of different behavior patterns in order to fulfill a given task. The complexity of this problem is especially high if the robot operates in a dynamic, unpredictable environment and requires the parallel control of multiple actuators. In this paper we present a novel architecture for robust and fast mobile robot control. The architecture is based on Teleo-Reactive Programs. We discuss the benefits and drawbacks of such programs, extend the basic definition for the parallel control of multiple actuators, and propose a new language and a compiler for extended Teleo-Reactive Programs. These tools simplify the creation of new behavior patterns and increase the runtime performance. Finally, we discuss implementation issues of the architecture when applying it to RoboCup Middle-Size soccer robots.\\nRobot control\\nAutonomous agent\\nArchitecture\\nComputer science\\nReal-time computing\\nCompiler\\nConstructed language\\nRobot\\nRobust control\\nMobile robot\\nDistributed computing',\n",
       " 604005: 'Planung und Steuerung dynamischer Kooperationsnetzwerke.\\nYear: 2001\\n#Citations: 0\\nJournal\\n\\nEngineering management\\nKnowledge management\\nEngineering',\n",
       " 605810: 'Responses to Social Predicament on Online Social Networks\\nYear: 2013\\n#Citations: 3\\nConference\\n\\nSocial network\\nComputer science\\nPublic relations\\nOnline participation\\nReciprocity (social psychology)',\n",
       " 607982: 'A Meta Knowledge Structure for Program Development Support.\\nYear: 1993\\n#Citations: 3\\nConference\\n\\nSystems engineering\\nComputer science\\nKnowledge management\\nKnowledge structure\\nProgram development',\n",
       " 609253: 'Protocols for Real Time Voice Communications on a Packet Local Network.\\nYear: 1986\\n#Citations: 7\\nConference\\n\\nEnd-to-end delay\\nComputer science\\nNetwork packet\\nComputer network\\nReal-time computing\\nLocal area network',\n",
       " 609973: 'The Use of a Touch-screen Computer for Dental Charting\\nYear: 1991\\n#Citations: 0\\nConference\\nSpringer, Berlin, Heidelberg\\nThis paper describes a computer software package which enables a dentist to maintain a database of patient records and to chart a patient’s teeth directly into the computer via a touch screen. The monitor screen can display all 32 adult teeth at once, or any of the four quadrants, or a single tooth. In this way it is possible to replace completely the usual paper records. However, at any given time, it is possible to obtain a print out of the patient’s dental chart and the other patient details, eg age, NHS number etc, at the touch of a key.\\nComputer software\\nData mining\\nFour quadrants\\nHuman–computer interaction\\nChart\\nMedicine',\n",
       " 610574: 'IT GOVERNANCE PRACTICES FOR IMPROVING STRATEGIC AND OPERATIONAL BUSINESS-IT ALIGNMENT\\nYear: 2011\\n#Citations: 9\\nConference\\n\\nThe literature suggests that business-IT alignment is an important antecedent of IS success, business process performance, and competitive advantage. Additionally, IT governance practices are highlighted as being instrumental to fostering business-IT alignment. In this paper, we derive various IT governance practices (in terms of structures, processes, relational mechanisms, and enterprise architecture characteristics) from literature and expert interviews. While prior investigations only considered the effect of such practices on strategic business-IT alignment, we also incorporate alignment at operational level. Using results from a case study in the IT services division of a large multi-national, multi-divisional company acting in diverse industries we highlight the effect of various IT governance practices and offer new insights by showing which mechanisms are effective in facilitating strategic or operational business-IT alignment. Our results indicate the most important practices for both strategic and operational alignment.\\nStrategic alignment\\nCorporate governance\\nEnterprise architecture\\nBusiness process\\nComputer science\\nCompetitive advantage\\nKnowledge management\\nBusiness-IT alignment\\nMarketing',\n",
       " 612668: 'Sparse vector linear prediction matrices with multidiagonal structure.\\nYear: 1999\\n#Citations: 0\\nConference\\n\\nPattern recognition\\nSystem of linear equations\\nComputer science\\nMatrix (mathematics)\\nSparse approximation\\nLinear prediction\\nArtificial intelligence',\n",
       " 614350: 'Prosodic pattern of utterance units in Japanese spoken dialogs.\\nYear: 1994\\n#Citations: 0\\nConference\\n\\nComputer science\\nUtterance\\nSpeech recognition',\n",
       " 615364: 'Detecting Sensor Signal Manipulations in Non-Linear Chemical Processes\\nYear: 2010\\n#Citations: 5\\nConference\\nSpringer, Berlin, Heidelberg\\nModern process control systems are increasingly vulnerable to subversion. Attacks that directly target production processes are difficult to detect because signature-based approaches are not well-suited to the unique requirements of process control systems. Also, anomaly detection mechanisms have difficulty coping with the non-linearity of industrial processes.\\nAnomaly detection\\nChemical process\\nDifficulty coping\\nNonlinear system\\nControl engineering\\nProcess control\\nEngineering',\n",
       " 618979: 'Fahrsimulation - Anforderungen an das Sichtsystem bei Daimler Benz\\nYear: 1991\\n#Citations: 0\\nConference\\nSpringer-Verlag',\n",
       " 621293: 'Abduction with hypotheses confirmation\\nYear: 2005\\n#Citations: 10\\nConference\\nMorgan Kaufmann Publishers Inc.\\nAbduction can be seen as the formal inference corresponding to human hypothesis making. It typically has the purpose of explaining some given observation. In classical abduction, hypotheses could be made on events that may have occurred in the past. In general, abductive reasoning can be used to generate hypotheses about events possibly occurring in the future (forecasting), or may suggest further investigations that will confirm or disconfirm the hypotheses made in a previous step (as in scientific reasoning). We propose an operational framework based on Abductive Logic Programming, which extends existing frameworks in many respects, including accommodating dynamic observations and hypothesis confirmation.\\nInference\\nComputer science\\nAbductive logic programming\\nArtificial intelligence\\nAbductive reasoning\\nMachine learning',\n",
       " 621425: 'Can we design artificial pedagogical agents to be intelligent enough to detect, model, and foster regulatory learning processes?\\nYear: 2011\\n#Citations: 1\\nConference\\nSpringer, Berlin, Heidelberg\\nSelf-regulated learning (SRL) involves a complex set of interactions between cognitive, metacognitive, motivational and affective processes. The key to understanding the influence of these self-regulatory processes on learning with open-ended, non-linear learning computerbased environments involves detecting, capturing, identifying, and classifying these processes as they temporally unfold during learning. Understanding the complex nature of these processes is key to building intelligent learning environments that are capable of adapting to the inherent fluctuations in learnersu0027 SRL processes and emerging understanding of the embedded educational content and related disciplinary knowledge. Recent developments in the use of and advances in the design of artificial pedagogical agents have begun to address these issues. However, we are still experiencing major theoretical, conceptual, methodological, and analytical challenges that may impede our ability to design more intelligent agents that are effectively and reliably able to detect, model, and foster learners SRL processes during learning. As such, the foci of this presentation are to: (1) introduce the complexity of SRL with current intelligent agent systems, (2) briefly present a hybrid theoretical model of SRL and describe how it can be used to analyze the temporally, unfolding sequences of processes during learning, (3) present and describe sample data to illustrate the nature and complexity of these processes and the various challenges they pose for designers and learners, and (4) present challenges for future research that combines several techniques and methods to design pedagogical agents and intelligent learning environments that effectively and reliably trace, model, and foster SRL.\\nIntelligent agent\\nFormal language\\nComputer science\\nDiscipline\\nMetacognition\\nHuman–computer interaction\\nArtificial intelligence\\nCognition\\nMachine learning\\nEducational content',\n",
       " 621898: 'A Dynamic Approach for the Online Knapsack Problem\\nYear: 2014\\n#Citations: 1\\nConference\\nSpringer, Cham\\nThe online knapsack problem (OKP) is a generalized version of the 0-1 knapsack problem (0-1KP) to a setting in which the problem inputs are revealed over time. Whereas the 0-1KP involves the maximization of the value of the knapsack contents without exceeding its capacity, the OKP involves the following additional requirements: items are presented one at a time, their features are only revealed at their arrival, and an immediate and irrevocable decision on the current item is required before observing the next one. This problem is known to be non-approximable in its general case. Accordingly, we study a relaxed variant of the OKP in which items delay is allowed: we assume that the decision maker is allowed to retain the observed items until a given deadline before deciding definitively on them. The main objective in this problem is to load the best subset of items that maximizes the expected value of the knapsack without exceeding its capacity. We propose an online algorithm based on dynamic programming, that builds-up the solution in several stages. Our approach incorporates a decision rule that identifies the most desirable items at each stage, then places the fittest ones in the knapsack. Our experimental study shows that the proposed algorithm is able to approach the optimal solution by a small error margin.\\nDecision rule\\nOnline algorithm\\nMathematical optimization\\nComputer science\\nChange-making problem\\nGeneralized assignment problem\\nContinuous knapsack problem\\nCutting stock problem\\nArtificial intelligence\\nKnapsack problem\\nMachine learning\\nPolynomial-time approximation scheme',\n",
       " 626168: 'Clustering and assessing the number of clusters with accelerated EM variant.\\nYear: 2007\\n#Citations: 0\\nConference\\n\\nData mining\\nCluster (physics)\\nComputer science\\nCluster analysis\\nSingle-linkage clustering',\n",
       " 628729: 'Evaluation of an alert system for selective dissemination of broadcast news\\nYear: 2003\\n#Citations: 9\\nConference\\n\\nThis paper describes the evaluation of the system for selective dissemination of Broadcast News that we developed in the context of the European project ALERT. Each component of the main processing block of our system was evaluated separately, using the ALERT corpus. Likewise, the user interface was also evaluated separately. Besides this modular evaluation which will be briefly mentioned here, as a reference, the system can also be evaluated as a whole, in a field trial from the point of view of a potential user. This is the main topic of this paper. The analysis of the main sources of problems hinted at a large number of issues that must be dealt with in order to improve the performance. In spite of these pending problems, we believe that having a fully operational system is a must for being able to address user needs in the future in this type of service.\\nBroadcasting\\nWorld Wide Web\\nComputer science\\nType of service\\nOperational system\\nModular design\\nUser interface\\nMultimedia\\nSpite',\n",
       " 630802: 'Preserving Mutual Interests in High Performance Computing Clusters.\\nYear: 1999\\n#Citations: 1\\nJournal\\n\\nComputer science\\nDistributed computing\\nHigh performance computing clusters',\n",
       " 636784: 'Evolving scheduling policies through a Genetic Programming framework\\nYear: 1999\\n#Citations: 1\\nConference\\nMorgan Kaufmann Publishers Inc.\\nIn this paper we investigate the potential use of GeneticProgramming for the solution of the one-machine totaltardiness problem, which has been the subject ofacademic research for almost four decades. To ourknowledge, no previous effort has been made to solvestatic scheduling problems in a GP-framework, in contrastto other evolutionary computation techniques that havebeen extensively used for this scope.\\nMathematical optimization\\nComputer science\\nScheduling (computing)\\nEvolutionary computation\\nGenetic programming',\n",
       " 637774: 'Checking Termination of Logic Programs with Function Symbols through Linear Constraints\\nYear: 2014\\n#Citations: 6\\nConference\\nSpringer, Cham\\nEnriching answer set programming with function symbols makes modeling easier, increases the expressive power, and allows us to deal with infinite domains. However, this comes at a cost: common inference tasks become undecidable. To cope with this issue, recent research has focused on finding trade-offs between expressivity and decidability by identifying classes of logic programs that impose limitations on the use of function symbols but guarantee decidability of common inference tasks. Despite the significant body of work in this area, current approaches do not include many simple practical programs whose evaluation terminates. In this paper, we present the novel class of rule-bounded programs. While current techniques perform a limited analysis of how terms are propagated from an individual argument to another, our technique is able to perform a more global analysis, thereby overcoming several limitations of current approaches. We also present a further class of cycle-bounded programs where groups of rules are analyzed together. We show different results on the correctness and the expressivity of the proposed techniques.\\nSignature (logic)\\nInference\\nComputer science\\nCorrectness\\nDecidability\\nTheoretical computer science\\nExpressive power\\nAnswer set programming\\nExpressivity\\nUndecidable problem',\n",
       " 642410: 'Using Orientation Code Difference Histogram (OCDH) for Robust Rotation-invariant Search.\\nYear: 2005\\n#Citations: 0\\nJournal\\n\\nHistogram\\nPattern recognition\\nInvariant (mathematics)\\nArtificial intelligence\\nMathematics',\n",
       " 646095: 'An Implementation of the Propositional Part of Krapfen, a Hybrid Knowledge Representation System.\\nYear: 1988\\n#Citations: 2\\nConference\\n\\nProcedural knowledge\\nKnowledge representation and reasoning\\nComputer science\\nArtificial intelligence\\nNatural language processing',\n",
       " 649244: 'Width of Points in the Streaming Model\\nYear: 2016\\n#Citations: 2\\nConference\\nSociety for Industrial and Applied Mathematics\\nIn this article, we show how to compute the width of a dynamic set of low-dimensional points in the streaming model. In particular, we assume that the stream contains both insertions of points and deletions of points to a set S, and the goal is to compute the width of the set S, namely the minimal distance between two parallel hyperplanes sandwiching the point set S.   Our algorithm (1 p e) approximates the width of the set S using space polylogarithmic in the size of S and the aspect ratio of S. This is the first such algorithm that supports both insertions and deletions of points to the set S: previous algorithms for approximating the width of a point set only supported additions [Agarwal et al. 2004; Chan 2006], or a sliding window [Chan and Sadjad 2006].   This solves an open question from the “2009 Kanpur list” of open problems in data streams, property testing, and related topics [Indyk et al. 2011].\\nDiscrete mathematics\\nData stream mining\\nCombinatorics\\nSliding window protocol\\nProperty testing\\nComputational geometry\\nHyperplane\\nPoint set\\nMathematics\\nCoreset',\n",
       " 649712: 'A Location Area Partitioning Strategy Using Genetic Algorithms for Mobile Location Tracking.\\nYear: 1999\\n#Citations: 0\\nJournal\\n\\nMobile location\\nComputer science\\nGenetic algorithm\\nDistributed computing',\n",
       " 658104: 'Hard real-time control using Simulink target for real-time Linux\\nYear: 2004\\n#Citations: 0\\nJournal\\n\\nComputer science\\nReal-time Control System\\nOperating system\\nEmbedded system',\n",
       " 658766: 'The Inverter Testing System of Asynchronous Motor Based on Modbus Communication\\nYear: 2011\\n#Citations: 0\\nConference\\nSpringer, Berlin, Heidelberg\\nThe inverter testing system of asynchronous motor is designed based on Modbus communication between Schindler ATV31 inverter and host computer. The measure and control of asynchronous motor are realized. The ATV31 inverter is tested by means of step response, sinusoid tracking response, braking response and low-speed response tests. The harmonic analysis of current and voltage of inverter output are completed. The results show that the measure and control system is stable and reliable. Meanwhile the harmonic components of inverter output reduce gradually with increasing load and output frequency.\\nStep response\\nInverter\\nInduction motor\\nComputer science\\nVoltage\\nHarmonic\\nElectronic engineering\\nHarmonic analysis\\nControl system\\nModbus\\nEmbedded system',\n",
       " 664311: 'Association Rules Mining Algorithm.\\nYear: 2005\\n#Citations: 1\\nConference\\n\\nData mining\\nComputer science\\nApriori algorithm\\nParallel computing\\nAssociation rule learning\\nData mining algorithm',\n",
       " 668708: 'The Plan4business Approach to Transfer Open Data into Real Estate Businesses\\nYear: 2013\\n#Citations: 1\\nConference\\nSpringer, Berlin, Heidelberg\\nSpatial planning data including urban, regional, spatial or zoning plans are not aggregated so far. Creating time series or comparative analyses on these data sets is not yet possible. The EU funded project Plan4business develops a service platform that can serve to users as a full catalogue of spatial planning data linked with other data sources such as statistics, OpenStreetMap, Urban Atlas and Corine Land Cover that are published as Open Data. The Plan4business platform will offer to clients not only the data itself in an integrated, harmonised and thus ready-to-use form, but also rich analysis and visualisation services via an API and an interactive web frontend. The users include mainly citizens, local authorities and real estate agencies. This paper introduces the problems of data integration and selected technical components of the Plan4business platform supporting data reuse and analysis.\\nData science\\nData integration\\nOpen data\\nZoning\\nReal estate\\nData set\\nSoftware engineering\\nSpatial planning\\nEngineering\\nMarketing\\nLand use\\nSpatial data infrastructure',\n",
       " 669189: 'Coping with System Complexity: Identifying Dichotomic Architectural Alternatives.\\nYear: 2007\\n#Citations: 0\\nJournal\\n\\nData science\\nComputer science\\nComputer security\\nCoping (psychology)',\n",
       " 669799: 'Collaborative decision making: an implementation of the Delphi approach in a social platform\\nYear: 2012\\n#Citations: 0\\nConference\\nIBM Corp.\\nAs enterprise use of social media platforms to support collaborative work continues to increase, studies that investigate the ways in which traditional group support systems can integrate with social media platforms are increasingly important. In this paper, we report on the results of a study in which we implemented a Delphi decision-making approach in SAP StreamWork, a web-based social media platform that supports social interaction and decision making. As with most social media systems, contributions by individuals in SAP StreamWork are shared immediately and attributed to the contributors. At first glance, these characteristics are at odds with the anonymity and iterative structure of the Delphi approach. We describe how we integrated the structured processes of the Delphi approach into the open collaboration model of SAP StreamWork and report on an evaluation of our system in which two groups used the resulting prototype tool for a real-life decision-making activity.\\nSocial relation\\nSocial media\\nComputer science\\nDelphi\\nKnowledge management\\nOpen collaboration\\nDelphi method\\nOdds\\nAnonymity\\nGroup decision-making',\n",
       " 670148: 'On Double Exponentiation for Securing RSA against Fault Analysis\\nYear: 2014\\n#Citations: 5\\nConference\\nSpringer, Cham\\nAt CT-RSA 2009, a new principle to secure RSA (and modular/group exponentiation) against fault-analysis has been introduced by Rivain. The idea is to perform a so-called double exponentiation to compute a pair (m d , m ϕ(N) − d ) and then check that the output pair satisfies the consistency relation: \\\\(m^d \\\\cdot m^{\\\\varphi(N)-d} \\\\equiv 1 \\\\bmod N\\\\). The author then proposed an efficient heuristic to derive an addition chain for the pair (d, ϕ(N) − d). In this paper, we revisit this idea and propose faster methods to perform a double exponentiation. On the one hand, we present new heuristics for generating shorter double addition chains. On the other hand, we present an efficient double exponentiation algorithm based on a right-to-left sliding window approach.\\nDiscrete mathematics\\nHeuristic\\nSliding window protocol\\nChinese remainder theorem\\nComputer security\\nModular design\\nResidue number system\\nExponentiation\\nMathematics\\nAddition chain\\nModular exponentiation',\n",
       " 671725: 'Tracking real-world phenomena with Smart Dust\\nYear: 2004\\n#Citations: 34\\nConference\\nSpringer, Berlin, Heidelberg\\nSo-called “Smart Dust” is envisioned to combine sensing, computing, and wireless communication capabilities in an autonomous, dust-grain-sized device. Dense networks of Smart Dust should then be able to unobtrusively monitor real-world processes with unprecedented quality and scale. In this paper, we present and evaluate a prototype implementation of a system for tracking the location of real-world phenomena (using a toy car as an example) with Smart Dust. The system includes novel techniques for node localization, time synchronization, and for message ordering specifically tailored for large networks of tiny Smart Dust devices. We also point out why more traditional approaches developed for early macro prototypes of Smart Dust (such as the Berkeley Motes) are not well suited for systems based on true Smart Dust.\\nSensor node\\nWireless network\\nSynchronization\\nWireless\\nComputer science\\nTracking system\\nReal-time computing\\nWireless ad hoc network\\nMacro\\nWireless sensor network\\nEmbedded system',\n",
       " 672965: \"Using Argumentation to Overcome Hypertext's HCI Failings.\\nYear: 1993\\n#Citations: 2\\nConference\\n\\nHypertext\\nComputer science\\nArgumentation theory\\nHuman–computer interaction\",\n",
       " 675534: 'Pre-service computer science teacher training within the professional development school (PDS) collaboration framework\\nYear: 2011\\n#Citations: 2\\nConference\\nSpringer, Berlin, Heidelberg\\nThe professional development school (PDS) represents a collaborative framework between high schools and teacher training institutions. The main objective of the PDS is to deepen the student teachersu0027 involvement in the school, to expose them to the variety of teacher work tasks, and to provide them with a wide range of experiences. This paper focuses on the development and implementation of a computer science (CS) student teacher practicum program that takes place within the PDS framework. We present the significant advantages that can be gained using PDS principles and demonstrate different activities performed in order to gain them within the training of CS student teachers. The paper reflects the accumulative knowledge acquired over the past five year at the Beit Berl College, Israel. We believe that this paper will contribute to the community of CS teacher preparation educators.\\nMedical education\\nComputer science\\nProfessional development\\nMathematics education\\nEngineering\\nPracticum',\n",
       " 680940: 'Predicting Student Success: An Application of Data Mining Techniques in Higher Educational Systems.\\nYear: 2008\\n#Citations: 1\\nJournal\\n\\nData science\\nData mining\\nEducational systems\\nEngineering',\n",
       " 681012: 'Lucas-kanade inverse compositional using multiple brightness and gradient constraints\\nYear: 2008\\n#Citations: 0\\nConference\\nInsticc-Inst Syst Technologies Information Control & Communication\\nA recently proposed fast image alignment algorithm is the inverse compositional algorithm based on Lucas-Kanade. In this paper, we present an overview of different brightness and gradient constraints used with the inverse compositional algorithm. We also propose an efficient and robust data constraint for the estimation of global motion from image sequences. The constraint combines brightness and gradient constraints under multiple quadratic errors. The method can accommodate various motion models. We concentrate on the global efficiency of the constraint in capturing the global motion for image alignment. We have applied the algorithm to various test sequences with ground truth. From the experimental results we conclude that the new constraint provides reduced motion error at the expense of extra computations.\\nInverse\\nComputer vision\\nImage warping\\nPattern recognition\\nComputer science\\nQuadratic equation\\nRobust statistics\\nGround truth\\nLucas–Kanade method\\nArtificial intelligence\\nBrightness\\nComputation',\n",
       " 683433: 'A FUZZY SYSTEM FOR INTEREST VISUAL DETECTION BASED ON SUPPORT VECTOR MACHINE\\nYear: 2007\\n#Citations: 0\\nConference\\n\\nStructured support vector machine\\nNeuro-fuzzy\\nSupport vector machine\\nControl engineering\\nArtificial intelligence\\nRelevance vector machine\\nEngineering\\nFuzzy control system',\n",
       " 685547: 'Some antecedents and consequences of computer-mediated communications use in an ongoing management group: a field study\\nYear: 1991\\n#Citations: 3\\nConference\\nUniversity of Minnesota\\nComputer science\\nKnowledge management',\n",
       " 505434: 'A knowledge-based approach to ontology learning and semantic annotation.\\nYear: 2004\\n#Citations: 2\\n\\n\\nThe so-called Semantic Web vision will certainly benefit from automatic semantic annotation of words in documents. We present a method, called structural semantic interconnections (SSI), that creates structural specifications of the possible senses for each word in a context, and selects the best hypothesis according to a grammar G, describing relations between sense specifications. The method has been applied to different semantic disambiguation problems, like automatic ontology construction, sensebased query expansion, disambiguation of words in glossary definitions. Evaluation experiments have been performed on each disambiguation task, as well\\nSemantic similarity\\nOntology (information science)\\nOntology alignment\\nInformation retrieval\\nSemantic Web Stack\\nComputer science\\nOWL-S\\nNatural language processing\\nArtificial intelligence\\nSocial Semantic Web\\nUpper ontology\\nSemantic computing',\n",
       " 511601: 'An OSF/1 UNIX for Massively Parallel Multicomputers.\\nYear: 1993\\n#Citations: 77\\n\\n\\nComputer science\\nMassively parallel\\nParallel computing\\nUnix\\nOperating system',\n",
       " 515592: 'Fuzzy Logic: Issues, Contentions and Perspectives (Abstract).\\nYear: 1994\\n#Citations: 2\\n\\n\\nFuzzy set operations\\nComputer science\\nFuzzy logic\\nArtificial intelligence',\n",
       " 527403: 'From Sequential Processes to Grid Computation.\\nYear: 2006\\n#Citations: 2\\n\\n\\nWe introduce an extended model for view-centric reasoning, EVCR, that provides more comprehensive and flexible abstractions for representing actual concurrency. The theory of Communicating Sequential Processes (CSP) provides an interleaved semantics for reasoning about concurrency through a sequentialized trace of events recorded by an idealized observer. The theory of View-Centric Reasoning (VCR) extended CSP with notions of parallel events and views, and lazy observation, to represent the true concurrency of simultaneous events and multiple, possibly imperfect observers. But VCR could be more general still, since its events, like those of CSP, are instantaneous. This restriction precludes the possibility of observing events that partially overlap in time. EVCR permits partially overlapping events to be observed and recorded by a lazy observer. The result is a more general model of concurrency; one that is more appropriate for reasoning about network functioning and, in particular, grid computation.\\nAbstraction\\nImperfect\\nConcurrency\\nComputer science\\nCommunicating sequential processes\\nTheoretical computer science\\nObserver (quantum physics)\\nGrid computation\\nSemantics',\n",
       " 535179: 'HandMove: a system for creating animated user interface components by direct manipulation\\nYear: 1995\\n#Citations: 1\\n\\nSpringer, Boston, MA\\nWe describe HandMove (Human ANimation by Direct Manipulation of Objects and Visual Elements), a highly interactive system for building animated scenes by direct manipulation. Its underlying model is based on concurrent evolution of graphical objects, position and attribute constraints, trajectory-based motion, event synchronization. Animation may be produced by time signals, user input or application values. Our objective is twofold: first, to present an animation model allowing intuitive and simple descriptions of complex animated scenes without textual programming; next, to integrate the resulting animation as dynamic elements in user interfaces built with a UIMS (User Interface Management System).\\nComputer graphics (images)\\nComputer science\\nHuman–computer interaction\\nAnimation\\nUser interface\\nEvent synchronization\\nNatural user interface\\nManagement system\\nTrajectory',\n",
       " 538914: 'Trust through Humanized Design.\\nYear: 2004\\n#Citations: 2\\n\\n\\nKnowledge management\\nBusiness',\n",
       " 555508: 'Studies on Loss Evaluation of Bending in Post Wall Waveguide for Microwave Transmission\\nYear: 2013\\n#Citations: 1\\n\\nSpringer, Dordrecht\\nPost wall waveguide is important structure for microwave transmission of integrated circuits with multi-layered substrates. It has simple periodic array of metallic or dielectric cylinders between parallel conducting plates. In this study, loss of bending part with the angle of 120° in post wall waveguide was evaluated both numerically and experimentally for microwave. We proposed the best configuration for bending part of the post wall waveguide.\\nMicrowave\\nComposite material\\nMicrowave transmission\\nBending\\nPost-wall waveguide\\nDielectric cylinder\\nMaterials science\\nIntegrated circuit\\nPeriodic graph (geometry)',\n",
       " 564427: 'Haralick’s Texture Features Computation Accelerated by GPUs for Biological Applications\\nYear: 2012\\n#Citations: 5\\n\\nSpringer, Berlin, Heidelberg\\nIn biological applications, features are extracted from microscopy images of cells and are used for automated classification. Usually, a huge number of images has to be analyzed so that computing the features takes several weeks or months. Hence, there is a demand to speed up the computation by orders of magnitude. This paper extends previous results of the computation of co-occurrence matrices and Haralick texture features, as used for analyzing images of cells, by general-purpose graphics processing units (GPUs). New GPUs include more cores (480 stream processors) and their architecture enables several new capabilities (namely, computing capabilities). With the new capabilities (by atomic functions) we further parallelize the computation of the co-occurrence matrices. The visually profiling tool was used to find the most critical bottlenecks which we investigated and improved. Changes in the implementation like using more threads, avoiding costly barrier synchronizations, a better handling with divergent branches, and a reorganization of the thread tasks yielded the desired performance boost. The computing time of the features for one image with around 200 cells is compared to the original software version as a reference, to our first CUDA version with computing capability v1.0 and to our improved CUDA version with computing capability v1.3. With the latest CUDA version we obtained an improvement of 1.4 to the previous CUDA version, computed on the same GPU (gForce GTX 280). In total, we achieved a speedup of 930 with the most recent GPU (gForce GTX 480, Fermi) compared to the original CPU version and a speedup of 1.8 compared to the older GPU with the optimized CUDA version.\\nGraphics\\nComputer vision\\nCo-occurrence matrix\\nCUDA\\nComputer science\\nParallel computing\\nThread (computing)\\nGeneral-purpose computing on graphics processing units\\nArtificial intelligence\\nStream processing\\nSpeedup\\nComputation',\n",
       " 579773: 'Integrating Reverse Engineering into Reuse Process.\\nYear: 1997\\n#Citations: 0\\n\\n\\nSoftware engineering\\nReuse\\nComputer science\\nReverse engineering',\n",
       " 583487: 'Cold Start Problem: A Lightweight Approach\\nYear: 2013\\n#Citations: 0\\n\\nSpringer Berlin Heidelberg\\nThe chapter presents the SWAPTeam participation at the ECML/PKDD 2011 - Discovery Challenge for the task on the cold start problem focused on making recommendations for new video lectures. The developed solution uses a content-based approach because it is less sensitive to the cold start problem that is commonly associated with pure collaborative filtering recommenders. The Challenge organizers encouraged solutions that can actually affect VideoLecture.net, thus the proposed integration strategy is the hybridization by switching. In addition, the surrounding idea for the proposed solution is that providing recommendations about cold items remains a chancy task, thus a computational resource curtailment for such task is a reasonable strategy to control performance trade-off of a day-to-day running system. The main contribution concerns about the compromise between recommendation accuracy and scalability performance of proposed approach.\\nRecommender system\\nCollaborative filtering\\nCold start\\nComputer science\\nCompromise\\nCold start (automotive)\\nComputational resource\\nScalability\\nDistributed computing',\n",
       " 594905: 'Experimentation System for Evaluating MySQL Database Management System Efficiency.\\nYear: 2005\\n#Citations: 0\\n\\n\\nComputer science\\nDatabase server\\nDatabase',\n",
       " 598801: \"EWSPT '92 Report.\\nYear: 1993\\n#Citations: 1\\n\\n\",\n",
       " 608567: 'Generating Object-Oriented Semantic Graph for Text Summarisation\\nYear: 2014\\n#Citations: 1\\n\\nSpringer, Cham\\nIn this research paper we propose to extend the semantic graph representation of natural language text to object-oriented semantic graph representation and generate a summary of the original text from this graph. We have provided rules to construct the object-oriented semantic graph and rules to generate the text summary from it. This process has been elaborated through a case study on a news story. An evaluation of the generated summary shows the effectiveness of the proposed approach. This work is a new direction in single document text summarisation research area from semantic perspective and requires further analysis and exploration.\\nNoun phrase\\nDependency relation\\nText graph\\nGraph database\\nPattern recognition\\nObject-oriented programming\\nComputer science\\nNatural language\\nNatural language processing\\nArtificial intelligence\\nAbstraction layer\\nGraph (abstract data type)',\n",
       " 610751: 'Efficient Transformation for Bottom-up Computation of Stable Models.\\nYear: 1997\\n#Citations: 0\\n\\n\\nComputer science\\nTop-down and bottom-up design\\nComputational science\\nComputation',\n",
       " 617844: 'Developing an Internet Section of an Introductory Course in Information Systems.\\nYear: 1998\\n#Citations: 0\\n\\n\\nInformation system\\nWorld Wide Web\\nComputer science\\nMultimedia\\nThe Internet',\n",
       " 623325: 'An architecture for building collaborative tools in Java.\\nYear: 2003\\n#Citations: 0\\n\\n\\nTo date, there are surprisingly few collaborative applications that exploit the accessibility of the Internet. The main reason behind this is that it is rather difficult and time consuming to build such one-off applications. In this paper, we introduce an architecture built in Java that would allow rapid and easy development of collaborative applications. This architecture also provides a feature that can dynamically rewire the collaborators in order to achieve greater efficiency. This architecture was tested with Fujaba[8] case tool by enhancing some of it’s single user capabilities to a level of real-time multi-user collaboration. Indeed, this approach proved to be a reliable solution to quickly building and deploying collaborative applications, and future work would be on making it more flexible and more efficient.\\nWorld Wide Web\\nArchitecture\\nComputer science\\nCollaborative software\\nExploit\\nComputer-aided software engineering\\nJava\\nThe Internet',\n",
       " 652234: 'An Application of the ψ-Theory to the Analysis of Business Process Models\\nYear: 2013\\n#Citations: 2\\n\\nSpringer, Berlin, Heidelberg\\nThis paper presents a method to analyse the consistency and completeness of process models according to the principles of the ψ-theory and the underlying concept of business transaction. Transactions specify the collaborative behaviour between actors while services are being requested and provided. The method assesses the consistency of a process in terms of the business transactions that can be inferred from it. To do so, it takes as input a process model that is converted to a transactional model. The transactional model is then analysed and revised so that all transactions become consistent and complete according to the transactional pattern. This enables to identify the problems on the original process model and to prompt areas of improvement.\\nArtifact-centric business process model\\nBusiness process management\\nBusiness process\\nComputer science\\nProcess modeling\\nBusiness process modeling\\nBusiness process discovery\\nBusiness Process Model and Notation\\nBusiness rule\\nProcess management',\n",
       " 653311: 'Investigating the use of interactive hypermedia systems\\nYear: 1994\\n#Citations: 0\\n\\nElsevier Science Inc.\\nWorld Wide Web\\nComputer science\\nHypermedia\\nHuman–computer interaction',\n",
       " 654655: 'Arguing with justifications between collaborating agents\\nYear: 2011\\n#Citations: 8\\n\\nSpringer, Berlin, Heidelberg\\nWe exploit the Justification Logic capabilities of reasoning about justifications, comparing pieces of evidence, and measuring the complexity of justifications in the context of argumentative agents. The research can be integrated into the larger context of integrating logic and argumentation. The paper introduces distributed justification logic $\\\\mathcal{DJL}$ as an extension of justification logic for multi-agent systems, and it also investigates the expressivity of $\\\\mathcal{DJL}$ for argumentative agents. Not knowing all of the implications of their knowledge base, agents use justified arguments for reflection and guidance.\\nJustification logic\\nArgumentative\\nArgument\\nArgumentation theory\\nExploit\\nKnowledge base\\nEpistemology\\nMathematics\\nExpressivity',\n",
       " 660320: 'Probabilistic Model Checking of Labelled Markov Processes via Finite Approximate Bisimulations\\nYear: 2014\\n#Citations: 16\\n\\nSpringer International Publishing\\nThis paper concerns labelled Markov processes (LMPs), probabilistic models over uncountable state spaces originally introduced by Prakash Panangaden and colleagues. Motivated by the practical application of the LMP framework, we study its formal semantics and the relationship to similar models formulated in control theory. We consider notions of (exact and approximate) probabilistic bisimulation over LMPs and, drawing on methods from both formal verification and control theory, propose a simple technique to compute an approximate probabilistic bisimulation of a given LMP, where the resulting abstraction is characterised as a finite-state labelled Markov chain (LMC). This construction enables the application of automated quantitative verification and policy synthesis techniques over the obtained abstract model, which can be used to perform approximate analysis of the concrete LMP. We illustrate this process through a case study of a multi-room heating system that employs the probabilistic model checker PRISM.\\nMarkov process\\nUncountable set\\nMarkov chain\\nAlgorithm\\nMarkov decision process\\nTheoretical computer science\\nStatistical model\\nProbabilistic logic\\nProbabilistic relevance model\\nMathematics\\nFormal verification',\n",
       " 672252: 'Development of Dynamic Composed Services Based on the Context\\nYear: 2007\\n#Citations: 3\\n\\nSpringer, London\\nFrancisco Javier Nieto, European Software Institute, Parque Tecnologico de Zamudio, E-48170 Zamudio-Bizkaia, Spain, francisco.nieto@esi.es Leire Bastida, European Software Institute, Parque Tecnologico de Zamudio, E48170 Zamudio-Bizkaia, Spain, leire.bastida@esi.es Marisa Escalante, European Software Institute, Parque Tecnologico de Zamudio, E-48170 Zamudio-Bizkaia, Spain, marisa.escalante@esi.es Alayn Gortazar, European Software Institute, Parque Tecnologico de Zamudio, E48170 Zamudio-Bizkaia, Spain, alayn.gortazar@esi.es\\nLibrary science\\nGeography',\n",
       " 678483: 'A jensen-shannon kernel for hypergraphs\\nYear: 2012\\n#Citations: 2\\n\\nSpringer, Berlin, Heidelberg\\nIn this paper we explore how to construct a Jensen-Shannon kernel for hypergraphs. We commence by calculating probability distribution over the steady state random walk on a hypergraph. The Shannon entropies required to construct the Jensen-Shannon divergence for pairs of hypergraphs are obtained from steady state probability distributions of the random walk. The Jensen-Shannon divergence between a pair of hypergraphs is the difference between the Shannon entropies of the separate hypergraphs and a composite structure. Our proposed kernel is not restricted to hypergraphs. Experiments on (hyper)graph datasets extracted from bioinformatics and computer vision datasets demonstrate the effectiveness and efficiency of the Jensen-Shannon hypergraph kernel for classification and clustering.\\nKernel (linear algebra)\\nDiscrete mathematics\\nCombinatorics\\nRandom walk\\nConstraint graph\\nHypergraph\\nProbability distribution\\nCluster analysis\\nEntropy (information theory)\\nIncidence matrix\\nMathematics',\n",
       " 679924: 'TPF: Performance, Capacity, Availability.\\nYear: 1987\\n#Citations: 15\\n\\n\\nComputer science\\nReliability engineering',\n",
       " 685073: \"Performance '83 (abstract).\\nYear: 1984\\n#Citations: 0\\n\\n\\nComputer science\\nReliability engineering\",\n",
       " 687179: 'How clean is your software? The role of software validation in digital preservation research projects\\nYear: 2011\\n#Citations: 0\\n\\n\\nPersonal software process\\nSoftware analytics\\nSoftware engineering\\nComputer science\\nSoftware peer review\\nPackage development process\\nSoftware project management\\nSoftware verification and validation\\nSoftware development\\nSocial software engineering',\n",
       " 688835: 'Correlation between Speech Quality and Weather\\nYear: 2013\\n#Citations: 0\\nJournal\\nSpringer, Berlin, Heidelberg\\nThis paper deals with an impact of atmospheric conditions on the speech quality in the GSM. We found out a correlation between weather conditions and the speech quality. The GSM technology is the most widely utilized communication standard which it is now coming to its bandwidth limitation especially in big cities and densely populated areas. Under such circumstances, even a minor weather change and rain could be a decisive factor causing changes in the quality of service. We have obtained both meteorological data and Mean Opinion Score value specifying the current speech quality in the GSM network. Those data are evaluated and compiled via statistical methods, whose accomplishment is dataset competent to be utilized by more advanced data mining methods. According to space distribution and fragmentation, our team has chosen set of suitable methods used to find data-mining, data analysis and correlation. As a computation result, our team found out the correlation between current rain density and the speech quality. Results from the MOS tests are reported, and an analysis of the obtained speech samples is presented. Outcomes are summarized and potential further directions for the continuation of research are discussed.\\nk-means clustering\\nGSM\\nComputer science\\nSpeech quality\\nContinuation\\nQuality of service\\nMean opinion score\\nCorrelation\\nArtificial intelligence\\nMachine learning\\nComputation',\n",
       " 691667: 'Active sets and unification\\nYear: 2011\\n#Citations: 0\\nConference\\nSpringer, Berlin, Heidelberg\\nAn active set is a unifying space being able to act as a \"bridge\" for transferring information, ideas and results between distinct types of uncertainties and different types of applications. An active set is a set of agents who independently deliver true or false values for a given proposition. An active set is not a simple vector of logic values for different propositions, the results are a vector but the set is not. The difference between an ordinary set and active set is that the ordinary set has passive elements with values of the attributes defined by an external agent, in the active set any element is an agent that internally defines the value of a given attribute for a passive element. In this paper we show the connection between classical, fuzzy, evidence theory and active sets. In conclusion at one external agent we substitute a set of experts or agents that evaluate in a conflicting way the logic value of a given proposition or attribute. Under the same meta level of active sets we can discover analogy and similarity among distinct theories of uncertainty and types of many valued logics.\\nEpistemic modal logic\\nData mining\\nEmpty set\\nProposition\\nComputer science\\nUnification\\nFuzzy logic\\nComplement (set theory)\\nAnalogy\\nEvidential reasoning approach',\n",
       " 693747: 'Database Design Research at the University of Toronto.\\nYear: 1982\\n#Citations: 0\\nJournal\\n\\nComputer science\\nDatabase design\\nDatabase',\n",
       " 695700: 'Modelling intellectual processes: the FRBR-CRM harmonization\\nYear: 2007\\n#Citations: 33\\nConference\\nSpringer, Berlin, Heidelberg\\nEven though the Dublin Core Metadata Element Set is well accepted as a general solution, it fails to describe more complex information assets and their cross-correlation. These include data from political history, history of arts and sciences, archaeology or observational data from natural history or geosciences. Therefore IFLA and ICOM are merging their core ontologies, an important step towards semantic interoperability of metadata schemata across all archives, libraries and museums. It opens new prospects for advanced global information integration services. The first draft of the combined model was published in June 2006.\\nOntology (information science)\\nData science\\nMetadata\\nWorld Wide Web\\nCore ontology\\nPolitical history\\nComputer science\\nAsset (computer security)\\nSemantic interoperability\\nBibliographic record\\nDigital library',\n",
       " 701070: 'Combining Packet Loss Compensation Methods for Robust Distributed Speech Recognition\\nYear: 2005\\n#Citations: 3\\nConference\\n\\nThis paper presents a combined packet loss compensation system for distributed speech recognition (DSR). Compensation is applied at three stages within the DSR process beginning with interleaving on the terminal device to reduce burst lengths in the received feature vector stream. On the receiver side estimation of missing vectors is applied to reconstruct the feature vector stream prior to recognition. Finally, the decoding process of the recogniser is modified to take into account the varying reliability of these estimated feature vectors. Experiments performed on both the Aurora connected digits task and the WSJCAM0 large vocabulary task show substantial gains in recognition accuracy across a range of packet loss conditions.\\nCompensation methods\\nFeature vector\\nPattern recognition\\nComputer science\\nPacket loss\\nSpeech recognition\\nArtificial intelligence\\nDecoding methods\\nVocabulary\\nConnected digits\\nTerminal device\\nInterleaving',\n",
       " 703288: 'Automated Assessment of Problem Difficulty in Mathematical Analysis\\nYear: 2007\\n#Citations: 0\\nConference\\nIOS Press\\nIt is common between teachers of mathematics to assess the difficulty of the problems they gave to students. The evaluation is mostly based on subjective appreciation with no explicit consideration of difficulty factors. However, in a computerized environment for mathematics instruction it would be highly beneficial to dispose of such explicit factors and automated assessment of problem difficulty. In the present paper a set of factors for sequence problems in analysis are proposed. For the automated detection of these factors a set of rules was defined. Knowledge representation and implementation details are described.\\nKnowledge representation and reasoning\\nDispose pattern\\nComputer science\\nManagement science',\n",
       " 705233: 'Spectral entropy-based voice activity detector for videoconferencing systems.\\nYear: 2010\\n#Citations: 7\\nConference\\n\\nComputer science\\nSpeech recognition\\nSpectral entropy\\nVideoconferencing\\nDetector',\n",
       " 706759: 'The generate-and-solve framework revisited: generating by simulated annealing\\nYear: 2013\\n#Citations: 3\\nConference\\nSpringer, Berlin, Heidelberg\\nThe Generate-and-Solve is a hybrid framework to cope with hard combinatorial optimization problems by artificially reducing the search space of solutions. In this framework, a metaheuristic engine works as a generator of reduced instances of the problem. These instances, in turn, can be more easily handled by an exact solver to provide a feasible (optimal) solution to the original problem. This approach has commonly employed genetic algorithms and it has been particularly effective in dealing with cutting and packing problems. In this paper, we present an instantiation of the framework for tackling the constrained two-dimensional non-guillotine cutting problem and the container loading problem using a simulated annealing generator. We conducted computational experiments on a set of difficult benchmark instances. Results show that the simulated annealing implementation overachieves previous versions of the Generate-and-Solve framework. In addition, the framework is shown to be competitive with current state-of-the-art approaches to solve the problems studied here.\\nSimulated annealing\\nMathematical optimization\\nPacking problems\\nCombinatorial optimization\\nAdaptive simulated annealing\\nSolver\\nOptimization problem\\nMathematics\\nGenetic algorithm\\nMetaheuristic',\n",
       " 712173: 'Computational complexity in P systems\\nYear: 2009\\n#Citations: 1\\nJournal\\n\\nAsymptotic computational complexity\\nAverage-case complexity\\nQuantum mechanics\\nTheoretical computer science\\nComplete\\nComputational resource\\nComputational complexity theory\\nPhysics',\n",
       " 716434: 'The Online Reference Works Program.\\nYear: 1986\\n#Citations: 0\\nJournal\\n\\nInformation retrieval\\nComputer science',\n",
       " 717609: 'Testing an Audio Spectrum Analyzer for Speech Recognition Systems.\\nYear: 1982\\n#Citations: 0\\nConference\\n\\nSpeech processing\\nSpeech coding\\nComputer science\\nVoice activity detection\\nSpeech recognition\\nAudio spectrum analyzer\\nAcoustic model',\n",
       " 719168: 'A Highly Efficient RFID Distance Bounding Protocol without Real-Time PRF Evaluation\\nYear: 2013\\n#Citations: 10\\nConference\\nSpringer, Berlin, Heidelberg\\nThere is a common situation among current distance bounding protocols in the literature: they set the fast bit exchange phase after a slow phase in which the nonces for both the reader and a tag are exchanged. The output computed in the slow phase is acting as the responses in the subsequent fast phase. Due to the calculation constrained RFID environment of being lightweight and efficient, it is the important objective of building the protocol which can have fewer number of message flows and less number of cryptographic operations in real time performed by the tag. In this paper, we propose a new highly efficient mutually-authenticated RFID distance bounding protocol that enables pre-computation which is carried out off-line by the tag. There is no evaluation on any PRF during the real time protocol running which makes the tag significantly more efficient at a low-cost. The protocol requires only O(1) complexity for achieving tag privacy. In addition, we give a detailed security analysis to prove that our protocol is secure against all common attacks in distance bounding.\\nTime Protocol\\nMutual authentication\\nComputer science\\nCryptography\\nComputer network\\nSecurity analysis\\nDistance-bounding protocol\\nCryptographic nonce\\nBounding overwatch\\nDistributed computing',\n",
       " 720048: 'A concurrent object-oriented approach to the eigenproblem treatment in shared memory multicore environments\\nYear: 2011\\n#Citations: 1\\nConference\\nSpringer, Berlin, Heidelberg\\nThis work presents an object-oriented approach to the concurrent computation of eigenvalues and eigenvectors in real symmetric and Hermitian matrices on present memory shared multicore systems. This can be considered the lower level step in a general framework for dealing with large size eigenproblems, where the matrices are factorized to a small enough size. The results show that the proposed parallelization achieves a good speedup in actual systems with up to four cores. Also, it is observed that the limiting performance factor is the number of threads rather than the size of the matrix. We also find that a reasonable upper limit for a \"small\" dense matrix to be treated in actual processors is in the interval 10000-30000.\\nShared memory\\nComputer science\\nMatrix (mathematics)\\nParallel computing\\nThread (computing)\\nHermitian matrix\\nMulti-core processor\\nSparse matrix\\nEigenvalues and eigenvectors\\nSpeedup',\n",
       " 722158: 'Program understanding with the lambda calculus\\nYear: 1987\\n#Citations: 10\\nConference\\nMorgan Kaufmann Publishers Inc.\\nA prerequisite of any attempt to build intelligent tools to assist in the programming process is a representation language for encoding programming knowledge. Languages that have been used for this purpose include the predicate calculus [5] and various program-schema languages [1,4]. This paper advocates a new candidate which is as expressive as the predicate calculus but more intimately connected w i th programming: the lambda calculus. Its advantages lie in its close resemblance to conventional programming languages, and in a straighforward model of inference by rewriting, which can be applied to automatic programming and program understanding. The use of the lambda calculus in an automatic program understander is described.\\nFunctional logic programming\\nFifth-generation programming language\\nLambda calculus\\nProgramming language\\nTyped lambda calculus\\nComputer science\\nSystem F\\nTheoretical computer science\\nChurch encoding\\nProgramming language theory\\nHigher-order programming',\n",
       " 723740: 'Exponential lower bounds for DPLL algorithms on satisfiable random 3-CNF formulas\\nYear: 2012\\n#Citations: 7\\nConference\\nSpringer, Berlin, Heidelberg\\nWe consider the performance of a number of DPLL algorithms on random 3-CNF formulas with n variables and m=rn clauses. A long series of papers analyzing so-called \"myopic\" DPLL algorithms has provided a sequence of lower bounds for their satisfiability threshold. Indeed, for each myopic algorithm ${\\\\mathcal A}$ it is known that there exists an algorithm-specific clause-density, $r_{\\\\mathcal A}$, such that if $r  2.78 and the same is true for generalized unit clause for all ru003e3.1. Our results imply exponential lower bounds for many other myopic algorithms for densities similarly close to the corresponding $r_{\\\\mathcal A}$.\\nDiscrete mathematics\\nCombinatorics\\nExponential function\\nExistential quantification\\nSatisfiability\\nAlgorithm\\nDPLL algorithm\\nPoisson distribution\\nMathematics',\n",
       " 728798: 'A lin-kernighan heuristic for the DCJ median problem of genomes with unequal contents\\nYear: 2014\\n#Citations: 1\\nConference\\nSpringer, Cham\\nIn this paper, we designed a distance metric as DCJ-Indel-Exemplar distance to estimate the dissimilarity between two genomes with unequal contents (with gene insertions/deletions (Indels) and duplications). Based on the aforementioned distance metric, we proposed the DCJ-Indel-Exemplar median problem, to find a median genome that minimize the DCJ-Indel-Exemplar distance between this genome and the given three genomes. We adapted Lin-Kernighan (LK) heuristic to calculate the median quickly by utilizing the features of adequate sub-graph decomposition and search space reduction technologies. Experimental results on simulated gene order data indicate that our distance estimator can closely estimate the real number of rearrangement events; while compared with the exact solver using equal content genomes, our median solver can get very accurate results as well. More importantly, our median solver can deal with Indels and duplications and generates results very close to the synthetic cumulative number of evolutionary events.\\nGenome\\nCombinatorics\\nHeuristic\\nComputer science\\nGenome rearrangement\\nMetric (mathematics)\\nSolver\\nReal number\\nLin–Kernighan heuristic\\nEstimator',\n",
       " 731271: 'Pattern discovery in distributed databases\\nYear: 1997\\n#Citations: 25\\nConference\\nAAAI Press\\nMost algorithms for learning and pattern discovery in data assume that all the needed data is available on one computer at a single site. This assumption does not hold in situations where a number of independent databases reside on geographically distributed nodes of a computer network. These databases cannot be moved to a single site due to size, security, privacy and data-ownership concerns but all of them together constitute the dataset in which patterns must be discovered. Some pattern discovery algorithms can be adapted to such situations and some others become inefficient or inapplicable. In this paper we show how a decision-tree induction algorithm may be adapted for distributed data situations. We also discuss some general issues relating to the adaptability of other pattern discovery algorithms to distributed data situations\\nAdaptability\\nData mining\\nInformation retrieval\\nComputer science\\nArtificial intelligence\\nDistributed database\\nMachine learning',\n",
       " 738913: 'The Information Organisation Driving Information Technology.\\nYear: 1994\\n#Citations: 0\\nConference\\n\\nInformation system\\nManagement information systems\\nInformation technology architecture\\nInformation mapping\\nInformation technology\\nComputer science\\nKnowledge management\\nInformation technology management\\nInformation and Communications Technology\\nInformation technology consulting',\n",
       " 740225: 'Demand Fulfillment in an Assemble-to-Order Production System\\nYear: 2014\\n#Citations: 0\\nJournal\\nSpringer, Cham\\nWe consider a computer manufacturer who assembles customized final products from various components. Customer orders specify the product configuration, the quantity and a desired delivery date. The online order promising (OP) process must announce a first promised delivery date to the customer. Demand fulfillment in this Assemble-to-Order (ATO) case is still little investigated and differs remarkably from the more popular Make-to-Stock (MTS) case: Bottlenecks are the assembly capacity and the stocks of components, which are available to promise (ATP). An important task of the demand fulfillment, besides OP, is Demand Supply Matching (DSM), i.e. deciding on the assembly date of orders and eventually changing the delivery date of promised orders (repromising). We present a new concept for demand fulfillment in the ATO case which consists of online OP for single orders arriving during the day and DSM once a day, linked in a rolling-horizon scheme. The DSM is based on a mixed integer programming (MIP) model which simultaneously determines assembly and delivery dates for all promised orders. We report on a case study with real data of a computer manufacturer with more than 10,000 orders on hand and 2,000 different components.\\nMathematical optimization\\nOperations research\\nAvailable-to-promise\\nInteger programming\\nSupply and demand\\nMathematics',\n",
       " 745926: 'COMPUTATION OF THE SEMANTIC RELATEDNESS BETWEEN WORDS USING CONCEPT CLOUDS\\nYear: 2009\\n#Citations: 14\\nConference\\n\\nDetermining the semantic relatedness between two words refers to computing a statistical measure of similarity between those words. Word similarity measures are useful in a wide range of applications such as natural language processing, query recommendation, relation extraction, spelling correction, document comparison and other information retrieval tasks. Although several methods that address this problem have been proposed in the past, effective computation of semantic relatedness still remains a challenging task. In this paper, we propose a new technique for computing the relatedness between two words. In our approach, instead of computing the relatedness between the two words directly, we propose to first compute the relatedness between their generated concept clouds using web-based coefficients. Next, we use the obtained measure to determine the relatedness between the original words. Our approach heavily relies on a concept extraction algorithm that extracts concepts related to a given query and generates a concept cloud for the query concept. We perform an evaluation on the Miller-Charles benchmark dataset and obtain a correlation coefficient of 0.882, which is better than the correlation coefficients of all other existing state of art methods, hence providing evidence for the effectiveness of our method.\\nSemantic similarity\\nCorrelation coefficient\\nInformation retrieval\\nComputer science\\nExplicit semantic analysis\\nSpelling\\nNatural language processing\\nArtificial intelligence\\nCloud computing\\nRelationship extraction\\nSemantic compression\\nComputation',\n",
       " 747610: 'A real-time living activity recognition system using off-the-shelf sensors on a mobile phone\\nYear: 2011\\n#Citations: 8\\nJournal\\nSpringer Berlin Heidelberg\\nWe propose an in-home living activity recognition method using only off-the-shelf sensors, namely, an accelerometer and a microphone, which are commonly applied in mobile phones. The proposed method firstly estimates a useru0027s movement condition roughly by acceleration sensing. Secondly, it classifies the working condition in detail by acoustic sensing when it estimates the condition to be working by acceleration sensing. We developed a prototype system to recognize the useru0027s living activity in real time and conducted two experiments to confirm the feasibility of the proposed method. As a result of the first experiment, three movement conditions; quiet, walking, and working, are classified with more than 95% accuracy by acceleration sensing. And it classified working into seven conditions with 85.9% accuracy by acoustic sensing. Moreover, the result of the second experiment shows that it is effective to adopt instance-based recognition according to the assumed application.\\nQUIET\\nOff the shelf\\nActivity recognition\\nComputer science\\nSimulation\\nAccelerometer\\nReal-time computing\\nAcceleration\\nArtificial intelligence\\nNatural language processing\\nMobile phone\\nMicrophone',\n",
       " 748915: 'Automatic Point of Interests Detection Using Spatio-Temporal Data Mining Techniques over Anonymous Trajectories\\nYear: 2014\\n#Citations: 3\\nConference\\nSpringer, Cham\\nLocation Based Services (LBS) are evolving very fast but despite this are still at an early phase of their evolution. The future LBS services will be more anticipatory of users needs and will exploit a broader range of information on users. In order to anticipate users’ needs, LBS providers should be able to understand users’ behaviours, preferences and interests automatically and without asking the user to specify them. Then using the user’s current situation and previously extracted behaviours, interests and dislikes, the user’s needs can be predicted at the relevant moment and provide the most appropriate sets of services. This paper shows the application of data mining techniques over anonymous sets of tracking data to recognise mobility behaviours and preferences of users such as Point of Interest (PoI). Tracking data are first anonymised then stored in a spatio-temporal database. Then, using data mining techniques, rules, models and patterns are recognised. Such knowledge, patterns and models are subsequently used for intelligent navigation services as input making suggestions.\\nData science\\nWorld Wide Web\\nComputer science\\nComputer network\\nLocation-based service\\nExploit\\nTracking data\\nKnowledge extraction\\nPoint of interest\\nPound (mass)\\nTemporal data mining',\n",
       " 751588: 'Preserving the Fabric of Our Lives: A Survey of Web.\\nYear: 2003\\n#Citations: 2\\nConference\\n\\nWorld Wide Web\\nComputer science',\n",
       " 755599: 'Lessons Learned from Teaching Open Source Software Development\\nYear: 2014\\n#Citations: 14\\nConference\\nSpringer, Berlin, Heidelberg\\nFree/Open Source Software allows students to learn valuable real world skills and experiences, as well as a create a portfolio to show future employers. However, the learning curve to joining FOSS can be daunting, often leading newcomers to walk away frustrated. Universities therefore need to find ways to provide a structured introduction to students, helping them overcome the barriers to entry. This paper describes two courses taught at two universities, built around a Communities of Practice model, and the lessons learned from these. Suggestions and insights are shared for how to structure and evaluate such courses for maximum effect.\\nComputer science\\nKnowledge management\\nPortfolio\\nBarriers to entry\\nLearning curve\\nOpen source software\\nOpen-source software development',\n",
       " 758850: 'Self-virtualized CAN controller for multi-core processors in real-time applications\\nYear: 2013\\n#Citations: 7\\nConference\\nSpringer, Berlin, Heidelberg\\nThe long-rising number of electronic control units (ECUs) in cars is a major problem for OEMs, because of high costs and installation space requirements. The complexity could be reduced by the use of multi-core processors, where several ECUs can be repartitioned into virtual machines (VMs) running on one multi-core processor. Such a consolidation of ECUs is challenging, because I/O devices for real-time capable interconnects have to be shared by multiple VMs. In this paper we present a concept for offloading the functionality for CAN controller virtualization into a self-virtualized controller. By means of a thorough real-time analysis, it is shown that proposed solution is capable of real-time message transmission with additional latencies, that are multiple orders smaller than the common deadlines.\\nAutomotive electronics\\nVirtualization\\nCAN bus\\nVirtual machine\\nComputer science\\nOriginal equipment manufacturer\\nReal-time computing\\nMulti-core processor\\nControl theory\\nSpace requirements\\nParallel computing\\nOperating system\\nEmbedded system',\n",
       " 761799: 'Better Tools - Less Education?\\nYear: 1989\\n#Citations: 7\\nConference\\n\\nSociology\\nKnowledge management',\n",
       " 762797: 'Nature-Inspired Fault Tolerant Area Monitoring in Sensor Network\\nYear: 2012\\n#Citations: 0\\nConference\\nSpringer, India\\nEffective network coverage and operational life span is key concern of randomly deployed Wireless Sensor Network (WSN) for performing monitoring function in designated region. Intrinsically, WSN consists of resource constraints sensor nodes. For effective coverage, it is undesirable activating all deployed set of nodes for getting the desired degree of coverage if the same result can be obtained by activating a small subset of deployed nodes for providing the sensing function in the concerned region. We study the problem of extending the life span of the sensor network for fault tolerant area coverage. The proposed genetic algorithm based approach aims to cover a sensed area with minimum number of active nodes and compute the maximum number of Sensing Cover Set (SCS) so that network life time can be prolonged by calculating the working schedule of cover set. Each SCS has been assigned the cover set ID. Each SCS works for the specified amount of time in an alternate fashion. Simulation experiment indicates that genetic algorithm based approach is able to optimally partition the nodes into different SCS.\\nKey distribution in wireless sensor networks\\nComputer science\\nReal-time computing\\nLife span\\nFault tolerance\\nWireless sensor network\\nGenetic algorithm\\nArea coverage\\nLife time',\n",
       " 764940: 'On Computing Preferred MUSes and MCSes\\nYear: 2014\\n#Citations: 7\\nConference\\nSpringer, Cham\\nMinimal Unsatisfiable Subsets (MUSes) and Minimal Correction Subsets (MCSes) are essential tools for the analysis of unsatisfiable formulas. MUSes and MCSes find a growing number of applications, that include abstraction refinement in software verification, type debugging, software package management and software configuration, among many others. In some applications, there can exist preferences over which clauses to include in computed MUSes or MCSes, but also in computed Maximal Satisfiable Subsets (MSSes). Moreover, different definitions of preferred MUSes, MCSes and MSSes can be considered. This paper revisits existing definitions of preferred MUSes, MCSes and MSSes of unsatisfiable formulas, and develops a preliminary characterization of the computational complexity of computing preferred MUSes, MCSes and MSSes. Moreover, the paper investigates which of the existing algorithms and pruning techniques can be applied for computing preferred MUSes, MCSes and MSSes. Finally, the paper shows that the computation of preferred sets can have significant impact in practical performance.\\nDiscrete mathematics\\nSoftware configuration management\\nComputer science\\nTheoretical computer science\\nPackage management\\nSoftware\\nConjunctive normal form\\nComputational complexity theory\\nDebugging\\nSoftware verification\\nComputation',\n",
       " 765817: 'Computational Infrastructures for School Improvement: A Way to Move Forward.\\nYear: 2008\\n#Citations: 0\\nConference\\n\\nThe instructional practices common in todayu0027s schools reveal a disconnect between instruction and evidence of the effects of that instruction on student learning. In this paper, we propose the creation of computational infrastructures that will help teachers make more informed decisions in their practice. These infrastructures formalize student and teacher routines to facilitate data collection and mining, in order to create actionable information. We then show an instance of such a computational infrastructure and describe its potential for improving instruction.\\nData science\\nData collection\\nComputer science\\nStudent learning',\n",
       " 767427: 'A general approach to the interoperability of HetSC and SystemC-AMS.\\nYear: 2007\\n#Citations: 6\\nConference\\n\\nComputer architecture\\nComputer science\\nInteroperability\\nSystemC AMS\\nWS-I Basic Profile\\nSemantic interoperability',\n",
       " 767593: 'Research on the City Emergency Logistics Scheduling Decision Based on Cloud Theory-Based Genetic Algorithm\\nYear: 2011\\n#Citations: 2\\nConference\\nSpringer, Berlin, Heidelberg\\nThe city emergency logistics scheduling is an important part of the city emergency management. When there are many candidate base station exist in a city, the issue belongs to multiple rescue-single object question. We think the time factor as the first consideration, and improve on the original Genetic Algorithm, use the Cloud Theory-Based Genetic Algorithm to resolve the issue of the city emergency logistics scheduling. The experimental result shows that when using the Cloud Theory-Based Genetic Algorithm to make decision for emergency logistics scheduling, we can get the optimum solution only a few genetic algebras with high accuracy and good immediacy.\\nBase station\\nComputer science\\nScheduling (computing)\\nEmergency management\\nOperations research\\nEmergency logistics\\nTime factor\\nImmediacy\\nGenetic algorithm\\nCloud computing',\n",
       " 769408: 'Efficiently Coding for Interactive Communication.\\nYear: 2011\\n#Citations: 7\\nJournal\\n\\nDiscrete mathematics\\nCoding (social sciences)\\nTheoretical computer science\\nMathematics',\n",
       " 770445: 'Combination of GSM and GPS signals for Mobile Positioning and Location Service Using Kalman Filter.\\nYear: 2007\\n#Citations: 3\\nConference\\n\\nLocation based services are becoming an emerging market due to technological advances achieved both at GSM phone operators and the multimedia nature of the mobile handsets. In this paper, a new methodology of mobile positioning integrating both GSM network using signal strengths and GPS readings in the light of an assisted GPS based approach. The methodology employs an extended Kalman filter approach in which the stochastic errors related to various measurements are appropriately characterized and modeled. The methodology uses Netmonitor software to retrieve network information including signal strength and cell-identities of various base transmitter stations (BTS). The distance from the mobile station (MS) to each BTS is therefore determined using Hata-Okumura radio propagation model. The different distances and the GPS readings are therefore combined in the framework of extended static Kalman filter. Once positioning is achieved, a .NET like application is implemented to access the Microsoft MapPoint Web Service, via the Internet (http protocol), which visualises the mobileu0027s location on a map, finds nearby points of interest (POI) and computes routes between them. In order to demonstrate the feasibility of the proposal, experiment is carried out in Birmingham area and compared to the result yielded by the commercial software of MobileLocate Ltd. An accuracy of less than 70 meters has been achieved, which shows substantial improvement over standard Timing Advance related techniques and the commercial software.\\nGSM\\nExtended Kalman filter\\nMobile phone tracking\\nMobile station\\nSimulation\\nLocation-based service\\nTiming advance\\nReal-time computing\\nControl engineering\\nGlobal Positioning System\\nEngineering\\nAssisted GPS',\n",
       " 771098: 'Jstacs: a java framework for statistical analysis and classification of biological sequences\\nYear: 2012\\n#Citations: 38\\nJournal\\nJMLR.org\\nJstacs is an object-oriented Java library for analysing and classifying sequence data, which emerged from the need for a standardized implementation of statistical models, learning principles, classifiers, and performance measures. In Jstacs, these components can be used, combined, and extended easily, which allows for a direct comparison of different approaches and fosters the development of new components. Jstacs is especially tailored to biological sequence data, but is also applicable to general discrete and continuous data. Jstacs is freely available at http://www.jstacs.de under the GNU GPL license including an API documentation, a cookbook, and code examples.\\nJava collections framework\\nJava annotation\\nComputer science\\nApplication programming interface\\nArtificial intelligence\\nStatistical model\\nPrinciples of learning\\nJava\\nMachine learning\\nStatistical analysis\\nLicense',\n",
       " 772349: 'An Efficient Method to Find Invalid Loops in a Communication Protocol and Its Application to HDLC.\\nYear: 1986\\n#Citations: 0\\nConference\\n\\nUser Datagram Protocol\\nComputer science\\nComputer network\\nReal-time computing\\nInternet Protocol Control Protocol\\nInternetwork protocol\\nUniversal composability\\nCommunications protocol\\nLink Control Protocol',\n",
       " 773669: 'Quantifiers and Approximation (Extended Abstract)\\nYear: 1990\\n#Citations: 1\\nConference\\n\\nDiscrete mathematics\\nMathematics',\n",
       " 773965: 'Green\\'s relations and their use in automata theory\\nYear: 2011\\n#Citations: 15\\nConference\\nSpringer, Berlin, Heidelberg\\nThe objective of this survey is to present the ideal theory of monoids, the so-called Greenu0027s relations, and to illustrate the usefulness of this tool for solving automata related  :[29],\"use Greenu0027s relations for proving four classical results related to automata theory: The result of Schutzenberger characterizing star-free languages, the theorem of factorization forests of Simon, the characterization of infinite words of decidable monadic theory due to Semenov, and the result of determinization of automata over infinite words of McNaughton.\\nQuantum finite automata\\nDiscrete mathematics\\nAutomata theory\\nCombinatorics\\nAlgebra\\nNested word\\nDecidability\\nMonoid\\nGreen\\'s relations\\nRegular language\\nMathematics\\nω-automaton',\n",
       " 775384: 'Making a Mind vs. Modeling the Brain: AI Back at a Branchpoint.\\nYear: 1995\\n#Citations: 1\\nJournal\\n\\nComputer science\\nArtificial intelligence\\nMachine learning',\n",
       " 775880: \"A Resilient Distributed Algorithm for Minimum-Weight Spanning Trees.\\nYear: 1987\\n#Citations: 6\\nConference\\n\\nExpected linear time MST algorithm\\nDiscrete mathematics\\nDistributed minimum spanning tree\\nComputer science\\nPrim's algorithm\\nParallel computing\\nDistributed algorithm\\nSpanning tree\\nShortest-path tree\\nKruskal's algorithm\\nMinimum spanning tree\",\n",
       " 781991: 'Collaborative Choreography: A Critical Inquiry into Designing Creative Interactive Systems\\nYear: 2014\\n#Citations: 2\\nConference\\nSpringer, Cham\\nIn choreographic process, technology can participate as a collaborator rather than as a tool, by transforming and eliciting creative opportunities. We propose that techniques such as modality shifts and abstraction are useful design strategies for provoking creative compositional choices. Modality shifts are the translation of movement data from one representation to another. Abstraction refers to the resolution and aesthetics of movement data representation that can modulate between greater specificity and ambiguity as a compositional interpretive strategy. This paper presents a contextual inquiry for an interactive system used to provoke creativity in choreographic process. Contemporary choreographic process is often distributed, relying on interactions between the choreographer and dancers to develop and evaluate movement material through exploration on different bodies. Based on this interaction model we choreographed and analyzed a dance piece in order to design a set of features that support system collaboration and agency in an intelligent autonomous choreographic system.\\nDance\\nExternal Data Representation\\nAbstraction\\nComputer science\\nSupport system\\nChoreography\\nHuman–computer interaction\\nContextual inquiry\\nCreativity\\nMultimedia\\nAmbiguity',\n",
       " 787986: 'The Role of workarounds during an OpenSource Electronic Medical Record System Implementation.\\nYear: 2010\\n#Citations: 19\\nConference\\n\\nA significant degree of customization of medical information technology is required to effectively integrate the promise of IT with the diversity and complexity of medical work. In the absence of such customizations, dissatisfaction and resistance toward the system arise. Indeed, the complexity of the medical work and the inability of software to tailor to the diverse medical practices may explain the limited diffusion of health information systems especially in North America. We study the role of workarounds during an open-source Electronic Medical Record System (EMR) implementation at a medium-size urgent care clinic in a major Canadian city. We found that the technology appropriation process involved the evolving of number of non-trivial workarounds in order to match the EMR to medical work. The emergence of workarounds is conceptualized as a knowledge creation and integration process. This perspective allows us to look at the antecedents and the change dynamics of workarounds in the clinic. Furthermore diverging from the negative view toward workarounds, we discuss the importance of incorporating workarounds during and following system development. The workaround perspective shed the light on how users’ behavior can be channeled into a constructive development effort. This paper contributes by examining the workaround of medical practitioners using an open-source electronic medical record system as well as offering a knowledge perspective for the study of EMR appropriation.\\nWorkaround\\nAppropriation\\nComputer science\\nInformation technology\\nConstructive\\nKnowledge management\\nImplementation\\nMedical record\\nHealth informatics\\nPersonalization',\n",
       " 789097: 'Constructs competition miner:process control-flow discovery of BP-domain constructs\\nYear: 2014\\n#Citations: 13\\nConference\\nSpringer, Cham\\nProcess Discovery techniques help a business analyst to understand the actual processes deployed in an organization, i.e. based on a log of events, the actual activity workflow is discovered. In most cases their results conform to general purpose representations like Petri nets or Causal nets which are preferred by academic scholars but difficult to comprehend for business analysts. In this paper we propose an algorithm that follows a top-down approach to directly mine a process model which consists of common BP-domain constructs and represents the main behaviour of the process. The algorithm is designed so it can deal with noise and not-supported behaviour. This is achieved by letting the different supported constructs compete with each other for the most suitable solution from top to bottom using ”soft” constraints and behaviour approximations. The key parts of the algorithm are formally described and evaluation results are presented and discussed.\\nBusiness process management\\nPetri net\\nGeneral purpose\\nSystems engineering\\nComputer science\\nFlow (psychology)\\nArtificial intelligence\\nProcess control\\nBusiness process modeling\\nBusiness process discovery\\nWorkflow',\n",
       " 790450: 'IT Impact on Individual Work: A Study in the Context of Healthcare Services\\nYear: 2009\\n#Citations: 5\\nConference\\n\\nThe use of IT has considerable potential to impact the healthcare industry. Recent applications such as electronic medication administration systems (EMAS) are expected to improve medication safety and delivery. However, the impact of such systems on users’ job performance is unclear and under-researched. This study develops a model to understand the individual impact of healthcare IS such as EMAS based on the job characteristics and relational job design theories. A pilot survey with 112 nurses was conducted to validate the model for EMAS implementation in a public hospital. The use of IS is seen to affect the perceived increase in skill variety. Prosocial values of nurses are found to strengthen the relationships between use of IS and perceived increase in task significance as well as beneficiary contact. Self-efficacy affects perceived increase in various job characteristics. Perceived increase in task identity and beneficiary contact in turn influence user efficiency and effectiveness. The expected contributions and remaining research plan are outlined.\\nHealth care\\nProsocial behavior\\nPublic hospital\\nComputer science\\nJob design\\nKnowledge management\\nHealthcare industry\\nBeneficiary\\nSelf-efficacy\\nJob performance\\nMarketing',\n",
       " 792443: 'Privately Waiting - A Usability Analysis of the Tor Anonymity Network\\nYear: 2010\\n#Citations: 17\\nConference\\nSpringer, Berlin, Heidelberg\\nAs the Internet is increasingly absorbing information from the real world it becomes more important to prevent unauthorized collection and abuse of personalized information. At the same time, democratic societies should establish an environment helping not only their own people but also people who face repressive censorship to access public information without being identified or traced. Internet anonymization tools such as Tor offer functionalities to meet this demand.\\nWeb usability\\nInternet privacy\\nPublic information\\nComputer science\\nCensorship\\nComputer security\\nUsability\\nAnonymity\\nThe Internet',\n",
       " 796041: 'Scalability of using Restricted Boltzmann Machines for combinatorial optimization\\nYear: 2017\\n#Citations: 9\\nJournal\\nElsevier\\nEstimation of Distribution Algorithms (EDAs) require flexible probability models that can be efficiently learned and sampled. Restricted Boltzmann Machines (RBMs) are generative neural networks with these desired properties. We integrate an RBM into an EDA and evaluate the performance of this system in solving combinatorial optimization problems with a single objective. We assess how the number of fitness evaluations and the CPU time scale with problem size and complexity. The results are compared to the Bayesian Optimization Algorithm (BOA), a state-of-the-art multivariate EDA, and the Dependency Tree Algorithm (DTA), which uses a simpler probability model requiring less computational effort for training the model. Although RBM–EDA requires larger population sizes and a larger number of fitness evaluations than BOA, it outperforms BOA in terms of CPU times, in particular if the problem is large or complex. This is because RBM–EDA requires less time for model building than BOA. DTA with its restricted model is a good choice for small problems but fails for larger and more difficult problems. These results highlight the potential of using generative neural networks for combinatorial optimization.\\nPopulation\\nBoltzmann machine\\nMathematical optimization\\nEstimation of distribution algorithm\\nAlgorithm\\nEvolutionary computation\\nCombinatorial optimization\\nArtificial neural network\\nOptimization problem\\nMathematics\\nScalability',\n",
       " 797742: 'On attributed relational graph matching using hopfield network\\nYear: 1994\\n#Citations: 0\\nConference\\nJohn Wiley & Sons, Inc.\\nComputer science\\nMatching (graph theory)\\nArtificial intelligence\\nHopfield network\\nMachine learning',\n",
       " 802089: 'Collaborative Business Process Management: Exploring Themes, Achievements, and Perspectives\\nYear: 2010\\n#Citations: 8\\nConference\\n\\nUnder labels such as global value chains, global production networks, interconnected firms, or outsourcing cross-boundary business processes have gained significant attention in practice and research. However, only little research has yet systematically examined the implications of crossboundary business processes for Business Process Management (BPM). These cross-boundary business processes together with the drivers of collaboration and network management as well as governance form one of the key challenges for today’s BPM research. In this study we thus systematically review literature and seek to answer whether BPM research in Information Systems (IS) has yet embraced and explored the concept of collaboration. We find that collaborative BPM is a growing trend in IS research, but that there still exist significant research gaps. Therefore, we propose a research agenda that points at potentially fruitful directions for future research.\\nInformation system\\nBusiness process management\\nInformation management\\nBusiness process\\nComputer science\\nKnowledge management\\nOutsourcing\\nBusiness relationship management\\nNetwork management\\nProcess management\\nBusiness analysis',\n",
       " 804213: 'Efficient Update on Exploitation Graphs for Vulnerability Analysis\\nYear: 2007\\n#Citations: 0\\nConference\\n\\nGraph\\nVulnerability assessment\\nComputer science\\nDistributed computing',\n",
       " 805263: 'A Randomized Controlled Trial of a Patient Accessible Medical Record\\nYear: 2003\\n#Citations: 2\\nConference\\nAmerican Medical Informatics Association\\nBackground Legal and technologic trends are making medical records more patient-accessible. The Health Insurance Portability and Accountability Act (HIPAA) stipulates that “patients must be able to see and get copies of their records, and request amendments.” Medical records are more commonly being stored in electronically, and methods have been developed to share these records with patients in a secure format.\\nHealth Insurance Portability and Accountability Act\\nRandomized controlled trial\\nMedical record\\nMedical emergency\\nMedicine',\n",
       " 807719: 'WordVenture – COOPERATIVE WordNet EDITOR - Architecture for Lexical Semantic Acquisition\\nYear: 2009\\n#Citations: 2\\nConference\\n\\nArchitecture\\nInformation retrieval\\nLexical semantics\\nComputer science\\nLexical functional grammar\\nArtificial intelligence\\nNatural language processing\\nWordNet',\n",
       " 808474: 'Australian undergraduate Internet usage: self-taught, self-directed, and self-limiting?\\nYear: 2000\\n#Citations: 14\\nJournal\\nKluwer Academic Publishers\\nThe Information Age is upon us and it heralds a new paradigm in the way universities conduct research. Lack of understanding and a cautionary stance towards the Internet has left many universities lagging far behind the needs of its student population. Research shows that both students and academics are struggling on their own to learn about these new channels of information with little, or no, guidance from their educational institution. As a consequence, the Internet remains a little understood and poorly utilised mode of gathering resource information for many of todayu0027s and tomorrowu0027s researchers.\\nPopulation\\nComputer science\\nKnowledge management\\nInternet Architecture Board\\nPedagogy\\nEducational institution\\nInternet research\\nLagging\\nInformation Age\\nHigher education\\nThe Internet',\n",
       " 810749: 'Knowledge Management Systems for Leveraging Enterprise Data Resources: Taxonomy and Key Issues.\\nYear: 2003\\n#Citations: 0\\nConference\\n\\nComputer science\\nPersonal knowledge management\\nEnterprise software\\nDigital firm\\nKnowledge management\\nEnterprise systems engineering\\nEnterprise information system\\nEnterprise planning system\\nEnterprise data management\\nEnterprise architecture management',\n",
       " 813000: 'On Lexicon Creation for Turkish LVCSR\\nYear: 2003\\n#Citations: 47\\nConference\\n\\nIn this paper, we address the lexicon design problem in Turkish large vocabulary speech recognition. Although we focus only on Turkish, the methods described here are general enough that they can be considered for other agglutinative languages like Finnish, Korean etc. In an agglutinative language, several words can be created from a single root word using a rich collection of morphological rules. So, a virtually infinite size lexicon is required to cover the language if words are used as the basic units. The standard approach to this problem is to discover a number of primitive units so that a large set of words can be created by compounding those units. Two broad classes of methods are available for splitting words into their sub-units; morphology-based and data-driven methods. Although the word splitting significantly reduces the out of vocabulary rate, it shrinks the context and increases acoustic confusibility. We have used two methods to address the latter. In one method, we use word counts to avoid splitting of high frequency lexical units, and in the other method, we recompound splits according to a probabilistic measure. We present experimental results that show the methods are very effective to lower the word error rate at the expense of lexicon size.\\nTurkish\\nRoot (linguistics)\\nComputer science\\nAgglutinative language\\nWord error rate\\nMorphology (linguistics)\\nSpeech recognition\\nLexicon\\nNatural language processing\\nArtificial intelligence\\nOut of vocabulary\\nProbabilistic logic',\n",
       " 816299: 'Long-Term Study of a Software Keyboard That Places Keys at Positions of Fingers and Their Surroundings\\nYear: 2013\\n#Citations: 5\\nConference\\nSpringer Berlin Heidelberg\\nIn this paper, we present a software keyboard called Leyboard that enables users to type faster. Leyboard makes typing easier by placing keys at the positions of fingers and their surroundings. To this end, Leyboard automatically adjusts its key positions and sizes to users’ hands. This design allows users to type faster and more accurately than using ordinary software keyboards, the keys of which are unperceptive. We have implemented a prototype and have performed a long-term user study. The study has proved the usefulness of Leyboard and its pros and cons.\\nLong term learning\\nComputer science\\nSoftware\\nHuman–computer interaction\\nMultimedia\\nText entry',\n",
       " 820964: 'Entwicklung eines KM Framework und Implementation Guide.\\nYear: 2003\\n#Citations: 0\\nConference\\n',\n",
       " 822699: 'Partial Inverse Heuristic for the Approximate Solution of Non-linear Equations\\nYear: 1999\\n#Citations: 1\\nConference\\nSpringer, Berlin, Heidelberg\\nWe show how to generate many fix-point iterators of the form x i +1= F(x i ) which could solve a given non-linear equation. In particular, these iterators tend to have good global convergence, and we show examples whereby obscure solutions can be discovered. This methods are only suitable for computer algebra systems, where the equations to be solved can be manipulated in symbolic form. Also, a systematic method for finding most or all solutions to nonlinear equations that have multiple solutions is described. The most successful iterators are constructed to have a small number of occurrences of x i in F. We use grouping of polynomial terms and expressions in x, e x and In x using known inverse relations to obtain better iterators. Each iterator is tried in a limited way, in the expectation that at least one of them will succeed. This heuristic shows a very good behaviour in most cases, in particular when the answer involves extreme ranges.\\nApplied mathematics\\nDiscrete mathematics\\nHeuristic\\nMathematical optimization\\nNonlinear system\\nPolynomial\\nComputer science\\nSymbolic computation\\nNumerical partial differential equations\\nRate of convergence\\nInverse relation\\nIterator',\n",
       " 826409: 'Preserving Consistency and Properties in Pairwise Comparisons Based Non-Numerical Ranking.\\nYear: 2010\\n#Citations: 0\\nJournal\\n\\nWe discuss property-driven non-numerical ranking by rough set partial order approximations and present property-consistency driven algorithm for the non-numerical ranking based on the pairwise comparisons.\\nPairwise comparison\\nData mining\\nRanking\\nComputer science\\nRough set\\nPotentially all pairwise rankings of all possible alternatives',\n",
       " 831355: 'Towards Autonomic Index Maintenance.\\nYear: 2006\\n#Citations: 4\\nConference\\n\\nAutomatic index selection has received significant attention in the autonomic computing field. Previous works have focused on providing tools and algorithms to help the DBA in the choice of indices for a given static workload. We present an approach for indexing management that works for workloads that may dynamically change with no human intervention at all. We automatically monitor statements submitted to the database with a built-in component, that interacts directly with the DBMS, creating and dropping indices on-the-fly. This paper presents a mechanism to integrate automatic index management components in relational databases. We discuss the heuristics considered and the observed experimental results for a PostgreSQL implementation. Resumo. A selecao automatica de indices e um topico dos mais relevantes na area de computacao autonoma. Os trabalhos existentes tem foco em ferramentas e algoritmos que ajudem o DBA na escolha de indices para uma dada carga estatica. Nesse trabalho sugerimos uma abordagem para gerencia de indices que funciona para cargas que mudam dinamicamente, sem intervencao humana. Ha um monitoramento automatico dos comandos submetidos para o banco de dados com um componente embutido, que interage diretamente com o SGBD, permitindo a criacao e destruicao de indices com a base em operacao. Este artigo apresenta um mecanismo que integra componentes de gerencia automatica de indices em bases de dados relacionais. Nos discutimos as heuristicas consideradas e tambem os resultados experimentais observados para uma implementacao utilizando PostgreSQL.\\nData mining\\nAutonomic computing\\nInformation retrieval\\nRelational database\\nComputer science\\nDatabase',\n",
       " 833112: 'Random Key Graphs.\\nYear: 2009\\n#Citations: 0\\nConference\\n\\nGraph\\nDiscrete mathematics\\nRandom graph\\nComputer science\\nComplex network\\nDistributed computing',\n",
       " 836707: 'Language learning as problem solving.\\nYear: 1988\\n#Citations: 4\\nConference\\n\\nWe present here a system under development, the present goals of which are to assist (a) students in inductively learning a set of rules to generate sentences in French, and (b) psychologists in gathering data on natural language learning. Instead of claimin~ an all-encompassing model or theory, we prefer to elaborate a tool, which is general and flexible enough to permit the testing of various theories. By controlling parameters such as initml knowledge, the nature and order o f the data, we can empirically determine how each parameter affects the efficiency of learning. Our ultimate goal is the modelling of human learning by machine. Learning is viewed as problem-solving, i.e. as the creation and reduction of a search-space, t~y integrating the student into the process, that is, by encouraging him to ask an expert (the system) certain kinds of questions like: can one say x ? how does one say x ? why does one say x ? we can ennance not only the efficiency of the learning, but also our understanding of the underlying processes. By having a tra.~e of the whole dialogue (what questions have been asked at, what time), Ave should be able to infer the studentu0027s learning strategies. I THE PROBLEM OF LEARNING A LANGUAGE: Language learning can be viewed as a special case of problem solving in which tlae learner tries to build and intelligently explore a hypothetical search space. If this view is correct, then two sets of questions arise immediately. On one hand one may want to know: a) what the nature of this search space is (what are the variables 9) b) how it is built (incremental learning: local vg global view), u0027 u0027 c) how it is explored (strategies: intelligent opportunistics vs systematic search). On the other hand, one may want to investigate how (i) the knowledge at the outset and (ii) the ordering of the data will affect the building and the searching of the space. Typically one does not learn from scratch, nor is it likely that one encounters either well-ordered data, or a Complete set of examples: natural learning is incremental. Obviously, these.facts imply that: * initial knowledge, in particular, knowledge of other languages may bias the kind of variables (attributes or hypotheses) constdered, i.e., included in the search space; * the order of the data (the examp es encountered by the student) may determine what rules are likely to be inferred at what moment, and finally rues are referred from mcomplete data (incremental learning). Furthermore, the same data may be characterized in different ways. That is, several equivalent descriptions may be inferred from the same data set. Whieli of these descriptions turns out to be the most adequate generally cannot be established until one knows the complete data set. Thus, rules may have to be revised in the light of new evidence. Consequently, errors are not only unavoidable parts of the learning process,but also an indispensable source of information for the learner. 2 THE PROBLEM OF TEACHING HOW TO LEARNt As we have shown, learning can be seen as searching. Actually, teaching, as well as learning, can be conceived of as problem solving or reasoning in an informatio.n-exchange environment. There is a sender, a goal, a message and a recewer. The SENDER may be a native speaker, a teacher, a parent, a book or a computer. The GOAL is the task or performance (output). In our case it is knowledge of how to produce sentences in French. The MESSAGE is the input to the learning component: examples from which the rules have to be inferred (1). The RECEIVER or learner can be any system, naturm or artlttcial, capable of perceiving, memorizing and analyzing a set of data and drawing the necessary conclusions: a child, a student, or a computer program (2). Learning occurs in various settings. Depending on the order of the examples and the control of the information flow we s eak of nator I . . . . . . p a experimental, or msmuttonal settings. Natural learning is characterized by the absence of a clearly defined learning objective (3), by noisy and heterogeneous material~ and by unordered examples. The underlying regumr:ties are thus multiple, diffuse, and hard to perceive. Experimentffl learning and teaching, on the other hand, have a ]earning objective, the material is error-free, homogeneous and coherently ordered according to some point of view (learner or teacher). Whereas experimental learning can be characterized by the following sequence: (i) encountering the data (ii) analysis, (iii) building and testing of h~,pothesis, (iv) feedback and (v) proof or aemonstration of the theo~, traditional teaching goes througfi the following stages: (i) exposition, 0i) practice, (iii) testing and (iv) evaluation. This can be schematized as follows: Teacher: sets the task and presents the learning material Student: analyzes the data; Teacher: provtdes a set of examples; Student: practices; Teacher: asks questions to test the gained knowledge; Student: answers the questions; Teacher: evaluates the answers, provides feedback (explanations) and organizes future data as a function of actual performance Student: integrates the feedback into the knowledge base and corrects misconceptions; As one can see, the information flow here is entirely teacher-controlled. He is the one who sets the task, and provides the examples and the feedback. Consequently, the teacher decides the nature and the order of the material to be learned. There are two major shortcomings in this approach. Not knowiug what information is needed by the learner, the teacher may present the wrong data. More importantly, the student is only loosely integrated in the learning process. Instead of being active, generating and testing plausible hypotheses (discovery learning), he reacts to questions, Thus, it may happen that the student perceives his task as the learning of the material rather than the learning of the underlying principles. I~norance of what or how to learn may result in (i) learning the unintended 0:) poor problem-solving skills or (iii) little transfer. As long as the learne~\" does not go beyond the informaBon given (the concrete word level), he cannot transfer the gained knowledge to similar situations, because the perception of similarity presupposes abstraction. Given these criticisms, it would be useful to have a system which has the qualities mentioned above without having the drawbacks. A good learning environment should be both flexible and constraining enough: * to allow for simulation of real Communication, that is to say, to provide a setting where both participants can take the initiative and control the information-flow, * O \" \" t ensure the learmng of the appropriate material (i.e., what to learn) as well as the necessary problem-solving skills (the methods, i.e, how to learn). A computerprogram could provide such an environment. It would offer different k!nds oiu0027 !nformation (see below: trace-function), while answering me stuuentu0027s questions as ne goes aJong generating and testing different sorts of hypotheses. 3 THE COGNITIVE ENGENEERu0027S TASK: to provide the user a friendly interface We will describe here a system under development, whose major goals are: * O u0027 \" \" t provide an environment whtch allows communication between a learner (student) and an expert (in our case the system); * O \" u0027 \" u0027 t s~mulate the mformatton-processmg aspect of natural learning, i.e., the inductive learning of grammatical rules to generate sentences in French. * to allow teachers and psychologists to test various theories.\\nExperiential learning\\nAlgorithmic learning theory\\nInductive transfer\\nComputer science\\nNatural language\\nLanguage acquisition\\nLearning environment\\nNatural language processing\\nArtificial intelligence\\nKnowledge base\\nDiscovery learning',\n",
       " 840705: 'The Role of Genetic Programming in Describing the Microscopic Structure of Hydrating Plaster\\nYear: 2002\\n#Citations: 1\\nConference\\n\\nComputer science\\nGenetic programming\\nArtificial intelligence\\nMachine learning',\n",
       " 842930: 'An Improved Text Retrieval Algorithm Based on Suffix Tree Similarity Measure\\nYear: 2010\\n#Citations: 0\\nConference\\nSpringer, Berlin, Heidelberg\\nIn information retrieval area, popular methods considered word frequency of retrieval terms and text corpus. These methods ignored the word sequence information between retrieval terms and text corpus, and then the good result limited to some special domains. This paper analyzes the word sequence information, and then computes the similarity between the query and text documents of corpus by applying a suffix tree similarity that combines with TF-IDF weighting method. Experimental results on standard document benchmark corpus RUTERS indicate that the new retrieval algorithm is an effective text retrieval algorithm. Comparing with the results of traditional word term weight TF-IDF similarity measure in the same retrieval algorithm, proposed method achieves an improvement of about 20% on the average of precision score.\\nWeighting\\nInformation retrieval\\nSimilarity measure\\nWord lists by frequency\\nComputer science\\nText corpus\\nAlgorithm\\nGeneralized suffix tree\\nSuffix tree\\nCompressed suffix array\\nText retrieval',\n",
       " 843524: 'STARLET: an affix-based compiler compiler designed as a logic programming system\\nYear: 1990\\n#Citations: 5\\nConference\\nSpringer, Berlin, Heidelberg\\nWe present STARLET, a new compiler compiler which compiles Extended Affix Grammars defining a translation into an executable program : the translator. We look at its operational semantics and we focus on the points which are close to or different from Prolog procedural semantics. We discuss the two interwoven issues which are Program Reliability (due to many static checks) and Program Efficiency (optimizations at compile time). Both are reached through a systematic use of grammatical properties.\\nOperational semantics\\nInterprocedural optimization\\nProgramming language\\nFunctional compiler\\nComputer science\\nCompiler-compiler\\nCompile time\\nCompiler correctness\\nCompiler\\nCompiler construction',\n",
       " 845024: 'A Clustering Algorithm for Predicting CardioVascular Risk\\nYear: 2007\\n#Citations: 2\\nConference\\n\\nCluster analysis is one area of machine learning of particular interest to data mining. It provides for the organization of a collection of patterns, represented as a vector in a multidimensional space, into clusters based on the similarity of these patterns. Medical decision support is also of increasing research interest. Ongoing collaborations between cardiovascular clinicians and computer science are looking at the application of neural networks, and in particular clustering, to the area of individual patient diagnosis, based on clinical records. The cardiovascular domain is characterized as a mixture of continuous and discrete data. This limits the use of the K-means algorithm, which is widely used for partitioning clusters in data mining. This paper presents an improvement on the K-means algorithm (KMIX) and allows its application to the mixture of attribute types found in the cardiovascular domain.\\nk-means clustering\\nData mining\\nCluster (physics)\\nComputer science\\nDecision support system\\nFSA-Red Algorithm\\nArtificial intelligence\\nCluster analysis\\nArtificial neural network\\nMachine learning',\n",
       " 846391: 'Specialized Affine Approximation for Nonlinear Systems Output Tracking Using Neural Networks\\nYear: 2009\\n#Citations: 1\\nConference\\nSpringer, Berlin, Heidelberg\\nA special model of artificial neural networks has been developed for the purpose of output tracking of a class of nonlinear systems and an original training structure basing on the error back-propagation algorithm is introduced. This approach which, on the ground of input-output observations, turns feasible the use of inverse control techniques appears much simpler than other existing neural control approaches for inverse control problem. Simulation results reveal that the proposed approach presents rapid training and good tracking performances.\\nIntelligent control\\nFeedforward neural network\\nComputer science\\nControl theory\\nStochastic neural network\\nRecurrent neural network\\nTypes of artificial neural networks\\nTime delay neural network\\nArtificial intelligence\\nDeep learning\\nArtificial neural network\\nMachine learning',\n",
       " 847042: 'An Enhanced Cluster Based Routing Algorithm for Wireless Sensor.\\nYear: 2006\\n#Citations: 10\\nConference\\n\\nKey distribution in wireless sensor networks\\nMultipath routing\\nLink-state routing protocol\\nDynamic Source Routing\\nComputer science\\nDestination-Sequenced Distance Vector routing\\nComputer network\\nWireless Routing Protocol\\nMobile wireless sensor network\\nZone Routing Protocol',\n",
       " 848696: 'Master-slave PGA and performance metrics\\nYear: 2007\\n#Citations: 0\\nConference\\nACTA Press\\nThis work deals with a global model of PGA. A short overview of the model is introduced. Our research is concentrated on a master-slave algorithm (somewhere also called global). The complexity analysis of the algorithm is created and the processor optimality is derived from the analysis. Based on the optimality derivation, theoretical results with results from the real implementation are compared and the limitations of the algorithm are stated.\\nMathematical optimization\\nComputer science\\nMaster/slave\\nGlobal model',\n",
       " 849475: 'A method for modeling liaison in a speech recognition system for French.\\nYear: 1998\\n#Citations: 3\\nConference\\n\\nIn French the pronunciations of many words change dramatically depending on the word immediately preceding it. The result of this phenomenon, known as “liaison”, in an ASR system that does not model “liaison” is the requirement of unnatural pronunciation and much user dissatisfaction. We present, in this paper, the development of an acoustic model which takes into account the wide variability of word pronunciations caused by the liaison, the integration of this model into a French continuous speech recognition system and decoding results.\\nSpeech corpus\\nPronunciation\\nComputer science\\nSpeech recognition\\nSpeaker recognition\\nArtificial intelligence\\nContinuous speech recognition system\\nNatural language processing\\nDecoding methods\\nSpeech technology\\nAcoustic model',\n",
       " 852384: 'Improving static variable orders via invariants\\nYear: 2007\\n#Citations: 8\\nConference\\nSpringer, Berlin, Heidelberg\\nChoosing a good variable order is crucial for making symbolic state-space generation algorithms truly efficient. One such algorithm is the MDD-based Saturation algorithm for Petri nets implemented in SmArT, whose efficiency relies on exploiting event  :[35],\"paper presents a novel, static ordering heuristic that considers place invariants of Petri nets. In contrast to related work, we use the functional dependencies encoded by invariants to merge decision-diagram variables, rather than to eliminate them. We prove that merging variables always yields smaller MDDs and improves event locality, while eliminating variables may increase MDD sizes and break locality. Combining this idea of merging with heuristics for maximizing event locality, we obtain an algorithm for static variable order which outperforms competing approaches regarding both time-efficiency and memory-efficiency, as we demonstrate by extensive benchmarking.\\nBoolean function\\nDiscrete mathematics\\nLocality\\nHeuristic\\nPetri net\\nComputer science\\nBinary decision diagram\\nAlgorithm\\nFunctional dependency\\nTheoretical computer science\\nHeuristics\\nStatic variable',\n",
       " 852874: 'A Spatial Logic based on Regions and Connection.\\nYear: 1992\\n#Citations: 1709\\nConference\\n\\nMereotopology\\nSpatial intelligence\\nComputer science\\nSpatial logic\\nTheoretical computer science\\nSpatial–temporal reasoning\\nRegion connection calculus',\n",
       " 853457: 'Locating Tandem Repeats in Weighted Biological Sequences\\nYear: 2012\\n#Citations: 0\\nConference\\nSpringer, Berlin, Heidelberg\\nA weighted biological sequence is a string in which a set of characters may appear at each position with respective probabilities of occurrence. We attempt to locate all the tandem repeats in a weighted sequence. By introducing the idea of equivalence classes in weighted sequences, we identify the tandem repeats of every possible length using an iterative partitioning technique, and present the O(n 2) time algorithm.\\nTandem repeat\\nEquivalence relation\\nPattern recognition\\nComputer science\\nDirect repeat\\nArtificial intelligence\\nEquivalence class',\n",
       " 858012: 'Using a differential pressure sensor as spirometer\\nYear: 2012\\n#Citations: 0\\nConference\\nSpringer, Berlin, Heidelberg\\nFor a doctor to determine the most accurate diagnosis of diseases of the respiratory tract, it must be as accurate as possible insight into the problem. Imaging technology allows to look into the body, unfortunately for example lung is an organ, where without contrast agent does not buy the picture. Furthermore, the methods that can be used are whole body plethysmography or, a better option, spirometry. A measurement of spirometry is performed by the pneumotachograph or the spirometry. Spirometer measures lung volumes and lung capacity. Pneumotachograph is the flow rate measuring device, but can also be used for indirect measurement of lung volumes and capacities. Spirogram is the result of spirometry measurements.\\nBiomedical engineering\\nSpirometer\\nImaging technology\\nPattern recognition\\nLung\\nSpirometry\\nComputer science\\nLung volumes\\nPressure sensor\\nArtificial intelligence\\nWhole Body Plethysmography',\n",
       " 695567: 'Einsatz von Standardprozessen bei der Gestaltung von Lehrveranstaltungen.\\nYear: 2001\\n#Citations: 0\\n\\n\\nDieser Artikel beschreibt, wie mit Hilfe von Standardprozessen ein Softwarepraktikum im Hauptstudium an der Universitat Ulm gestaltet wurde. Dieses Praktikum sollte nicht nur Entwicklungstatigkeiten schulen, sondern insbesondere auch auf begleitende Tatigkeiten wie Konfigurationsund Qualitatsmanagement eingehen. Der Leser erhalt einen kurzen Uberblick uber den Aufbau des Praktikums, die Durchfuhrung im SS2000 und einen Einblick in die dabei gewonnenen Erfahrungen.',\n",
       " 709763: 'A Simple Multi-Secret Sharing Scheme to Achieve Both Optimal Improvement Ratios.\\nYear: 2007\\n#Citations: 0\\n\\n\\nSecure multi-party computation\\nSecret sharing\\nComputer science\\nComputer network',\n",
       " 714243: 'EPIQuest: A Multiuser and Multiproject Web Tool to Build Online Forms for Biomedical Studies\\nYear: 2011\\n#Citations: 0\\n\\nSpringer, Berlin, Heidelberg\\nThe growth, both in size and complexity, of current biomedical studies requires semi-automated and user-friendly computer tools to facilitate electronic data capture and reporting. However, existing tools are expensive (researchers aren´t able to pay for them) or they are too specifically developed that they cannot be extended to other applications. EPIQuest, an academic-research environment developed tool, overcome these limitations. EPIQuest is a multiuser web-based form building tool, with the capacity to manage multiple studies, each with multiple and multi-language questionnaires. It complies with all IT security and data protection legislation, including user authentication and role-based restrictions. Daily back-ups and a log files for audits complement the security of the application. We describe the performance of the EPIQuest in accommodating multiple international studies with several users working on various questionnaires in real time by secure web connection. We also compare EPIQuest with other similar tools.\\nWorld Wide Web\\nAuthentication\\nAudit\\nInternational studies\\nComputer tools\\nLegislation\\nEngineering\\nData Protection Act 1998\\nElectronic data capture',\n",
       " 718313: 'Richtigstellungen und Antworten zum Diskussionsbeitrag\\nYear: 2008\\n#Citations: 0\\n\\n\\nDer Inhalt meines Diskussionsbeitrages, auf den sich der vorangehende Text bezieht, last sich wie folgt zusammenfassen: Ein Fach wie die Physik ist stark, weil sie zwar vielfaltig strukturiert ist, in jeder Beziehung nach ausen aber geschlossen auftritt. Unser (gedachtes) Fach ist in vielerlei Hinsicht weitverstreut und deshalb ist es schwach. Wir sollten daher daruber diskutieren, wie wir es geschlossener und damit starker machen konnten. Die obige Reaktion von Herrn Hoppner auf diese Aufforderung last sich wie folgt paraphrasieren: (a) Die Situation ist bestens („... gar nicht so schlecht“) und wir sind auf einem guten Weg. Fur Erorterungen daruber im Sinne des Bibelschen Beitrages gibt es keinen besonderen Anlas. (b) Ohne engeren Bezug zu Bibels Beitrag behandelt Herr Hoppner aber daruber hinaus eine Reihe von eigenen Themen, die von den Gedanken der Steinzeitmenschen bis hin zu Veranstaltungen und Studiengangen an seiner Universitat DuisburgEssen reichen. Da die vielen unter (b) angesprochenen Themen mit meinem Beitrag nichts zu tun haben, besteht fur mich keinerlei Anlas zu einer Auserung hierzu. (a) druckt eine personliche Meinung aus, die man respektiert, wenn auch nicht teilt. Insoweit besteht auch hier kein Anlas zur Kommentierung. Leider hat Herr Hoppner aber bei der Formulierung seiner Meinung Verfalschungen meines Textes einfliesen lassen. Schon den Gesamttenor meines Textes einer sachlich-nuchternen Analyse hat er zu einer „Klage“ verfalscht. Es besteht daher Anlas zu einer Korrektur, wobei ich mich auf die drei wichtigsten Punkte beschranke.',\n",
       " 730754: 'Supporting Operating Systems for Reconfigurable Computing: A Distributed Service Oriented Approach.\\nYear: 2009\\n#Citations: 6\\n\\n\\nOperating systems for reconfigurable computing are becoming an attractive field of research. They provide a well-defined programming model and a run-time environment, which greatly simplifies the development process and management of reconfigurable applications. One of the main challenges for the design of such systems is to provide both powerful and efficient abstractions to deal with the complexity of the integration between hardware and software domains in general, and the special features of the reconfiguration process in particular. The contributions in this paper try to give solutions to both problems, first taking a distributed system approach based on system-level middleware, and second providing transparent reconfiguration as one of the advanced services provided by the middleware.\\nMiddleware\\nMiddleware (distributed applications)\\nDistributed object\\nProgramming paradigm\\nComputer science\\nDistributed design patterns\\nDistributed algorithm\\nOperating system\\nControl reconfiguration\\nDistributed computing\\nReconfigurable computing',\n",
       " 732193: 'Using Analytical Modeling To Ensure Client/Server Application Performance.\\nYear: 1996\\n#Citations: 2\\n\\n\\nServer-side\\nClient\\nRemote evaluation\\nComputer science\\nComputer network\\nOperating system\\nApplication server\\nClient–server model',\n",
       " 734514: 'Divide and Conquer: Implementing the Capacity Performance Council in Pieces.\\nYear: 2001\\n#Citations: 0\\n\\n\\nComputer science\\nComputer security\\nDivide and conquer algorithms',\n",
       " 756926: 'An O-O Language for Advanced Applications.\\nYear: 1991\\n#Citations: 0\\n\\n\\nProgramming language\\nComputer science\\nLanguage technology',\n",
       " 758481: 'Optimizing multi-thread string matching for network processor based intrusion management system.\\nYear: 2006\\n#Citations: 0\\n\\n\\nString matching is the core algorithm and the most time consuming operation of almost every modern Network Intrusion Management System (NIMS). In this paper we aim at integrating string matching with multi-thread parallelism to dramatically improve the performance of NIMS. The string matching procedure under multi-thread parallelism situation is modeled and researched. The results are utilized to instruct the design of an improved Aho-Corasick (AC) algorithm, named as AC_MT, for network processor (NP) based NIMS. A simplified NIMS prototype and both the AC and AC_MT algorithms are implemented on Intel’s NP platform IXDP2850. The evaluation results tested with SmartBits 600 reveals that the performance of the NIMS prototype is improved by 44.7%~148.8% depending on the different lengths of the input packets and different number of threads, under both algorithms using the same number of threads situation.\\nString searching algorithm\\nNetwork processor\\nIntrusion\\nComputer science\\nParallel computing\\nNetwork packet\\nThread (computing)\\nManagement system',\n",
       " 759219: 'Remote copy 100 km testing.\\nYear: 2006\\n#Citations: 0\\n\\n\\nRemote sensing',\n",
       " 769826: 'Designing and Measuring High-Performance Processors.\\nYear: 1988\\n#Citations: 0\\n\\n\\nComputer science\\nEmbedded system',\n",
       " 773755: 'A Survey of Social Web Mining Applications for Disease Outbreak Detection\\nYear: 2015\\n#Citations: 3\\n\\nSpringer, Cham\\nSocial Web Media is one of the most important sources of big data to extract and acquire new knowledge. Social Networks have become an important environment where users provide information of their preferences and relationships. This information can be used to measure the influence of ideas and the society opinions in real time, being very useful on several fields and research areas such as marketing campaigns, financial prediction or public healthcare among others. Recently, the research on artificial intelligence techniques applied to develop technologies allowing monitoring web data sources for detecting public health events has emerged as a new relevant discipline called Epidemic Intelligence. Epidemic Intelligence Systems are nowadays widely used by public health organizations like monitoring mechanisms for early detection of disease outbreaks to reduce the impact of epidemics. This paper presents a survey on current data mining applications and web systems based on web data for public healthcare over the last years. It tries to take special attention to machine learning and data mining techniques and how they have been applied to these web data to extract collective knowledge from Twitter.\\nData science\\nPublic health\\nWeb system\\nSocial network\\nSocial web\\nCollective intelligence\\nOutbreak\\nPublic healthcare\\nBig data\\nMedicine',\n",
       " 774743: 'Change paths in reasoning\\nYear: 2007\\n#Citations: 2\\n\\nCEUR-WS.org\\nMillions of research funding has been put down to develop - what I call - old forms - of reasoning that are characterized by strong focus on theoretical properties and strict adherence to the completeness properties of reasoning procedures. Despite the large amount of work and results that have been achieved, various benchmarks reinstate that the progress does not suffice for needs in the scale of many enterprise applications and the  :[71],\"believe that a fundamental change in research on reasoning is required, giving up basic assumptions such as completeness to gain performance required in many real-world applications. These new paths should start with a deriving a clear understanding of what types of questions should be solved, where reasoning can help, where properties like soundness and completeness are really required and what impact of departing from those properties is acceptable.\\nData science\\nSoundness\\nCompleteness (statistics)\\nCompleteness (order theory)\\nManagement science\\nMathematics',\n",
       " 778541: 'Adaptive Algorithm in Glossary Search.\\nYear: 2003\\n#Citations: 0\\n\\n\\nSearch algorithm\\nComputer science\\nArtificial intelligence\\nAdaptive algorithm\\nGlossary\\nBest-first search',\n",
       " 791175: 'Einsatz des Konzepts Machine-in-the-Loop-Learning.\\nYear: 2002\\n#Citations: 0\\n\\n',\n",
       " 795791: 'Approach to Generating Monitoring Code toward Advanced Self-healing\\nYear: 2011\\n#Citations: 0\\n\\nSpringer, Berlin, Heidelberg\\nSystem administrator deals with many problems, as computing environment becomes increasingly complex. Systems with ability to recognize system states and heal to resolve these problems offer a solution. Much experience and knowledge are required to build a self-healing system. Self-healings have inherent difficulties. Much attention has recently been focused on self-healing ability that recognizes problems arising in a target system. However, if a system wants to provide self-healing functionalities, there are many loads such as target system analysis and system environment analysis for external problem. Thus, this paper proposes using deployment diagram for self-healing approach to determine problem arising in external environment. The UML deployment diagram is widely used for resource specification of a system and generally designed in the system design phase. The approach proposes of 1) analysis for associations between software and hardware; 2) generating a monitor using constraints in deployment diagrams; and 3) adding the monitor to the component after adapting it to the specific software architecture. As proof of the approach, we automatically generate a resource monitor automatically, and used a video conference system. We illustrate how the method detects anomalies using the example.\\nSoftware deployment\\nUnified Modeling Language\\nSoftware engineering\\nComputer science\\nSystems design\\nSoftware\\nDeployment diagram\\nSystem administrator\\nSoftware architecture\\nVideoconferencing',\n",
       " 804069: 'Data Quality Assurance in Workflow Management.\\nYear: 2008\\n#Citations: 0\\n\\n\\nWorkflow technology\\nData quality\\nComputer science\\nDocument management system\\nWorkflow engine\\nEnterprise data management\\nData management\\nWorkflow\\nWorkflow management system\\nProcess management',\n",
       " 809930: 'Focused Batch Tuning.\\nYear: 1999\\n#Citations: 0\\n\\n\\nProcess engineering',\n",
       " 822868: 'The Modularity Equation in the Class of 2-uninorms\\nYear: 2015\\n#Citations: 5\\n\\nSpringer, Cham\\nThis paper is mainly devoted to solving the functional equations of modularity of special class of aggregation operators with 2-neutral elements. Our investigations are motivated by modular logical connectives and their generalizations used in fuzzy set theory e.g. triangular norms, conorms, uninorms and nullnorms. In this work the modularity of two binary operations from the family of 2-uninorms (\\\\(\\\\textbf{U}_{k(e,f)}\\\\)) which generalizes both uninorms and nullnorms is considered. In particular, all of the possible solutions for one of the three classes of these operations depending on the position of its absorbing and neutral elements are characterized.\\nLogical connective\\nGeneralization\\nPure mathematics\\nFuzzy set\\nOperator (computer programming)\\nModular design\\nFunctional equation\\nMathematics\\nBinary operation\\nModularity',\n",
       " 837272: 'Gloss Patch Selection Based on Support Vector Regression.\\nYear: 2002\\n#Citations: 4\\n\\n\\nPattern recognition\\nComputer science\\nSupport vector machine\\nGloss (annotation)\\nArtificial intelligence',\n",
       " 848847: 'ABACUS - A Fast Fortran System For The IBM/360.\\nYear: 1968\\n#Citations: 0\\n\\n\\nIBM\\nProgramming language\\nAbacus (architecture)\\nComputer science\\nParallel computing\\nFortran',\n",
       " 852449: 'Robust and Efficient Estimation of Elasticity Parameters using the linear Finite Element Method.\\nYear: 2007\\n#Citations: 37\\n\\n\\nRealistic elasticity parameters are important for the accurate simulation of deformable objects, e. g. in medical simulations. In this paper, we present an approach for estimating elasticity parameters for isotropic elastic materials using the linear Finite Element Method. Employing the initial undeformed geometry and a measured forcedeformation relation, the method computes the elasticity parameters based on Quadratic Programming. The structure of the stiffness matrix is employed to accelerate the estimation process. Experiments suggest, that the parameter estimation approach can be used for noisy data.\\nApplied mathematics\\nIsotropy\\nMathematical optimization\\nExtended finite element method\\nFinite element method\\nStiffness matrix\\nQuadratic programming\\nEstimation theory\\nElasticity (economics)\\nMathematics\\nMixed finite element method',\n",
       " 853962: 'Minimal Preference Change\\nYear: 2013\\n#Citations: 2\\n\\nSpringer, Berlin, Heidelberg\\nWe propose a novel approach to preference change. We treat a set of preferences as a special kind of theory, and define minimal change contraction and revision operations in the spirit of minimal change as advocated by the Alchourron, Gardenfors, and Makinson AGM theory of belief revision. We characterise minimal contraction of preference sets by a set of postulates and prove a representation theorem. We also give a linear time algorithm which implements minimal contraction by a single preference. We also define minimal contraction by a set of preferences, and for a significant special case state postulates, prove a representation theorem, and provide an efficient algorithm implementing minimal contraction by a set of preferences.\\nDiscrete mathematics\\nAlgebra\\nRepresentation theorem\\nTime complexity\\nMathematics\\nBelief revision\\nSpecial case',\n",
       " 856447: 'Compiling High Performance Fortran.\\nYear: 1995\\n#Citations: 9\\n\\nSociety for Industrial and Applied Mathematics, Philadelphia, PA (United States)\\nHigh Performance Fortran (HPF) is the first widely supported, efficient, and portable parallel programming language for shared and distributed-memory systems. This paper describes a production-quality HPF compiler for a set of parallel machines.\\nProgramming language\\nComputer science\\nParallel processing\\nParallel computing\\nFortran\\nCompiler\\nParallel programming model\\nHigh Performance Fortran',\n",
       " 858685: 'Integration agiler Prozesse in die Softwaretechnik- Ausbildung im Informatik-Grundstudium\\nYear: 2003\\n#Citations: 2\\n\\n\\nObjektorientierte Programmierung zu lehren erfordert einiges an Didaktik, da die Objektorientierung stark in die Praxis der Softwareentwicklung eingebunden ist. Das Paradigma muss aber nicht nur praktisch, sondern auch konzeptionell in den Software-Entwicklungsprozessen eingeordnet werden. Die Bezuge reichen von der Analyse uber den Entwurf und die Implementierung bis hin zur Integration in bestehende Softwarelandschaften. Nach unseren Erfahrungen ist fur eine solche Einordnung die klassische Veranstaltungsform mit Vorlesung und begleitenden, kleinen, bindungslosen Ubungen nicht mehr angemessen. Wir planen deshalb fur das Sommersemester 2003, die in die Objektorientierung einfuhrende Grundstudiumsveranstaltung neu zu strukturieren. Dabei sollen Prinzipien agiler Entwicklungsprozesse in den Ubungsteil eingehen. Agile Methoden sind durch ihre kurzen Projektzyklen, die sich iterativ entwickelnden Architekturen und die vielschichtigen Ruckkopplungsmechanismen aus unserer Sicht besonders geeignet. Die Studierenden lernen dadurch relevante Fragenstellungen der objektorientierten Softwareentwicklung in kurzer Zeit aus eigener Erfahrung kennen und konnen daruber in Rucksprachen diskutieren. So konnen dann Konzepte in der Vorlesung auf wissenschaftlichem Niveau reflektiert werden.\\nHumanities\\nPhilosophy',\n",
       " 859940: 'Relating disjunctive logic programs to default theories\\nYear: 1993\\n#Citations: 14\\nConference\\nMIT Press\\nDefault logic\\nComputer science\\nDisjunctive normal form\\nAlgorithm\\nDisjunctive syllogism\\nTheoretical computer science\\nStable model semantics\\nPhilosophy of logic\\nPredicate functor logic\\nLogic programming\\nDynamic logic (modal logic)',\n",
       " 865632: 'Le Rayonnement D’une Antenne Parabolique Par Une Approche Temporelle Semi-Analytique\\nYear: 2005\\n#Citations: 2\\nJournal\\nSpringer\\nCet article decrit une methode semi-analytique du calcul du champ electromagnetique rayonne par une antenne a reflecteur parabolique. Basee sur l’approximation de l’optique geometrique dans le domaine temporel, la methode s’appuie sur les travaux de Skulkin et Turchin sur le rayonnement de reflecteurs plans. Elle tient compte de la polarisation de la source primaire ainsi que de sa defocalisation possible. Les resultats numeriques presentes illustrent son egale capacite a simuler en regime impulsionnel ou frequentiel, en regime transitoire ou etabli, le rayonnement electromagnetique dans la zone eclairee, en tout point proche ou eloigne du reflecteur. Avec cette methode, quelques secondes de calculs sur un ordinateur disposant d’un processeur Rise a 400 MHz suffisent pour simuler le comportement electromagnetique d’une telle antenne. La methode a ete validee par comparaison avec les resultats de la litterature sur le sujet et par verification du bilan de puissance.\\nAntenna radiation patterns\\nIntegral representation\\nOptics\\nMathematics',\n",
       " 867361: 'On the security of an efficient attribute-based signature\\nYear: 2013\\n#Citations: 4\\nConference\\nSpringer, Berlin, Heidelberg\\nIn CT-RSA 2011, Maji et.al proposed an attribute-based signature (ABS) scheme, which is the most efficient ABS scheme that supports general predicates until now. They claimed that their ABS scheme is unforgeable under generic group model. Unfortunately, we found a forgery attack on this ABS scheme. In this paper, we firstly give a forgery example, then analyze the reason cause this attack and gives the conditions this attack worked. We found this attack is fatal to Maji et.al’s ABS scheme.\\nAttribute based signature\\nComputer science\\nComputer security\\nGeneric group model',\n",
       " 868042: 'Learning attentive fusion of multiple bayesian network classifiers\\nYear: 2012\\n#Citations: 0\\nConference\\nSpringer, Berlin, Heidelberg\\nUsing Bayesian networks (BNs) for classification tasks has received significant attention as BNs can encode and represent domain-expertsu0027 knowledge as well as data in their structures and conditional probability tables. While structure learning and constructing the structure by hand according to an ensemble of domain-expert opinions are two common approaches to make a BN structure, finding an optimal structure to attain a high correct classification rate -especially for high dimensional problems- is still a challenging task. In this paper we propose a framework - called Local Bayesian Network Experts Fusion (LoBNEF) - in that, instead of making a single network, multiple Bayesian Network Classifiers (BNCs) are built and their outputs are attentively fused. The attentive fusion process is learned interactively using a Bayesian reinforcement learning method. We demonstrate that learning different BNCs in the first step and then fusing their decisions in an attentive and sequential manner is an efficient and robust method in terms of correct classification rate.\\nENCODE\\nVariable-order Bayesian network\\nConditional probability\\nPattern recognition\\nComputer science\\nStructure learning\\nFusion\\nBayesian network\\nArtificial intelligence\\nClassification rate\\nMachine learning\\nReinforcement learning',\n",
       " 870555: 'Study of Game Scheme for Elementary Historical Education\\nYear: 2008\\n#Citations: 2\\nConference\\nSpringer, Berlin, Heidelberg\\nIt is important for development of education game to get the correct balance and find the best hybrid mode between education and game. In this paper, the factor considered during the design of education game is discussed, and several hybrid modes of education and game are proposed. Specifically for elementary historical education, the paper research on education game scheme of network role-play from the perspective of educational psychology, and design a case of historical education game using RPG mode with fully considering of knowledge and education. Players experience history by historical role-play, convey the sentiment of history by communication of players, and do with the hybrid integration of the game and education.\\nVideo game design\\nComputer science\\nGame art design\\nSimulation\\nGame design document\\nGame design\\nMetagaming\\nSimulations and games in economics education\\nGame Developer\\nMultimedia\\nNon-cooperative game',\n",
       " 875054: 'Geocast Routing in Vehicular Networks for Reduction of CO 2 Emissions\\nYear: 2011\\n#Citations: 7\\nConference\\nSpringer, Berlin, Heidelberg\\nPollution and gas emissions are increasing and negatively impacting global warming. Consequently, researchers are looking for solutions that save environment. Greenhouse gas (GHG) emissions from vehicles are considered to be one of the main contributing sources. Carbon dioxide (CO 2) is the largest component of GHG emissions. Vehicular networks offer promising technology that can be applied for reduction of CO 2 emissions. One of the major applications of vehicular networks is Intelligent Transportation Systems (ITS). To exchange and distribute messages, geocast routing protocols have been proposed for ITS applications. Almost all of these protocols evaluate network-centric performance measures, instead of evaluating the impact of the protocol on the vehicular system. Nowadays, the harmful effects of air pollutants have been the subject of considerable public debate. Vehicles’ stop-and-go condition, high speed, and high accelerations are environmentally unfriendly actions (EUF) that increase the amount of emissions. These actions can happen frequently for vehicles approaching a traffic light signal (TLS). Therefore, we propose a new protocol named environmentally friendly geocast (EFG), which focuses on minimizing CO 2 emissions from vehicles approaching a TLS by avoiding the EUF actions. Simulation results demonstrate that the proposed protocol can achieve effective reduction of vehicle CO 2 emissions.\\nGlobal warming\\nAutomotive engineering\\nComputer science\\nEnvironmentally friendly\\nComputer network\\nPollution\\nIntelligent transportation system\\nGeocast\\nGreenhouse gas\\nVehicular ad hoc network\\nRouting protocol',\n",
       " 876431: 'Trust Management Through Hardware Means: Design Concerns and Optimizations\\nYear: 2011\\n#Citations: 7\\nConference\\nSpringer, Dordrecht\\nTrust in security demanding software platforms is a very important feature. For this reason, Trusted computing group has specified a TPM hardware module that can enforce and guaranty a high trust level to all the platform’s involved entities. However, the TPM’s features can not be fully exploited in systems under extreme physical conditions. To solve this problem, the use of a special purpose hardware module, physically connected to a host security system’s device acting as a local trusted third party, has been proposed in literature. In this chapter, we describe the hardware structure of such a hardware module, called Autonomous Attestation Token (AAT) and discuss hardware resource constrains, security bottlenecks that can stem from improper design of its various components integrated in the AAT’s structure. We conclude that the efficiency of the AAT system is closely related to the efficiency of its public key encryption–decryption unit (RSA encryption–decryption module). In this book chapter, we address these issues by describing a design methodology toward a low hardware resources (small chip covered area) and side channel attack resistant RSA hardware architecture. The described hardware architectures’ implementations provide very optimistic results of very low chip covered area and high computation speed thus verifying the efficiency of the proposed algorithms and architecture design approach.\\nTrusted third party\\nTrusted Computing\\nComputer science\\nDesign methods\\nSoftware\\nSide channel attack\\nComputer hardware\\nPublic-key cryptography\\nSecurity token\\nHardware architecture',\n",
       " 877544: 'Minimum Memory Vectorisation of Wavelet Lifting\\nYear: 2013\\n#Citations: 4\\nConference\\nSpringer, Cham\\nWith the start of the widespread use of discrete wavelet transform the need for its effective implementation is becoming increasingly more important. This work presents a novel approach to discrete wavelet transform through a new computational scheme of wavelet lifting. The presented approach is compared with two other. The results are obtained on a general purpose processor with 4-fold SIMD instruction set (such as Intel x86-64 processors). Using the frequently exploited CDF 9/7 wavelet, the achieved speedup is about 3× compared to naive implementation.\\nLifting scheme\\nComputer science\\nParallel computing\\nSecond-generation wavelet transform\\nDiscrete wavelet transform\\nCascade algorithm\\nStationary wavelet transform\\nWavelet packet decomposition\\nWavelet\\nSpeedup',\n",
       " 880330: 'Harmonizing the semantics of technical terms by the generic component model.\\nYear: 2010\\n#Citations: 1\\nJournal\\nStud Health Technol Inform\\nWorking interoperability not only requires harmonized systemu0027s architectures, but also the same interpretation of technical specifications in order to guide the development process. This paper analyzes the commonly used terms to introduce different kinds of coded concepts by an alignment with the Generic Component Model (GCM).\\nData mining\\nTechnical specifications\\nComputer science\\nInteroperability\\nGCM transcription factors\\nSemantics',\n",
       " 880700: 'An efficient parallel strategy for matching visual self-similarities in large image databases\\nYear: 2012\\n#Citations: 0\\nConference\\nSpringer, Berlin, Heidelberg\\nDue to high interest of social online systems, there exists a huge and still increasing amount of image data in the web. In order to handle this massive amount of visual information, algorithms often need to be redesigned. In this work, we developed an efficient approach to find visual similarities between images that runs completely on GPU and is applicable to large image databases. Based on local self-similarity descriptors, the approach finds similarities even across modalities. Given a set of images, a database is created by storing all descriptors in an arrangement suitable for parallel GPU-based comparison. A novel voting-scheme further considers the spatial layout of descriptors with hardly any overhead. Thousands of images are searched in only a few seconds. We apply our algorithm to cluster a set of image responses to identify various senses of ambiguous words and re-tag similar images with missing tags.\\nModalities\\nComputer vision\\nData mining\\nExistential quantification\\nComputer science\\nArtificial intelligence\\nDatabase',\n",
       " 882327: 'IT-Arbeitsmarkt - Katastrophe oder Normalisierung?\\nYear: 2002\\n#Citations: 0\\nJournal\\n\\nWorld Wide Web\\nComputer science',\n",
       " 884621: 'Training Resource Allocating Network using Medoids and Significant Patterns.\\nYear: 2007\\n#Citations: 0\\nConference\\n\\nComputer science\\nResource allocation\\nArtificial intelligence\\nMachine learning\\nMedoid',\n",
       " 891461: 'Linear time computable problems and first-order descriptions\\nYear: 1996\\n#Citations: 113\\nJournal\\nCambridge University Press (CUP)\\nDiscrete mathematics\\nMathematical economics\\nAlgebra\\nFirst order\\nTime complexity\\nComputable number\\nMathematics\\nComputable analysis',\n",
       " 897687: 'CONTENT-BASED IMAGE RESIZING ON MOBILE DEVICES\\nYear: 2012\\n#Citations: 5\\nConference\\n\\nContent-aware image resizing are effective algorithms that allow to take into account the visual content of images during the resizing process. Despite the technological advances in the context of mobile devices, content-aware image resizing algorithms are still far to be used on a hand held device due to the computational resources needed during the resizing. In this paper we afford this problem employing a method which has linear complexity with respect to the number of lines (rows/columns) to be reduced/augmented. The method has been tested, both qualitatively and quantitatively, on a mobile platform.\\nRow\\nComputer vision\\nResizing\\nComputer science\\nMobile device\\nArtificial intelligence\\nLinear complexity',\n",
       " 901073: 'Hiding Fuzzy Association Rules Set.\\nYear: 2009\\n#Citations: 0\\nConference\\n\\nFuzzy classification\\nDefuzzification\\nFuzzy set operations\\nComputer science\\nFuzzy logic\\nArtificial intelligence\\nAdaptive neuro fuzzy inference system\\nFuzzy associative matrix\\nFuzzy association rules\\nMachine learning',\n",
       " 903459: 'A Category of Labelled Petri Nets and Compositional Proof System (Extended Abstract)\\nYear: 1988\\n#Citations: 6\\nConference\\n\\nDiscrete mathematics\\nCombinatorics\\nPetri net\\nComputer science\\nStochastic Petri net',\n",
       " 905794: 'A Sharing Analysis for SAFE\\nYear: 2006\\n#Citations: 17\\nConference\\n\\nWe present a sharing analysis for the functional language Safe. This is a first-order eager language with facilities for programmer-controlled destruction and copying of data structures. It provides also regions, i.e. disjoint parts of the heap where the programmer may allocate data structures. The language and its associated type syste m guaranteeing that destruction facilities and region management are done in a safe way were presented in a previous paper [6]. That type system uses two functions, called sharerec and shareall, which are supposed to give upper approximations to the set of variables respectively sharing a recursive substructure, or any substructure, of a given variable. In this paper we present the formal definition of such functio ns. In order to have a modular and efficient analysis, we provide signatures for functions , which summarize their sharing behaviour. The paper ends up describing the implementation of the analysis and some examples.\\nData structure\\nProgramming language\\nDisjoint sets\\nProgrammer\\nFunctional programming\\nComputer science\\nCopying\\nHeap (data structure)\\nTheoretical computer science\\nModular design\\nRecursion',\n",
       " 907500: 'A Qualitative Investigation of Risk Perceptions in the Case of Check-in Services\\nYear: 2014\\n#Citations: 1\\nConference\\n\\nVarious data scandals have raised people’s risk perceptions all around the world. Due to the sensitivity of location information, these concerns are particularly significant in the context of mobile location-based services (LBS) and are generally considered a major inhibiting factor for their usage. The aim of this study is to investigate different risk facets that encompass a special type of LBS usage, namely location-based social networking service (LBSNS) usage. Based on previous literature, eight risk facets are revealed. The qualitative study provided support for five of the identified risk facets, namely: secondary use risk, provider misrepresentation risk, social risk, property risk and surveillance risk. Additionally, perceived risk of stalking was identified as a new risk facet and the concept of social risk was refined into three subcategories. This study contributes to extant research by further specifying perceived risk which leads to a better understanding of the concept of LBSNS usage.\\nInternet privacy\\nSocial network\\nCheck-in\\nComputer science\\nMisrepresentation\\nKnowledge management\\nRisk perception\\nStalking\\nExtant taxon\\nQualitative research\\nPerception',\n",
       " 909340: 'A time synchronization method for wireless sensor networks\\nYear: 2012\\n#Citations: 3\\nConference\\nSpringer, Berlin, Heidelberg\\nAs consistent time scale is essential to facilitate group operations and improve network performance, time synchronization is regard as a critical piece of infrastructure for distributed network measurement and control systems, especially for wireless sensor networks (WSNs). However, existing time synchronization algorithms for WSNs either do not provide enough scalability to achieve compatibility with other sync protocols, or do not fully take into account the characteristics of WSNs. This paper proposes a time synchronization method (TSM) to achieve precise time synchronization and reach the frequency drift compensation in WSNs at the same time. Evaluations show that TSM synchronizes wireless sensor nodes precisely with a magnitude of microsecond. Moreover, it has a good performance of stability and energy efficient.\\nKey distribution in wireless sensor networks\\nWireless\\nEfficient energy use\\nComputer science\\nData synchronization\\nReal-time computing\\nsync\\nWireless sensor network\\nNetwork performance\\nScalability',\n",
       " 914322: 'From restricted path consistency to Max-Restricted Path Consistency\\nYear: 1997\\n#Citations: 55\\nConference\\nSpringer, Berlin, Heidelberg\\nThere is no need to show the importance of the filtering techniques to solve constraint satisfaction problems i.e. to find values for problem variables subject to constraints that specify which combinations of values are consistent. They can be used during a preprocessing step to remove once and for all some local inconsistencies, or during the search to efficiently prune the search tree. Recently, in [5], a comparison of the most practicable filtering techniques concludes that restricted path consistency (RPC) is a promising local consistency that requires little additional cpu time compared to arc consistency while removing most of the path inverse inconsistent values. However, the RPC algorithm used for this comparison (presented in [1] and called RPC1 in the following) has a non optimal worst case time complexity and bad average time and space complexities. Therefore, we propose RPC2, a new RPC algorithm with O(end2) worst case time complexity and requiring less space than RPC1 in practice. The second aim of this paper is to extend RPC to new local consistencies, k-RPC and Max-RPC, and to compare their pruning efficiency with the other practicable local consistencies. Furthermore, we propose and study a Max-RPC algorithm based on AC-6 that we used for this comparison.\\nConstraint satisfaction\\nMathematical optimization\\nLocal consistency\\nSearch algorithm\\nCPU time\\nComputer science\\nFilter (signal processing)\\nAlgorithm\\nConstraint satisfaction problem\\nTime complexity\\nSearch tree',\n",
       " 914608: 'Scale-and-orientation independent computer pattern perception\\nYear: 1990\\n#Citations: 0\\nConference\\n\\nComputer science\\nPattern perception\\nCognitive psychology\\nArtificial intelligence\\nCategorical perception\\nMachine learning',\n",
       " 918237: 'Research on a Integrated Real-Time Simulation Platform for Aircraft Control System\\nYear: 2012\\n#Citations: 1\\nConference\\nSpringer, Berlin, Heidelberg\\nIn order to meet the requirements of hardware-in-the-loop simulation for aircraft control system, an integrated real-time simulation platform is presented, then its functions, working principal, and architecture are introduced in detail. Analyzed several key technologies such as memory database, real-time simulation and general simulation modeling; with the advantages of high universality, integration and flexibility, this platform can effectively support the development and execution of real-time and hardware-in-the-loop simulation.\\nArchitecture\\nSystems engineering\\nSimulation\\nSimulation modeling\\nControl engineering\\nHardware-in-the-loop simulation\\nControl system\\nEngineering\\nReal-time simulation',\n",
       " 922283: 'Parallel Algorithms for 2-D Convolution.\\nYear: 1986\\n#Citations: 24\\nConference\\n\\nComputer science\\nConvolution\\nParallel algorithm\\nParallel computing\\nOverlap–add method',\n",
       " 927230: 'SIMPLE DESIGN OF THE STATE OBSERVER FOR LINEAR TIME-VARYING SYSTEMS\\nYear: 2009\\n#Citations: 1\\nConference\\n\\nState observer\\nAlpha beta filter\\nSeparation principle\\nControl theory\\nControl engineering\\nEngineering\\nTime complexity',\n",
       " 929837: 'Region of Interest Discovery in Location-Based Social Networking Services with Protected Locations\\nYear: 2013\\n#Citations: 0\\nConference\\nSpringer, Berlin, Heidelberg\\nRegion of Interest (ROI) discovery is one of the most common interests in Location-based social networking services (LBSNS). While former researches mainly utilize the accurate location history, this paper explores the methods to extract those regions with protected locations. A spatial-temporal cloaking check-in model following k-anonymity principle is introduced. And methods to extract two kinds of ROIs, popular regions and personal regions, are proposed respectively. Experimental results illustrate that by analyzing the characteristics of those protected locations, ROIs are able to be discovered as well. Furthermore, our work shows that privacy protection and personalized services can be both achieved in LBSNS.\\nMobile computing\\nCloaking\\nWorld Wide Web\\nSocial network\\nComputer science\\nComputer security\\nKnowledge extraction\\nRegion of interest\\nSocial computing\\nPrivacy model',\n",
       " 930596: 'Runtime generation of robot control code from ontology file\\nYear: 2011\\n#Citations: 2\\nConference\\nSpringer, Berlin, Heidelberg\\nThis paper provides an initial implementation of the novel module to transform OWL-S ontology into executable robot control code. We explore the idea of formalizing robot behavior descriptions using Semantic Web knowledge representation. The paper describes the methodology and implementation details of the robot control code generator to translate ontology file descriptions to a compilable Java code, as well as the robot control framework to execute the code at  :[69],\"validate our approach with the experiment, conducted on Sctios G5 robot. The task \"follow the red object\" is translated into a working Java code from OWL-S ontology file. The generated Java code is compiled and executed at run-time. As a result, the robot is following the person with a red folder in his hands.\\nOntology\\nRobot control\\nKnowledge representation and reasoning\\nProgramming language\\nComputer science\\nSemantic Web\\nCode generation\\nBehavior-based robotics\\nRobot\\nExecutable',\n",
       " 932773: 'Enumeration of the bases of the bicircular matroid on a complete bipartite graph.\\nYear: 2003\\n#Citations: 1\\nJournal\\n\\nDiscrete mathematics\\nComplete bipartite graph\\nBicircular matroid\\nCombinatorics\\nEdge-transitive graph\\nForbidden graph characterization\\nSimplex graph\\nGraphic matroid\\nFactor-critical graph\\nGraph minor\\nMathematics',\n",
       " 933995: 'Constrained function optimization using PSO with polynomial mutation\\nYear: 2011\\n#Citations: 4\\nConference\\nSpringer, Berlin, Heidelberg\\nConstrained function optimization using particle swarm optimization (PSO) with polynomial mutation is proposed in this work. In this method non-stationary penalty function approach is adopted and polynomial mutation is performed on global best solution in PSO. The proposed method is applied on 6 benchmark problems and obtained results are compared with the results obtained from basic PSO. The experimental results show the efficiency and effectiveness of the method.\\nParticle swarm optimization\\nMathematical optimization\\nPolynomial\\nComputer science\\nAlgorithm\\nFunction optimization\\nArtificial intelligence\\nMachine learning\\nPenalty method',\n",
       " 938534: 'The Dynamics of Women in IT: A Unifying Framework\\nYear: 2010\\n#Citations: 0\\nConference\\n\\nComputer science\\nKnowledge management\\nManagement science',\n",
       " 941119: 'Variation in Adoption Rates of a Patient Web Portal with a Shared Medical Record by Age, Gender, and Morbidity Level\\nYear: 2006\\n#Citations: 21\\nConference\\nAmerican Medical Informatics Association\\nGerontology\\nFamily medicine\\nMedical record\\nMedicine\\nThe Internet',\n",
       " 943288: 'Microcomputer management and programming: Ogdin, C A, Prentice-Hall, New Jersey, USA (1980) 348 pp, £12.30.\\nYear: 1981\\n#Citations: 0\\nJournal\\n\\nComputer science\\nParallel computing\\nMicrocomputer\\nOperating system',\n",
       " 950275: 'Image enhancement of X-ray film base on mutil-scale retinex\\nYear: 2011\\n#Citations: 3\\nConference\\nSpringer, Berlin, Heidelberg\\nView of film system for medical diagnosis was presented. the system which took the cold cathode fluorescent lamps (CCFL) as the background light source, excluded ambient light impact on the concept of film by a light shell , and realized the digital X-ray film through the CCD camera the image information transferred to the computer. The details of hidden areas on some obscure digital X-ray images were enhanced by multi-scale Retinex (MSR) algorithm. With this method, the image contrast enhancement, sharpening and dynamic range compression was achieved at the same time. The information of hidden areas of X-ray image was obviously enhanced. The enhancement technique was compared with other techniques such as histogram equalization, homomorphism filter. The result of experiment shows that the MSR algorithm can overcome the lack of enhancement of traditional digital X-ray method and satisfy the clinic demand.\\nSharpening\\nComputer vision\\nColor constancy\\nX-ray\\nCold cathode\\nComputer science\\nArtificial intelligence\\nHistogram equalization\\nDynamic range compression\\nFilm base\\nShadow and highlight enhancement',\n",
       " 952181: 'Total Quality and the IS Function.\\nYear: 1993\\n#Citations: 0\\nConference\\n\\nComputer science\\nKnowledge management\\nTotal quality management',\n",
       " 954605: 'Exploiting Trust and Suspicion for Real-time Attack Recognition in Recommender Applications\\nYear: 2007\\n#Citations: 3\\nConference\\nSpringer, Boston, MA\\nAs is widely practiced in real world societies, fraud and deception are also ubiquitous in the virtual world. Tracking and detecting such malicious activities in the cyber space is much more challenging due to veiled identities and imperfect knowledge of the environment. Recommender systems are one of the most attractive applications widely used for helping users find their interests from a wide range of interesting choices that makes them highly vulnerable to malicious attacks. In this paper we propose a three dimensional trust based filtering model that detects noise and attacks on recommender systems through calculating three major factors: Importance, Frequency, and Quality. The results obtained from our experiments show that the proposed approach is capable of correctly detecting noise and attack and is hence able to decrease the absolute error of the predicted item rating value.\\nRecommender system\\nAutoregressive–moving-average model\\nReputation system\\nCollaborative filtering\\nDeception\\nComputer science\\nComputer security\\nAs is\\nFilter (signal processing)\\nApproximation error',\n",
       " 954827: 'Implementing a Dynamic Pricing Scheme for QoS Enabled IPv6 Networks.\\nYear: 2005\\n#Citations: 0\\nConference\\n\\nIPv6\\nData mining\\nComputer science\\nDynamic pricing\\nComputer network\\nQuality of service',\n",
       " 955581: 'Das EUREKA-Projekt PROTOS\\nYear: 1987\\n#Citations: 10\\nConference\\nSpringer, Berlin, Heidelberg\\nZiel des EUREKA-Projekts PROTOS (Prolog TQOIS for Building Expert Systems) ist die Realisierung integrierter Prolog-Werkzeuge zur Entwicklung von Expertensystemen. Das Projekt gliedert sich in vier Teilprojekte:  :[26],\"und  :[28],\"fur  :[26],\"und :[30],\"Werkzeugevaluation\\nProgramming language\\nExpert system\\nProlog\\nEngineering',\n",
       " 957139: 'Nonmonotonic logic for default theories\\nYear: 1984\\n#Citations: 4\\nConference\\n\\nDefault logic\\nComputer science\\nNon-monotonic logic\\nArtificial intelligence\\nMachine learning',\n",
       " 959509: 'The Evaluation and Comparative Study with a New Clustered Based Machine Learning Algorithm.\\nYear: 2006\\n#Citations: 0\\nJournal\\n\\nPattern recognition\\nComputer science\\nArtificial intelligence\\nMachine learning\\nLearning classifier system',\n",
       " 961884: 'Outlier Detection with Uncertain Data.\\nYear: 2008\\n#Citations: 113\\nConference\\n\\nIn recent years, many new techniques have been developed for mining and managing uncertain data. This is because of the new ways of collecting data which has resulted in enormous amounts of inconsistent or missing data. Such data is often remodeled in the form of uncertain data. In this paper, we will examine the problem of outlier detection with uncertain data sets. The outlier detection problem is particularly challenging for the uncertain case, because the outlier-like behavior of a data point may be a result of the uncertainty added to the data point. Furthermore, the uncertainty added to the other data points may skew the overall data distribution in such a way that true outliers may be masked. Therefore, it is critical to be able to remove the effects of the uncertainty added both at the aggregate level as well as at the level of individual data points. In this paper, we will examine a density based approach to outlier detection, and show how to use it to remove the uncertainty from the underlying data. We present experimental results illustrating the effectiveness of the method.\\nData point\\nAnomaly detection\\nComputer science\\nOutlier\\nUncertain data\\nArtificial intelligence\\nSkew\\nMissing data\\nMachine learning',\n",
       " 964162: 'EVALUATION OF TEXT CLASSIFICATION ALGORITHMS - for a Web-based Market Data Warehouse\\nYear: 2005\\n#Citations: 0\\nConference\\n\\nData warehouse\\nData transformation\\nData mining\\nWarehouse\\nInformation retrieval\\nComputer science\\nDimensional modeling\\nWeb application\\nStatistical classification\\nMarket data\\nDatabase',\n",
       " 967909: 'Understanding and managing process interaction in IS development projects\\nYear: 2012\\n#Citations: 1\\nConference\\nSpringer\\nSoftware-based information systems must be developed and implemented as a part of business change. This is a major challenge, since business change and the development of software-based information systems usually are performed in separate processes. Thus, there is a need to understand and manage the relationship between these two kinds of processes. In this paper we draw on a longitudinal case study. We suggest a framework to analyze the case as interaction between software development processes and organizational change processes. In the analysis we find that the framework enables us to understand critical events in the case, what led to the events, and what the consequences are. We discuss the implications for information systems research and in particular we discuss the contribution to project management of iterative and incremental software development.\\nInformation system\\nInformation systems research\\nIterative and incremental development\\nComputer science\\nKnowledge management\\nIncremental build model\\nSoftware\\nSoftware development process\\nProcess interaction\\nProject management',\n",
       " 972044: 'A dataflow graph transformation language and query rewriting system for RDF ontologies\\nYear: 2012\\n#Citations: 4\\nConference\\nSpringer, Berlin, Heidelberg\\nUsers interested in biological and biomedical information sets on the semantic web are frequently not computer scientists. These researchers often find it difficult to use declarative query and view definition languages to manipulate these RDF data sets. We define a language IML consisting of a small number of graph transformations that can be composed in a dataflow style to transform RDF ontologies. The languageu0027s operations closely map to the high-level manipulations users undertake when transforming ontologies using a visual editor. To reduce the potentially high cost of evaluating queries over these transformations on demand, we describe a query rewriting engine for evaluating queries on IML views. The rewriter leverages IMLu0027s dataflow style and optimizations to eliminate unnecessary transformations in answering a query over an IML view. We evaluate our rewriteru0027s performance on queries over use case view definitions on one or more biomedical ontologies.\\nOntology (information science)\\nData mining\\nRDF query language\\nProgramming language\\nComputer science\\nOpen Biomedical Ontologies\\nPath expression\\nSemantic Web\\nDataflow\\nGraph rewriting\\nDatabase\\nRDF',\n",
       " 972797: 'A Mixed Methods Approach for Measuring the Impact of Delivery-Centric Interventions on Clinician Workflow\\nYear: 2012\\n#Citations: 2\\nConference\\nAmerican Medical Informatics Association\\nHealth interventions vary widely. Pharmaceuticals, medical devices and wellness promotion are defined as ‘outcome-centric.’ They are implemented by clinicians for the use and benefit of consumers, and intervention effectiveness is measured by a change in health outcome. Electronic health records, computerized physician order entry systems and telehealth technologies are defined as ‘delivery-centric.’ They are implemented by organizations for use by clinicians to manage and facilitate consumer health, and the impact of these interventions on clinician workflow has become increasingly important. The methodological framework introduced in this paper uses a two-phase sequential mixed methods design that qualitatively explores clinician workflow before and after implementation of a delivery-centric intervention, and uses this information to quantitatively measure changes to workflow activities. The mixed methods protocol provides a standardized approach for understanding and determining the impact of delivery-centric interventions on clinician workflow.\\nWellness promotion\\nPsychological intervention\\nNursing\\nTriage\\nMedical emergency\\nTelehealth\\nConsumer health\\nMedicine\\nWorkflow\\nStandardized approach\\nComputerized physician order entry',\n",
       " 983431: 'Software architecture based connection manager.\\nYear: 2007\\n#Citations: 2\\nConference\\n\\nApplications architecture\\nSoftware engineering\\nMultilayered architecture\\nComputer science\\nSoftware architecture description\\nArchitecture tradeoff analysis method\\nSolution architecture\\nReference architecture\\nResource-oriented architecture\\nSoftware architecture',\n",
       " 985419: 'A Neural Network Approach for Software Development Cost Estimation.\\nYear: 1997\\n#Citations: 0\\nConference\\n\\nData mining\\nComputer science\\nCost estimate\\nArtificial neural network\\nSoftware development',\n",
       " 985898: 'Engineering a complex ontology with time\\nYear: 2003\\n#Citations: 7\\nConference\\nMorgan Kaufmann Publishers Inc.\\nBecause it is difficult to engineer a complex ontology with time, we here consider a method that allows for factorizing the complexity of the engineering process, FONTE (Factorizing ONTology Engineering complexity). FONTE divides the engineering task into building a time-less domain ontology and a temporal theory independently from each other. FONTE provides an operator that assembles the two independently developed ontologies into the targeted ontology. We investigate the quality of the proposed operator by applying it to a practical case study, viz. the engineering of an ontology about researchers including temporal interactions.\\nOntology (information science)\\nOntology engineering\\nOntology alignment\\nOntology-based data integration\\nProcess ontology\\nComputer science\\nOpen Biomedical Ontologies\\nTheoretical computer science\\nArtificial intelligence\\nSuggested Upper Merged Ontology\\nUpper ontology\\nMachine learning',\n",
       " 987013: 'A formal method of describing e-learning systems\\nYear: 2005\\n#Citations: 1\\nConference\\nIADIS (International Association for Development of the Information Society)\\nTeachers find it difficult to give a lesson as intended when they use current e-Learning systems because of the limitations in the specifications of systems. A formal method of describing e-Learning systems was developed so that teachers could manage the lessons they desire to give. A learning state transition diagram based on a learneru0027s actions and states of learning (LSTD) is described, and a formal method for describing the diagram is presented. The method facilitates the design and development of adaptive e-Learning systems.\\nFormal system\\nProgramming language\\nComputer science\\nState diagram\\nFormal specification\\nDiagram\\nGrammar systems theory\\nRefinement\\nFormal methods\\nFormal verification',\n",
       " 988455: 'Gb Ethernet Protocols for Clusters: An OpenMPI, TIPC, GAMMA Case Study.\\nYear: 2007\\n#Citations: 1\\nConference\\n\\nEthernet over PDH\\nCarrier Ethernet\\nComputer science\\nParallel computing\\nComputer network\\nATA over Ethernet\\nConnection-oriented Ethernet\\nTIPC\\nEthernet Global Data Protocol\\nRDMA over Converged Ethernet\\nSynchronous Ethernet',\n",
       " 994405: 'Team, Troop, Gang & Crowd: Collaborative Work in Distance Education\\nYear: 2000\\n#Citations: 1\\nConference\\nAssociation for the Advancement of Computing in Education (AACE)\\nEducational technology\\nCollaborative learning\\nSociology\\nDistance education\\nTeaching method\\nPedagogy',\n",
       " 997982: 'An o *(1.84 k) parameterized algorithm for the multiterminal cut problem\\nYear: 2013\\n#Citations: 0\\nConference\\nSpringer, Berlin, Heidelberg\\nWe study the multiterminal cut problem, which, given an n-vertex graph whose edges are integer-weighted and a set of terminals, asks for a partition of the vertex set such that each terminal is in a distinct part, and the total weight of crossing edges is at most k. Our weapons shall be two classical results known for decades. One is max volume min (s,t)-cuts by [Ford and Fulkerson, Flows in Networks. Princeton University Press, 1962], and the other is isolating cuts by [Dahlhaus et al., The complexity of multiterminal cuts. SIAM J. Comp. 23(4), 1994]. We sharpen these old weapons with the help of submodular functions, and apply them to this problem, which enable us to design a more elaborated branching scheme on deciding whether a non-terminal vertex is with a terminal or not. This bounded search tree algorithm can be shown to run in $1.84^k\\\\cdot n^{{\\\\cal O}(1)}$, thereby breaking the $2^k\\\\cdot n^{{\\\\cal O}(1)}$ barrier. As a by-product, it gives a $1.36^k\\\\cdot n^{{\\\\cal O}(1)}$ algorithm for 3-terminal cut. The preprocessing applied on non-terminal vertices might be of use for study of this problem from other aspects.\\nGraph\\nDiscrete mathematics\\nCombinatorics\\nVertex (geometry)\\nSubmodular set function\\nPartition (number theory)\\nMathematics\\nParameterized algorithms\\nBranching (version control)\\nSearch tree\\nBounded function',\n",
       " 998388: 'A correlation-maximization denoising filter used as an enhancement frontend for noise robust bird call classification.\\nYear: 2009\\n#Citations: 5\\nConference\\n\\nIn this paper, we propose a Correlation-Maximization denoising filter which utilizes periodicity information to remove additive noise in bird calls. We also developed a statistically-based noise robust bird-call classification system which uses the denoising filter as a frontend. Enhanced bird calls which are the output of the denoising filter are used for feature extraction. Gaussian Mixture Models (GMM) and Hidden Markov Models (HMM) are used for classification. Experiments on a large noisy corpus containing bird calls from 5 species have shown that the Correlation-Maximization filter is more effective than the Wiener filter in improving the classification error rate of bird calls which have a quasi-periodic structure. This improvement results in a 4.1% classification error rate which is better than the system without a denoising frontend and a system with a Wiener filter denoising frontend.\\nWiener filter\\nNoise reduction\\nPattern recognition\\nComputer science\\nWord error rate\\nFeature extraction\\nSpeech recognition\\nArtificial intelligence\\nHidden Markov model\\nGaussian noise\\nMaximization\\nMixture model',\n",
       " 1001706: 'From Expected Improvement to Investment Portfolio Improvement: Spreading the Risk in Kriging-Based Optimization\\nYear: 2014\\n#Citations: 5\\nConference\\nSpringer, Cham\\nThe increasing use of time-consuming simulations in the industry has spawned a growing interest in coupling optimization algorithms with fast-to-compute surrogate models. A major challenge in this approach is to select the approximated solutions to evaluate on the real problem. To address this, the Kriging meta-model offers both an estimate of the mean value and the standard error in an unknown point. This feature has been exploited in a number of so-called prescreening utility functions that seek to maximize the outcome of an expensive evaluation. The most widely used are the Probability of Improvement (PoI) and Expected Improvement (ExI) functions.\\nKriging\\nMathematical optimization\\nMean value\\nComputer science\\nPortfolio optimization\\nOptimization algorithm\\nInvestment portfolio\\nStandard error',\n",
       " 1005427: 'Tough-Maximum Graphs.\\nYear: 2001\\n#Citations: 0\\nJournal\\n\\nGraph\\nDiscrete mathematics\\nCombinatorics\\nMathematics',\n",
       " 1007187: 'Haptic communication tools for collaborative deformation of molecules\\nYear: 2012\\n#Citations: 4\\nConference\\nSpringer, Berlin, Heidelberg\\nSeveral previous studies have investigated collaborative approaches for processing complex environments. Beyond the improvement of performance and working efficiency, these studies highlighted two important constraints, which limit the efficiency of these approaches. First, social loafing which is linked to the redundancy of roles in the same group. Second, coordination conflicts which are linked to the limits of communication in standard collaborative environments. This paper addresses these issues by providing an efficient group structure to overcome the social loafing, which is then coupled with haptic metaphors to improve communication between partners. The experimental study, conducted in the context of molecular docking, shows an improvement for group efficiency as well as communication between partners.\\nGroup structure\\nSocial loafing\\nHaptic communication\\nComputer science\\nRedundancy (engineering)\\nHuman–computer interaction\\nHaptic technology',\n",
       " 1011709: 'Homomorphisms preserving deterministic context-free languages\\nYear: 2012\\n#Citations: 2\\nConference\\nSpringer, Berlin, Heidelberg\\nThe paper characterizes the family of homomorphisms, under which the deterministic context-free languages, the LL context-free languages and the unambiguous context-free languages are closed. The family of deterministic context-free languages is closed under a homomorphism h if and only if h is either a code of bounded deciphering delay, or the images of all symbols under h are powers of the same string. The same characterization holds for LL context-free languages. The unambiguous context-free languages are closed under h if and only if either h is a code, or the images of all symbols under h are powers of the same string.\\nDiscrete mathematics\\nContext-free language\\nCombinatorics\\nComputer science\\nClosure (mathematics)\\nAbstract family of languages\\nDeterministic context-free language\\nCone (formal languages)\\nHomomorphism\\nRegular language\\nBounded function',\n",
       " 1012494: 'Data driven system identification using evolutionary algorithms\\nYear: 2012\\n#Citations: 2\\nConference\\nSpringer, Berlin, Heidelberg\\nWe present an evolutionary algorithm(EA) based system identification technique from measurement data. The nonlinear optimization task of estimating the premise parameters of a Takagi-Sugeno-Kang fuzzy system is achieved by a EA, the consequent parameters are estimated by least squares. This reduces the search space dimension leading to greatly reduced load on the EA. The significant contribution of this work is in formulating the fitness function that judiciously applies selection pressure by 1) penalizing low firing strengths of rules, and, 2) by penalizing low rank design matrix at the rule consequents. The proposed method is tested on the identification of non-linear systems.\\nLeast squares\\nMathematical optimization\\nData-driven\\nEvolutionary algorithm\\nComputer science\\nNonlinear programming\\nFitness function\\nDesign matrix\\nArtificial intelligence\\nFuzzy control system\\nSystem identification\\nMachine learning',\n",
       " 1013871: 'A Living Lab for Internet of Things Vending Machines\\nYear: 2012\\n#Citations: 8\\nConference\\nSpringer, Berlin, Heidelberg\\nVending machines are often considered mere dispenser facilities that trigger low engagement in their users. Instead, it is a market that is not only growing and expanding, but also evolving from a technological as well as service point of view. An experiential Internet of Things vending machine has been designed with the continuous involvement of users at different levels within San Raffaele Scientific Institute’s City of the Future Living Lab in Milan. This paper illustrates the case of the Living Lab methodology adopted for the development of an innovative Internet of Things vending machine service.\\nExperiential learning\\nService design\\nCo-creation\\nInternet privacy\\nWorld Wide Web\\nInternet of Things\\nSmart city\\nLiving lab\\nBusiness',\n",
       " 1014505: \"An Implementation of Chen & Han's Shortest Paths Algorithm.\\nYear: 2000\\n#Citations: 43\\nConference\\n\\nDiscrete mathematics\\nCombinatorics\\nShortest path problem\\nComputer science\\nJohnson's algorithm\\nConstrained Shortest Path First\\nYen's algorithm\\nFloyd–Warshall algorithm\\nSuurballe's algorithm\\nShortest Path Faster Algorithm\\nK shortest path routing\",\n",
       " 1017296: 'Secure Web Development Teaching Modules\\nYear: 2010\\n#Citations: 4\\nConference\\n\\nWeb application security has been an emerging topic while an increasing number of information systems are designed based on Extensible Makeup Language (XML) and using Hypertext Transfer Protocol (HTTP) for communications. For example, in recent years, social networking software has been used intensively, especially among college students, and integrated with various marketing or gaming software. This workshop will discuss security issues in web application development and demonstrate web security vulnerabilities and countermeasures through hands-on exercises. The exercises are developed by a NSF-funded project called SWEET (Secure web development teaching). SWEET is consisted of eight teaching modules of web application security. To demonstrate potential web server vulnerabilities, the teaching modules include hands-on exercises that are preconfigured in Linux virtual machines. The workshop will also discuss examples of incorporating SWEET in Information Systems curriculum. Workshop Leader Information (Please attach a copy of your resume in your email submission) Name: Li-Chiou Chen Affiliation: Pace University Postal Address: 320 Goldstein Academic Center 861 Bedford Rd. Pleasantville, NY10549 Telephone: 914-7733907 Cell: Fax: Email: lchen@pace.edu Additional Workshop Presenters (copy for each one) Name: Affiliation: Postal Address: Telephone: Cell:\\nInformation system\\nWeb development\\nInternet security\\nWorld Wide Web\\nComputer science\\nWeb modeling\\nWeb application development\\nWeb application security\\nHypertext Transfer Protocol\\nWeb server',\n",
       " 1017985: 'On the rainbow connectivity of graphs: complexity and FPT algorithms\\nYear: 2011\\n#Citations: 2\\nConference\\nSpringer, Berlin, Heidelberg\\nFor a graph G = (V, E) and a color set C, let f : E → C be an edge-coloring of G which is not necessarily proper. Then, the graph G edge-colored by f is rainbow connected if every two vertices of G has a path in which all edges are assigned distinct colors. Chakraborty et al. defined the problem of determining whether the graph colored by a given edge-coloring is rainbow connected. Chen et al. introduced the vertex-coloring version of the problem as a variant, and we introduce the total-coloring version in this paper. We settle the precise computational complexities of all the three problems from two viewpoints, namely, graph diameters and certain graph classes. We also give FPT algorithms for the three problems on general graphs when parameterized by the number of colors in C; these results imply that all the three problems can be solved in polynomial time for any graph with n vertices if |C| = O(log n).\\nDiscrete mathematics\\nCombinatorics\\nLine graph\\nRainbow coloring\\nGraph power\\nCubic graph\\nAlgorithm\\nCycle graph\\nSymmetric graph\\nMathematics\\nVoltage graph\\nComplement graph',\n",
       " 1019276: 'Propositions, Propositional Attitudes and Belief Revision.\\nYear: 1998\\n#Citations: 3\\nConference\\n\\nComputer science\\nAlgorithm\\nEpistemology\\nBelief revision',\n",
       " 1022019: 'Indexing with gaps\\nYear: 2011\\n#Citations: 9\\nConference\\nSpringer, Berlin, Heidelberg\\nIn Indexing with Gaps one seeks to index a text to allow pattern queries that allow gaps within the pattern query. Formally a gappedpattern over alphabet Σ is a pattern of the form p = p1g1p2g2 ... glpl+1, where ∀i, pi ∈ Σ* and each gi is a gap length ∈ N. Often one considers these patterns with some bound constraints, for example, all gaps are bounded by a gap-bound  :[70],\"solutions have, lately, been proposed for the case of one gap only with a predetermined size. More specifically, an indexing solution for patterns of the form p1 ċ g ċ p2, where g is known apriori. In this case the :[70],\"solutions mentioned are preprocessed in O(n log∈ n) time and O(n) space, where the pattern queries are answered in O(|p1| + |p2|), for constant sized alphabets. For the more general case when there is a bound G these results can be easily adapted with a multiplicative factor of O(G) for the preprocessing, i.e. O(n log∈ nG) preprocessing time and O(nG) preprocessing space. Alas, these :[70],\"solutions do not lend to more than one  this :[183],\"paper we propose a solution for k gaps one with preprocessing time O(nG2k logk n log log n) and space of O(nG2k logk n) and query time O(m + 2k log log n), where m = Σi=1 |pi|.\\nLog-log plot\\nCombinatorics\\nMultiplicative function\\nA priori and a posteriori\\nSearch engine indexing\\nPattern matching\\nMathematics\\nAlphabet\\nBounded function',\n",
       " 1025374: 'Optimal neighborhood broadcast in star graphs.\\nYear: 2004\\n#Citations: 0\\nJournal\\n\\nBlock graph\\nOuterplanar graph\\nCombinatorics\\nLine graph\\nTree-depth\\nComputer science\\nGeneralized Petersen graph\\nDistance-hereditary graph\\nWindmill graph\\nSplit graph',\n",
       " 1028515: 'Partitioning a deformed urban grid.\\nYear: 2002\\n#Citations: 0\\nConference\\n\\nDiscrete mathematics\\nComputer science\\nTheoretical computer science\\nComputational science\\nGrid',\n",
       " 1029012: 'Experimental Evaluation of Different Pricing Mechanisms for Content Distribution over Peer to Peer Networks\\nYear: 2005\\n#Citations: 3\\nConference\\n\\nThis paper extends previous work by the authors in which they propose a dynamic distribution model based on modified economic growth theory to determine file distribution patterns in peer-to-peer networks. Although the theoretical model provides a good foundation for exploring different pricing mechanisms for peer-to-peer networks, there are several issues that remain unexplored because of computational difficulties. In this paper, we use the methods of experimental economics to create a sequence of experimental designs to explore some of these issues. The designs mimic the structure of the industry, the type of current and future property rights, some technical constraints, and the strategic interactions between the different actors.\\nExperimental economics\\nDistribution model\\nProperty rights\\nPeer-to-peer\\nComputer science\\nManagement science\\nDesign of experiments',\n",
       " 1031492: 'Modeling reusable security aspects for software architectures: A pattern driven approach\\nYear: 2005\\n#Citations: 1\\nConference\\n\\nComputer architecture\\nSoftware design\\nComputer science\\nSoftware security assurance\\nSoftware architecture description\\nComponent-based software engineering\\nSoftware construction\\nArchitectural pattern\\nSoftware development\\nSoftware framework',\n",
       " 1032599: 'Building a model of an intelligent multi-agent system based on distributed knowledge bases for solving problems automatically\\nYear: 2012\\n#Citations: 3\\nConference\\nSpringer, Berlin, Heidelberg\\nIn this paper, we propose a model of an Intelligent Multi-Agent System based on three distributed knowledge bases for solving problems automatically. Besides, we present architectures of agents in the system. We also illustrate an application of this model in three fields: plane geometry, 2D analytic geometry, and algebra. In our application, we use JADE platform, Maple, MathML, XML, …Finally, we show a method to test effects of the system developed from the model of MAS proposed.\\nDistributed knowledge\\nIntelligent agent\\nXML\\nComputer science\\nPlane (geometry)\\nMobile agent\\nMulti-agent system\\nAnalytic geometry\\nTheoretical computer science\\nMathML\\nDistributed computing',\n",
       " 1034194: 'VESMP (VERY SHORT MESSAGE PROTOCOL) AN SMS-BASED PROTOCOL FOR PROCESS MONITORING AND SYSTEM REMOTE ADMINISTRATION\\nYear: 2016\\n#Citations: 2\\nConference\\n\\nRemote administration\\nComputer science\\nComputer network\\nInternet Protocol Control Protocol',\n",
       " 1036492: \"Sub-propositional Fragments of the Interval Temporal Logic of Allen's Relations\\nYear: 2014\\n#Citations: 13\\nConference\\nSpringer, Cham\\nInterval temporal logics provide a natural framework for temporal reasoning about interval structures over linearly ordered domains, where intervals are taken as the primitive ontological entities. The most influential propositional interval-based logic is probably Halpern and Shohamu0027s Modal Logic of Time Intervals, a.k.a. HS. While most studies focused on the computational properties of the syntactic fragments that arise by considering only a subset of the set of modalities, the fragments that are obtained by weakening the propositional side have received very scarce attention. Here, we approach this problem by considering various sub-propositional fragments of HS, such as the so-called Horn, Krom, and core fragment. We prove that the Horn fragment of HS is undecidable on every interesting class of linearly ordered sets, and we briefly discuss the difficulties that arise when considering the other fragments.\\nOntology\\nInterval temporal logic\\nComputer science\\nAlgorithm\\nTheoretical computer science\\nLinear temporal logic\\nConjunctive normal form\\nModal logic\\nTemporal logic\\nSyntax\\nUndecidable problem\",\n",
       " 1038880: 'm-Asynchronous Cellular Automata\\nYear: 2012\\n#Citations: 8\\nConference\\nSpringer, Berlin, Heidelberg\\nA new model for the study of ACA dynamical behavior has been introduced. The classical properties of injectivity, surjectivity and expansivity have been adapted to the new setting. Preliminary results show that the injectivity is almost always equal to surjectivity and that both property are almost always implied by expansivity.\\nAsynchronous communication\\nCellular automaton\\nDiscrete mathematics\\nAsynchrony\\nComputer science\\nTheoretical computer science\\nAlmost surely',\n",
       " 1039100: 'A Systematic Analysis of the Effect of Task Clarity on Software Development Design\\nYear: 2000\\n#Citations: 1\\nConference\\n\\nTwo different types of development tasks are distinguished: Clear and unclear development tasks. Based on hypotheses from organizational theory two different designs of software development are derived. The transformational design is appropriate if the development task is clear. In case of an unclear development task software development should employ the adaptive design. The transformational design conforms to the explicit recommendations and implicit assumptions of process oriented software quality management, a software management style considered by many authors to be the universally valid paradigm of software development. Because of the fundamental differences between the two designs we conclude, that process oriented software quality management is not universally valid and should not be applied to unclear software development tasks.\\nPersonal software process\\nComputer science\\nSoftware peer review\\nKnowledge management\\nSoftware project management\\nSoftware development process\\nSoftware construction\\nSoftware verification and validation\\nSoftware development\\nGoal-Driven Software Development Process',\n",
       " 1039487: 'Combining Text and Image Analysis in The Web Filtering System \"WEBGUARD\"\\nYear: 2004\\n#Citations: 1\\nConference\\n\\nWeb  applications  increasingly  utilize  search  techniques  that  heavily  rely  on content-based text and image analyses. For example,  for  parental  site  filtering,  it  is  necessary  to  identify  adult  sites. These  applications  must  rely  on  a  semantic analysis of images in the process of identification where text analysis alone is insufficient.  In this article, we describe our site filtering system \"WebGuard\" and show the importance of image analysis in such system. Our results show that it can detect and filter adult content effectively.\\nData mining\\nText mining\\nWorld Wide Web\\nInformation retrieval\\nComputer science\\nFilter (signal processing)\\nWeb application',\n",
       " 1040562: 'Evaluation of Incomplete Absorption Using Analog-Hybrid Simulation\\nYear: 1984\\n#Citations: 1\\nConference\\nSpringer, Berlin, Heidelberg\\nAnalog-Hybride Simulation Der Nichtlinearen Pharmakokinetik Von Der Unvollstandigen Apsorption — Orale Heilmittelanwendung ist wegen der unvollstandigen Absorbierung oft problematisch, die haupt-grunde des erwahnten Phanomens sind: unvollstandige Auflosung, begrenzte Anwesenheitszeit der Heilmittel am Absorption platz (wegen des Heilmitteltransports durch den Gastrointestinaltrakt), Unstabilitat der Heil-mittel in Verdaungsflussigkeiten, Metabolismus oder Degradation in Gastrointestinalwanden, Metabolismus im Leber, oder irgendeine Kombination von oben erwahnten Grunden. Bei der Pharmakokinetischen Studie, die bei dem Entwurf der richtigen Dosierungsform und entsprechenden Dosierungsregimen zu machen ist, muss das Phanomen der unvollstandigen Absorbierung in das pharmakokinetische Modell eingeschlossen wereden, weswegen das entsprechende Modell nichtlinear wird. Wenn die erreichbare Genauigkeit der „in vivo“ Daten und das Ziel der modelierung berucksichtig werden, kann die unvollstandige Absorbierung auf vier Weisen simuliert werden: Die erste Moglichkeit ist die Verringerung der Dose durch den vorgeschriebenen Prozent der Absorption, die zweite ist die Hinzufugung von einen zusatzlichen kumulativen gastrointestinalen Abteil, der bei Beseitigung des unabsorbierten Teil der Dose ermoglicht. Bei der dritten Moglichkeit wird die Absorptiongeschwindigkeitkonstante im richtigen Moment, der durch die kumulative Heilmittelmenge im Gastrointes tinaltrakt (wenn das vorgeschriebene Prozent der Absorption erreicht ist) geschatzt wird, zu null gedreht. Die letzte Alternative ist eine Kombination der zweiten und dritten Moglichkeit, wobei der „Fenstereffekt“ der heilmittelabsorption und die Ausscheidung des nichtabsorbierten Heilmittels in Feaces simuliert werden. Die Auswahl der richtigen Alternative fur die konkrette pharmakokinetische Modelierung hangt von der Vorauskenntnis von dem Heilmittelvorgang im Mensschenkorper und naturlich von der letzten Annaherung der Modellausgang-grossen zum „in vivo“ Daten ab. Diese Arbeit behandelt die Simulation der unvolstandigen Absorption des Ampicilins auf dem Analog-hybrid-rechener EAI 5 80, wobei die Ergebnisse der realisierten Studie verwendet werden. Die oben genannten Moglichkeiten der Simulation werden kurz diskutiert und die beste Alternative wird ausgesucht.\\nGynecology\\nPhysics',\n",
       " 875626: 'A Performance Isolation Technique Ensuring SLA of Web Systems Having Primary-backup Web Switch.\\nYear: 2005\\n#Citations: 0\\n\\n\\nWeb system\\nWorld Wide Web\\nComputer science\\nTemporal isolation among virtual machines\\nComputer network\\nWeb service\\nBackup\\nWeb server',\n",
       " 882228: 'Transferring HCI modelling and design techniques to practitioners: a framework and empirical work\\nYear: 1994\\n#Citations: 17\\n\\nCambridge University Press\\nSoftware engineering\\nComputer science\\nOperations research\\nFormal specification\\nDesign research\\nDesign rationale',\n",
       " 885045: 'Visual Programming of Web Data Aggregation Applications\\nYear: 2003\\n#Citations: 14\\n\\n\\nStatic web page\\nWeb API\\nMashup\\nWeb page\\nComputer science\\nData Web\\nVisual programming language\\nWeb modeling\\nWeb navigation\\nMultimedia',\n",
       " 899062: 'Overview of stream C: Measuring quality: evaluation and assessment.\\nYear: 2003\\n#Citations: 0\\n\\n\\nSystems engineering\\nEnvironmental science',\n",
       " 899480: 'A Survey on Clustering Algorithms for web Applications.\\nYear: 2008\\n#Citations: 1\\n\\n\\nCanopy clustering algorithm\\nData mining\\nCURE data clustering algorithm\\nClustering high-dimensional data\\nData stream clustering\\nCorrelation clustering\\nDocument clustering\\nComputer science\\nCluster analysis\\nDBSCAN',\n",
       " 900503: 'Formalizing MOF-Metamodels.\\nYear: 2008\\n#Citations: 0\\n\\n\\nProgramming language',\n",
       " 910438: 'Constraint-Based Model Mining: Algorithms and Applications.\\nYear: 2003\\n#Citations: 0\\n\\n\\nData mining\\nComputer science\\nArtificial intelligence\\nMachine learning',\n",
       " 916140: 'On Image Thresholding by Entropic and Probabilistic Distance Criteria\\nYear: 1999\\n#Citations: 0\\n\\nIASTED/ACTA Press\\nPattern recognition\\nComputer science\\nArtificial intelligence\\nThresholding\\nProbabilistic logic\\nBalanced histogram thresholding',\n",
       " 918870: 'Modeling an Infinite Emotion Space for Expressionistic Cartoon Face Animation.\\nYear: 2003\\n#Citations: 3\\n\\n\\nInspired by traditional expressive animation, we attempt to propose an infinite emotion-space as a model to control free-form facial expression synthesis. Although a number of models already exist for capturing, synthesizing, learning and retargeting facial expressions, very few of them actually focus on modeling the emotion-space itself. Most of these models span a finite set of captured/created expressions, and apply modelspace affine transformations to retarget them, or obtain new ones. We consider the fact that in reality any expression essentially originates in the emotion space (the brain), which eventually manifests itself as a group of transformations or interactions of physical body structures (bones, tendons, muscles, skin layers, etc.). In this light, we present an infinite emotion space model for syntheses of an infinite range of expressions for facial animation, limited only by the creativity and imagination of an animator. CR Categories: I.3.5 [Computer Graphics]: Computational Geometry and Object Modeling – surfaces and object representations.\\nExpression (mathematics)\\nComputer graphics (images)\\nComputer science\\nObject model\\nFacial expression\\nAnimation\\nComputer facial animation\\nComputer animation\\nComputer graphics\\nFacial motion capture',\n",
       " 932055: 'Technology Value Analysis of the Ship Design Value Stream.\\nYear: 2002\\n#Citations: 0\\n\\n\\nEnvironmental science\\nValue stream mapping\\nNaval architecture\\nMarine engineering',\n",
       " 936110: 'Fuzzy Grading: Fuzzy Logic for Uncertainty Management of Linguistic Evaluations.\\nYear: 2010\\n#Citations: 2\\n\\n\\nNeuro-fuzzy\\nFuzzy classification\\nDefuzzification\\nFuzzy set operations\\nComputer science\\nFuzzy logic\\nArtificial intelligence\\nAdaptive neuro fuzzy inference system\\nType-2 fuzzy sets and systems\\nMembership function',\n",
       " 940157: 'Attribute Reducts Using Multistep Relational Extension Matrix.\\nYear: 2010\\n#Citations: 0\\n\\n\\nData mining\\nPattern recognition\\nMatrix (mathematics)\\nComputer science\\nArtificial intelligence\\nAttribute domain',\n",
       " 945375: 'Enabling High-Performance Data Service in the Web Environment.\\nYear: 2003\\n#Citations: 0\\n\\n\\nWeb development\\nWorld Wide Web\\nComputer science\\nWeb standards\\nData Web\\nWeb service\\nData as a service\\nWS-Policy',\n",
       " 959078: 'From Idea to Knowledge - Generating New Knowledge on E-Business.\\nYear: 2004\\n#Citations: 0\\n\\n\\nElectronization or knowledgization is under way in society, world-over. This process works the transformation of the industrial society into knowledge society, and requires a new level of border-crossing cooperation – and catalyzing of the same. This exploratory study seeks to make sense of catalyzing aimed at generating new knowledge on e-business by turning research initiatives stemming from Business, University, and Government (B.U.G.) from idea to knowledge. This action research based single case study focuses on eBRC, a university joint venture created as part of eTampere to fulfill the goals of eEurope. Theoretically, the study is anchored to network and service management literature.\\nProcedural knowledge\\nBody of knowledge\\nElectronic business\\nDomain knowledge\\nPersonal knowledge management\\nKnowledge-based systems\\nKnowledge management\\nKnowledge extraction\\nBusiness\\nKnowledge society',\n",
       " 976710: 'Some Separability Problems in the Plane.\\nYear: 2000\\n#Citations: 6\\n\\n\\nComputer science\\nMathematical analysis',\n",
       " 984931: 'Maintenance de bases de connaissances terminologiques.\\nYear: 2004\\n#Citations: 0\\n\\n',\n",
       " 989627: 'The Participation of MedGIFT Group at ImageCLEFmed 2010.\\nYear: 2010\\n#Citations: 1\\n\\n\\nWorld Wide Web\\nInformation retrieval\\nComputer science',\n",
       " 1010600: 'Multi-temporal Satellite Image Analysis Using Unsupervised Techniques\\nYear: 2013\\n#Citations: 3\\n\\nSpringer, Berlin, Heidelberg\\nThis paper presents flood assessment using non-parametric techniques for multi-temporal time series MODIS (Moderate Resolution Imaging Spectro radiometer) satellite images. The unsupervised methods like mean shift algorithm and median cut are used for automatic extraction of water pixel from the image. The extracted results presents a comparative study of unsupervised image segmentation methods. The performance evaluation indices like root mean square error and receiver operating characteristics are used to study algorithm performance. The result reported in this paper provides useful information for multi-temporal time series image analysis which can be used for current and future research.\\nComputer vision\\nSatellite\\nReceiver operating characteristic\\nComputer science\\nMean squared error\\nMedian cut\\nImage segmentation\\nArtificial intelligence\\nPixel\\nMean-shift\\nRadiometer',\n",
       " 1020441: 'University of Kashmir Information Systems Integration Plan: Database Perspective.\\nYear: 2007\\n#Citations: 0\\n\\n\\nInformation system\\nEngineering management\\nKnowledge management\\nGeography',\n",
       " 1024814: 'Trilateration Localization for Multi-robot Teams.\\nYear: 2008\\n#Citations: 8\\n\\n\\nComputer vision\\nRobot control\\nComputer science\\nArtificial intelligence\\nRobot\\nTrilateration',\n",
       " 1026942: 'Quality Improvement Process for Information Systems.\\nYear: 1990\\n#Citations: 0\\n\\n\\nInformation system\\nComputer science\\nQuality management\\nProcess management',\n",
       " 1032426: 'A Computation-System Based Method for Automated Proving of Protocols Against Services.\\nYear: 1983\\n#Citations: 2\\n\\n\\nProgramming language\\nComputer science\\nComputation',\n",
       " 1038253: 'Detecting Definite Least Association Rule in Medical Database\\nYear: 2014\\n#Citations: 4\\n\\nSpringer, Singapore\\nLeast association rule refers to the rule that only rarely occur in database but they might reveal some interesting knowledge in certain domain applications. In certain medical datasets, finding these rules is very important and required further analysis. In this paper we applied our novel measure known as Definite Factor (DF) with SLP-Growth algorithm to mining the Definite Least Association Rule (DELAR) from a benchmarked medical datasets. DELAR is also highly correlated and evaluated based on standard Lift measure. The result shows that DF can be used as alternative measure in capturing the interesting rules and thus verify its scalability.\\nData mining\\nComputer science\\nAssociation rule learning\\nDatabase\\nScalability',\n",
       " 1040121: 'SensorML for Grid Sensor Networks.\\nYear: 2006\\n#Citations: 9\\n\\n\\nThis paper describes an approach based on Globus toolkit for developing grid sensor networks. The key aspect is also represented on the use of a novel information service based on a relational data model, namely iGrid developed within the European GridLab project. iGrid is used to integrate sensor networks in Grid environments by means of the design of an information structure based on Sensor Modeling Language (SensorML). A case study is also presented in order to provide some relevant details about our approach and to verify the concrete applicability of the proposed methodology.\\nInformation structure\\nGrid computing\\nSensorML\\nComputer science\\nModeling language\\nRelational model\\nWireless sensor network\\nSensor web\\nGrid\\nDistributed computing',\n",
       " 1041107: 'The Evolution of Storage Administration.\\nYear: 1990\\n#Citations: 0\\n\\n\\nEnvironmental science\\nWaste management',\n",
       " 1045715: 'Display Techniques and Methods for Cross-medial Data Analysis.\\nYear: 2003\\n#Citations: 5\\nJournal\\n\\n♣ Corresponding Author: Luciano Gamberini Ergonomics and New Technology Labs, Department of General Psychology, University of Padova via Venezia 8, 35131 Padova, Italy Tel: +39-049-827-6605 Fax: +39-049-827-6600 Email: luciano.gamberini@unipd.it Various kinds of resources (physical, digital, local, far), settings (real and mediated, single or multiuser) and mediating tools are simultaneously active during the interaction with digital environments. In conducting research on human-computer interaction is then vital to work with cross-medial data collections, namely with data which derive from different collection procedures addressing various aspects of the interaction and which are combined according to an overarching methodological rationale. The present paper intends to describe some techniques for the collection and displaying of cross-media data, integrating them with some methodological considerations. Three procedures will be illustrated, namely the split-screen technique, that allows the synchronized visualization of different environments on the same screen; the action indicator augmented display, that allows to enrich the visual recording with signals notifying the occurrence of a particular event; the pentagram, which allows to transcribe multiple sequences of events in their reciprocal temporal relationship. The basic characteristic of these techniques are described and illustratively applied to the interaction with virtual environments.\\nReciprocal\\nVisualization\\nPsychology\\nHuman–computer interaction',\n",
       " 1046654: 'Population resizing using nonlinear dynamics in an ecology-based approach\\nYear: 2012\\n#Citations: 3\\nConference\\nSpringer, Berlin, Heidelberg\\nIt is well known that, in nature, populations are dynamic in space and time. This means that the size of populations oscillate across their habitats over time. This work uses the concepts of habitats, ecological relationships, ecological successions and population dynamics to build a cooperative search algorithm, named ECO. This work aims to explore the population sizing not as a parameter but as a dynamic process. The Artificial Bee Colony (ABC) was used in the experiments where benchmark mathematical functions were optimized. Results were compared with ABC running alone, with and without the use of population dynamics. The ECO algorithm with population dynamics performed better than the other approaches, possibly thanks to the ecological interactions (intra and inter-habitats) that enabled the co-evolution of populations and to a more natural survival selection mechanism by the use of population dynamics.\\nPopulation\\nEcology\\nFunction (mathematics)\\nNonlinear system\\nSearch algorithm\\nHabitat\\nResizing\\nComputer science\\nEcological relationship\\nArtificial intelligence\\nMachine learning',\n",
       " 1048515: 'Effective data-race detection for the kernel\\nYear: 2010\\n#Citations: 140\\nConference\\nUSENIX Association\\nData races are an important class of concurrency errors where two threads erroneously access a shared memory location without appropriate synchronization. This paper presents DataCollider, a lightweight and effective technique for dynamically detecting data races in kernel modules. Unlike existing data-race detection techniques, DataCollider is oblivious to the synchronization protocols (such as locking disciplines) the program uses to protect shared memory accesses. This is particularly important for low-level kernel code that uses a myriad of complex architecture/device specific synchronization mechanisms. To reduce the runtime overhead, DataCollider randomly samples a small percentage of memory accesses as candidates for data-race detection. The key novelty of DataCollider is that it uses breakpoint facilities already supported by many hardware architectures to achieve negligible runtime overheads. We have implemented DataCollider for the Windows 7 kernel and have found 25 confirmed erroneous data races of which 12 have already been fixed.\\nKernel (linear algebra)\\nSynchronization\\nUniform memory access\\nShared memory\\nComputer science\\nConcurrency\\nParallel computing\\nReal-time computing\\nThread (computing)\\nNovelty\\nDistributed shared memory\\nDistributed computing',\n",
       " 1054770: 'Understanding the Role of Organizational Culture for Design and Success of Enterprise Architecture Management\\nYear: 2013\\n#Citations: 32\\nJournal\\nUniversität Leipzig\\nEnterprise architecture management is considered a valuable means to guide the consistent design and evolution of increasingly complex information systems. Despite existing research on EAM methods and models, organizations often face serious difficulties making EAM effective. The paper proposes to take organizational culture as a highly aggregated construct describing the context of EAM initiatives for building situational-or for that matter culture sensitive EAM methods-into account. We find that organizational culture significantly moderates the impact of EAMu0027s design on EAMu0027s success. In group culture, hierarchical culture and developmental culture it is essential to develop EAM from a passive into an actively designing approach to make it effective. Particularly in group culture it is rewarding to strive for an EAM approach that impacts stakeholders outside the IT department.\\nInformation system\\nInformation management\\nComputer science\\nOrganizational culture\\nKnowledge management\\nEnterprise architecture management',\n",
       " 1055523: 'Extending OpenStack Access Control with Domain Trust\\nYear: 2014\\n#Citations: 28\\nConference\\nSpringer, Cham\\nOpenStack has been rapidly established as the most popular open-source platform for cloud Infrastrusture-as-a-Service in this fast moving industry. In response to increasing access control requirements from its users, the OpenStack identity service Keystone has introduced several entities, such as domains and projects in addition to roles, resulting in a rather complex and somewhat obscure authorization model. In this paper, we present a formalized description of the core OpenStack access control (OSAC). We further propose a domain trust extension for OSAC to facilitate secure cross-domain authorization. We have implemented a proof-of-concept prototype of this trust extension based on Keystone. The authorization delay introduced by the domain trusts is 0.7 percent on average in our experiments.\\nWorld Wide Web\\nComputer science\\nComputer security\\nAuthorization\\nIdentity management\\nAccess control\\nCloud computing',\n",
       " 1057598: 'Compositions of Codings.\\nYear: 1993\\n#Citations: 0\\nConference\\n\\nDiscrete mathematics\\nComputer science',\n",
       " 1061858: 'The First Language Problem.\\nYear: 2002\\n#Citations: 0\\nConference\\n\\nContext-sensitive language\\nProgramming language\\nComputer science\\nParallel computing\\nVery high-level programming language\\nObject language\\nUniversal Networking Language\\nLanguage identification\\nFirst-generation programming language\\nFirst language\\nLanguage primitive',\n",
       " 1063894: 'Parallel Preconditioning of Sparse Symmetric Eigenproblems\\nYear: 1999\\n#Citations: 0\\nConference\\n\\nApplied mathematics\\nComputer science',\n",
       " 1071405: 'Bridging the gaps towards advanced data discovery over semi-structured data\\nYear: 2012\\n#Citations: 0\\nConference\\nSpringer, Berlin, Heidelberg\\nIn this work we argue that two main gaps currently hinder the development of new applications requiring sophisticated data discovery capabilities over rich (semi-structured) entity-relationship data. The first gap exists at the conceptual level, and the second at the logical level. Aiming at fulfilling the identified gaps, we propose a novel methodology for developing data discovery applications. We first describe a data discovery extension to the classic ER conceptual model termed Entity Relationship Data Discovery (ERD2). We further present a novel logical model termed the Document Category Sets (DCS) model, used to represent entities and their relationships within an enhanced document model, and describe how data discovery requirements captured by the ERD2 conceptual model can be translated into the DCS logical model. Finally, we propose an efficient data discovery system implementation, and share details of two different data discovery applications that were developed in IBM using the proposed methodology.\\nSemi-structured data\\nData science\\nData mining\\nData discovery\\nData modeling\\nConceptual model\\nComputer science\\nLogical data model\\nData model\\nDatabase\\nConceptual model (computer science)\\nEntity–relationship model',\n",
       " 1072516: 'On Optimal Parameters for Ant Colony Optimization Algorithms.\\nYear: 2005\\n#Citations: 66\\nConference\\n\\nAnt Colony Optimization (ACO) is a metaheuristic introduced by Dorigo et al. [9] which uses ideas from nature to find solutions to instances of the Travelling Salesman Problem (TSP) and other combinatorial optimisation problems. In this paper we analyse the parameter settings of the ACO algorithm. These determine the behaviour of each ant and are critical for fast convergence to near optimal solutions of a given problem instance. We classify TSP instances using three measures of complexity and uniformity. We describe experimental work that attempts to correlate ‘types’ of TSP problems with parameter settings for fast convergence. We found these optimal parameter settings to be highly problemspecific and dependent on the required accuracy of the solution. This inspired us to explore techniques for automatically learning the optimal parameters for a given TSP instance. We devised and implemented a hybrid ACO algorithm, similar to the one independently developed in [16], which uses a genetic algorithm in the early stages to ‘breed’ a population of ants possessing near optimal behavioural parameter settings for a given problem. This hybrid algorithm converges rapidly for a wide range of problems when given a population of ants with diverse behavioural parameter settings.\\nAnt colony optimization algorithms\\nArtificial bee colony algorithm\\nMathematical optimization\\nHybrid algorithm\\nParallel metaheuristic\\nExtremal optimization\\nComputer science\\nMeta-optimization\\nTravelling salesman problem\\nMetaheuristic',\n",
       " 1074707: \"A Parallel Algorithm for the Linear Complementarity Problem with an M-Matirx.\\nYear: 2003\\n#Citations: 0\\nConference\\n\\nMathematical optimization\\nComputer science\\nParallel algorithm\\nParallel computing\\nComplementarity theory\\nLemke's algorithm\\nLinear complementarity problem\\nMixed complementarity problem\\nCriss-cross algorithm\",\n",
       " 1078554: 'Reconfigurable Systems and their Influence on Mobile and Multimedia Applications.\\nYear: 2006\\n#Citations: 1\\nConference\\n\\nWith the advent of field programmable logic devices it became possible to design and implement digital systems without the need for the technological steps dealing with silicon. Tremendous progress in this area has made it possible to advance configurable microchips from programmable logic arrays - PLA (early 1970s) and further simple gate arrays, that appeared on the market in the mid-1980s, to platform field programmable gate arrays (FPGA) containing more than 10 million system gates and incorporating complex heterogeneous structures, such as PowerPC processors. Recent research results show that future programmable logic might achieve 100 billion devices per square centimeter, which permits to argue that cheap molecular-scale reconfiguration is likely to become the predominant digital technology in a decade hence. The impact of FPGAs on different development directions in computer science, electrical and computer engineering is growing continuously. Today, advanced research is being intensively performed in the areas of system-onchip and network-on-chip supported by the extensive use of computer-aided design (CAD) systems. Traditionally, FPGA-targeted CAD systems are based on schematic and hardware description language design flows involving model-specific tools and core generators. Recently, system level specification languages (such as Handel-C and SystemC) have been developed and are now frequently used. This clearly demonstrates that the domain of reconfigurable systems design is very dynamic and many-sided. The rapid evolution of FPGA technology and relevant CAD systems requires a large number of well-prepared engineers in these areas. Hence an ongoing review of the corresponding curricula is necessary to incorporate the recent advances. Consequently the impact of reconfigurable systems on contemporary engineering education is also growing continuously. This tutorial is intended to cover the majority of hot topics related to reconfigurable systems with a profound analysis and comparison of alternative approaches, such as hardware/software versus configware. It demonstrates advantages of reconfigurable systems in terms of technical characteristics and economic aspects and shows their significant influence on mobile computing and multimedia applications. The tutorial also includes a profound discussion of a novel methodology that has been used for teaching reconfigurable systems.\\nComputer science\\nSystems design\\nField-programmable gate array\\nSystemC\\nMultimedia\\nPowerPC\\nControl reconfiguration\\nProgrammable logic device\\nHardware description language\\nReconfigurable computing',\n",
       " 1082713: 'From likelihood uncertainty to fuzziness: a possibility-based approach for building clinical DSSs\\nYear: 2012\\n#Citations: 6\\nConference\\nSpringer, Berlin, Heidelberg\\nFor data classification, in fields like medicine, where vague concepts have to be considered, and where, at the same time, intelligible rules are required, research agrees on utility of fuzzy logic. In this ambit, if statistical information about the problem is known, or can be extracted from data, it can be used to define fuzzy sets and rules. Statistical knowledge can be acquired in terms of probability distributions or likelihood functions. Here, an approach is proposed for the transformation of likelihood functions into fuzzy sets, which considers possibility measure, and different methods arising from this approach are presented. By using real data, a comparison among different methods is performed, based on the analysis of transformation properties and resulting fuzzy sets characteristics. Finally, the best method to be used in the context of clinical decision support systems (DSSs) is chosen.\\nData mining\\nFuzzy classification\\nDefuzzification\\nFuzzy set operations\\nComputer science\\nFuzzy measure theory\\nFuzzy set\\nArtificial intelligence\\nFuzzy number\\nType-2 fuzzy sets and systems\\nMembership function\\nMachine learning',\n",
       " 1083924: 'Computational Metaphor Identification in Communities of Blogs.\\nYear: 2008\\n#Citations: 3\\nConference\\n\\nThis poster presents a computational analysis of conceptual metaphors in a community of political blogs. Like sentiment analysis or opinion extraction, computational metaphor identification can provide an understanding of the framings or conceptualizations used in a community. This poster includes an implementation overview and results summary.\\nData science\\nInternet privacy\\nComputer science\\nSentiment analysis\\nLinguistics\\nPolitics\\nMetaphor\\nComputational analysis\\nOpinion extraction',\n",
       " 1086356: 'Factorisation of OMT Models.\\nYear: 1999\\n#Citations: 0\\nConference\\n\\nData mining\\nInformation retrieval\\nComputer science\\nFactorization',\n",
       " 1090942: 'Is linguistic information relevant for the text legal classification problem\\nYear: 2005\\n#Citations: 5\\nConference\\n\\nRule-based machine translation\\nData mining\\nComputer science\\nArtificial intelligence\\nNatural language processing',\n",
       " 1092600: 'Anoraks Among the Suits and Jeans: Computers, Law and the Legal Academy.\\nYear: 1997\\n#Citations: 4\\nJournal\\n\\nInternet privacy\\nComputer science\\nLaw',\n",
       " 1094945: 'An Industrial Fuzzy PID Autotuner Based on the Relay Method\\nYear: 2014\\n#Citations: 1\\nConference\\nSpringer, Cham\\nThe article analyses a auto-tuning method for a fuzzy PID controller based on the relay experiment. The algorithm was implemented and tested on a real plant for redox agent stabilisation in a paper mill. Experiments have discovered some unsolved, practical problems which were discussed in the paper i.e. determination of the ON-OFF parameters, the non-shocked switching from the ON-OFF tuning algorithm into a continues fuzzy PID algorithm.\\nPID controller\\nComputer science\\nControl theory\\nFuzzy pid controller\\nFuzzy pid\\nControl system\\nFuzzy control system\\nAuto tuning\\nRelay',\n",
       " 1096597: 'An evaluation oof spectral transitivity functions for speech segmentation in variable frame-rate speech vocoding.\\nYear: 1991\\n#Citations: 0\\nConference\\n\\nComputer science\\nSpeech recognition\\nNatural language processing\\nArtificial intelligence\\nSpeech segmentation\\nVariable frame rate\\nTransitive relation',\n",
       " 1099225: 'DELAY EFFICIENT MAC PROTOCOL FOR DIFFUSION BASED ROUTING IN WIRELESS SENSOR NETWORKS\\nYear: 2008\\n#Citations: 0\\nConference\\n\\nIn this paper we present DESMAC a contention based Medium Access Control protocol for Diffusion based routing in Wireless Sensor Networks. One of the main challenges in WSNs is to balance delay efficiency and energy consumption. Surveillance and monitoring application as well as many other need low latency data delivery; but, since sensor nodes have a small source of energy usually Active/Sleep cycles are used to reduce the energy consumption which causes higher delay. We use routing information to adaptively change the duty cycle for different loads. In our Cross Layer Design the Routing Layer can manipulate the duty cycle of underlying MAC protocol. The diffusion control messages are used to adapt the duty cycle to variation in the load. Also extensive use of some nodes can damage the connectivity of network. Therefore we provide a mechanism to balance the load between several possible paths. We discuss DESMAC design and compare our simulation results to S-MAC and IEEE 802.11 standard. DESMAC achieves significant latency reduction (up to 50 times better delay than S-MAC) while ensuring energy efficiency and load\\nLink-state routing protocol\\nDynamic Source Routing\\nComputer science\\nEnhanced Interior Gateway Routing Protocol\\nComputer network\\nWireless Routing Protocol\\nMobile wireless sensor network\\nRouting Information Protocol\\nZone Routing Protocol\\nRouting protocol\\nDistributed computing',\n",
       " 1103071: 'Is there an emotion signature in intonational patterns? and can it be used in synthesis?\\nYear: 2003\\n#Citations: 2\\nConference\\n\\nComputer science\\nSpeech recognition',\n",
       " 1103989: 'Preface - Papers from the Conference for PhD Students in Computer Science.\\nYear: 1999\\n#Citations: 0\\nJournal\\n\\nDiscrete mathematics\\nComputer science\\nMathematics education\\nMathematics',\n",
       " 1104220: 'S-NET: a foundation for knowledge representation languages\\nYear: 1979\\n#Citations: 1\\nConference\\nMorgan Kaufmann Publishers Inc.\\nA new knowledge representation scheme called S-Net is presented. The S-Net is a descendent of both semantic networks and recently developed AI languages. We are willing to introduce procedures into our network notations as FRL and KRL do. However, these languages have a serious disadvantage that the programmer should specify, explicitly by using indicators such as WHEN-FILLED, TO-FILL etc., when the attached procedures are invoked. This results in the restriction of systemu0027s abilities of solving problems. To avoid this, the programmer should always pay attention to the overal control issues during the coding of his procedures. In our new formalism, the explicit specification is not necessary. The problem solver based on the S-Net dynamically determines which procedure is invoked when, according to the problem solving situations, not to the pre-specified indicators. We also discuss the problems of property inheritance through hierarchy. The inheritance mechanism provided so far is so restrictive that the programmer should do all things in his procedures. In the S-Net, the property inheritance is further augmented by the u0027explicit path specificationu0027. The detailed construction of the problem solver, which performs both forward and backward reasonings appropriately, is also given.\\nNotation\\nProgramming language\\nComputer science\\nCoding (social sciences)\\nTheoretical computer science\\nArtificial intelligence\\nHierarchy\\nKnowledge representation and reasoning\\nProgrammer\\nSemantic network\\nSolver\\nFormalism (philosophy)\\nMachine learning',\n",
       " 1105034: 'Bodily expression media by dual domain design of shadow\\nYear: 2013\\n#Citations: 1\\nConference\\nSpringer, Berlin, Heidelberg\\nIn an improvised bodily expression, it is important to create the image inside the self. We developed a body expression generator called \"shadow media\" that generates an image by causing a gap between the body and its shadow. In this study, we focused on the dual residual shadow, a type of the shadow media, which generates a dual gap. Using this aspect of the shadow media, we develop new body expression media by introducing fluctuation and cellar automation to the boundary of the dual residual shadow. Experimental results indicate that these shadow media outputs can effectively support the generation of bodily expressions.\\nComputer vision\\nResidual\\nShadow\\nExpression (mathematics)\\nComputer science\\nAutomation\\nArtificial intelligence\\nMultimedia',\n",
       " 1107177: 'A systematic algorithm to construct neuro-fuzzy inference system.\\nYear: 2007\\n#Citations: 8\\nConference\\n\\nData mining\\nNeuro-fuzzy\\nComputer science\\nArtificial intelligence\\nAdaptive neuro fuzzy inference system\\nMachine learning\\nInference system',\n",
       " 1113293: 'Nondeterminism Degrees for Context-Free Languages.\\nYear: 1995\\n#Citations: 4\\nConference\\n\\nContext-free language\\nSecond-generation programming language\\nProgramming language\\nComputer science\\nAbstract family of languages',\n",
       " 1114199: 'Combining HMM processing and formant measurements in automatic speech recognition.\\nYear: 1995\\n#Citations: 0\\nConference\\n\\nSpeech processing\\nPattern recognition\\nComputer science\\nSpeech recognition\\nSpeaker recognition\\nArtificial intelligence\\nFormant\\nHidden Markov model\\nAcoustic model',\n",
       " 1115014: 'Q+: Interactive Visual Modeling for Performance Analysis and Simulation of Queueing Systems.\\nYear: 1994\\n#Citations: 0\\nJournal\\n\\nVisual modeling\\nComputer science\\nQueueing theory\\nDistributed computing',\n",
       " 1119309: 'Computer Entertainment in Cars and Transportation\\nYear: 2013\\n#Citations: 0\\nConference\\nSpringer, Cham\\nThis workshop deals with the potential that entertainment systems and games hold for the transportation context. Travelling by car, bus, plane or by foot can be frustrating and full of negative experiences, but also holds great potential for innovative entertainment application. New off the shelf technology offers great potential beyond old-fashioned rear seat entertainment systems with the sole purpose of keeping kids quiet. The richness of contextual factors and social situations have so far not sufficiently been exploited, which is why this workshop aims at discussing potentials for gaming in transportation.\\nQUIET\\nOff the shelf\\nEntertainment\\nComputer science\\nHuman–computer interaction\\nComputer entertainment\\nMultimedia',\n",
       " 1123136: 'A reading history logger for supporting reading habit development\\nYear: 2011\\n#Citations: 1\\nConference\\nSpringer, Berlin, Heidelberg\\nWe are developing a social networking site for the purpose of support for a reading habit development. To support the habit development, it is necessary to grasp the state of the useru0027s reading in real time. However, letting a user register every reading history is a big burden for the user aiming at the habit development. Therefore we have developed a bookmark-style reading history logger device using Eye-Fi and PSoC. The bookmark device has a function to register the reading date/time information to any photo-sharing site. Our social networking site for a habit development can get the reading time by checking a web feed of the photo-sharing site.\\nGRASP\\nSocial network\\nComputer science\\nWeb feed\\nPeer mentoring\\nHabit\\nPSoC\\nMultimedia',\n",
       " 1124433: 'Ordered Compactifications of Products of Two Totally Ordered Spaces\\nYear: 1999\\n#Citations: 2\\nJournal\\n\\nWe describe the semilattice of ordered compactifications of X × Y smaller than βoX × βoY where X and Y are certain totally ordered topological spaces, and where βoZ denotes the Stone–Cech ordered- or Nachbin-compactification of Z. These basic cases are used to illustrate techniques for describing the semilattice of ordered compactifications of X × Y smaller than βoX × βoY for arbitrary totally ordered topological spaces X and Y. Such products X × Y provide many counterexamples in the theory of ordered compactifications.\\nDiscrete mathematics\\nCombinatorics\\nTopological space\\nHausdorff maximal principle\\nTotal order\\nSingularity\\nOrder type\\nCounterexample\\nSemilattice\\nMathematics',\n",
       " 1127822: 'The Science of Writing by C. Michael Levy and Sara Ransdell.\\nYear: 1997\\n#Citations: 0\\nJournal\\n\\nSociology\\nPublic relations\\nManagement',\n",
       " 1131298: 'Refinement Checking for Interface Automata with Z Notation.\\nYear: 2010\\n#Citations: 0\\nConference\\n\\nZ notation\\nProgramming language\\nComputer science\\nSteinhaus–Moser notation\\nAutomaton\\nTheoretical computer science\\nX-ray notation',\n",
       " 1132564: 'TRAINING NETWORK MANAGERS TO RECOGNISE INTRUSION ATTACKS\\nYear: 2004\\n#Citations: 2\\nConference\\n\\nIntrusion\\nComputer science\\nComputer security\\nNetwork security\\nComputer network\\nIntrusion prevention system\\nIntrusion detection system',\n",
       " 1132861: 'A Comparison between two Approaches to Categorical Automata Theory.\\nYear: 1981\\n#Citations: 0\\nJournal\\n\\nQuantum finite automata\\nDiscrete mathematics\\nAutomata theory\\nAlgebra\\nNested word\\nCategorical variable\\nDFA minimization\\nMathematics\\nTheory of computation\\nω-automaton',\n",
       " 1137530: 'Evenly Spaced Pareto Front Approximations for Tricriteria Problems Based on Triangulation\\nYear: 2013\\n#Citations: 14\\nConference\\nSpringer, Berlin, Heidelberg\\nIn some technical applications like multiobjective online control an evenly spaced approximation of the Pareto front is desired. Since standard evolutionary multiobjective optimization (EMO) algorithms have not been designed for that kind of approximation we propose an archive-based plug-in method that builds an evenly spaced approximation using averaged Hausdorff measure between archive and reference front. In case of three objectives this reference font is constructed from a triangulated approximation of the Pareto front from a previous experiment. The plug-in can be deployed in online or offline mode for any kind of EMO algorithm.\\nMathematical optimization\\nComputer science\\nFont\\nMulti-objective optimization\\nTriangulation\\nTriangulation (social science)\\nHausdorff measure',\n",
       " 1139486: 'An Automated Hammerstein Recurrent Neural Network for Dynamic Applications.\\nYear: 2005\\n#Citations: 4\\nConference\\n\\nComputer science\\nRecurrent neural network\\nProbabilistic neural network\\nSpeech recognition\\nTime delay neural network',\n",
       " 1140107: 'X-Similarity: Computing Semantic Similarity between Concepts from Different Ontologies\\nYear: 2006\\n#Citations: 94\\nJournal\\nDigital Information Research Foundation\\nSemantic Similarity relates to computing the similarity between concepts (terms) which are not necessarily lexically similar. We investigate approaches for computing semantic similarity by mapping terms to an ontology and by examining their relationships in that ontology. More specifically, we investigate approaches to computing the semantic similarity between natural language terms (using WordNet as the underlying reference ontology) and between medical terms (using the MeSH ontology of medical and biomedical terms). The most popular semantic similarity methods are implemented and evaluated using WordNet and MeSH. The focus of this work is also on cross ontology methods which are capable of computing the semantic similarity between terms stemming from different ontologies (WordNet and MeSH in this work). This is a far more difficult problem (than the single ontology one referred to above) which has not been investigated adequately in the literature. X-Similarity, a novel cross-ontology similarity method is also a contribution of this work. All methods examined in this work are integrated into a semantic similarity system which is accessible on the Web.\\nData mining\\nSemantic Web Stack\\nComputer science\\nOWL-S\\nNatural language processing\\nArtificial intelligence\\nSemantic computing\\nSemantic similarity\\nOntology (information science)\\nOntology-based data integration\\nInformation retrieval\\nOntology Inference Layer\\nUpper ontology',\n",
       " 1144321: 'From Single-Site Web Applications to the Design of Web-Site-Families\\nYear: 2006\\n#Citations: 1\\nConference\\n\\nWeb applications, or web sites, are an important communication medium conveying information between organizations and the users of their web applications. To ensure a unique appearance of their web applications, organizations dene standardized content, navigation and presentation requirements for web applications within their corporate identity. However, specialized information supplied by organizational units may not t into this standardized scheme. Web site families try to overcome this situation by capturing the requirements necessary to fulll the corporate identity, while at the same time providing the exibilit y to specify requirements which are particular for individual organizational units. For this purpose, they rely on a hierarchical model in which common requirements for a family of web sites are captured. Those requirements may be extended, rened or re-structured within a concrete web site of an organizational unit as long as it adheres to the common requirements. In this paper the structure of web site families as well as consistency criteria that allow the exible denition of families of web sites, are presented.\\nWeb development\\nWorld Wide Web\\nWeb standards\\nWeb engineering\\nData Web\\nWeb modeling\\nWeb navigation\\nEngineering\\nWeb service\\nWS-Policy',\n",
       " 1147305: 'ORB3 - MUSICAL ROBOTS WITHIN AN ADAPTIVE SOCIAL COMPOSITION SYSTEM\\nYear: 2005\\n#Citations: 0\\nConference\\nMichigan Publishing, University of Michigan Library\\nGesture capture, motion tracking and 3D visualisation technologies have generated many new musical forms, often extending the mannerisms or behaviours of a given performer or discipline, providing new compositional frameworks for real time synthesis in response to action. In many cases these approaches are presented within a single domain, a live stage performance, a site specific installation, a shared networked visualisation of collaborative composition. The reality is that these ‘interactivating spaces’ [1] whether haptic, [5] tactile [9] or ubiquitous [11] is that they manifest new forms of interaction, between people, systems and the medium of sound. Free Sound can be understood to be an extension of the ‘open work’ where the base materials for a compositional process are created through a model of exchange, interaction and resynthesis. The resulting output of these activities can be broadcast and disseminated through a range of technologies to both social and private spaces. This research suggests that there are new interaction models and social compositional frameworks to be found in these cybrid spaces, a previously intangible location often dominated by the broadcast and publishing industry. A marketing model defined by revenue streams and a value chain. In the case of socially mediated composition or ‘free sound’ there is still a value chain, it’s investors and beneficiaries are the open source community, the collaborators and participants within such mediated systems and the resulting free sound.\\nRevenue\\nBroadcasting\\nComputer science\\nVisualization\\nGesture\\nReal-time computing\\nHuman–computer interaction\\nPerforming arts\\nRobot\\nMusical form\\nHaptic technology',\n",
       " 1147978: 'Translation and rotation of the cricothyroid joint revealed by phonation-synchronized high-resolution MRI.\\nYear: 2003\\n#Citations: 2\\nConference\\n\\nCricothyroid Joint\\nComputer science\\nSpeech recognition\\nPhonation',\n",
       " 1154133: 'Neuere Entwicklungen und Projekte auf dem Gebiet der Betriebssysteme.\\nYear: 1981\\n#Citations: 0\\nJournal\\n\\nWorld Wide Web\\nComputer science',\n",
       " 1159246: 'Testability Analysis and Improvements of Register-Transfer Level Digital Circuits\\nYear: 2012\\n#Citations: 11\\nJournal\\n\\nThe paper presents novel testability analysis method applicable to register-transfer level digital circuits. It is shown if each module stored in a design library is equipped both with information related to design and information related to testing, then more accurate testability results can be achieved. A mathematical model based on virtual port conception is utilized to describe the information and proposed testability analysis method. In order to be effective, the method is based on the idea of searching two special digraphs developed for the purpose. Experimental results gained by the method are presented and compared with results of existing methods.\\nTestability\\nDesign for testing\\nDigital electronics\\nData path\\nComputer science\\nTheoretical computer science\\nTestability analysis\\nRegister-transfer level\\nTest compression',\n",
       " 1161143: 'Covering Polygons Is Hard (Preliminary Abstract)\\nYear: 1988\\n#Citations: 2\\nConference\\n\\nDiscrete mathematics\\nCombinatorics\\nPolygon\\nComputer science',\n",
       " 1162061: 'Generative knowledge for computer troubleshooting\\nYear: 1990\\n#Citations: 2\\nConference\\nPitman Publishing\\nTroubleshooting\\nComputer science\\nArtificial intelligence\\nGenerative grammar\\nMachine learning',\n",
       " 1165981: 'A datalog recognizer for almost affine λ-CFGs\\nYear: 2011\\n#Citations: 6\\nConference\\nSpringer-Verlag\\nThe recent emergence of linguistic formalisms exclusively based on the simply-typed λ-calculus to represent both syntax and semantics led to the presentation of innovative techniques which apply to both the problems of parsing and generating natural languages. A common feature of these techniques consists in using strong relations between typing properties and syntactic structures of families of simply-typed λ-terms. Among significant results, an efficient algorithm based on Datalog programming is presented in [Kan07] for context-free grammar of almost linear λ-terms, which are linear λ-terms augmented with a restricted form of copy. We present an extension of this method to terms for which deletion is allowed.\\nTree-adjoining grammar\\nAffine transformation\\nContext-sensitive grammar\\nS-attributed grammar\\nProgramming language\\nL-attributed grammar\\nComputer science\\nNatural language processing\\nArtificial intelligence\\nParsing\\nSyntax\\nDatalog',\n",
       " 1172845: 'Developing SBVR Vocabularies and Business Rules from OWL2 Ontologies\\nYear: 2013\\n#Citations: 7\\nConference\\nSpringer, Berlin, Heidelberg\\nSemantics of Business Vocabulary and Business Rules (SBVR) is OMG adopted metamodel allowing defining noun concepts, verb concepts and business rules of a problem domain in structured natural language based on formal logics. SBVR business vocabulary and business rules are capable of representing ontologies. There are some research works devoted to transforming SBVR into Web Ontology Language OWL2. The reverse way of representing ontology concepts with SBVR structured language was not investigated though there are much more ontologies than SBVR vocabularies. Our research is concentrated on methodology for creating SBVR vocabularies and rules from OWL2 ontologies without a loss of the expressive power, characteristic for ontologies, as some ontology-specific concepts have no direct representation in SBVR. The particular attention is devoted to applying SBVR vocabulary in semantic search.\\nOntology (information science)\\nOntology\\nSemantics of Business Vocabulary and Business Rules\\nSemantic search\\nComputer science\\nNatural language\\nArtificial intelligence\\nNatural language processing\\nVocabulary\\nBusiness rule\\nWeb Ontology Language',\n",
       " 1177723: 'Mayo clinic smoking status classification system: extensions and improvements.\\nYear: 2009\\n#Citations: 37\\nConference\\nAmerican Medical Informatics Association\\nThis paper describes improvements of and extensions to the Mayo Clinic 2006 smoking status classification system. The new system aims at addressing some of the limitations of the previous one. The performance improvements were mainly achieved through remodeling the negation detection for non-smoker, temporal resolution to distinguish a past and current smoker, and improved detection of the smoking status category of unknown. In addition, we introduced a rule-based component for patient-level smoking status assignments in which the individual smoking statuses of all clinical documents for a given patient are aggregated and analyzed to produce the final patient smoking status. The enhanced system builds upon components from Mayo’s clinical Text Analysis and Knowledge Extraction System developed within IBM’s Unstructured Information Management Architecture framework. This reusability minimized the development effort. The extended system is in use to identify smoking status risk factors for a peripheral artery disease NHGRI study.\\nInformation management\\nDisease\\nSimulation\\nKnowledge extraction\\nMedical physics\\nCurrent smoker\\nMedicine',\n",
       " 1183563: 'AReIT:Adaptive Reliable Information Transport Protocol for Wireless Sensor Networks\\nYear: 2009\\n#Citations: 2\\nConference\\nCSREA Press\\nThe reliable delivery of services in service oriented architectures often entails the underlying basis of having well structured system and communication network models. With the rapid proliferation of ad-hoc mode of communication, such as Wireless Sensor Networks (WSNs), the reliable delivery of services increasingly encounters new communication and also network perturbation challenges. Empirically the core of service delivery in WSN is information transport from the sensor nodes to the service via a sink node. In this work we classify the different services provided by the WSNs, and provide a reliable information transport protocol (AReIT) for enhanced service delivery. AReIT exploits the spatial and temporal redundancies inside the WSN to provide efficient adaptation for changing service requirement and evolving network conditions. Simulation results show that AReIT provides tunable reliability allowing to save expensive retransmissions while maintaining the reliability level desired by the service.\\nBest-effort delivery\\nWireless network\\nKey distribution in wireless sensor networks\\nComputer science\\nComputer network\\nWireless WAN\\nMobile wireless sensor network\\nWireless sensor network\\nSensor web\\nService delivery framework\\nDistributed computing',\n",
       " 1185599: 'Risk Management and Bilateral Contracts in Multi-agent Electricity Markets\\nYear: 2014\\n#Citations: 10\\nConference\\nSpringer, Cham\\nIn competitive energy markets, customers can freely choose their energy suppliers. The electricity trade can be done in organized markets or using bilateral contracts between customers and suppliers. In the latter case, market participants set the terms and conditions of agreements independent of the market operator. They often enter into bilateral contracts to hedge against pool price volatility. Furthermore, these contracts are very flexible since the negotiating parties can specify their own contract terms. This article focuses on bilateral trading and presents the key features of software agents able to negotiate forward bilateral contracts. Special attention is devoted to risk management in bilateral contracting, notably utility functions and trading strategies for dealing with risk. The article also presents a case study on forward bilateral contracting involving risk management: a retailer agent and an industrial customer agent negotiate a 24h-rate tariff.\\nTrading strategy\\nSoftware agent\\nTariff\\nMulti-agent system\\nRisk management\\nContract management\\nIndustrial organization\\nVolatility (finance)\\nBusiness\\nNegotiation',\n",
       " 1186722: 'CONTROL STRATEGY OF CONSTANT MILLING FORCE SYSTEM AND METAL REMOVAL RATE MAXIMIZION\\nYear: 2010\\n#Citations: 0\\nConference\\n\\nControl engineering\\nMetal\\nEngineering',\n",
       " 1189345: 'Towards faster planning with continuous resources in stochastic domains\\nYear: 2008\\n#Citations: 10\\nConference\\nAAAI Press\\nAgents often have to construct plans that obey resource limits for continuous resources whose consumption can only be characterized by probability distributions. While Markov Decision Processes (MDPs) with a state space of continuous and discrete variables are popular for modeling these domains, current algorithms for such MDPs can exhibit poor performance with a scale-up in their state space. To remedy that we propose an algorithm called DPFP. DPFPu0027s key contribution is its exploitation of the dual space cumulative distribution functions. This dual formulation is key to DPFPu0027s novel combination of three features. First, it enables DPFPu0027s membership in a class of algorithms that perform forward search in a large (possibly infinite) policy space. Second, it provides a new and efficient approach for varying the policy generation effort based on the likelihood of reaching different regions of the MDP state space. Third, it yields a bound on the error produced by such approximations. These three features conspire to allow DPFPu0027s superior performance and systematic trade-off of optimality for speed. Our experimental evaluation shows that, when run stand-alone, DPFP outperforms other algorithms in terms of its any-time performance, whereas when run as a hybrid, it allows for a significant speedup of a leading continuous resource MDP solver.\\nMathematical optimization\\nComputer science\\nDual space\\nMarkov decision process\\nProbability distribution\\nCumulative distribution function\\nArtificial intelligence\\nSolver\\nState space\\nMachine learning\\nSpeedup',\n",
       " 1193714: 'Using pint/spirits architecture to enhance intelligent networks service solutions.\\nYear: 2004\\n#Citations: 1\\nConference\\n\\nArchitecture\\nComputer science\\nComputer network\\nIntelligent Network\\nIntelligent computer network',\n",
       " 1194496: 'A Variant of Early Parsing\\nYear: 1997\\n#Citations: 0\\nConference\\nSpringer-Verlag\\nComputer science\\nSpeech recognition\\nNatural language processing\\nArtificial intelligence\\nParsing',\n",
       " 1198182: 'TTL : a formalism to describe local and global properties of distributed systems\\nYear: 1992\\n#Citations: 4\\nJournal\\nEDP Sciences\\nDans ce travail on developpe un formalisme logique qui permet de formuler et de prouver des proprietes de systemes repartis a etats finis. Ce formalisme se base sur la notion de «branching time» et su0027appelle Typed Temporal Logic (TTL). Pour un systeme reparti D on introduit deux theories de TTL, cu0027est-a-dire LLT D  et LGTT D  (Local Time Theory et Local and Global Time Theory of D, respectivement). La theorie LTT D  permet de specifier des systemes repartis par des axiomes locaux, cu0027est-a-dire proprietes qui sont vraies par rapport a des observations locales de parties de systemes\\nCombinatorics\\nGlobal time\\nFormalism (philosophy)\\nMathematics\\nBranching (version control)',\n",
       " 1202812: 'On and off units detect information bottle-necks for speech recognition.\\nYear: 1991\\n#Citations: 0\\nConference\\n\\nSpeech processing\\nPattern recognition\\nIntelligent character recognition\\nComputer science\\nViseme\\nAudio mining\\nVoice activity detection\\nSpeech recognition\\nSpeaker recognition\\nArtificial intelligence\\nAcoustic model',\n",
       " 1203397: 'SPN-hash: improving the provable resistance against differential collision attacks\\nYear: 2012\\n#Citations: 9\\nConference\\nSpringer, Berlin, Heidelberg\\nCollision resistance is a fundamental property required for cryptographic hash functions. One way to ensure collision resistance is to use hash functions based on public key cryptography (PKC) which reduces collision resistance to a hard mathematical problem, but such primitives are usually slow. A more practical approach is to use symmetric-key design techniques which lead to faster schemes, but collision resistance can only be heuristically inferred from the best probability of a single differential characteristic path. We propose a new hash function design with variable hash output sizes of 128, 256, and 512 bits, that reduces this gap. Due to its inherent Substitution-Permutation Network (SPN) structure and JH mode of operation, we are able to compute its differential collision probability using the concept of differentials. Namely, for each possible input differences, we take into account all the differential paths leading to a collision and this enables us to prove that our hash function is secure against a differential collision attack using a single input difference. None of the SHA-3 finalists could prove such a resistance. At the same time, our hash function design is secure against pre-image, second pre-image and rebound attacks, and is faster than PKC-based hashes. Part of our design includes a generalization of the optimal diffusion used in the classical wide-trail SPN construction from Daemen and Rijmen, which leads to near-optimal differential bounds when applied to non-square byte arrays. We also found a novel way to use parallel copies of a serial matrix over the finite field GF(24), so as to create lightweight and secure byte-based diffusion for our design. Overall, we obtain hash functions that are fast in software, very lightweight in hardware (about 4625 GE for the 256-bit hash output) and that provide much stronger security proofs regarding collision resistance than any of the SHA-3 finalists.\\nSHA-2\\nDouble hashing\\nCollision resistance\\nCryptographic hash function\\nAlgorithm\\nHash function\\nHash chain\\nMathematics\\nCollision attack\\nMDC-2',\n",
       " 1206203: 'Township Health Center Information System Based on Cloud Computing\\nYear: 2012\\n#Citations: 0\\nConference\\nSpringer, Berlin, Heidelberg\\nIn order to sovle the insufficiencies of Chinese township health center informatization construction, the article analyzed the problems of Chinese township health center informatization construction and the advantages of Cloud computing in township health center informatization construction by investigation and analysis, then suggested to design the township health center information system based on Cloud Computing, and intruduced the network design, system structure, data storage and technology architecture of township health center information system based on Cloud Computing in detail.\\nInformation system\\nArchitectural technology\\nSystem structure\\nNetwork planning and design\\nComputer data storage\\nComputer science\\nComputer security\\nInformatization\\nDatabase\\nCloud computing',\n",
       " 1208749: 'Service-Oriented Design: The jABC Approach\\nYear: 2006\\n#Citations: 4\\nConference\\nSchloss Dagstuhl - Leibniz-Zentrum fÃ¼r Informatik\\nReviewing our 10 years of experience in service engineering  :[9],\"systems from the point of view of  :[17],\"then and now, we observe that much is common to the  :[29],\"We aim in our current research at establishing a  the :[39],\"notions used by the service-oriented programming                           :[72],\"are convinced that combined approaches, that blend  of the current :[80],\"SO-scenario with the rigour and semantic standardization culture of the telecommunication community  :[96],\"dramatically increase  of the :[99],\"development of a large class of software systems. Incremental formalization and automatic  :[114],\"may be again the key to achieving confidence  :[123],\"for services that interact and interoperate on a  :[132],\"scale.\\nService oriented design\\nService design\\nService engineering\\nRigour\\nSoftware engineering\\nComputer science\\nInteroperability\\nSoftware system\\nStandardization',\n",
       " 1211384: 'Minimal Belief Change and the Pareto Principle\\nYear: 1999\\n#Citations: 3\\nJournal\\nSpringer\\nThis paper analyzes the notion of a minimal belief change that incorporates new information. I apply the fundamental decision-theoretic principle of Pareto-optimality to derive a notion of minimal belief change, for two different representations of belief: First, for beliefs represented by a theory – a deductively closed set of sentences or propositions – and second for beliefs represented by an axiomatic base for a theory. Three postulates exactly characterize Pareto-minimal revisions of theories, yielding a weaker set of constraints than the standard AGM postulates. The Levi identity characterizes Pareto-minimal revisions of belief bases: a change of belief base is Pareto-minimal if and only if the change satisfies the Levi identity (for “maxichoice” contraction operators). Thus for belief bases, Pareto-minimality imposes constraints that the AGM postulates do not. The Ramsey test is a well-known way of establishing connections between belief revision postulates and axioms for conditionals (“if p, then q”). Pareto-minimal theory change corresponds exactly to three characteristic axioms of counterfactual systems: a theory revision operator that satisfies the Ramsey test validates these axioms if and only if the revision operator is Pareto-minimal.\\nAxiom\\nBasic belief\\nClosed set\\nCounterfactual conditional\\nIf and only if\\nEpistemology\\nRamsey RESET test\\nMathematics\\nCalculus\\nBelief revision\\nPareto principle',\n",
       " 1216380: 'A Proof of Convergence of Asynchronous Boltzmann Machine\\nYear: 1998\\n#Citations: 0\\nConference\\n\\nConvergence (routing)\\nAsynchronous communication\\nBoltzmann machine\\nComputer science\\nTheoretical computer science\\nArtificial intelligence\\nArtificial neural network\\nMachine learning',\n",
       " 1221507: 'Visualization of protein-protein interaction networks using force-directed layout\\nYear: 2003\\n#Citations: 2\\nConference\\nSpringer, Berlin, Heidelberg\\nProtein interactions, when visualized as an undirected graph, often yield a nonplanar, disconnected graph with nodes of wide range of degrees. Many graph-drawing programs are of limited use in visualizing protein interactions, either because they are too slow, or because they produce a cluttered drawing with many edge crossings or a static drawing that is not easy to modify to reflect changes in data. We have developed a new force-directed layout algorithm for drawing protein interactions in three-dimensional space. Our algorithm divides nodes into three groups based on their interacting properties: biconnected subgraph in the center, terminal nodes at the outermost region, and the rest in between them. Experimental results show that our algorithm efficiently generates a clear and aesthetically pleasing drawing of large-scale protein interaction networks and that it is much faster than other force-directed layouts.\\nProtein protein interaction network\\nGraph\\nProtein–protein interaction\\nProtein Interaction Networks\\nComputer science\\nVisualization\\nForce-directed graph drawing\\nTheoretical computer science\\nDistributed computing',\n",
       " 1223165: 'DIME - Distributed Interactive Medical Environment.\\nYear: 1994\\n#Citations: 0\\nJournal\\n\\nComputer science\\nMultimedia\\nDistributed computing',\n",
       " 1225118: 'The role of the Singapore government in national computerisation.\\nYear: 1993\\n#Citations: 1\\nConference\\n\\nPublic administration\\nComputer science\\nMarketing\\nGovernment',\n",
       " 1227021: 'Distributed Objects from a Patterns Perspective\\nYear: 1999\\n#Citations: 0\\nConference\\nIEEE Computer Society\\nNowadays, infrastructures for Distributed Object Computing such as COM, CORBA or RMI have become common place. When building software systems with one of these technologies it is essential to understand the fundamental concepts behind them. But what are the concepts behind these infrastructures? Actually, there is no architectural description available, neither for DCOM nor for CORBA or RMI. However, only with this knowledge it is possible to build distributed systems that adhere to functional and non-functional requirements. With patterns a new method for building and also for analyzing software systems has emerged.Patterns help to get a substantial understanding of the structure and dynamics of distributed objects systems such as DCOM or CORBA. The tutorial presents a pattern system that covers many fundamental aspects of Distributed Object Computing. A distributed objects infrastructures. web of patterns will be presented that together reveal the architecture of distributed objects infrastructures.\\nCSIv2\\nArchitecture\\nDistributed object\\nDistributed object computing\\nComputer science\\nCommon Object Request Broker Architecture\\nDistributed design patterns\\nSoftware system\\nDistributed Component Object Model\\nDistributed computing',\n",
       " 1228401: 'Integrating Domain Ontologies into Knowledge-Based Systems\\nYear: 2005\\n#Citations: 4\\nConference\\n\\nThe work presented in this paper deals with the integration of heavyweight ontologies into Knowledge-Based Systems (KBS). We claim that such ontologies have to be built at the conceptual level, and that their use in a KBS requires an operationalization step, that consists in transcribing the ontology in an operational knowledge representation language according to a given scenario of use. For this purpose, we propose TooCoM, a tool based on the Conceptual Graphs model and dedicated to the edition and the operationalization of heavyweight ontologies.\\nOntology\\nTranscription (linguistics)\\nComputer science\\nKnowledge management\\nArtificial intelligence\\nNatural language processing\\nOperationalization\\nOntology (information science)\\nGraph\\nKnowledge representation and reasoning\\nSoftware engineering\\nKnowledge-based systems\\nIDEF5',\n",
       " 1228939: 'Marketplaces as Communication Patterns in Mobile Ad-Hoc Networks*\\nYear: 2003\\n#Citations: 9\\nConference\\nSpringer, Berlin, Heidelberg\\nThis paper proposes a novel communication pattern for mobile multihop ad-hoc networks which is based on a marketplace metaphor. In order to substantially increase the probability that negotiating peers sucessfully reach an agreement, communication is focused on a static geographic area, called the marketplace. Users are not constrained to be at the marketplace physically, but are allowed to utilize other ones mobile devices located at the marketplace to let a software agent or a service installed on each device negotiate with others on their behalf. The forwarding and negotiation protocols needed to implement the marketplace solution are described in this work. Additionally, a prototypical implementation of the protocols is evaluated in a simulation environment. Since simulation results strongly depend on the mobility model, three realistic models based on an extension of the random way-point model are used. Their movement patterns are resulting from persons on a music festival, a university campus, and an exhibition.\\nMobile ad hoc network\\nMobile computing\\nComputer science\\nSoftware agent\\nComputer network\\nMobility model\\nAdaptive quality of service multi-hop routing\\nOptimized Link State Routing Protocol\\nGeocast\\nVehicular ad hoc network\\nDistributed computing',\n",
       " 1233378: 'An investigation into the social network between three generations in a household: bridging the interrogational gaps between the senior and the youth\\nYear: 2011\\n#Citations: 4\\nConference\\nSpringer, Berlin, Heidelberg\\nThe traditional pattern of living arrangements makes the family a strong source of financial and emotional support for its members, and it connects grandparents and grandchildren in a unique bond. Unfortunately, it is reported that the number of older people living alone is rising in most countries. Although a lot of effort has been put into slowing down the social and emotional isolation experienced by the elderly, little has been done to investigate the social interaction between generations. In order to bridge intergenerational gaps between three generations of a family, this research work begins with an interview-based study to give insight into individual perspectives among those aged parents living alone and to identify their specific needs in generational connections and interactions.\\nSocial relation\\nSocial psychology\\nBond\\nGrandparent\\nAged parents\\nSocial network\\nBridging (networking)\\nPsychology\\nEmotional isolation',\n",
       " 1063848: 'Designing an Agent to Support Interactive Access to Museum Information.\\nYear: 2000\\n#Citations: 0\\n\\n\\nIf we consider most applications accessible through the Web, we can notice a lack of support able to adapt to the different information needs that different users may have regarding a certain topic. Adaptive support, by which an application provides different information taking into account the users’ interactions, can provide useful assistance. However, completely automatic adaptive support can still be confusing for users who may not understand the reasons for the dynamic change in behaviour of the application. Thus, users may benefit from the introduction of agents aiming at providing interactive support to access information of interest. In this paper, we present an approach that provides an agent (a virtual assistant) able to implement adaptive behaviour in such a way as to support a Web visit to museum information.\\nInformation needs\\nRemote assistance\\nComputer science\\nAdaptive behaviour\\nHuman–computer interaction\\nNotice',\n",
       " 1071939: 'A Pattern-Based Approach towards the Guided Reuse of Safety Mechanisms in the Automotive Domain\\nYear: 2014\\n#Citations: 2\\n\\nSpringer, Cham\\nThe reuse of architectural measures or safety mechanisms is widely-spread in practice, especially in well-understood domains, as is reusing the corresponding safety-case to document the fulfillment of the target safety goal(s). This seems to harmonize well with the fact that safety standards recommend (if not dictate) performing many analyses during the concept phase of development as well as the early adoption of multiple measures at the architectural design level. Yet this front-loading is hindered by the fact that safety argumentation is not well-integrated into architectural models in the automotive domain and as such does not support comprehensible and reproducible argumentation nor any evidence for argument correctness. The reuse is neither systematic nor adequate.\\nLife-critical system\\nArchitectural design\\nSystems engineering\\nComputer science\\nReuse\\nArgumentation theory\\nCorrectness\\nAs is\\nRisk analysis (engineering)\\nSafety standards\\nAutomotive industry',\n",
       " 1074314: 'Upgrading the Capacity Planning Process.\\nYear: 1991\\n#Citations: 0\\n\\n\\nCapacity planning\\nEnvironmental economics\\nBusiness',\n",
       " 1079039: 'The Publication of Interactive 3D-Data in Chemistry.\\nYear: 2001\\n#Citations: 0\\n\\n\\nWorld Wide Web\\nInteractive 3d',\n",
       " 1082759: 'Embedded Meteorological Airport Systems.\\nYear: 2003\\n#Citations: 0\\n\\n\\nMeteorology\\nComputer science',\n",
       " 1102462: 'JPEG Adapted quantization matrix for low vision viewers.\\nYear: 2006\\n#Citations: 1\\n\\n\\nComputer vision\\nComputer graphics (images)\\nComputer science\\nJPEG\\nArtificial intelligence\\nQuantization (image processing)\\nQuantization matrix\\nLow vision',\n",
       " 1105437: 'User-oriented QoS Control Methods for Distributed Multimedia Systems.\\nYear: 2002\\n#Citations: 0\\n\\n\\nMobile QoS\\nComputer science\\nComputer network\\nQuality of service\\nWireless Multimedia Extensions\\nUser oriented\\nMultimedia',\n",
       " 1110498: 'Assessment of innovative measures implemented in European bus systems using key performance indicators\\nYear: 2014\\n#Citations: 1\\n\\nE.T.S.I. Caminos, Canales y Puertos (UPM)\\nThis paper reports the results of the assessment of a range of measures implemented in bus systems in five European cities to improve the use of public transport by increasing its attractiveness and enhancing its image in urban areas. This research was conducted as part of the EBSF project (European Bus System of the Future) from 2008 to 2012. New buses (prototypes), new vehicle and infrastructure technologies, and operational best practices were introduced, all of which were combined in a system approach. The measures were assessed using multicriteria analysis to simultaneously evaluate a certain number of criteria that need to be aggregated. Each criterion is measured by one or more key performance indicators (KPI) calculated in two scenarios (reference scenario, with no measure implemented; and project scenario, with the implementation of some measures), in order to evaluate the difference in the KPI performance between the reference and project scenario. The results indicate that the measures produce a greater benefit in issues related to bus system productivity and customer satisfaction, with the greatest impact on aspects of perceptions of comfort, cleanliness and quality of service, information to passengers and environmental issues. The study also reveals that the implementation of several measures has greater social utility than very specific and isolated measures.\\nPerformance indicator\\nCustomer satisfaction\\nBest practice\\nQuality of service\\nMulticriteria analysis\\nPublic transport\\nAttractiveness\\nEngineering\\nPerception\\nEnvironmental economics\\nOperations management',\n",
       " 1119501: 'Lokale Netze: Alternativen, Kopplung, Marktchancen, Akzeptanz\\nYear: 1983\\n#Citations: 1\\n\\nTeubner',\n",
       " 1126833: 'High Quality LCD Imaging System - Beyond 8 Bits.\\nYear: 2002\\n#Citations: 3\\n\\n\\nComputer science\\nLiquid-crystal display\\nComputer hardware',\n",
       " 1140292: 'Advanced Information Processing for TMN-Research in RACE I\\nYear: 1993\\n#Citations: 0\\n\\nNorth-Holland Publishing Co.\\nInformation processing\\nComputer science\\nTelecommunications Management Network\\nMultimedia',\n",
       " 1152767: 'A Stochastic Method for Solving Inverse Problems in Epidemic Modelling.\\nYear: 2003\\n#Citations: 2\\n\\n\\nWe describe a stochastic optimization method that can be used to solve inverse problems in epidemic modelling. Although in general it cannot be expected that these inverse problems have solutions and that possible solutions can be approximated by local optimization methods, our optimization method worked well when applied to a model for the epidemics caused by Respiratory Syncytial Virus (RSV) and the empirical data of various locations. We conjecture that similar results can be obtained for other epidemics and other models.\\nStochastic optimization\\nMathematical optimization\\nComputer science\\nInverse problem\\nLocal search (optimization)\\nConjecture',\n",
       " 1171487: 'Deploying a Common Data Quality Architecture.\\nYear: 2006\\n#Citations: 0\\n\\n\\nData architecture\\nArchitecture\\nData quality\\nSoftware engineering\\nComputer science\\nReliability engineering',\n",
       " 1175750: 'Online Outlier Detection System for Learning Time Data in E-Learning and Its Evaluation.\\nYear: 2004\\n#Citations: 11\\n\\n\\nAnomaly detection\\nTime data\\nE learning\\nComputer science\\nArtificial intelligence\\nMachine learning',\n",
       " 1190613: 'Multiagent Based Approach for Supporting Situation Assessment.\\nYear: 2010\\n#Citations: 0\\n\\n\\nComputer science\\nRisk analysis (engineering)\\nSituation analysis',\n",
       " 1200926: 'Gesture Components for Natural Interaction with In-Car Devices\\nYear: 2003\\n#Citations: 21\\n\\nSpringer, Berlin, Heidelberg\\nThe integration of more and more functionality into the human machine interface (HMI) of vehicles increases the complexity of device handling. Thus optimal use of different human sensory channels is an approach to simplify the interaction with in-car devices. This way the user convenience increases as much as distraction decreases. In this paper the gesture part of a multimodal system is described. It consists of a gesture optimized user interface, a real time gesture recognition system and an adaptive help system for gesture input. The components were developed in course of extensive usability studies. The so built HMI allows intuitive, effective and assisted operation of infotainment in-car devices, like radio, CD, telephone and navigation system, with handposes and dynamic hand gestures.\\nDistraction\\nInteraction technique\\nGesture\\nNavigation system\\nUsability\\nCommunication channel\\nGesture recognition\\nHuman–computer interaction\\nEngineering\\nUser interface',\n",
       " 1207386: 'Two Languages, And Their Environment, Founded on Basic Data Base Management System Constructs.\\nYear: 1978\\n#Citations: 3\\n\\n\\nStructure of Management Information\\nProgramming language\\nSoftware engineering\\nComputer science\\nManagement system',\n",
       " 1210970: 'Model-manipulation in decision support systems : a plan-based approach\\nYear: 1987\\n#Citations: 2\\n\\nU.M.I.\\nDecision analysis\\nDecision tree\\nIntelligent decision support system\\nComputer science\\nDecision support system\\nBusiness decision mapping\\nR-CAST\\nEvidential reasoning approach\\nManagement science\\nDecision engineering',\n",
       " 1216920: 'Efficient Sparse Dynamic Programming for the Merged LCS Problem.\\nYear: 2008\\n#Citations: 0\\n\\n\\nDynamic programming\\nComputer science\\nParallel computing',\n",
       " 1218774: 'Column heterogeneity as a measure of data quality\\nYear: 2006\\n#Citations: 9\\n\\n\\nData quality is a serious concern in every data management application, and a variety of quality measures have been proposed, including accuracy, freshness and completeness, to capture the common sources of data quality degradation. We identify and focus attention on a novel measure, column heterogeneity, that seeks to quantify the data quality problems that can arise when merging data from different sources. We identify desiderata that a column heterogeneity measure should intuitively satisfy, and discuss a promising direction of research to quantify database column heterogeneity based on using a novel combination of cluster entropy and soft clustering. Finally, we present a few preliminary experimental results, using diverse data sets of semantically different types, to demonstrate that this approach appears to provide a robust mechanism for identifying and quantifying database column heterogeneity.\\nData mining\\nFuzzy clustering\\nData set\\nData quality\\nComputer science\\nColumn (database)\\nMerge (version control)\\nCompleteness (statistics)\\nData management',\n",
       " 1221498: 'Forecasting Net Migration by Functional Demographic Model\\nYear: 2013\\n#Citations: 0\\n\\nSpringer, Berlin, Heidelberg\\nNet migration is the net total of migrants during the period, that is, the total number of immigrants less the annual number of emigrants, including both citizens and noncitizens. To derive estimates of net migration, the United Nations Population Division takes into account the past migration history of a country or area, the migration policy of a country, and the influx of refugees in recent periods. The data to calculate these official estimates come from a variety of sources, including border statistics, administrative records, surveys, and censuses. When no official estimates can be made because of insufficient data, net migration is derived through the balance equation, which is the difference between overall population growth and the natural increase during the intercensal period. In this contribution, we apply the functional data model to Italian data, for forecasting net migration numbers.\\nEconometrics\\nPopulation\\nEmigration\\nRefugee\\nPopulation growth\\nNet migration rate\\nImmigration\\nFunctional data model\\nGeography',\n",
       " 1224371: 'New Book - Performance Solutions: A Practical Guide to Creating Responsive, Scalable Software.\\nYear: 2001\\n#Citations: 2\\n\\n\\nSoftware engineering\\nComputer science\\nSoftware\\nScalability',\n",
       " 1226599: 'A Permutation Based Genetic Algorithm for RNA Secondary Structure Prediction.\\nYear: 2002\\n#Citations: 23\\n\\n\\nComputer science\\nPermutation\\nRna secondary structure prediction\\nBioinformatics\\nComputational biology\\nGenetic algorithm',\n",
       " 1235417: 'Nonlinear filters in genomic control.\\nYear: 1999\\n#Citations: 8\\n\\n\\nNonlinear system\\nComputer science\\nControl theory\\nAdaptive filter',\n",
       " 1238526: 'The Influence of Multiprogramming Limit on Interactive Response Time in a Virtual Memory System.\\nYear: 1977\\n#Citations: 0\\n\\n\\nExtended memory\\nVirtual memory\\nComputer science\\nThrashing\\nData diffusion machine\\nMemory management\\nMemory map\\nOverlay\\nFlat memory model\\nOperating system',\n",
       " 1239202: 'SMART VIEW: A Serious Game Supporting Spatial Orientation of Subjects with Cognitive Impairments\\nYear: 2014\\n#Citations: 2\\nConference\\nSpringer, Cham\\nThe paper presents SMART VIEW a serious game developed with the aim of helping young people with moderate cognitive disabilities acquire those spatial abilities that are key prerequisites to autonomous mobility. The game was conceived for cognitively impaired teenagers; it proposes exercises supporting the acquisition and consolidation of competences related to space awareness and self-perception in the space; such skills are necessary to develop the sense of spatial orientation, which is critical for the target population. SMART VIEW makes use of Touch Screen tables so to allow easier access to the game content and augmented interaction. Particular attention has been devoted to the game interface design, so to make it free from cognitive barriers and fully accessible to the target population. Contents are as close as possible to reality and the educational strategy entails slow and gradual increase of the game complexity, so to properly sustain the users’ cognitive effort.\\nPerspective-taking\\nCognitive effort\\nPopulation\\nCompetence (human resources)\\nComputer science\\nHuman–computer interaction\\nCognitive disabilities\\nCognition\\nMultimedia\\nGame complexity\\nInterface design',\n",
       " 1240813: 'A Standard Protocol for an Autonomous, Decentralized Building Automation System\\nYear: 1999\\n#Citations: 1\\nConference\\nIEEE Computer Society\\nThe paper summarizes a specification for a standard protocol for multi-vender building automation systems. Based on the ANSI/ASHRAE Standard 135-1995, the specification extends the functionality of the BACnet protocol in order to realize an autonomous, decentralized BAS(Building Automation System). By following this specification, a building automation constructor could construct a multi-vender-type BAS with more eficincy than using a conventional BAS, and with a significant savings.\\nBuilding management system\\nTotally integrated automation\\nProcess automation system\\nSoftware engineering\\nComputer science\\nBACnet\\nBuilding automation\\nASHRAE 90.1\\nDistributed computing\\nEmbedded system\\nManufacturing Automation Protocol',\n",
       " 1242355: 'Priorities, Promoters and Inhibitors in Deterministic Non-Cooperative P Systems\\nYear: 2014\\n#Citations: 2\\nConference\\nSpringer, Cham\\nMembrane systems (with symbol objects) are distributed controlled multiset processing systems. Non-cooperative P systems with either promoters or inhibitors (of weight not restricted to one) are known to be computationally complete. Since recently, it is known that the power of the deterministic subclass of such systems is subregular. We present new results on the weight (one and two) of promoters and inhibitors, as well as characterizing the systems with priorities only.\\nPromoter\\nCombinatorics\\nSubclass\\nMultiset\\nComputer science',\n",
       " 1245134: 'Improved Modeling and Design Using Assimilation and Property Modeling.\\nYear: 1996\\n#Citations: 2\\nJournal\\n\\nAssimilation (phonology)\\nProgramming language\\nComputer science',\n",
       " 1246494: 'Distinct Approaches To Value System In Collaborative Networks Environments\\nYear: 2006\\n#Citations: 14\\nConference\\nSpringer, Boston, MA\\nFor several years, Value Systems have been studied by two distinct scientific disciplines: economy and psycho-sociology. Each discipline developed a different concept of Value System, based on distinct assumptions about value. On one hand, economists assume that value means how much (usually money) a product or service is worth to someone, relative to other things; on the other hand socio-psychologists define value as shared beliefs on moral/ethical principles of the organizational unit.\\nOrganizational unit\\nComputer science\\nValue system\\nKnowledge management\\nCollaborative network\\nVirtual organization',\n",
       " 1249270: 'HABIT FORMATION IN ONLINE COMMUNITIES\\nYear: 2009\\n#Citations: 5\\nConference\\n\\nA long standing dilemma of online communities is that a small group of community members account for a disproportionate amount of contributions. Prior studies built on intent-based explanations cannot fully explain the phenomenon. This paper introduces the concept of habit formation as a key driver of individual contributions and investigates how habit is formed and how it influences individuals’ participation behavior in online communities. We propose that a threshold of behavioral repetitions exists for individuals to develop a habit. Once the threshold is surpassed, the habit of participation grows stronger and becomes self-reinforcing. We also propose that habit formation weakens the influence of reciprocity, social capital and competition on user participation in virtual communities. Using a panel data of 130,882 postings across 115 discussion boards, we find support for all the hypotheses. Our analysis contributes to the emerging literature on routinized information technology use.\\nSocial psychology\\nPanel data\\nSocial capital\\nComputer science\\nInformation technology\\nHabit\\nReciprocity (social psychology)\\nDilemma\\nPhenomenon\\nMarketing\\nVirtual community',\n",
       " 1249622: 'Multi-view Passive Acquisition Device for 3D Face Recognition.\\nYear: 2008\\n#Citations: 2\\nConference\\n\\nComputer vision\\nFacial recognition system\\nThree-dimensional face recognition\\nComputer science\\nArtificial intelligence\\nFace detection',\n",
       " 1253126: 'Innovaciones en los lenguajes C# 2.0 y el futuro C#3.0.\\nYear: 2006\\n#Citations: 0\\nConference\\n\\nComputer science\\nHumanities\\nProcess management',\n",
       " 1253720: 'Uncertainty, Bayesian Belief Nets, and Knowledge Management.\\nYear: 2003\\n#Citations: 0\\nConference\\n\\nMany decisions, of an entrepreneurial as well as an institutional or personal character, have to be made on the basis of incomplete or partial information about the outcomes and results and, hence, under conditions of rist and uncertainty. Among the numerous proposals for dealing with uncertainty Bayesianism has gained a prominent role. Although originally founded in decision theory, where for some it still constitutes a paragon of rational choice, Bayesian methods have become increasingly popular in recent years in statistics, in particular since the inception of Bayesian Belief Nets (BBNs), also known as Bayesian networks, now an area of lively research.\\nRational choice theory\\nComputer science\\nBayesian network\\nDecision theory\\nBayesian belief nets\\nManagement science\\nBayesian probability',\n",
       " 1255550: 'DART: an efficient method for direction-aware bichromatic reverse k nearest neighbor queries\\nYear: 2013\\n#Citations: 6\\nConference\\nSpringer, Berlin, Heidelberg\\nThis paper presents a novel type of queries in spatial databases, called the direction-aware bichromatic reverse k nearest neighbor (DBRkNN) queries,which extend the bichromatic reverse nearest neighbor queries.Given two disjoint sets, P and S, of spatial objects, and a query object q in S, the DBRkNN query returns a subset P′ of P such that k nearest neighbors of each object in P′ include q and each object in P′ has a direction toward q within a pre-defined distance.We formally define the DBRkNN query, and then propose an efficient algorithm, called DART, for processing the DBRkNN query. Our method utilizes a grid-based index to cluster the spatial objects, and the B+-tree to index the direction angle.We adopt a filter-refinement framework that is widely used in many algorithms for reverse nearest neighbor queries. In the filtering step,DART eliminates all the objects that are away from the query object more than the pre-defined distance, or have an invalid direction angle. In the refinement step, remaining objects are verified whether the query object is actually one of the k nearest neighbors of them. From extensive experiments, we show that DART outperforms an R-tree-based naive algorithm in both indexing time and query processing time.\\nQuery optimization\\nk-nearest neighbors algorithm\\nR-tree\\nData mining\\nFixed-radius near neighbors\\nComputer science\\nBest bin first\\nNearest neighbor graph\\nArtificial intelligence\\nNearest-neighbor chain algorithm\\nNearest neighbor search\\nMachine learning',\n",
       " 1257266: 'Empirical Studies in Multimedia Retrieval Evaluation.\\nYear: 2007\\n#Citations: 0\\nConference\\n\\nInformation retrieval\\nComputer science\\nMultimedia\\nEmpirical research',\n",
       " 1257742: 'The Design of Supermarket Electronic Shopping Guide System Based on ZigBee Communication\\nYear: 2011\\n#Citations: 2\\nConference\\nSpringer, Berlin, Heidelberg\\nBased on the ZigBee networking technology and protocol analysis, The paper designs a ZigBee Network Model with the features of communication and location which mainly rests on CC2431 ZigBee network location property and further propose a mobile electronic supermarket shopping guide system which can locate expected goods , navigation and offer the latest information on supermarket product.\\nElectronic shopping\\nProtocol analysis\\nComputer science\\nComputer network\\nNetwork model\\nEmbedded system',\n",
       " 1259022: 'Measurement and Analysis of Anthropometric Parameters of Young Male Vehicle Drivers\\nYear: 2014\\n#Citations: 3\\nConference\\nSpringer, Cham\\nIn this study, anthropometric data of 1243 vehicle drivers were sampled and the their age was from 17 to 34 years and averaged 21.85±2.82years. 76 anthropometric static parameters and 11 functional parameters were studied. The 76 static parameters were measured with the Non-contact 3d human boy scanners of VITUS SMART XXL systems while the 11 functional parameters were measured manually with Martin measuring scale. The correlation and fitting formulas of body height, sitting height and other parameters were measured and obtained. We also contrasted measured data with data form GJB 1835-1993. The present analysis showed that the correlation between sizes of body length and sitting height was significant. Sizes of body length and enclosing size and width direction were all increased compared to those in the 1980s. The present results were consistent with other researchers’ current research results. The measured data could be an important basis for the data of young male anthropometric parameters and edition of relative standard and design of specific equipment.\\nAnthropometry\\nSimulation\\nCorrelation\\nEngineering\\nStatistics\\nSitting height\\nCorrelation analysis',\n",
       " 1266380: 'Learning at a distance and library use: Open University students and libraries.\\nYear: 2001\\n#Citations: 0\\nJournal\\n\\nOpen university\\nComputer science\\nKnowledge management\\nDistance education\\nMathematics education',\n",
       " 1267135: 'Eine objektorientierte Zugriffsschicht zu relationalen Datenbanken.\\nYear: 1995\\n#Citations: 3\\nJournal\\n\\nWorld Wide Web\\nSoftware engineering\\nComputer science',\n",
       " 1268277: 'Maturity Matters: Performance Determinants of the Procurement Business Function\\nYear: 2008\\n#Citations: 29\\nConference\\n\\nThe procurement business function is increasingly recognized as strategic and subject of performance management. In this paper we present a research model to decompose the procurement function by six maturity dimensions (strategy, e-technology, process, information, monitoring and organization). The model is based on the proposition that an organizations’ procurement performance is positively related to its procurement maturity. In addition, we hypothesize that the alignment between the different procurement maturity dimensions positively effects the maturity-performance relation. A survey was conducted among 117 Dutch organizations from various industries and size categories, to apply the research model and test the hypothesis. From regression analysis we found significant positive, and stable net effects of procurement maturity on procurement performance. Alignment did not effect the shape of the maturity-performance relationship, but (by one type of measurement) it does increases the strength of the relationship. We conclude that our research model supports procurement maturity assessment and benchmarking for organizations, to improve their procurement business function in an integrative way.\\nComputer science\\nRegression analysis\\nService Integration Maturity Model\\nKnowledge management\\nBusiness function\\nProcurement\\nPerformance management\\nBenchmarking\\nOperations management\\nProcess management',\n",
       " 1268785: 'Privacy-Enhanced Deniable Authentication E-Mail Service\\nYear: 2011\\n#Citations: 4\\nConference\\nSpringer, Berlin, Heidelberg\\nE-mail brings us lots of conveniences. Especially with help of PGP and S/MIME, it gives both confidentiality and message/origin authentication. However, in some cases for strong privacy, a message sender will not want to let others know even the fact that he sent a message to a recipient. Very recently, Harn and Ren proposed a fully deniable authentication scheme for E-mail where a sender can repudiate his or her signature. In this paper, however, their deniable authentication scheme is proved not to be fully deniable. To resolve this deniability problem, we suggest a designated verifier signature scheme to support strong privacy, and construct a privacy-enhanced deniable authentication E-mail scheme using the designated verifier signature scheme. Compared with the Harn and Ren’s scheme, the proposed scheme has a simple cryptographic structure and can be easily realized with the existing secure E-mail systems.\\nDeniable encryption\\nAuthentication\\nCryptography\\nComputer science\\nComputer security\\nData Authentication Algorithm\\nAuthentication protocol\\nAnonymity\\nDesignated verifier signature\\nDeniable authentication',\n",
       " 1270031: 'MPI-ClustDB: A fast String Matching Strategy Utilizing Parallel Computing.\\nYear: 2006\\n#Citations: 1\\nConference\\n\\nString searching algorithm\\nCommentz-Walter algorithm\\nBiology\\nParallel computing\\nTheoretical computer science\\nApproximate string matching\\nString metric',\n",
       " 1272897: 'Implementing Modules in the Coq System\\nYear: 2003\\n#Citations: 41\\nConference\\nSpringer, Berlin, Heidelberg\\nThe paper describes the implementation of interactive ML-style modules in the recent version 7.4 of Coq proof assistant. Modules (especially higher-order) provide a very convenient tool for parametrized theories which was lacking in Coq for years. Their interactive character extends naturally the interactive environment provided by the proof assistant. The implementation follows the paradigm of recent versions of Coq to separate the correctness-critical code from the rest of the system, using abstraction barriers.\\nAbstraction\\nComputer science\\nAlgorithm\\nTheoretical computer science\\nProof assistant',\n",
       " 1274721: 'Foreword Volume 72.\\nYear: 2002\\n#Citations: 0\\nJournal\\n\\nComputer science\\nTheoretical computer science\\nMathematics education',\n",
       " 1276130: 'GAs in global optimization of mixed integer non-linear problems\\nYear: 1999\\n#Citations: 0\\nConference\\nMorgan Kaufmann Publishers Inc.\\nInteger\\nMathematical optimization\\nNonlinear system\\nGlobal optimization\\nComputer science\\nBranch and price\\nOptimization problem\\nConstrained optimization',\n",
       " 1279312: \"Bayes-optimal reinforcement learning for discrete uncertainty domains\\nYear: 2012\\n#Citations: 11\\nConference\\nInternational Foundation for Autonomous Agents and Multiagent Systems\\nAn important subclass of reinforcement learning problems are those that exhibit only discrete uncertainty: the agentu0027s environment is known to be sampled from a finite set of possible worlds. In contrast to generic reinforcement learning problems, it is possible to efficiently compute the Bayes-optimal policy for many discrete uncertainty RL domains. We demonstrate empirically that the Bayes-optimal policy can result in substantially and significantly improved performance relative to a state of the art probably approximately correct RL algorithm. Our second contribution is to bound the error of using slightly noisy estimates of the discrete set of possible Markov decision process parameters during learning. We suggest that this is an important and probable situation, given such models will often be constructed from finite sets of noisy, real-world data. We demonstrate good empirical performance on a simulated machine repair problem when using noisy parameter estimates.\\nFinite set\\nProbably approximately correct learning\\nComputer science\\nQ-learning\\nMarkov decision process\\nArtificial intelligence\\nMachine learning\\nReinforcement learning\\nPossible world\\nBayes' theorem\",\n",
       " 1280042: 'A Comparative Study of Numerical Techniques for 2D Transient Heat Conduction Equation Using Finite Element Method.\\nYear: 2009\\n#Citations: 5\\nConference\\n\\nBoundary knot method\\nAlternating direction implicit method\\nComputer science\\nMathematical analysis\\nExtended finite element method\\nFinite element method\\nTheoretical computer science\\nHeat equation\\nMixed finite element method\\nSmoothed finite element method',\n",
       " 1281047: 'Polar quantization of sinusoids from speech signal blocks.\\nYear: 2003\\n#Citations: 3\\nConference\\n\\nPattern recognition\\nComputer science\\nSpeech recognition\\nPolar\\nArtificial intelligence\\nQuantization (signal processing)',\n",
       " 1286905: 'A Feature Extraction Application on a Reconfigurable Image Processor.\\nYear: 1998\\n#Citations: 0\\nConference\\n\\nComputer vision\\nPattern recognition\\nComputer science\\nFeature extraction\\nImage processor\\nArtificial intelligence',\n",
       " 1288969: 'A Java Meta-Level Architecture for the Dynamic Handling of Aspects.\\nYear: 2000\\n#Citations: 5\\nConference\\n\\nComputer architecture\\nArchitecture\\nApplications architecture\\nComputer science\\nReal time Java\\nstrictfp\\nReference architecture\\nJava\\nOperating system',\n",
       " 1289923: 'Raman fiber lasers for optical communication application\\nYear: 2003\\n#Citations: 0\\nJournal\\nSpringer\\nWe review the principle and characteristics of cascaded Raman fiber lasers in their telecommunication applications. The fundamentals of Raman fiber lasers are described, such as pumping scheme, fiber type and reflectors. We explain simple equations forcw laser operation as well as a possible way to calculate spectral width. We investigate the common issues in the use of Raman fiber lasers: theoretical optimization, control of the linewidth, suppression level of the other Stokes orders and relative intensity noise. Finally the more complex multiple-wavelength Raman fiber lasers are reviewed.\\nOptical fiber\\nPolarization-maintaining optical fiber\\nFiber optic sensor\\nDispersion-shifted fiber\\nPhotonic-crystal fiber\\nOptics\\nElectronic engineering\\nDouble-clad fiber\\nMathematics\\nCoherent anti-Stokes Raman spectroscopy\\nFiber laser',\n",
       " 1291882: 'Comparison of Multi-population PBIL and Adaptive Learning Rate PBIL in Designing Power System Controller\\nYear: 2014\\n#Citations: 3\\nConference\\nSpringer, Cham\\nPopulation-Based Incremental Learning (PBIL) is a combination of Genetic Algorithm with competitive learning derived from Artificial Neural Network. It has recently received increasing attention due to its effectiveness, easy implementation and robustness. Despite these strengths, it has been reported recently that PBIL suffers from issues of loss of diversity in the population. To deal with the issue of premature convergence, we propose in this paper a parallel PBIL based on multi-population. In parallel PBIL, two populations are used where both probability vectors (PVs) are initialized to 0.5. The approach is used to design a power system controller for damping low-frequency oscillations. To show the effectiveness of the approach, simulations results are compared with the results obtained using standard PBIL and another diversity increasing PBIL called herein as PBIL with Adapting learning rate (APBIL). It is shown that Parallel PBIL approach performs better than the standard PBIL and is as effective as APBIL.\\nCompetitive learning\\nPopulation\\nControl theory\\nMathematical optimization\\nPremature convergence\\nComputer science\\nElectric power system\\nRobustness (computer science)\\nArtificial neural network\\nGenetic algorithm',\n",
       " 1292837: 'Complexity of Octagonal and Rectangular Cartograms.\\nYear: 2005\\n#Citations: 18\\nConference\\n\\nA cartogram is a type of map used to visualize data. In a map regions are displayed in their true shapes and with their exact relations with the adjacent regions. However, such a map can only be used to demonstrate the actual area values of the regions. Sometimes, we need to display other data on a map, such as population, pollution, electoral votes, production rates, etc. One efficient way to do so is to modify the map such that the area of each shape corresponds to the data to be displayed. A map with given relationships between regions for which each region has pre-specified area is called a cartogram (see [1] for details). There are two major cartogram types: contiguous area cartograms [2, 3, 6, 7, 12], where the regions are deformed but stay connected, and non-contiguous area cartograms [8], where regions preserve their shapes but may lose adjacency relationships. Rectangular cartograms, where every region is a rectangle is a specific type of contigous area cartograms which tries to preserve both the adjacency relations and the shape, but this does not exist for all area values. Kreveld and Speckmann [13] introduced the first automated algorithms for such cartograms. Heilmann et al. proposed RecMap [5] to approximate familiar land covering map region shapes by rectangles. Rahman et al. studied slicing and good slicing graphs and their orthogonal drawings [9], which are similar to orthogonal cartograms. It was left as an open problem whether testing the feasibility of a rectangular cartogram is NP-hard. In this paper, we make significant progress towards answering this question. We first study what we call cartograms of orthogonal octagons where every region is an orthogonal polygon with at most 8 sides. We also assume that the cartogram must be placed within a rectangle of fixed size (a canvas). We show that testing whether a cartogram of orthogonal octagons exists is NP-hard. We then use a very similar reduction to prove NPhardness of a problem where, all faces are rectangles, except for one face corresponding to the “sea” around islands and peninsulas (see the examples in [13]).\\nAdjacency list\\nDiscrete mathematics\\nPopulation\\nCombinatorics\\nPolygon\\nOpen problem\\nCovering space\\nComputer science\\nContiguity (probability theory)\\nRectangle\\nCartogram',\n",
       " 1293411: \"Kleene's Theorem and the Solution of Metabolic Carbon Labeling Systems.\\nYear: 2004\\n#Citations: 2\\nConference\\n\\nCarbon Labeling Systems (CLS) are large equation systems that describe the dynamics of labeled carbon atoms in a metabolic network. The rapid solution of these systems is the algorithmic backbone of C Metabolic Flux Analysis (MFA) which has become one of the most widely used tools in Metabolic Engineering. A new algorithm is presented for the solution of CLS which is not based on iteration schemes or numerical linear algebra methods but on path tracing of labeled particles. It is shown that the set of all paths from the system input to the internal network nodes directly gives the clue to an explicit solution of CLS. The promising potential of this new solution algorithm are outlined. 1 Metabolic Flux Analysis In recent years Metabolic Flux Analysis (MFA) by using C isotopes has become one of the most widely used tools in Metabolic Engineering [Wi01, W02]. MFA allows to determine quantitatively all fluxes in the central metabolism of a micro organism or higher cell. The metabolic flux maps resulting from this analysis serve to compare different strains of a micro organism to diagnose the effects of a genetic manipulation or even give hints to further improve the production capabilities of a given organism. MFA is based on a carbon labeling experiment where C labeled substrates are fed to the cells. The C isotopes are then distributed all over the metabolic network due to the metabolic activity. Finally, the enrichment of C isotopes in the intra-cellular metabolite pools tends to an isotopically stationary state, which means that constant fractions of unlabeled and labeled carbon atoms are encountered in all pools. In this state the isotope enrichment is measured by NMR or MS instruments [Sz98]. From this measurement data the metabolic fluxes are estimated based on a mathematical model of the carbon labeling dynamics in the system. The sole biological knowledge that is required for this procedure is the biochemical structure of the metabolic network, and the carbon atom transitions in each single reaction step. This knowledge is rather well established for central metabolism, but the method can also be used to distinguish between network variances.\\nDiscrete mathematics\\nBiological system\\nReaction step\\nMetabolic flux analysis\\nMetabolic engineering\\nMetabolic network\\nFlux\\nGenetics\\nStationary state\\nNumerical linear algebra\\nMathematics\\nCarbon\",\n",
       " 1296112: 'Surface-normals from closed paths\\nYear: 1979\\n#Citations: 14\\nConference\\nMorgan Kaufmann Publishers Inc.\\nIt is now well established that the shading present in an image of an object is a potential source of 3-D shape information. With this in mind, we seek constraints arising out of the assumption that an image portrays an object with a smooth surface. On obtaining a threshold and a depth-invariance constraint (the latter requiring integration around closed curves) we offer a method of shape from shading for the purpose of demonstrating their potential usefulness.\\nComputer vision\\nComputer science\\nArtificial intelligence\\nPhotometric stereo\\nNormal\\nShading',\n",
       " 1297928: 'Well-being to well done!: the development cycle in role-playing games\\nYear: 2006\\n#Citations: 4\\nConference\\nSpringer, Berlin, Heidelberg\\nInterest in designing games to convey persuasive messages concerning human well-being is growing, but presents a number of challenges. A significant problem comes in connecting the gameplay with the persuasive intent. We show how the gameplay structure of \"avatar development\" in popular-role playing games can be applied to the design of persuasive well-being games.\\nPersuasive technology\\nPersuasion\\nGame mechanics\\nEmergent gameplay\\nVideo game design\\nComputer science\\nTurns, rounds and time-keeping systems in games\\nGame design\\nHuman–computer interaction\\nAvatar',\n",
       " 1300333: 'TOWARDS A MULTI-AGENT ARCHITECTURE FOR WEB APPLICATIONS\\nYear: 2008\\n#Citations: 0\\nConference\\n\\nSpace-based architecture\\nData architecture\\nComputer architecture\\nApplications architecture\\nSystems engineering\\nMultilayered architecture\\nComputer science\\nSolution architecture\\nReference architecture\\nEnterprise architecture framework\\nMultitier architecture',\n",
       " 1302035: 'A reasoner for generalized Bayesian dl-programs\\nYear: 2008\\n#Citations: 0\\nConference\\nCEUR-WS.org\\nIn this paper, we describe an ongoing reasoner implementation for reasoning with generalized Bayesian dl-programs and thus for dealing with deterministic ontologies and logic programs and probabilistic (mapping) rules in an integrated framework.\\nOntology (information science)\\nSemantic reasoner\\nComputer science\\nArtificial intelligence\\nProbabilistic logic\\nMachine learning\\nAND gate\\nBayesian probability',\n",
       " 1306187: 'PERSONAL KNOWLEDGE MANAGEMENT AS AN ICEBREAKER - Motivating Contributions to Knowledge Management Systems\\nYear: 2007\\n#Citations: 1\\nConference\\n\\nInformation management\\nPersonal information management\\nDomain knowledge\\nComputer science\\nPersonal knowledge management\\nKnowledge management\\nOrganizational learning\\nKnowledge engineering\\nData management',\n",
       " 1307992: 'ANTS with Firefly Communication.\\nYear: 2005\\n#Citations: 3\\nConference\\n\\nAutonomous Nano-Technology Swarm (ANTS) from NASA employs numerous, autonomous, l-kg solar sails for surveying and studying asteroids in the Asteroid Belt. There is no convincing work on a simulator that validates the solar sail’s behaviors and weak propellant system in the extreme space environment. Thus, we have developed and verified an Environment Agent (EA) that simulates gravity and light force based on well-understood Newtonian and sound light force equations. Sail Agents (SA) simulate swarm behaviors that are able to turn their reflective surface in four orthogonal directions and produce 3-D maneuvers. The simulator is able to convincingly model key behaviors of SAs. We also provide a model that has the simplest swarm behaviors and unorthodox sensors for testing feasibility of ANTS using EA. The communication is done via on-off light patterns – firefly.\\nPropellant\\nSwarm behaviour\\nSpace environment\\nComputer science\\nAsteroid belt\\nSolar sail\\nAerospace engineering\\nAsteroid\\nFirefly protocol',\n",
       " 1309515: 'Parallel pre-processing of affymetrix microarray data\\nYear: 2010\\n#Citations: 6\\nConference\\nSpringer, Berlin, Heidelberg\\nThe study of genes is currently carried out by systematic analysis that relies on data produced by the microarray technology. The recent development of such technology and the increasing number of analysed samples result in an increased volume of raw data for each experiment. The time for preprocessing represents an important amount of the analysis, so the need to introduce tools for the efficient preprocessing arises. This paper presents a system able to manage and preprocess microarray data in a parallel way. First experimental results on Affymetrix data showing appreciable improvements in term of execution times are discussed.\\nData mining\\nComputer science\\nAffymetrix GeneChip Operating Software\\nRaw data\\nPreprocessor\\nMicroarray analysis techniques\\nGene chip analysis\\nMicroarray databases',\n",
       " 1312587: 'Wavelet-Based Speaker Change Detection in Single Channel Speech Data\\nYear: 2009\\n#Citations: 0\\nConference\\n\\nChange detection\\nPattern recognition\\nComputer science\\nCommunication channel\\nSpeech recognition\\nArtificial intelligence\\nWavelet',\n",
       " 1316039: 'On the transitive acyclic subdigraph polytope.\\nYear: 1993\\n#Citations: 6\\nConference\\n\\nDiscrete mathematics\\nComputer science\\nPolytope\\nTransitive relation',\n",
       " 1319706: 'On-line adaptation of neuro-prostheses with neuronal evaluation signals\\nYear: 2006\\n#Citations: 0\\nConference\\n\\nExperiments have demonstrated that prosthetic devices can in principle be controlled by brain signals. However, in stable long-term ap- plications neuroprostheses may suffer substantially from non-stationarities of the recorded signals. Such changes currently require supervised re- learning procedures which must be conducted under laboratory conditions, hampering the envisioned everyday use of such devices. As an alternative we here propose an on-line adaptation scheme that exploits a secondary signal source from brain regions reflecting the useru0027s affective evaluation of the neuro-prostheticu0027s performance. Using realistic assumptions about recordable signals and their noise levels, our simulations show that pros- thetic devices can be adapted successfully during normal, everyday usage.\\nComputer science\\nArtificial intelligence\\nMachine learning\\nSignal source',\n",
       " 1326065: 'Creating a Data Collection for Evaluating Rich Speech Retrieval\\nYear: 2012\\n#Citations: 4\\nConference\\n\\nWe describe the development of a test collection for the investigation of speech retrieval beyond identification of relevant content. This collection focuses on satisfying user information needs for queries associated with specific types of speech acts. The collection is based on an archive of the Internet video from Internet video sharing platform (blip.tv), and was provided by the MediaEval benchmarking initiative. A crowdsourcing approach was used to identify segments in the video data which contain speech acts, to create a description of the video containing the act and to generate search queries designed to refind this speech act. We describe and reflect on our experiences with crowdsourcing this test collection using the Amazon Mechanical Turk platform. We highlight the challenges of constructing this dataset, including the selection of the data source, design of the crowdsouring task and the specification of queries and relevant items.\\nSpeech retrieval\\nInternet video\\nComputer science\\nCrowdsourcing\\nUser information\\nNatural language processing\\nArtificial intelligence\\nBenchmarking\\nThe Internet\\nData collection\\nWorld Wide Web\\nSpeech analytics\\nInformation retrieval',\n",
       " 1327342: 'Customer relationship management using partial focus feature reduction\\nYear: 2012\\n#Citations: 1\\nConference\\nSpringer, Berlin, Heidelberg\\nEffective data mining solutions have for long been anticipated in Customer Relationship Management (CRM) to accurately predict customer behavior, but in a lot of research works we have observed sub-optimal CRM classification models due to inferior data quality inherent to CRM data set. This paper is proposed to present our new classification framework, termed Partial Focus Feature Reduction, poised to resolve CRM data set with Reduced Dimensionality using a collection of efficient data preprocessing techniques characterizing a specially tailored modality grouping method to significantly improve feature relevancy as well as reducing the cardinality of the features to reduce computational cost. The resulting model yields very good performance result on a large complicated real-world CRM data set that is much better than ones from complex models developed by renowned data mining practitioners despite all data anomalies.\\nCustomer relationship management\\nData mining\\nData quality\\nConsumer behaviour\\nComputer science\\nData pre-processing\\nCardinality\\nCurse of dimensionality\\nArtificial intelligence\\nMachine learning',\n",
       " 1329644: 'Online: Aus EUnet wurde UUNET.\\nYear: 1997\\n#Citations: 0\\nJournal\\n\\nEngineering\\nMultimedia',\n",
       " 1331044: 'Modeling and Quering Periodic Temporal Databases.\\nYear: 1995\\n#Citations: 13\\nConference\\n\\nData mining\\nComputer science\\nTemporal database\\nPeriodic graph (geometry)',\n",
       " 1333772: 'Design of Configuration Algorithms of Commonly-Used Topologies for a Multiprocessor : STAR.\\nYear: 1985\\n#Citations: 2\\nConference\\n\\nComputer science\\nParallel computing\\nMultiprocessing\\nNetwork topology\\nDistributed computing',\n",
       " 1341035: 'NeuroVR 1.5 - a free virtual reality platform for the assessment and treatment in clinical psychology and neuroscience\\nYear: 2009\\n#Citations: 15\\nConference\\nUSA\\nAt MMVR 2007 we presented NeuroVR (http://www.neurovr.org) a free virtual reality platform based on open-source software. The software allows non-expert users to adapt the content of 14 pre-designed virtual environments to the specific needs of the clinical or experimental setting. Following the feedbacks of the 700 users who downloaded the first version, we developed a new version - NeuroVR 1.5 - that improves the possibility for the therapist to enhance the patientu0027s feeling of familiarity and intimacy with the virtual scene, by using external sounds, photos or videos. Specifically, the new version now includes full sound support and the ability of triggering external sounds and videos using the keyboard. The outcomes of different trials made using NeuroVR will be presented and discussed.\\nVirtual reality\\nSoftware\\nHuman–computer interaction\\nMultimedia\\nMedicine\\nFeeling',\n",
       " 1344391: 'Research on Modeling Microblog Posts Scale Based on Nonhomogeneous Poisson Process\\nYear: 2011\\n#Citations: 0\\nConference\\nSpringer, Berlin, Heidelberg\\nResearch on modeling microblog posts scale was the foundation of predicting the number of microblog posts. To predict the microblog posts was beneficial to reasonably schedule load and estimate flow. Firstly, this paper explained the mathematical definition of microblog posts scale problem, compared the three microblogging characteristics random,independent and orderly with the four conditions of poisson process and established the nonhomogeneous poisson process model for microblog posts scale problem. Then, took sina microblog as experimental platform, established the model and calculated the arrival intensity function and mean function based on the measured datas of sina microblog posts. Finally,partial mathematical test was done to the model, then conducted predicting the number of sina microblog posts, which showed quite good predicting performance by comparing with the measured datas. Finally summarized the whole paper and pointed out the future work.\\nData mining\\nSocial media\\nInformation retrieval\\nComputer science\\nMicroblogging\\nPoisson process',\n",
       " 1347062: 'FPGA implementation of a cortical network based on the hodgkin-huxley neuron model\\nYear: 2012\\n#Citations: 3\\nConference\\nSpringer, Berlin, Heidelberg\\nIn this paper a biological neural network based on the Hodgkin-Huxley neuron model is implemented using Xilinx Field Programmable Gate Array (FPGA). By employing appropriate computational techniques, such as CORDIC, and step-by-step time integration of the respective equations, an exact response of the neuron is calculated. Neurons are simple units that exhibit high level behaviors during interaction in a network. The Parallel processing feature of FPGA makes this platform an ideal candidate to model these networks. We implemented a network with 16 neurons and the result of this implementation is validated using MATLAB simulation.\\nHodgkin huxley neuron\\nBiological neuron model\\nMATLAB\\nComputer science\\nArtificial intelligence\\nComputer hardware\\nHodgkin–Huxley model\\nPattern recognition\\nParallel computing\\nField-programmable gate array\\nCORDIC\\nVHDL\\nBiological neural network',\n",
       " 1348457: 'Generalized latent factor models for social network analysis\\nYear: 2011\\n#Citations: 29\\nConference\\nAAAI Press\\nHomophily and stochastic equivalence are two primary features of interest in social networks. Recently, the multiplicative latent factor model (MLFM) is proposed to model social networks with directed links. Although MLFM can capture stochastic equivalence, it cannot model well homophily in networks. However, many real-world networks exhibit homophily or both homophily and stochastic equivalence, and hence the network structure of these networks cannot be modeled well by MLFM. In this paper, we propose a novel model, called generalized latent factor model (GLFM), for social network analysis by enhancing homophily modeling in MLFM. We devise a minorization-maximization (MM) algorithm with linear-time complexity and convergence guarantee to learn the model parameters. Extensive experiments on some real-world networks show that GLFM can effectively model homophily to dramatically outperform state-of-the-art methods.\\nEconometrics\\nConvergence (routing)\\nSocial network\\nMultiplicative function\\nComputer science\\nHomophily\\nTheoretical computer science\\nEquivalence (measure theory)\\nArtificial intelligence\\nNetwork structure\\nSocial network analysis\\nFactor analysis\\nMachine learning',\n",
       " 1350866: '10241 Executive Summary -- Information Visualization\\nYear: 2010\\n#Citations: 2\\nConference\\nSchloss Dagstuhl\\nInformation Visualization (InfoVis) focuses on the use of visualization techniques to help people understand and analyze data. While related fields such as Scientific Visualization involve the pres ...\\nData science\\nGeovisualization\\nBiological data visualization\\nData visualization\\nInformation visualization\\nVisualization\\nComputer science\\nVisual analytics\\nInteractive visualization\\nHuman–computer interaction\\nScientific visualization',\n",
       " 1354071: 'How Much Do You Trust Me? Learning a Case-Based Model of Inverse Trust\\nYear: 2014\\n#Citations: 8\\nConference\\nSpringer, Cham\\nRobots can be important additions to human teams if they improve team performance by providing new skills or improving existing skills. However, to get the full benefits of a robot the team must trust and use it appropriately. We present an agent algorithm that allows a robot to estimate its trustworthiness and adapt its behavior in an attempt to increase trust. It uses case-based reasoning to store previous behavior adaptations and uses this information to perform future adaptations. We compare case-based behavior adaptation to behavior adaptation that does not learn and show it significantly reduces the number of behaviors that need to be evaluated before a trustworthy behavior is found. Our evaluation is in a simulated robotics environment and involves a movement scenario and a patrolling/threat detection scenario.\\nInverse\\nComputer science\\nTrustworthiness\\nPatrolling\\nKnowledge management\\nHuman–computer interaction\\nArtificial intelligence\\nRobot\\nRobotics\\nMachine learning\\nHuman–robot interaction',\n",
       " 1358953: 'Hypergraph partitioning for the parallel computation of continuous Petri nets\\nYear: 2011\\n#Citations: 1\\nConference\\nSpringer, Berlin, Heidelberg\\nContinuous Petri net can be used for performance analysis or static analysis. The analysis is based on solving the associated ordinary differential equations. However, large equation groups will give us overhead computing. To solve this issue, this paper presents a method to compute these differential equations in parallel. We first map the Petri net to a hypergraph, and then partition the hypergraph with minimal inter-processor communication and good load balance; Based on the partition result, we divide the differential equations into several blocks; Finally we design parallel computing algorithm to compute these equations. Software hMETIS and SUNDIALS have been used to partition the hypergraph and to support the parallel computing, respectively. Gas Station problem and Dining Philosopher problem have been used to demonstrate the benefit of our method.\\nDifferential equation\\nPetri net\\nOrdinary differential equation\\nLoad balancing (computing)\\nComputer science\\nStatic analysis\\nHypergraph\\nParallel computing\\nTheoretical computer science\\nSoftware\\nPartition (number theory)',\n",
       " 1362128: 'Parameterized Verification of Broadcast Networks of Register Automata\\nYear: 2013\\n#Citations: 14\\nConference\\nSpringer, Berlin, Heidelberg\\nWe study parameterized verification problems for networks of interacting register automata. We consider safety properties expressed in terms of reachability, from arbitrarily large initial configurations, of a configuration exposing some given control states and patterns.\\nCounter machine\\nBroadcasting\\nParameterized complexity\\nComputer science\\nAutomaton\\nBroadcasting (networking)\\nReachability\\nTheoretical computer science\\nPSPACE\\nArbitrarily large',\n",
       " 1362903: \"A diagnostic reasoning approach to defect prediction\\nYear: 2011\\n#Citations: 2\\nConference\\nSpringer Berlin Heidelberg\\nDuring software testing, defect prediction approaches measure current reliability status, forecasting future program failures, and provide information on how many defects need to be removed before shipping. Existing approaches often require faults to be detected and identified as a new one, before a model-based trend can be fitted. While during regression testing failures may frequently occur, it is not evident which are related to new faults. Consequently, reliability growth trending can only be performed in sync with fault identification and repair, which is often performed in between regression test cycles. In this paper we present a dynamic, reasoning approach to estimate the number of defects in the system early in the process of regression testing. Our approach, coined Dracon, is based on Bayesian fault diagnosis over abstractions of program traces (also known as program spectra). Experimental results show that Dracon systematically estimates the exact number of (injected) defects, provided sufficient tests cases are available. Furthermore, we also propose a simple, analytic performance model to assess the influence of failed test cases in the estimation. We observe that our empirical findings are in agreement with the model.\\nData mining\\nComputer science\\nRegression testing\\nTest case\\nPerformance model\\nsync\\nDiagnostic reasoning\\nBayesian probability\\nSoftware testing\\nBayes' theorem\",\n",
       " 1363491: 'Must Pinwheels Move During Visual Development\\nYear: 1997\\n#Citations: 0\\nConference\\nSpringer, Berlin, Heidelberg\\nThe pinwheel-like arrangement of iso-orientation domains around orientation centers is a ubiquitous structural element of orientation preference maps in primary visual cortex. Here we investigate how activity-dependent mechanisms constrain the way in which orientation centers can form during visual development. We consider the dynamics of a large class of models for the activity-dependent self-organization of orientation preference maps. We prove for this class of models that the density of orientation centers which proliferate as orientation selectivity arises from an unselective state exhibits a universal lower bound. At least π/Λ2 pinwheels must form initially, where d is the characteristic wavelength of iso-orientation domains. Due to topological constraints the density of orientation centers can only change by discrete creation and annihilation events. Consequently densities lower than π/Λ2 must develop through an initial overproduction and subsequent annihilation of pinwheels. Monitoring the density of orientation centers during development therefore offers a powerful novel approach to test whether orientation preference arises by activity-dependent mechanisms or is genetically predetermined.\\nComputer vision\\nTopology\\nDiscrete mathematics\\nVisual cortex\\nComputer science\\nUpper and lower bounds\\nArtificial intelligence',\n",
       " 1365286: 'Limiting Adversarial Budget in Quantitative Security Assessment\\nYear: 2014\\n#Citations: 5\\nConference\\nSpringer\\nWe present the results of research of limiting adversarial budget in attack games, and, in particular, in the failure-free attack tree models presented by Buldas-Stepanenko in 2012 and improved in 2013 by Buldas and Lenin. In the previously presented models attacker’s budget was assumed to be unlimited. It is natural to assume that the adversarial budget is limited and such an assumption would allow us to model the adversarial decision making more close to the one that might happen in real life. We analyze three atomic cases – the single atomic case, the atomic AND, and the atomic OR. Even these elementary cases become quite complex, at the same time, limiting adversarial budget does not seem to provide any better or more precise results compared to the failure-free models. For the limited model analysis results to be reliable, it is required that the adversarial reward is estimated with high precision, probably not achievable by providing expert estimations for the quantitative annotations on the attack steps, such as the cost or the success probability. It is doubtful that it is reasonable to face this complexity, as the failure-free model provides reliable upper bounds, being at the same time computationally less complex.\\nBoolean function\\nComputer science\\nAttack tree\\nOperations research\\nSecurity assessment\\nLimiting\\nAdversarial system',\n",
       " 1367335: 'An evaluation of using mutual information for selection of acoustic-features representation of phonemes for speech recognition\\nYear: 2002\\n#Citations: 8\\nConference\\nInternational Speech Communication Association\\nThis paper addresses the problem of finding a subset of the acoustic feature space that best represents the phoneme set used in a speech recognition system. A maximum mutual information approach is presented for selecting acoustic features to be combined together to represent the distinctions among the phonemes. The overall phoneme recognition accuracy is slightly increased for the same length of feature vector for clean speech and at 10 dB compared to FFT-based Mel-frequency cepstrum coefficients (MFCC) by using acoustic features selected based on a maximum mutual information criterion. Using 16 different feature sets, the rank of the feature sets based on mutual information can predict phoneme recognition accuracy with a correlation coefficient of 0.71 compared to a correlation coefficient of 0.28 when using a criterion based on the average pair-wise Kullback-Liebler divergence to rank the feature sets.\\nMel-frequency cepstrum\\nCorrelation coefficient\\nFeature vector\\nDivergence\\nPattern recognition\\nComputer science\\nCepstrum\\nSpeech recognition\\nFast Fourier transform\\nFeature (machine learning)\\nMutual information\\nArtificial intelligence',\n",
       " 1371721: 'Cluster File Server Exploiting Multi-level Deduplication.\\nYear: 2008\\n#Citations: 0\\nConference\\n\\nData deduplication\\nFile server\\nComputer science\\nOperating system',\n",
       " 1374109: 'Trusted Authentication Between User and Machine.\\nYear: 2003\\n#Citations: 0\\nConference\\n\\nLightweight Extensible Authentication Protocol\\nTrusted Network Connect\\nGeneric Bootstrapping Architecture\\nComputer science\\nComputer security\\nTrusted Platform Module\\nData Authentication Algorithm\\nAuthentication protocol\\nDirect Anonymous Attestation\\nMulti-factor authentication',\n",
       " 1376759: 'A Reference Model for Seamless Cross-Organizational Collaboration in the Public Sector.\\nYear: 2008\\n#Citations: 4\\nConference\\nGITO-Verlag\\nToday, electronic cross-company collaboration is about to gain significant momentum, but still shows weaknesses with respect to productivity, flexibility and quality: a lack of standardized supporting e-business solutions, unclear terminology and unstructured business processes prevent from seamless interoperability and the fast development of a globally networked service economy. A novel approach is now required which facilitates a comprehensive industrialization of related concepts and methodologies. In this work, we present the St. Gallen Media Reference Model (MRM) and extend it to fulfill the specific needs of electronic, cross-organizational collaboration. Based on the three components \"Organizational\" (structural as well as process-oriented organization of interaction between agents), \"Logical\" (common language between agents) and \"Physical\" (the physical infrastructure enabling interaction), we amend the reference model by introducing key principles which improved the performance of computer programming during the past decades. To show its real-world applicability and potential for performance enhancement, we apply this extended MRM to the specific case of governmental administration in Switzerland.\\nInformation management\\nBusiness process\\nTerminology\\nSystems engineering\\nReference model\\nComputer science\\nInteroperability\\nKnowledge management\\nPublic sector\\nService economy\\nComputer programming',\n",
       " 1379113: 'Audition and speech perception in the chimpanzee.\\nYear: 1990\\n#Citations: 0\\nConference\\n\\nCrossmodal\\nComputer science\\nMotor theory of speech perception\\nSpeech recognition\\nSpeech perception',\n",
       " 1383834: 'Emerging Framework for The Evaluation of Open Source Security Tools.\\nYear: 2008\\n#Citations: 0\\nConference\\n\\nThe drive from the South African Government towards the adoption of open source software across all platforms, incurred a number of research and development questions. The open source domain provides especially SMME’s with options to implement high quality software that are financially viable. Although software costs is a major factor within providing proper working environments, specific security issues pertaining to open source needs to be addressed. With the opening of networks as well as the availability of information, companies need not only implement security policies, but also constantly upgrade implementations. The study of open source security issues as well as the actual evaluation of tools therefore becomes essential. The purpose of this paper is to study the security issues within the open source environment and looking specifically at the use of security software originating from the open source domain. We provide details and results of surveys conducted around the adoption of security tools within South African companies. The study leads to us proposing a emerging framework for the evaluation of open source security tools.\\nComputer science\\nComputer security\\nImplementation\\nUpgrade\\nSoftware\\nSecurity software\\nSecurity policy\\nOpen source software\\nGovernment',\n",
       " 1384677: 'Dispute prevention and dispute resolution in networked health information technology\\nYear: 2009\\n#Citations: 3\\nConference\\nDigital Government Society of North America\\nThe United States has committed to promote Health Information Technology through Electronic Health Records that will be exchanged among participants in the healthcare enterprise. In anticipation of problems, legal remedies have been established to protect the rights of all participants, especially their rights to protect the privacy of their own information. However, there are certain to be situations where disputes arise among participants that can be resolved without recourse to legal action. This paper pursues the possibility of establishing policies to encourage alternative dispute resolution through online methods integrated into the health information technology processes and lays out areas requiring research.\\nHealth care\\nPublic relations\\nDispute resolution\\nOnline dispute resolution\\nHealth information technology\\nDispute mechanism\\nAlternative dispute resolution\\nBusiness',\n",
       " 1239507: 'Distributed Textile Image Database System by Kansei Information Processing.\\nYear: 1995\\n#Citations: 14\\n\\n\\nInformation processing\\nInformation retrieval\\nComputer science\\nKansei\\nDatabase design\\nImage database',\n",
       " 1244547: 'An Efficient Verifiable Shuffle with Perfect Zero-knowledge Proof System.\\nYear: 2004\\n#Citations: 7\\n\\n\\nDiscrete mathematics\\nVerifiable secret sharing\\nProof complexity\\nZero-knowledge proof\\nCalculus\\nMathematics',\n",
       " 1253067: 'Spam Detection: A Syntax and Semantic-Based Approach\\nYear: 2006\\n#Citations: 2\\n\\n\\nWorld Wide Web\\nComputer science\\nSpam and Open Relay Blocking System\\nSyntax',\n",
       " 1267893: 'Exploring Text-based and Graphical-based Usable Interfaces for Mobile Chat Systems.\\nYear: 2007\\n#Citations: 1\\n\\n\\nCurrent text-based mobile chat systems hinder navigation with long chat archive in a limited screen display. Moreover, it is time consuming and cumbersome to track messages that are sent by specific chatters. Hence, we proposed a graphicalbased usable interface that aids navigation and message tracking with minimal key-presses and enhances the chatting experience with avatars and emoticons. In addition, we explored the usable interface design of mobile chat systems by visualising the navigation to facilitate easier understanding of the messages’ contents. We statistically evaluated the relationships between user interfaces and usability to uncover the key attributes that enhance mobile chat usability. The empirical research outcomes exemplified that there was a significant linear relationship between the user interface and usability on text-based and graphical-based usable interfaces for mobile chat systems. Moreover, the experimental evaluation results indicated that text-based usability can be improved by creating interface that encourages usages; whereas the graphical-based mobile chat is augmented by creating a user friendly interface that enhances user satisfaction, encourages usages and promotes ease of navigation. The findings and results typified the potential use of graphical-based mobile chat systems to substitute the current text-based systems which is under utilised in the commercial arena. Daniel Kuen Seong Su, Victoria Siew Yen Yee, Jesse Read “Exploring Text-based and Graphical-based Usable Interfaces for Mobile Chat Systems” Vol. I No. 3 (Dec. 2007). ISSN: 1697-9613 (print) 1887-3022 (online). www.eminds.uniovi.es Daniel Kuen Seong Su, Victoria Siew Yen Yee, Jesse Read\\nUSable\\nComputer science\\nUsability\\nHuman–computer interaction\\nUser Friendly\\nUser interface\\nMultimedia\\nEmpirical research\\nInterface design',\n",
       " 1275641: 'QBE para Datalog\\nYear: 1996\\n#Citations: 0\\n\\nUniversidade da Coruña\\nEn este articulo se presenta una herramienta desarrollada en arquitectura Cliente-Servidor denominada EasyDatalog. EasyDtalog es una interfaz grafica para consultas de Bases de Datos Deductivas que recoge la tradicion de las interfaces QBE (Query By Example) modernizandolo mediante el uso de una interfaz grafica en entorno Windows y la posibilidad de realizar consultas recursivas. Se analiza la problematica de la traduccion a programa Datalog de consultas recursivas de diferentes tipos expresadas mediante la interfaz QBE.\\nComputer science\\nHumanities\\nQuery by Example\\nDatalog',\n",
       " 1278913: 'Use of Diffusion Tensor Images in Glioma Growth Modeling for Radiotherapy Target Delineation\\nYear: 2013\\n#Citations: 2\\n\\nSpringer, Cham\\nIn radiotherapy of gliomas, a precise definition of the treatment volume is problematic, because current imaging modalities reveal only the central part of the tumor with a high cellular density, but fail to detect all regions of microscopic tumor cell spread in the adjacent brain parenchyma. Mathematical models can be used to integrate known growth characteristics of gliomas into the target delineation process. In this paper, we demonstrate the use of diffusion tensor imaging (DTI) for simulating anisotropic cell migration in a glioma growth model that is based on the Fisher-Kolmogorov equation. For a clinical application of the model, it is crucial to develop a detailed understanding of its behavior, capabilities, and limitations. For that purpose, we perform a retrospective analysis of glioblastoma patients treated at our institution. We analyze the impact of diffusion anisotropy on model-derived target volumes, and interpret the results in the context of the underlying images. It was found that, depending on the location of the tumor relative to major fiber tracts, DTI can have significant influence on the shape of the radiotherapy target volume.\\nNuclear medicine\\nBiomedical engineering\\nDiffusion MRI\\nGrowth model\\nGlioblastoma\\nDiffusion Anisotropy\\nImaging modalities\\nComputer science\\nGlioma\\nRadiation therapy',\n",
       " 1284694: 'A Thread in Time Saves Tabling Time.\\nYear: 1996\\n#Citations: 23\\n\\n\\nProgramming language\\nComputer science\\nThread (computing)',\n",
       " 1296853: 'Page Analyzer: A Tool for Web Performance Modeling.\\nYear: 2001\\n#Citations: 0\\n\\n\\nStatic web page\\nWeb performance\\nWorld Wide Web\\nWeb page\\nComputer science\\nWeb-based simulation\\nSpectrum analyzer',\n",
       " 1301044: 'Enterprise Information Architecture for Traceability.\\nYear: 2010\\n#Citations: 0\\n\\n\\nEnterprise architecture\\nApplications architecture\\nSoftware engineering\\nComputer science\\nSolution architecture\\nNIST Enterprise Architecture Model\\nEnterprise architecture framework\\nEnterprise information security architecture\\nEnterprise life cycle\\nEnterprise architecture management',\n",
       " 1307349: 'Individuelle Arbeitsvorbereitungen am System UNIX\\nYear: 1989\\n#Citations: 0\\n\\nTeubner\\nComputer science\\nUnix\\nOperating system',\n",
       " 1314966: 'Integrated design process support with VHDL-A\\nYear: 1995\\n#Citations: 2\\n\\n\\nIntegrated logistics support\\nSoftware engineering\\nComputer science\\nIntegrated design\\nProcess support\\nVHDL\\nDesign process',\n",
       " 1321008: 'Integrated Process Management System and RFID Directory Services\\nYear: 2004\\n#Citations: 0\\n\\nSpringer, Boston, MA\\nThis paper describes an implementation of the Integrated Process Management System, which includes manufacturing process management for building parts, and also construction process management at construction site. To observe the flow of the building parts, RFIDs are stuck to all parts to be managed, and several checkpoints, which we named “gates”, are introduced within the coherent process through part-manufacturing and building construction. The requirements of the RFID directory services are also discussed.\\nManufacturing process management\\nSoftware engineering\\nComputer science\\nLightweight Directory Access Protocol\\nProcess management system\\nDirectory service',\n",
       " 1331543: 'Set-based Concurrent Engineering.\\nYear: 1993\\n#Citations: 4\\n\\n\\nConcurrent engineering\\nSoftware engineering\\nComputer science',\n",
       " 1333795: 'An application of standard BAO theory to some information algebras.\\nYear: 1998\\n#Citations: 0\\n\\n\\nAlgebra\\nMathematics',\n",
       " 1335738: 'A polyhedral approach for the staff rostering problem\\nYear: 1999\\n#Citations: 0\\n\\n\\nComputer science\\nOperations research',\n",
       " 1344525: 'Using a Spatio-Temporal FastMarching Planner to Politely Avoid Moving Persons\\nYear: 2012\\n#Citations: 1\\n\\nSpringer, Berlin, Heidelberg\\nWhen mobile robots operate in home environments, a robot should consider the inhabitants while moving around. In this work, an approach is presented, which at the one hand predicts the movements of a person in a very simple way, and on the other hand uses the predicted movement to plan a motion path of the robot. We deploy a potential field approach to predict the person’s movement trajectory and use an modified Fast Marching planner to access a time-variable cost function for the planning process. The goal of our development is an early avoiding behavior of the robot, when the robot passes a person. This should increase the acceptance of the robot, and signal a “busy”-behavior. We show the feasibility of the presented approach in some first simulation results.\\nSocial robot\\nComputer vision\\nFast marching method\\nPlanner\\nReal-time computing\\nPlanning process\\nArtificial intelligence\\nEngineering\\nRobot\\nPotential field\\nMobile robot\\nTrajectory',\n",
       " 1352185: 'The Sales Scenario: A Model-Driven Software Product Line.\\nYear: 2008\\n#Citations: 1\\n\\n\\nComputer science\\nManufacturing engineering\\nSoftware product line\\nProcess management',\n",
       " 1354731: 'Parallel Packaging of Micro Electro Mechanical Systems (MEMS) Using Self-alignment\\nYear: 2012\\n#Citations: 2\\n\\nSpringer, Berlin, Heidelberg\\nPackaging is one of the major cost drivers for MEMS devices. Currently wire bonding is the dominant method for electrically connecting MEMS chips to substrate. Using self-alignment a method for packaging multiple MEMS at the same time has been developed. The presented process achieves high throughput and precise alignment at low cost. The Controlled Collapse Re-flow Chip Joining (C-4) process has been adapted to the specific requirements of MEMS. The combination of coarse robotics and liquid solder self-alignment guarantees precise positioning and alignment of the individual MEMS chips to the respective substrates. The new method has been implemented in a case study. In the study force sensors have been packaged. Precise angular alignment of the sensors is critical for receiving accurate measurements. Results of the case study are presented.\\nFlip chip\\nWire bonding\\nMicroelectromechanical systems\\nWafer-level packaging\\nDeep reactive-ion etching\\nElectronic engineering\\nChip\\nSolder paste\\nChip-scale package\\nMaterials science',\n",
       " 1363538: 'A Saturation Network to Tolerate Faults and Intrusions.\\nYear: 1986\\n#Citations: 7\\n\\n\\nSaturation (chemistry)\\nComputer science\\nPetrology',\n",
       " 1364731: \"REBPS'03: Motivation, Objectives and Overview. Message from the Workshop Organizers.\\nYear: 2003\\n#Citations: 3\\n\\n\\nComputer science\\nMultimedia\",\n",
       " 1366722: 'Detektion von Leukozyten mit Hilfe neuronaler Strukturen\\nYear: 1998\\n#Citations: 0\\n\\nSpringer, Berlin, Heidelberg\\nDie Bestimmung der Anzahl und Geschwindigkeit von Leukozyten in Venolen ermoglicht Ruckschlusse auf den Aktivierungszustand des Immunsystems. In diesem Beitrag werden neuronale Netze zur Detektion von Leukozyten in Sequenzen von Mikrozirkulationsaufnahmen eingesetzt. Das Training der Netze erfolgt mit synthetischen Leukozytenbildern, die uber ein stochastisches Modell gewonnen werden. Kunstliche Zellenmuster bieten eine wesentlich bessere Anpassungsfahigkeit an neues Bildmaterial, als dies reales Bildmaterial ermoglicht. Um die Leistungsfahigkeit des Zellenmodells zu uberprufen, werden Netze mit echten und synthetischen Datensatzen trainiert. Dabei erzielen Netze auf Basis synthetischer Zellenmuster in fast allen Netzkonfigurationen bessere Ergebnisse als solche, die mit echten Zellenbildern trainiert wurden.\\nGynecology\\nPhysics',\n",
       " 1368903: 'A Natural Measure for Denoting Software System Complexity\\nYear: 2010\\n#Citations: 0\\n\\nSpringer, Berlin, Heidelberg\\nThe problem of complexity measurement is as old as programming, when programming became a major problem for the software industry in the sixties. The fact is clearly attested in the two NATO reports on software engineering [A14]. Von Neumann himself give a lot of attention to complexity in the last decade of his shortened lifetime.\\nProgramming language\\nControl flow graph\\nComputer science\\nSoftware system\\nTransactional memory\\nSoftware\\nVon Neumann architecture',\n",
       " 1373685: 'Peer-Support Intervention for Early Reading Literacy.\\nYear: 2004\\n#Citations: 0\\n\\n\\nLiteracy\\nPeer support\\nPsychology\\nPedagogy',\n",
       " 1380026: 'Yahoo! Data Quality: Driving Cross-Organizational Improvement.\\nYear: 2008\\n#Citations: 0\\n\\n\\nInternet privacy\\nData quality\\nComputer science',\n",
       " 1387178: 'Development of an Android Application for Sobriety Test Using Bluetooth Communication\\nYear: 2011\\n#Citations: 2\\n\\nSpringer, Berlin, Heidelberg\\nDrinking is one of the most prominent causes for social problems like domestic violence, drinking and driving, and health problems. If who drunken can check promptly how much blood alcohol content, abstain from drunken driving or successive drinking schedule. In this paper, how to develop an effective application for transmission and expression of drunken report from digital portable breathalyzer to Android Smartphone using Bluetooth module were suggested. A simple user friendly GUI is also implemented for user. The user can check the report for his present blood alcohol level promptly using this App. And then he can decide whether to continue or stop drinking immediately.\\nAndroid (operating system)\\nSobriety\\nBreathalyzer\\nComputer science\\nComputer security\\nAlcohol level\\nBluetooth communication\\nUser Friendly\\nBlood alcohol content\\nBluetooth',\n",
       " 1390698: 'Design of an antenna array for GNSS/GPS network\\nYear: 2012\\n#Citations: 1\\nConference\\nSpringer, Berlin, Heidelberg\\nThis work focuses precisely on the design of a smart antenna printed on dielectric substrate operating at frequency L1 = 1575.42 MHz This device consists of an antenna array to be integrated, in a GNSS/GPS network, with the aim of detecting ionosphere disturbances associated with land-based. To address such concerns, we studied an antenna array, consisting of four square elements, patch type, operating at the L1 frequency. As a first step, a simple square printed radiating structure was designed to test adaptation and radiation characteristics. In a second step, a square shape (2 * 2) antenna array has been studied. This type of sensor (networks) should respond no later than fifteen minutes after the main shock of an earthquake.\\nDipole antenna\\nTelecommunications\\nAntenna rotator\\nComputer science\\nArtificial intelligence\\nAntenna factor\\nComputer vision\\nOmnidirectional antenna\\nAntenna (radio)\\nAntenna measurement\\nAntenna array\\nElectrical engineering\\nMicrostrip antenna',\n",
       " 1392181: 'A SPATIAL SAMPLING MECHANISM FOR EFFECTIVE BACKGROUND SUBTRACTION\\nYear: 2007\\n#Citations: 18\\nConference\\nINSTICC-INST SYST TECHNOLOGIES INFORMATION CONTROL & COMMUNICATION\\nIn the video surveillance literature, background (BG) subtraction is an important and fundamental issue. In this context, a consistent group of methods operates at region level, evaluating in fixed zones of interest pixel values’ statistics, so that a per-pixel foreground (FG) labeling can be performed. In this paper, we propose a novel hybrid, pixel/region, approach for background subtraction. The method, named Spatial-Time Adaptive Per Pixel Mixture Of Gaussian (STAPPMOG), evaluates pixel statistics considering zones of interest that change continuously over time, adopting a sampling mechanism. In this way, numerous classical BG issues can be efficiently faced: actually, it is possible to model the background information more accurately in the chromatic uniform regions exhibiting stable behavior, thus minimizing foreground camouflages. At the same time, it is possible to model successfully regions of similar color but corrupted by heavy noise, in order to minimize false FG detections. Such approach, outperforming state of the art methods, is able to run in quasi-real time and it can be used at a basis for more structured background subtraction algorithms.\\nBackground subtraction\\nComputer vision\\nChromatic scale\\nPattern recognition\\nComputer science\\nGaussian\\nSampling (statistics)\\nArtificial intelligence\\nPixel\\nSubtraction',\n",
       " 1393469: 'Throughput-Delay Trade-Offs in Slotted WDM Ring Networks\\nYear: 2010\\n#Citations: 6\\nConference\\nSpringer, Berlin, Heidelberg\\nWe analyse the throughput-delay trade-offs that arise in an optical burst-switched slotted WDM ring, where each node can transmit and receive on a subset of the available wavelengths. Specifically, we compare SWING, an access control scheme that combines opportunistic transmission and dynamic reservations, with a purely opportunistic aceess scheme. By means of analysis, we highlight the shortcomings of the opportunistic scheme in terms of load balancing and fairness. We then evaluate the performance of both schemes by simulation under several traffic scenarios and show that SWING yields the best throughput-delay trade-off.\\nWavelength-division multiplexing\\nOptical burst switching\\nComputer science\\nLoad balancing (computing)\\nComputer network\\nTrade offs\\nAccess control\\nThroughput\\nThroughput delay\\nSwing\\nDistributed computing',\n",
       " 1395487: 'Using Qualitative Reasoning for a Recommender System\\nYear: 2010\\n#Citations: 0\\nConference\\nIOS Press\\nThis paper presents the foundation for a new methodology for a collaborative recommender system (RS). This methodology is based on the degree of consensus of a group of users stating their preferences via qualitative orders-of-magnitude. The structure of distributive lattice is considered in defining the distance between users and the RSs new users. This proposed methodology incorporates incomplete or partial knowledge into the recommendation process using qualitative reasoning techniques to obtain consensus of its users for recommendations.\\nRecommender system\\nWorld Wide Web\\nDistributive lattice\\nInformation retrieval\\nComputer science\\nRSS\\nQualitative reasoning',\n",
       " 1396500: 'Mining Interesting Temporal Rules with Genetic Programming and Specialized Hardware.\\nYear: 2003\\n#Citations: 1\\nConference\\n\\nComputer science\\nGenetic programming\\nArtificial intelligence\\nGenetic representation\\nMachine learning',\n",
       " 1403418: 'On the jointly unsupervised feature vector normalization and acoustic model compensation for robust speech recognition.\\nYear: 2007\\n#Citations: 0\\nConference\\n\\nFeature vector\\nNormalization (statistics)\\nPattern recognition\\nComputer science\\nSpeech recognition\\nFeature (machine learning)\\nArtificial intelligence\\nAcoustic model',\n",
       " 1405747: 'Simultaneous optimisation of several variables in a probabilistic language model.\\nYear: 1989\\n#Citations: 2\\nConference\\n\\nComputer science\\nSpeech recognition\\nNatural language processing\\nArtificial intelligence\\nProbabilistic logic\\nProbabilistic relevance model\\nLanguage model',\n",
       " 1406079: 'Preparing to Use the Distributed Facility in IBM Smalltalk.\\nYear: 1996\\n#Citations: 5\\nJournal\\n\\nIBM\\nProgramming language\\nComputer science\\nSmalltalk\\nOperating system',\n",
       " 1408385: 'Pitch estimation of speech signal with the wavelet transform.\\nYear: 1993\\n#Citations: 1\\nConference\\n\\nConstant Q transform\\nHarmonic wavelet transform\\nPattern recognition\\nComputer science\\nSecond-generation wavelet transform\\nSpeech recognition\\nDiscrete wavelet transform\\nArtificial intelligence\\nStationary wavelet transform\\nWavelet packet decomposition\\nWavelet\\nWavelet transform',\n",
       " 1416591: 'The use of linear feature projection for precipitation classification using measurements from commercial microwave links\\nYear: 2012\\n#Citations: 3\\nConference\\nSpringer, Berlin, Heidelberg\\nHigh frequency electromagnetic waves are highly influenced by atmospheric conditions, namely wireless microwave links with carrier frequency of tens of GHz can be used for precipitation monitoring. In the scope of this paper we present a novel detection/classification system capable of detecting wet periods, with the ability to classify the precipitation type as rain or sleet, given an attenuation signal from spatially distributed wireless commercial microwave links. Fade (attenuation) dynamics was selected as a discriminating feature providing the data for classification. Linear Feature Extraction method is formulated; thereafter, the efficiency is evaluated based on real data. The detection/classification system is based on the Fisheru0027s linear discriminant and likelihood ratio test. Its performance is demonstrated using actual Received Signal Level measurements from a cellular backhaul network in the northern part of Israel. In particular, the use of the raw data as well as its derivatives to achieve better classification performance is suggested.\\nMicrowave\\nWireless\\nTelecommunications\\nLikelihood-ratio test\\nBackhaul (telecommunications)\\nComputer science\\nRemote sensing\\nFeature extraction\\nAttenuation\\nLinear discriminant analysis\\nPrecipitation',\n",
       " 1419258: 'The Electronic Law Reports - A Case Study.\\nYear: 1996\\n#Citations: 0\\nJournal\\n\\nInternet privacy\\nLaw Reports\\nComputer science\\nLaw',\n",
       " 1420181: 'How Not to Configure Your Firewall: A Field Guide to Common Firewall Configurations.\\nYear: 2001\\n#Citations: 2\\nConference\\n\\nFirewall (construction)\\nComputer science\\nComputer network\\nContext-based access control\\nApplication firewall\\nStateful firewall\\nCheck Point VPN-1\\nArt history',\n",
       " 1422719: 'Design and Implementation of the Loop Restructuring Feature for the MIRAI Parallelizing Complier.\\nYear: 2003\\n#Citations: 0\\nConference\\n\\nComputer architecture\\nComputer science\\nParallel computing\\nRestructuring',\n",
       " 1424933: 'SURE: surface entropy for distinctive 3d features\\nYear: 2012\\n#Citations: 27\\nConference\\nSpringer, Berlin, Heidelberg\\nIn this paper, we present SURE features --- a novel combination of interest point detector and descriptor for 3D point clouds and depth images. We propose an entropy-based interest operator that selects distinctive points on surfaces. It measures the variation in surface orientation from surface normals in the local vicinity of a point. We complement our approach by the design of a view-pose-invariant descriptor that captures local surface curvature properties, and we propose optional means to incorporate colorful texture information seamlessly. In experiments, we compare our approach to a state-of-the-art feature detector in depth images (NARF) and demonstrate similar repeatability of our detector. Our novel pair of detector and descriptor achieves superior results for matching interest points between images and also requires lower computation time.\\nComputer vision\\nCurvature\\nFeature detection\\nOperator (computer programming)\\nArtificial intelligence\\nPoint cloud\\nDetector\\nMathematics\\nComputation',\n",
       " 1426774: 'Segmentation of video sequences for partition tree generation.\\nYear: 1997\\n#Citations: 7\\nJournal\\nSpringer\\nIn this paper we propose a segmentation structure to generate a partition tree with multiple partition proposals. These multiple partitions are obtained for every image in a hierarchical way, from the coarsest one to the finest one. Time evolution of the regions is defined through a projection step which relates the previous coded partition with the current partition tree. Finer partitions than the projected one are defined segmenting the projected partition using texture criteria, while coarser partitions are obtained merging regions with motion criteria. Morphological tools are used both in the projection and the re-segmentation steps.\\nImage processing\\nElectronic engineering\\nCoding (social sciences)\\nTree structure\\nArtificial intelligence\\nGraph partition\\nComputer vision\\nPattern recognition\\nSegmentation\\nMathematical morphology\\nPartition (number theory)\\nPartition refinement\\nMathematics',\n",
       " 1434443: 'Design Elements for a Better AI-Language.\\nYear: 1988\\n#Citations: 0\\nConference\\n\\nDesign elements and principles\\nEngineering drawing\\nComputer science\\nArtificial intelligence\\nMachine learning',\n",
       " 1435983: 'Modified Counter-Propagation Network\\nYear: 1998\\n#Citations: 0\\nConference\\n\\nPattern recognition\\nComputer science\\nArtificial intelligence\\nArtificial neural network',\n",
       " 1437394: 'Making Description Logic Based Knowledge Representation Systems More Usable.\\nYear: 1992\\n#Citations: 1\\nJournal\\n\\nUSable\\nComputational logic\\nKnowledge representation and reasoning\\nAutoepistemic logic\\nComputer science\\nMultimodal logic\\nDescription logic\\nArtificial intelligence\\nNatural language processing\\nOntology language',\n",
       " 1439875: 'The importance of the first syllable in English spoken word recognition by adult Japanese speakers.\\nYear: 1998\\n#Citations: 0\\nConference\\n\\nSpoken word recognition\\nComputer science\\nSpeech recognition\\nLogogen model\\nSyllable',\n",
       " 1441168: 'Selecting TV news stories and newswire articles related to a target article of newswire using SVM.\\nYear: 2000\\n#Citations: 0\\nConference\\n\\nInformation retrieval\\nComputer science\\nSupport vector machine',\n",
       " 1442764: 'Understanding auditory navigation to physical landmarks\\nYear: 2012\\n#Citations: 3\\nConference\\nSpringer, Berlin, Heidelberg\\nWe present two studies that seek to better understand the role spatialised (3D) audio can play in supporting effective pedestrian navigation. 24 participants attempted to navigate and locate physical landmarks in a local botanical gardens using a gpsTunes [1] based auditory navigation system coupled with a map. Participants were significantly better at locating prominent than non-prominent physical landmarks. However, no significant quantative difference was found between the use of a map only and map + audio. Qualitative analysis revealed significant issues when physical landmarks are used, and common strategies when combining audio and map navigation. We highlight the implications of these in relation to existing work, and provide guidelines for future designers to employ.\\nComputer vision\\nComputer science\\nNavigation system\\nPedestrian navigation\\nArtificial intelligence',\n",
       " 1446810: 'MEDINFORM: An Enterprise-Wide Medical Information and Telemedicine System.\\nYear: 1999\\n#Citations: 0\\nConference\\n\\nTelemedicine\\nComputer science\\nKnowledge management',\n",
       " 1446963: 'A resource class independent deadlock detection algorithm\\nYear: 1981\\n#Citations: 27\\nConference\\nVLDB Endowment\\nA method of detecting deadlocks among processes which can be suspended due to contention for any class of resource is described. Three classes of resources are described, uniquely-named resources such as Locks, M of N resources such as Teleprocessing Sessions or Magnetic Tape Drives, and Poolresources such as variable length storage pools. By using boolean expressions to describe how a process, suspended due to resource conflict, can have its request satisfied by resources released by other processes, the deadlock detection algorithm is independent of resource tables. The algorithm produces a set of potential u0027victimsu0027 which can break all the detected deadlocks. A deadlock resolution algorithm based choosing the \"least costly\" process in deadlock is proposed.\\nEdge chasing\\nMagnetic tape\\nComputer science\\nDeadlock resolution\\nDeadlock\\nTheoretical computer science\\nDeadlock prevention algorithms\\nBoolean expression',\n",
       " 1448152: 'A new prediction model to discover probability of document in the website\\nYear: 2007\\n#Citations: 0\\nConference\\n\\nData warehouse\\nData mining\\nPetri net\\nNaive Bayes classifier\\nComputer science\\nArtificial intelligence\\nMachine learning',\n",
       " 1448546: 'Enhancement of Eyeround Images Based on an Improved Fuzzy Algorithm\\nYear: 1999\\n#Citations: 0\\nJournal\\nFuji Technology Press Ltd.\\nPattern recognition\\nComputer science\\nFuzzy logic\\nFuzzy set\\nArtificial intelligence',\n",
       " 1448802: 'Multinational Web-based Training: Issues to Consider\\nYear: 1999\\n#Citations: 0\\nConference\\nAssociation for the Advancement of Computing in Education (AACE)\\nMultinational corporation\\nComputer science\\nKnowledge management\\nWeb application',\n",
       " 1449637: 'Simultaneous stabilization based on output measurement.\\nYear: 1995\\n#Citations: 112\\nJournal\\nInstitute of Information Theory and Automation of the Academy of Sciences of the Czech Republic\\nBased on a recent convex programming algorithm for simultaneous stabilization by linear state feedback, we propose two types of control law for stabilizing a family of systems, when either a simultaneously stabilizing state feedback gain or a simultaneously stabilizing output injection matrix exists, and complete state information is not available. The proposed control laws are illustrated by a numerical example.\\nMathematical optimization\\nState information\\nLinear state feedback\\nMatrix (mathematics)\\nControl theory\\nConvex optimization\\nMathematics',\n",
       " 1451898: 'A VIRTUAL ENVIRONMENT FOR ARCHIVING MICRO-PRESENCE WITH IMAGE-BASED MODEL ACQUISITION\\nYear: 2007\\n#Citations: 0\\nConference\\n\\nComputer vision\\nVirtual machine\\nComputer graphics (images)\\nComputer science\\nImage based\\nArtificial intelligence\\nMultimedia',\n",
       " 1452476: 'Distributed genetic programming by an object oriented system using java and corba.\\nYear: 2004\\n#Citations: 1\\nJournal\\n\\nDistributed object\\nProgramming language\\nMethod\\nObject-oriented programming\\nComputer science\\nCommon Object Request Broker Architecture\\nInteroperable Object Reference\\nGenetic programming\\nObject (computer science)\\nJava',\n",
       " 1453065: 'Tampere University of Technology at TREC 2001\\nYear: 2001\\n#Citations: 1\\nConference\\nNational Institute of Standards and Technology\\nIn this paper we present the prototype based text matching methodology used in the Routing Sub-Task of TREC 2001 Filtering Track. The methodology examines texts on word and sentence levels. On the word level the methodology is based on word coding and transforming the codes into histograms by the means of Weibull distribution. On the sentence level the word coding is done in a similar manner as on the word level. But instead of making histograms we use a more simple method. After the word coding, we transform the sentence vectors to sentence feature vectors using Slant transform. The paper includes also description of the TREC runs and some discussion about the results.\\nHistogram\\nFeature vector\\nInformation retrieval\\nComputer science\\nFilter (signal processing)\\nWeibull distribution\\nAutomation\\nCoding (social sciences)\\nSpeech recognition\\nArtificial intelligence\\nNatural language processing\\nSentence',\n",
       " 1456491: 'The preconditioned GMRES method for systems of coupled FEM-BEM equations\\nYear: 1998\\n#Citations: 8\\nJournal\\n\\nWe analyze the generalized minimal residual method (GMRES) as a solver for coupled finite element and boundary element equations. To accelerate the convergence of GMRES we apply a hierarchical basis block preconditioner for piecewise linear finite elements and piecewise constant boundary elements. It is shown that the number of iterations which is necessary to reach a given accuracy grows only poly-logarithmically with the number of unknowns.\\nBoundary knot method\\nMathematical optimization\\nPreconditioner\\nGeneralized minimal residual method\\nMathematical analysis\\nExtended finite element method\\nFinite element method\\nBoundary element method\\nMathematics\\nMixed finite element method\\nSpectral element method',\n",
       " 1457765: 'Estimation of 3D Instantaneous Motion of a Ball from a Single Motion-Blurred Image\\nYear: 2008\\n#Citations: 6\\nConference\\nSpringer, Berlin, Heidelberg\\nWe present a single-image algorithm for reconstructing the 3D velocity, the 3D spin axis, and the angular speed of a moving ball. Peculiarity of the proposed algorithm is that this reconstruction is achieved by accurately analyzing the blur produced by the ball motion during the exposure. We combine image analysis techniques in order to obtain 3D estimates, that are then integrated into a geometrical model for recovering the 3D motion.\\nComputer vision\\nLinear motion\\nSpin-½\\nAngular velocity\\nQuarter-pixel motion\\nMotion field\\nComputer science\\nMotion blur\\nArtificial intelligence\\nMotion estimation\\nPoint spread function',\n",
       " 1462352: 'A Pairing Based Authentication and Key Establishment Scheme for Remote Patient Monitoring Systems\\nYear: 2013\\n#Citations: 1\\nConference\\nSpringer, Cham\\nWith the evolution of Wireless Medical Sensor Networks (WMSNs), real-time remote patient monitoring has become more feasible than ever before. Different sensors can be used e.g. at home to monitor patient’s vital signs such as pulse, respiration and blood pressure. However, given the distributed nature of WMSNs for remote patient monitoring, there is a greater challenge in ensuring data security, integrity, confidentiality and access control. This is because the transmission of personal and medical information is done over insecure communication channels i.e. the Internet. At the same time, patient’s physiological data are highly sensitive and remote patient monitoring systems are extremely vulnerable to many attacks. Since there is great need to access the real-time data inside WMSN nodes, proper authentication of entities (e.g. health personnel) must be ensured before allowing them access. To this end, this paper proposes a pairing based authentication and key establishment scheme for remote patient monitoring systems. The scheme is two-factor i.e. combines smartcard and password, and achieves various desirable properties such as mutual authentication, strong access control, patient identity privacy, patient un-traceability, replay attack resistance and forward secrecy.\\nMutual authentication\\nInternet privacy\\nAuthentication\\nRemote patient monitoring\\nComputer science\\nComputer security\\nInformation security\\nAccess control\\nPassword\\nReplay attack\\nWireless sensor network',\n",
       " 1466209: 'Query Expansion Based-on Similarity of Terms for Improving Arabic Information Retrieval\\nYear: 2012\\n#Citations: 9\\nConference\\nSpringer, Berlin, Heidelberg\\nThis research suggests a method for query expansion on Arabic Information Retrieval using Expectation Maximization (EM). We employ the EM algorithm in the process of selecting relevant terms for expanding the query and weeding out the non-related terms. We tested our algorithm on INFILE test collection of CLLEF2009, and the experiments show that query expansion that considers similarity of terms both improves precision and retrieves more relevant documents. The main finding of this research is that we can increase the recall while keeping the precision at the same level by this method.\\nQuery optimization\\nQuery language\\nInformation retrieval\\nArabic\\nQuery expansion\\nComputer science\\nExpectation–maximization algorithm\\nWeb query classification\\nRanking (information retrieval)\\nNatural language processing\\nArtificial intelligence\\nRecall',\n",
       " 1469167: 'Guardian Knowledge Farm Agents and Security Architectures: Web Services, XML, and Wireless Mappings.\\nYear: 2003\\n#Citations: 0\\nConference\\n\\nWeb development\\nWorld Wide Web\\nXML\\nComputer science\\nComputer security\\nWeb standards\\nSecurity service\\nWeb 2.0\\nWeb application security\\nWeb service\\nWS-Policy',\n",
       " 1470373: 'Is Criticism of Computing Academe Inevitably Divisive\\nYear: 1999\\n#Citations: 2\\nJournal\\n\\nCriticism\\nProgramming language\\nComputer science\\nEpistemology',\n",
       " 1472067: 'New machine learning algorithm: random forest\\nYear: 2012\\n#Citations: 3\\nConference\\nSpringer, Berlin, Heidelberg\\nThis Paper gives an introduction of Random Forest. Random Forest is a new Machine Learning Algorithm and a new combination Algorithm. Random Forest is a combination of a series of tree structure classifiers. Random Forest has many good characters. Random Forest has been wildly used in classification and prediction, and used in regression too. Compared with the traditional algorithms Random Forest has many good virtues. Therefore the scope of application of Random Forest is very extensive.\\nPattern recognition\\nRegression\\nComputer science\\nAlgorithm\\nTree structure\\nArtificial intelligence\\nGeneralization error\\nClassifier (linguistics)\\nRandom forest\\nMachine learning',\n",
       " 1474208: \"Rural residents' perceptions and needs of telecare in taiwan\\nYear: 2012\\n#Citations: 0\\nConference\\nSpringer, Berlin, Heidelberg\\nThe purpose of this study was to explore rural residentsu0027 perceptions and needs of a telecare system after they have used it. The samples were collected using structured questionnaires with face to face interviews between July 1 and September 30, 2009. Results from this exploratory study show that most elderly people have never heard or touched telecare systems before the study was conducted. However, the general perceptions of such systems include improvement of interacting with medical staffs, safety protection, convenient care, and one needed item of services in daily life. Especially, the mostly risk perception is privacy risk, that is, data confidentiality and individual privacy. Generally, most elderly residents evaluated their telecare experiences and perceptions as being positive. Besides, most elderly resident were willing to use the telecare system without fees. However, they felt risky about confidentiality and privacy toward this technology. To improve trustworthy perception of this novel technology, telecare providers should implement appropriate safeguards to protect patient health information exchanged in a telecare setting. Also, the physicians/nurses should take the time to communicate with the residents, especially in the form of education, about the benefits of technology. To optimize the effectiveness of this promising technique, more research on the relationship between residentsu0027 (or patientsu0027) perceptions and influences of technology will need to be conducted continually in future.\\nComputer science\\nComputer security\\nTrustworthiness\\nFace-to-face\\nTelecare\\nNeeds assessment\\nArtificial intelligence\\nMedical education\\nConfidentiality\\nRisk perception\\nExploratory research\\nPerception\\nMachine learning\",\n",
       " 1475749: 'An Overview of FRAPPS 2.0: A Framework for Resolution-based Automated Proof Procedure Systems\\nYear: 1992\\n#Citations: 1\\nConference\\nSpringer Berlin Heidelberg\\nConjunctive query\\nComputer science\\nAlgorithm\\nTheoretical computer science\\nPriority queue\\nProof procedure\\nRule of inference',\n",
       " 1476506: 'Complexity Results for Paraconsistent Inference Relations.\\nYear: 2002\\n#Citations: 14\\nConference\\n\\nIn this paper, the complexity of several paraconsistent inference relations, based on multivalued logics, is investigated. Many inference relations pointed out so far by Arieli and Avron, Besnard and Schaub, D’Ottaviano and da Costa, Frisch, Levesque, Priest are considered from the computational side. All these relations can be gathered into two categories: the basic ones stem directly from the notions of models within 3 or 4-valued logics, while the refined ones are based on notions of preferred models for such logics. Completing complexity results by Cadoli and Schaerf (centered on the basic relations), we show that the refined paraconsistent inference relations that have been defined in the framework of multivalued logics are highly intractable. Especially, we prove that the inference problems corresponding to these relations are Πp2complete, even in the simple case where the database is a CNF formula and the query is a propositional symbol.\\nDisjunction introduction\\nParaconsistent logic\\nComputer science\\nInference\\nSymbol\\nAlgorithm\\nTheoretical computer science',\n",
       " 1479521: 'Optimal Operation Planning of Wind-Hydro Power Systems Using a MILP Approach\\nYear: 2014\\n#Citations: 1\\nConference\\nSpringer, Berlin, Heidelberg\\nThis paper addresses an approach for a day-ahead operation of a wind-hydro power system in an electricity market. A wind-hydro system is able to mitigate the intermittence and the variations on wind power, mitigating the economic penalty due to unbalance in the satisfaction of the compromises. The approach consists in a model given by a mixed-integer linear programming. This model maximizes the profit in the day-ahead market, taking into consideration the operating constraints of both the wind the farm and the pumping-hydro system. Finally, numerical case studies illustrate the interest and effectiveness of the proposed approach.\\nElectricity market\\nHydro power\\nElectric power system\\nControl engineering\\nLinear programming\\nEngineering\\nReliability engineering\\nWind power',\n",
       " 1482588: 'Ad Hoc Routing Protocol Performance Comparisons for Vehicular Ad Hoc Networks.\\nYear: 2005\\n#Citations: 0\\nConference\\n\\nMobile ad hoc network\\nAd hoc On-Demand Distance Vector Routing\\nComputer science\\nComputer network\\nAdaptive quality of service multi-hop routing\\nAd hoc wireless distribution service\\nWireless Routing Protocol\\nOptimized Link State Routing Protocol\\nWireless ad hoc network\\nVehicular ad hoc network',\n",
       " 1484282: 'Invited Talk: Embedded Test for Systems-on-a-Chip.\\nYear: 1999\\n#Citations: 0\\nJournal\\n\\nComputer architecture\\nComputer science\\nChip\\nElectronic engineering',\n",
       " 1486445: 'Learning Styles in a Non-Linear Training Environment.\\nYear: 1989\\n#Citations: 19\\nConference\\n\\nKinesthetic learning\\nExperiential learning\\nLearning styles\\nCollaborative learning\\nComputer science\\nBlended learning\\nCooperative learning\\nMultimedia',\n",
       " 1488658: 'Dealing with Mixing of English Verbs in Hindi for Machine Translation.\\nYear: 2005\\n#Citations: 0\\nConference\\n\\nRule-based machine translation\\nExample-based machine translation\\nHindi\\nComputer science\\nMachine translation\\nEnglish verbs\\nSynchronous context-free grammar\\nMachine translation software usability\\nArtificial intelligence\\nNatural language processing',\n",
       " 1494332: 'Comprehensive depiction of configuration-dependent performance anomalies in distributed server systems\\nYear: 2006\\n#Citations: 3\\nConference\\nUSENIX Association\\nDistributed server systems allow many configuration settings and support various application workloads. Often performance anomalies, situations where actual performance falls below expectations, only manifest under particular runtime conditions. This paper presents a new approach to examine a large space of potential runtime conditions and to comprehensively depict the conditions under which performance anomalies are likely to occur. In our approach, we derive our performance expectations from a hierarchy of sub-models in which each submodel can be independently adjusted to consider new runtime conditions. We then produce a representative set of measured runtime condition samples (both normal and abnormal)with carefully chosen sample size and anomaly error threshold. Finally, we employ decision tree based classification to produce an easy-to-interpret depiction of the entire space of potential runtime conditions. Our depictions can be used to guide the avoidance of anomaly-inducing system configurations and it can also assist root cause diagnosis and performance debugging. We present preliminary experimental results with a real J2EE middleware system.\\nMiddleware\\nDecision tree\\nComputer science\\nRuntime verification\\nDepiction\\nHierarchy\\nRoot cause\\nSample size determination\\nDebugging\\nDistributed computing',\n",
       " 1495587: 'Rapidly Developing Spoken Chinese Dialogue Systems with the d-Ear SDS SDK\\nYear: 2005\\n#Citations: 0\\nConference\\n\\nDeveloping a spoken dialog system is typically timeconsuming, and must often be accomplished using difficult-tolearn professional technologies. Most existing toolkits use statistical semantic parsers and model a dialogue interaction as a finite-state network. However, for developing flexible spoken Chinese dialogue systems, these toolkits have several problems. A new toolkit named the d-Ear SDS SDK is introduced here. The SDK suggests a multi-session dialogue system framework with a powerful semantic parser specially designed for spoken Chinese understanding, and a powerful dialogue manager providing non-finite-state dialogue control. To set up a new dialogue system, the developer can customize all the system modules with domain-specific information and operations, using the d-Ear SDS Studio to save time. Using the SDK, we have built several dialogue systems with excellent performance in a very short time.\\nSystem framework\\nSpoken dialog\\nStudio\\nComputer science\\nSpeech recognition\\nParsing',\n",
       " 1496982: 'Learning a Motor Grammar of Iconic Gestures\\nYear: 2014\\n#Citations: 2\\nJournal\\n\\nLearning a Motor Grammar of Iconic Gestures Amir Sadeghipour (sadeghipour@uni-bielefeld.de) Stefan Kopp (skopp@techfak.uni-bielefeld.de) Faculty of Technology, Center of Excellence ‘Cognitive Interaction Technology’ (CITEC), Bielefeld University, P.O. Box 100 131, D-33501 Bielefeld, Germany Abstract In this paper, we present a computational investigation into the compositionality of iconic gestures by trying to learn a motor grammar. We propose a grammar formalism that learns (1) the salient, invariant features of single movement segments (motor primitives) and (2) the hierarchical organization of these segments in complex gesturing. The formalism is applied to a dataset of natural iconic gestures. The extracted structure reveals compositional patterns of iconic gesturing. Keywords: gesture; motor program; probabilistic grammar Introduction An integral part of our communicative ability is to gesture, i.e. to perform expressive bodily actions as (part of) an utterance. Gesturing has received much interest during the last decades and work in (Psycho-)Linguistics, Cognitive Psychology and Human-Computer Interaction has provided many models of gesture production (e.g. Kopp, Bergmann, and Kahl (2013)) or gesture recognition (see Mitra and Acharya (2007) for a survey). Most of these models focus either on the higher cognitive processes (e.g., of multimodal conceptualization or speech-gesture formulation) or on low-level vision-based per- ception and recognition. Little is known about the sensory- motor representations that underlie and possibly shape those cognitive processes during perception, interpretation and pro- duction of gestural behavior. We focus on natural iconic gestures, which are sponta- neously and extemporaneously performed in communication to refer to objects or events by depicting visual-spatial as- pects. As illustrated in Figure 1, spontaneous iconic gestur- ing exhibits a very large variability even when performed for the same object. Extracting the communicative significance of an iconic gesture thus involves (at least) two steps: (1) an iconic mapping of physical movement onto visuospatial im- agery (e.g. a circular trajectory onto aspects of “roundness”, “size”, or “orientation”); (2) a referential mapping of this im- agery onto concrete objects or events (e.g. the specific round window being referred to). Here we are concerned with the first iconic mapping only and we want to understand how movements are used to create gestural imagery. Classically, iconic gestures are assumed to have no linguis- tic structure with a composition of primitives. Rather, Mc- Neill (2000) has argued for a “global semiosis” of such ges- ticulations, holding that the meanings of ‘parts’ of a gesture are determined by the meaning of the whole (and not the other way around as in language). On the other hand, it is widely ac- knowledged that the motor system is organized hierarchically (Hamilton u0026 Grafton, 2007), such that given intentions are mapped onto motor goals that are then refined into structured motor programs and on to motor primitives (Mussa-Ivaldi u0026 Solla, 2004). In line with this view, Flash and Hochner (2005) argued that our motor repertoire can be spanned by combining motor primitives according to syntactic rules. As the motor system is also involved in the perception of ges- tures (Montgomery, Isenberg, u0026 Haxby, 2007), this hierar- chical structure of motor knowledge should also guide the interpretation of communicative gestures. Against this back- ground, the question is (1) whether and how a compositional and hierarchical motor structure can be identified in gestu- ral movement and (2) how this may guide the comprehension and production of iconic gestures with their global semiosis. Performing way 1: Drawing with an index finger size=big; projection=(x,y); repetition=1; start-position=low; v=fast; ... Wristsu0027 movement trajectories size=medium; projection=(x,z); repetition=2; start-position=high; v=slow;… t Performing way 2: Drawing with two hands synchronously size=big; projection=(x,y); repetition=1; direction=bottom-up; v=medium; ... Wristsu0027 movement trajectories size=medium; projection=(x,y); repetition=1; direction=top-down; v=slow; … Figure 1: Different iconic gestures performed for a virtual 3D sphere, along with the respective wrist trajectories. In this paper we present a computational investigation into the compositionality of iconic gesturing by trying to learn a “motor grammar” of iconic gestures. After discussing rel- evant work, we propose a hybrid grammar-based approach that statistically identifies low-level feature-based regularities (“symbolization process”) and integrates this with searching for their compositional organization in high-level syntactic rules. Then, we discuss results from an application of this\\nPrinciple of compositionality\\nSemiosis\\nComputer science\\nCognitive science\\nGesture\\nMotor program\\nCognitive psychology\\nGesture recognition\\nGrammar\\nLinguistics\\nSyntax\\nPerception',\n",
       " 1501620: 'Speech Event Detection using Multiband Modulation Energy\\nYear: 2005\\n#Citations: 18\\nConference\\n\\nThe need for efficient, sophisticated features for speech event detection is inherent in state of the art processing, enhancement and recognition systems. We explore ideas and techniques from non-linear speech modeling and analysis, like modulations and multiband filtering and propose new energy and spectral content features derived through filtering in multiple frequency bands and tracking dominant modulation energy in terms of the Teager-Kaiser Energy of separate AM-FM components. We present a detection-theoretic motivation and incorporate them in two detection schemes namely word boundary and voice activity detection. The modulation approach demonstrated noisy speech endpoint detection accuracy, reaching »40% error reduction on NTIMIT. In a voice activity scheme, improvement in overall misclassification error of a high hit-rate detector reached 7.5% on Aurora 2 and 9.5% on Aurora 3 databases.\\nPattern recognition\\nComputer science\\nVoice activity detection\\nFilter (signal processing)\\nModulation\\nSpeech recognition\\nSpeech modeling\\nArtificial intelligence\\nDetector\\nRadio spectrum\\nModulation (music)',\n",
       " 1502707: 'Speaker normalization with a mixture of recurrent networks.\\nYear: 1997\\n#Citations: 6\\nConference\\n\\nNormalization (statistics)\\nPattern recognition\\nComputer science\\nArtificial intelligence',\n",
       " 1506965: \"Implementation Strategy for ISDN in the Deutsche Bundespost's Network.\\nYear: 1986\\n#Citations: 1\\nConference\\n\\nIntegrated Services Digital Network\\nComputer science\\nComputer network\",\n",
       " 1512767: 'GnT: A solver for disjunctive logic programs\\nYear: 2004\\n#Citations: 29\\nConference\\nSpringer, Berlin, Heidelberg\\nDisjunctive logic programming under the stable model semantics [3] is a form of answer set programming (ASP) which is understood nowadays as a new logic programming paradigm. The basic idea is that a given problem is solved by devising a logic program such that the stable models of the program correspond to the solutions of the problem, which are then found by computing stable models for the program. The success of ASP is much due to efficient solvers, such as dlv [5] and smodels [9], which have been developed in recent years. Consequently, many interesting applications of the paradigm have emerged: planning, model checking, reachability analysis, and product configuration, just to mention some.\\nProgramming language\\nComputer science\\nTheoretical computer science\\nStable model semantics\\nDeclarative programming\\nLogic programming\\nAnswer set programming\\nWell-founded semantics\\nFunctional logic programming\\nDiscrete mathematics\\nHorn clause\\nInductive programming\\nAlgorithm',\n",
       " 1515215: 'UFOme: A User Friendly Ontology Mapping Environment.\\nYear: 2007\\n#Citations: 3\\nConference\\n\\nRecently the Ontology Mapping Problem (OMP) has been identified as a key factor towards the success of the Semantic Web and related applications. This problem arises since it is possible for different people to give, through ontologies, different conceptualizations of the same (or overlapping) knowledge domain. In order to tackle the OMP several algorithms have been designed. They aim at discovering correspondences (aka mappings) between ontology entities. However, these algorithms mostly suffer from the following shortcomings: (i) do not allow to quickly combine and/or compare different mapping strategies; (ii) do not offer support for evaluating mapping strategies in terms of quality of results and performance. In this paper we present a pluginbased system called UFOme along with its current implementation. We illustrate how it can be exploited to graphically design mapping tasks by connecting different types of modules. UFOme provides three categories of modules. The first one (i.e., visualization) allows to explore the ontologies to be mapped. The second one (i.e., matching) provides different types of individual matchers, exploited to discover mappings between ontologies, and a module for combining them. The third one (i.e., evaluation) enables to evaluate each module of the mapping task, a sub mapping task, or the mapping task in the whole w.r.t performance and quality of results.\\nOntology (information science)\\nOntology alignment\\nOntology-based data integration\\nWorld Wide Web\\nInformation retrieval\\nProcess ontology\\nWeb mapping\\nComputer science\\nOpen Biomedical Ontologies\\nSuggested Upper Merged Ontology\\nUpper ontology',\n",
       " 1517195: 'A holonic multi-agent system for robust, flexible, and reliable medical diagnosis\\nYear: 2003\\n#Citations: 16\\nJournal\\nSpringer, Berlin, Heidelberg\\nReliable, cost-efficient, and fast medical diagnosis, especially in crucial cases, is still a big challenge in today’s world. This paper presents a holonic medical diagnosis system that combines the advantages of holonic systems and multi-agent systems in order to implement a highly efficient and robust Internet-based diagnosis system for diseases. The proposed holonic medical diagnosis system consists of a tree-like structured alliance of medical experts – realized by agents – that collaborate in order to provide a viable medical diagnosis. Each agent has a certain responsibility. Agents at higher levels of the holarchy represent experts in a broader field of diseases while the leaves are experts in one specific disease. The goal-based decision-making process is based on a hybrid, i.e., reactive and deliberative architecture. Reactive behavior is needed to compare the information provided to the agent with its pattern base in which possible appearances of the disease are stored in form of patterns. Deliberative behavior is needed in order to interpret and put in context the original data and information provided to the agent and to analyze and evaluate the results of the pattern matching process.\\nArchitecture\\nComputer science\\nDecision support system\\nMulti-agent system\\nPattern matching\\nHolarchy\\nMedical diagnosis\\nDistributed computing\\nThe Internet',\n",
       " 1519481: 'Efficient Sensor Placement for Surveillance Problems\\nYear: 2009\\n#Citations: 13\\nConference\\nSpringer, Berlin, Heidelberg\\nWe study the problem of covering a two-dimensional spatial region P , cluttered with occluders, by sensors. A sensor placed at a location p covers a point x in P if x lies within sensing radius r from p and x is visible from p , i.e., the segment px does not intersect any occluder. The goal is to compute a placement of the minimum number of sensors that cover P . We propose a landmark-based approach for covering P . Suppose P has *** holes, and it can be covered by h sensors. Given a small parameter *** u003e 0, let *** : = *** (h ,*** ) = (h /*** )(1 + ln (1 + *** )). We prove that one can compute a set L of O (*** log*** log(1/*** )) landmarks so that if a set S of sensors covers L , then S covers at least (1 *** *** )-fraction of P . It is surprising that so few landmarks are needed, and that the number of landmarks depends only on h , and does not directly depend on the number of vertices in P . We then present efficient randomized algorithms, based on the greedy approach, that, with high probability, compute $O(\\\\tilde{h}\\\\log \\\\lambda)$ sensor locations to cover L ; here $\\\\tilde{h} \\\\le h$ is the number sensors needed to cover L . We propose various extensions of our approach, including: (i) a weight function over P is given and S should cover at least (1 *** *** ) of the weighted area of P , and (ii) each point of P is covered by at least t sensors, for a given parameter t *** 1.\\nRandomized algorithm\\nCombinatorics\\nMathematical optimization\\nWeight function\\nMonte Carlo algorithm\\nVertex (geometry)\\nComputer science\\nGreedy algorithm\\nWireless sensor network\\nLambda\\nDistributed computing\\nThe Intersect',\n",
       " 1521632: 'Volume Manufacturing - ICs and Boards: DFT to the Rescue?\\nYear: 1996\\n#Citations: 0\\nConference\\n\\nManufacturing engineering\\nEngineering',\n",
       " 1525688: 'IMPLEMENTATION OF EPS_T2DM - Implementation of Early Prediction System for Type 2 Diabetes Mellitus\\nYear: 2008\\n#Citations: 0\\nConference\\n\\nDiabetes mellitus\\nComputer science\\nKnowledge management\\nIntensive care medicine\\nType 2 Diabetes Mellitus\\nPrediction system',\n",
       " 1529716: 'Ora – Save the Forest! Designing a Social Impact Game\\nYear: 2014\\n#Citations: 0\\nConference\\nSpringer, Berlin, Heidelberg\\nComputer models for designing educational games need to have practical applications as well as underlying theoretical principles. In this paper, we present the Structural Playability Process (SPP), a new approach for designing and implementing serious games. Using the SPP designed game Ora – Save the Forest! as a case study, we describe the four SPP spaces: education, translation, design and engine. Ora is a forest-pest-management game based on scientific models and intended to inform players about the complexities of ecosystem management. Preliminary user study results show that SPP is an effective method of producing motivating and successful learning environments.\\nData science\\nEcosystem management\\nWorld Wide Web\\nComputer science\\nEffective method\\nGame design\\nScientific modelling\\nSocial impact',\n",
       " 1533899: 'An Estimation for the Average Error of the Chebyshev Interpolation in Wiener Space\\nYear: 2011\\n#Citations: 0\\nConference\\nSpringer, Berlin, Heidelberg\\nIn this paper, the first kind of Chebyshev interpolation in the Wiener space are discussed. under the L p norm, the convergence properties of Chebyshev interpolation polynomials base on the zeros of the Chebyshev polynomials are proved. Furthermore, the estimation for the average error of the first kind of Chebyshev interpolation polynomials are weakly equivalent to the average errors of the corresponding best polynomial approximation. while p = 4, the weakly asypmtotic order \\\\(e^{4} (H_{n}, G_{4}) \\\\approx 1 / \\\\sqrt{n}\\\\) of the average error in the Wiener space is obtained.\\nChebyshev polynomials\\nChebyshev nodes\\nNearest-neighbor interpolation\\nDiscrete mathematics\\nPolynomial interpolation\\nMathematical analysis\\nInterpolation\\nStairstep interpolation\\nChebyshev filter\\nMathematics\\nChebyshev iteration',\n",
       " 1534806: 'Body Movement in Music Information Retrieval\\nYear: 2009\\n#Citations: 18\\nConference\\n\\nMusic information retrieval\\nComputer science\\nSpeech recognition\\nPop music automation\\nMultimedia',\n",
       " 1535111: 'Usability Evaluation of Hospital Websites in Nigeria: What Affects End Users’ Preferences?\\nYear: 2014\\n#Citations: 7\\nConference\\nSpringer, Cham\\nHospital providers need to deliver satisfactory services in a specialized field which involves a great number of stakeholders with different concerns, needs and requirements. Some hospitals’ policies have been focused on providing health and medical services to the public. Less attention has been given to the responsibility to provide useful, accurate health information of high quality to their key publics mainly by facilitating interactive communication with patients, citizens and physicians and community services. To date, hospitals are turning increasingly towards the Internet and have developed their own web presence in order to enhance interactive communication practices. The research evaluated the usability of hospital websites in Nigeria, focusing on two websites in south- west of the country. Evaluation criteria for assessment were developed. The results provided empirical evidence that websites should be easy to use as well as aesthetically pleasing but must be rich in information content.\\nWeb presence\\nEmpirical evidence\\nEnd user\\nComputer science\\nUsability\\nAesthetic design\\nMultimedia\\nHealth information\\nThe Internet',\n",
       " 1399713: 'Virtuelle Anprobe im Internet\\nYear: 2010\\n#Citations: 0\\n\\nOldenbourg Verlag\\nInternet privacy\\nBusiness\\nThe Internet',\n",
       " 1406868: 'WebA Mobile (Web Analysis Mobile): Assistance Tool for the Design and Evaluation of Websites for Mobile Devices\\nYear: 2009\\n#Citations: 5\\n\\nSpringer, London\\nThis chapter presents Mobile WebA (Assistance tool for the design and evaluation of sites for mobile devices), a new module of the WebA application developed by the Aragonese Usability Laboratory. This module facilitates the evaluation of usability and accessibility through the completion of the guidelines that are recommended by the best practices in the “W3C Mobile Web 1.0 Initiative,” in addition to allowing the completion and analysis of relevant tests of user satisfaction.\\nMobile technology\\nMobile computing\\nMobile search\\nWorld Wide Web\\nBest practice\\nComputer science\\nUsability\\nMobile device\\nMobile Web\\nWireless Application Protocol\\nMultimedia',\n",
       " 1411852: 'Peer Rewiring in Semantic Overlay Networks under Churn - (Short Paper).\\nYear: 2010\\n#Citations: 0\\n\\n\\nWorld Wide Web\\nComputer science\\nComputer network\\nOverlay network',\n",
       " 1419368: 'Creating online discursive spaces that legitimate alternative ways of knowing.\\nYear: 2002\\n#Citations: 5\\n\\n\\nAlthough educators have long recognised prior learning and life experience in their pedagogical strategies epistemological or cultural difference has not generally been legitimated. Knowledge originating from within non-western cultural groups, whether indigenous or migratory has not been valued. Such hegemony has created negative consequences for members of minority groups and has led to the exclusion of a range of possible epistemologies that might enhance learning. The advent of asynchronous models of communication, and in particular online learning, offers possibilities for more inclusionary and validating environments and pedagogy, by creating the opportunity for reflection through the dissociation from time and space. Yet technology does not in itself determine social process and if, like education, it remains enmeshed in a Western paradigm the possibilities for change remain limited. We will propose a model of use for online discussion boards that recognises them as a separate ‘thinking space’ beyond the formality of the classroom. This allows us to create new discursive spaces in which the student has the opportunity to engage in learning in way that is culturally appropriate for themselves, valuing their own worldview and epistemology. In a culturally diverse classroom, the discussion board can become a central enabling point of reference that reduces the colonisation of the student by an academic steering media, allowing for praxis-based learning to occur. In such a model facilitation of the discursive and reflective processes assumes prominence, affording educators the opportunity to bridge the gap between the propositional and practical forms of knowledge construction.\\nPraxis\\nPolitical science\\nCultural group selection\\nFormality\\nIndigenous\\nPublic relations\\nModels of communication\\nCultural diversity\\nHegemony\\nEpistemology\\nOnline discussion',\n",
       " 1424318: 'Workshop: Mastery of Pattern Concepts through Pattern Writing.\\nYear: 2000\\n#Citations: 0\\n\\n\\nComputer science\\nArtificial intelligence',\n",
       " 1427644: 'Evaluating Data Quality of Software Effort Metrics.\\nYear: 2008\\n#Citations: 0\\n\\n\\nData quality\\nSoftware engineering\\nSoftware quality analyst\\nComputer science\\nSoftware quality control\\nSoftware\\nSoftware quality\\nSoftware verification and validation',\n",
       " 1429480: 'Fuzzy Arithmetic for Uncertainty Analysis\\nYear: 2013\\n#Citations: 3\\n\\nSpringer, Berlin, Heidelberg\\nWhen the theory of fuzzy sets arose as a new mathematical concept in the field of information processing some 50 years ago, it rapidly advanced to becoming a well-established scientific discipline and a challenging object of both theoretical research and practical application. Since its introduction by Lotfi A. Zadeh [21], enormous progress has been made and numerous subdomains of fuzzy set theory have emerged, such as fuzzy logic and approximate reasoning, fuzzy pattern recognition and fuzzy modeling, expert systems and fuzzy control – and fuzzy arithmetic. Compared to most other fields, the topic of fuzzy arithmetic has received only little attention in the early years, and the scope of its practical application has barely exceeded the level of elementary academic examples. The reasons for this may be seen in the absence of a well-organized, systematic and consistent elaboration of the theory of fuzzy arithmetic, the lack of practical approaches to its effective implementation, and the apparent underestimation of its potential for the solution of real-world problems.\\nFuzzy classification\\nDefuzzification\\nFuzzy set operations\\nComputer science\\nFuzzy logic\\nFuzzy set\\nArtificial intelligence\\nFuzzy control system\\nFuzzy number\\nType-2 fuzzy sets and systems\\nMachine learning',\n",
       " 1436831: 'Classified Advertisement Analysis in the Context of an Expert System in Ad Matching.\\nYear: 1984\\n#Citations: 1\\n\\n\\nData mining\\nInformation retrieval\\nComputer science\\nExpert system',\n",
       " 1449437: 'An Instrumentation Solution for Reliable Three-Tier Applications.\\nYear: 1999\\n#Citations: 0\\n\\n\\nComputer science\\nInstrumentation\\nEmbedded system',\n",
       " 1453948: 'devd: a device configuration daemon\\nYear: 2003\\n#Citations: 1\\n\\nUSENIX Association\\nHot-pluggable bus technologies have proliferated, rendering traditional boot time configuration of devices via an /etc/rc script insufficient for many useru0027s needs. Most implementations of hot-plug technologies have provided a means to address these deficiencies, yet their solutions tend to be confined to only that technology. The goal of FreeBSDu0027s devd(8) is to provide a uniform framework by which interesting events relating to hot-plugging can be handled. devd provides a regular framework for these technologies to have user-land configuration commands run in a generic, extensible way. The implementation encountered a number of issues which are instructive to explore. devd only responds to events that the kernel generates and does not participate in interactions with the kernel that would block another thread of execution. At the present time, devd supports executing arbitrary commands when a driver attaches to the tree, when it detaches and when a bus detects an unknown device attached to that bus.\\nKernel (linear algebra)\\nComputer science\\nThread (computing)\\nImplementation\\nRendering (computer graphics)\\nExtensibility\\nDaemon\\nEmbedded system',\n",
       " 1456321: 'Illuminant influence on the reconstruction of NIR spectra\\nYear: 2003\\n#Citations: 0\\n\\nSociety for Imaging Science and Technology\\nIn order to recover spectral reflectances or transmittances using a multispectral imaging based technique, it is necessary to know the spectral radiance of the illuminant used to light the samples in the acquisition process. In this study, we analyzed the influence of the spectral distribution of the illuminant on the reconstruction of spectral reflectances in the near infrared region of the spectrum (NIR). We considered a set of 30 textile samples with different spectral reflectance in this region. We tested the performance of a principal component analysis (PCA) based method and a non-linear estimation method (NLE), which allow us to obtain the spectral reflectance of samples in the NIR region from a small number of measurements performed with a CCD camera. Using numerical simulation, we analyzed the number and shape of the optimum filters that need to be used in the acquisition channels in order to obtain good spectral reconstructions under several lighting conditions. Finally, we studied the quality of the reconstructions with a set of commercially available filters which are similar to the optimum filters obtained in the simulations. The results obtained show that the reconstruction does not depend heavily on the illuminant used. This indicates that, with the same set of filters, we can obtain good reconstructions for different types of illuminant.\\nComputer simulation\\nSpectral power distribution\\nMultispectral image\\nNear-infrared spectroscopy\\nRemote sensing\\nOptics\\nSpectral line\\nStandard illuminant\\nMaterials science\\nRadiance\\nPrincipal component analysis',\n",
       " 1466306: 'Design Principles for Ontological Support of Bayesian Evidence Management\\nYear: 2010\\n#Citations: 3\\n\\nIOS Press\\nThis chapter describes work on an integrated system that can assist analysts in exploring hypotheses using Bayesian analysis of evidence from a variety of sources. The hypothesis exploration is aided by an ontology that represents domain knowledge, events, and causality for Bayesian reasoning, as well as models of information sources for evidential reasoning. We are validating the approach via a tool, Magellan, that uses both Bayesian models and logical models for an analystu0027s prior knowledge about how evidence can be used to evaluate hypotheses. The ontology makes it possible and practical for complex situations of interest to be modeled and then analyzed formally.\\nData science\\nDesign elements and principles\\nOntology\\nCausality\\nBayesian inference\\nDomain knowledge\\nComputer science\\nEvidential reasoning approach\\nBayesian probability',\n",
       " 1472329: 'Development of Communication Software by Stepwise Refinement\\nYear: 1987\\n#Citations: 3\\n\\nNorth-Holland Publishing Co.\\nSoftware engineering\\nComputer science\\nTop-down and bottom-up design\\nSoftware',\n",
       " 1475560: 'An efficient authentication scheme for contactless smartcards using elliptic curve cryptography.\\nYear: 2006\\n#Citations: 2\\n\\n\\nNowadays the protection of information against unauthorized disclosure, transfer, modification, or destruction, whether accidental or intentional, is a very important issue that concerns the information society. The scope of this paper is to develop a Contactless Smartcard protocol, which will be able operate securely and effectively, under a variety of attack methods. The system implements a novel mutual authentication procedure between a Contactless Reader and a Smartcard, calculates securely the corresponding parameters, and protects the system against malicious attacks. The system can be used in a wide spectrum of applications that require simplicity, ease of use, long life, low cost and portability. Suitable applications could be, Electronic Payments, Public Transport Electronic Fare, Highway toll payments, Medical Applications, and Access Control.\\nMutual authentication\\nHardware security module\\nComputer science\\nComputer security\\nUsability\\nSmart card\\nComputer network\\nAccess control\\nSoftware portability\\nElliptic curve cryptography\\nPayment',\n",
       " 1479534: 'TALP: Xgram-based spoken language translation system.\\nYear: 2004\\n#Citations: 12\\n\\n\\nThis paper introduces TALP, a speech-to-speech statistical machine translation system developed at the TALP Research Center (Barcelona, Spain). TALP generates translations by searching for the best scoring path through a Finite-State Transducers (FSTs), which models an Xgram of the bilingual language defined by tuples. A detailed description of the system and the core processes to train it from a parallel corpus are presented. Results on the Chinese-English supplied task of the Int. Workshop on Spoken Language Translation (IWSLT’04) Evaluation Campaign are shown and discussed. 1. Overview of the system TALP (Traduccio Automatica del Llenguatge Parlat) is a speech-to-speech statistical machine translation system developed at the TALP Research Center (Barcelona, Spain) during the last years. It implements an integrated architecture by joining speech recognition and translation in one single step. Mathematically, the system produces a translation by maximizing the joint probability between source and target languages, which is equivalent to a language model of an special language with bilingual units (called tuples). TALP implements this tuple language model by means of a Finite-State Transducer (FST) considering an Xgram memory, that is, a variablelength N-gram model which adapts its length to evidence in the data. Xgrams have proved good results in speech recognition tasks in the past [1]. Given such a bilingual FST, the search for a translation becomes the search for the best-scoring path among the transducer’s edges. This search can be performed by dynamic programming, using well-known decoding techniques from the speech recognition domain. This way, the Viterbi algorithm and a beam search can be used forwards taking only source-language words into account (first part of each tuple), reading words in the target language during trace-back to produce the translation. Using This work has been partially supported by the Spanish Government under grant TIC2002-04447-C02 (ALIADO project), the European Union under grant FP6-506738 (TC-STAR project) and the Dep. of Universities, Research and Information Society (Generalitat de Catalunya). Figure 1: A translation FST from Spanish to English the same structure and search method, acoustic models can be omitted to perform text translation tasks only. This translation FST is learned automatically from a parallel corpus in three main steps (and an optional preprocessing). First, an automatic word alignment is produced. Currently this is done by the freely-available GIZA++ software [2], implementing well-known IBM and HMM translation models [3, 4]. From this alignment, a tuple extraction algorithm generates the set tuples that induces a sequential segmentation of both source and target sentences. These tuples must respect word order in both languages, as this is necessary for the transducer to produce a correct-order translated output. Finally, Xgrams are learned using standard language modeling techniques. Previous publications on this system include [5] and [6]. The organization of the paper is as follows. Section 2 offers an overview of the system architecture, whereas sections 2 and 3 deepen into details on translation generation and training issues. Section 4 presents the experimental framework used to evaluate the system, whose results are discussed in section 5. Finally, section 6 concludes and outlines future research lines. 2. Translation generation Statistical machine translation is based on the assumption that every sentence e in the target language is a possible translation of a given sentence f in the source language. The main difference between two possible translations of a given sentence is a probability assigned to each, which is to be learned from a bilingual text corpus. This probability can be modeled by a joint probability model of source and target languages. In this case, solving the translation problem is finding the sentence in the target language that maximises equation 1. This probability can be approximated by an Xgram of a joint or bilingual language model, learned from a set of tuples, as expressed in equation 2. e = arg max e {p(e, f)} = · · · = (1)\\nRule-based machine translation\\nExample-based machine translation\\nTuple\\nComputer science\\nMachine translation\\nText corpus\\nMachine translation software usability\\nArtificial intelligence\\nNatural language processing\\nComputer-assisted translation\\nLanguage model',\n",
       " 1485153: 'XNODE: Fast Retrieval of XML Data from Relational Tables.\\nYear: 2002\\n#Citations: 3\\n\\n\\nSemi-structured data\\nEfficient XML Interchange\\nStreaming XML\\nInformation retrieval\\nComputer science\\nXML validation\\nDocument Structure Description\\nXML database\\nXML schema\\nDatabase\\nXML Schema Editor',\n",
       " 1494232: 'Garbage Cut for Garbage Collection of Iterative Prolog Programs.\\nYear: 1986\\n#Citations: 4\\n\\n\\nGarbage\\nProgramming language\\nComputer science\\nManual memory management\\nMark-compact algorithm\\nParallel computing\\nProlog\\nGarbage collection',\n",
       " 1509457: 'Detecting change in burnt landscapes using a terrestrial LiDAR system\\nYear: 2012\\n#Citations: 0\\n\\nRMIT University\\nA Terrestrial LiDAR system or Terrestrial Laser Scanner (TLS) was used to detect changes in burnt landscapes. Since wildfires are a common occurrence in the Australian landscape, prescribed burns are routinely carried out by land management agencies and government departments. These prescribed burns reduce the fuel load which decreases the severity of subsequent unplanned wildfires. Recent advances in LiDAR have enabled the successful measurement of complex structures in the field with both high accuracy and precision. LiDAR remote sensing has been used for estimating a wide variety of forest metrics. However, airborne LiDAR in particular has been unsuited for measuring understorey vegetation. Modern ground-based LiDAR systems can overcome some of the shortcomings of airborne LiDAR systems (sub-centimetre resolution, canopy obscuration). In this study, four plots of 10m radius were chosen within a prescribed burn area in St. Andrews, Victoria which took place in April 2012. One plot was unburnt (control) while the other three plots were given different fire treatments to simulate different fire severities. The TLS was operated from the centre of the plot and data was collected at a resolution of 10mm at a radius of 10m. Laser scans were captured pre-burn, and post-burn in week two. Data analysis was carried out at different scales (voxel and plot) and at the vertical strata comprising near-surface and surface fuel layer within 1m from the ground. Within voxels, metrics used to compute change were changes in point density and maximum z value. At the plot scale, change in volume was computed.\\nMeteorology\\nPrescribed burn\\nVegetation\\nLaser scanning\\nUnderstory\\nRemote sensing\\nLidar\\nAccuracy and precision\\nGeography\\nCanopy',\n",
       " 1516187: 'Specification of Audio/Video Exchange Based on the Reference Model of ODP\\nYear: 1994\\n#Citations: 0\\n\\nNorth-Holland Publishing Co.\\nReference model\\nComputer science\\nMultimedia',\n",
       " 1519294: 'Using Cyclic String Matching to Find Rotational and Reflectional Symmetries in Shapes\\nYear: 1996\\n#Citations: 2\\n\\nWorld Scientific Press\\nString searching algorithm\\nDiscrete mathematics\\nTheoretical physics\\nMathematics\\nHomogeneous space',\n",
       " 1520693: 'Study on Transformed Keywords Identification in Spam Filtering\\nYear: 2012\\n#Citations: 0\\n\\nSpringer, Berlin, Heidelberg\\nBy means of Active-Jamming, spammers deform original keywords into a variety of deformation, which can escape from the traditional filtering based on original keywords matching. In order to identify the transformed keywords, a comprehensive summary of the deformations and corresponding solutions for each case is put forward. Based on the summary, a transformed keywords identification scheme is designed specific to three broad categories. And a technique based on character co-occurrence is proposed to identify the transformed keywords in a flexible way, in which the bidirectional-ranged searching is innovatively put forward.\\nData mining\\nWorld Wide Web\\nIdentification scheme\\nComputer science\\nFilter (signal processing)',\n",
       " 1521201: 'Querying and Splitting Techniques for SBA: A Model Checking Based Approach\\nYear: 2011\\n#Citations: 0\\n\\nSpringer Berlin Heidelberg\\nCurrent approaches to fragmentation of services are not business-oriented. They are not based on a real temporal query language, and in general, they return execution traces instead of parts of the process. We propose in this work an approach for fragmentation based on model checking and slicing techniques. Fragmentation is based on business rules expressed in LTL. In our work the fragmentation does not consist in splitting a web service composition in a set of fragments. It is defined as the seeking of a single fragment that contributes to the verification of a business rule.\\nQuery language\\nWeb service composition\\nModel checking\\nBusiness process\\nComputer science\\nSlicing\\nFragmentation (computing)\\nWeb service\\nDatabase\\nBusiness rule',\n",
       " 1527533: 'Evolutionary Path to Network Storage Management.\\nYear: 1991\\n#Citations: 2\\n\\n\\nNetwork storage\\nComputer science\\nComputer network',\n",
       " 1530371: 'Extending Test and Evaluation Modeling and Simulation Capabilities with Gaming Technology (abstract).\\nYear: 2009\\n#Citations: 0\\n\\n\\nSystems engineering\\nModeling and simulation\\nHuman–computer interaction\\nEngineering',\n",
       " 1536250: 'Mixed Reality Techniques for Visualizations in a 3D Information Space.\\nYear: 2007\\n#Citations: 0\\n\\n\\nComputer science\\nHuman–computer interaction\\nInformation space\\nMixed reality\\nMultimedia',\n",
       " 1536811: 'Bulk-loading of a multidimensional file: algorithm and its performance evaluation.\\nYear: 2002\\n#Citations: 0\\nJournal\\n\\nComputer science\\nComputational science\\nDistributed computing',\n",
       " 1537870: 'Prediction of Insertion-Site Preferences of Transposons Using Support Vector Machines and Artificial Neural Networks\\nYear: 2014\\n#Citations: 0\\nConference\\nSpringer, Cham\\nTransposons are segments of DNA that are capable of moving from one location to another within the genome of a cell. Understanding transposon insertion-site preferences is critically important in functional genomics and gene therapy studies. It has been found that the deformability property of the local DNA structure of the integration sites, called V step , is of significant importance in the target-site selection process. We considered the V step profiles of insertion sites and developed predictors based on Artificial Neural Networks (ANN) and Support Vector Machines (SVM), and trained them with a Sleeping Beauty transposon dataset. We found that both ANN and SVM predictors are excellent in finding the most preferred regions. However, the SVM predictor outperforms the ANN predictor in recognizing preferred sites, in general.\\nGenome\\nRadial basis function network\\nPattern recognition\\nComputer science\\nTransposable element\\nSupport vector machine\\nFunctional genomics\\nSleeping Beauty transposon system\\nArtificial intelligence\\nArtificial neural network\\nMachine learning',\n",
       " 1538985: 'The order of B-convergence of the Gaussian Runge-Kutta method\\nYear: 1986\\n#Citations: 16\\nJournal\\nSpringer Science and Business Media LLC\\nIn this note the exact order ofB-convergence is determined for them-stage Gaussian Runge-Kutta method. Form=1 this order is 2, whereas form≥2 this order turns out to be onlym.\\nConvergence (routing)\\nRunge–Kutta methods\\nDifferential equation\\nMathematical optimization\\nMathematical analysis\\nGaussian\\nInitial value problem\\nMathematics',\n",
       " 1539337: 'Partial implication semantics for desirable propositions\\nYear: 2004\\n#Citations: 7\\nConference\\nAAAI Press\\nMotivational attitudes play an important role in investigations into intelligent agents. One of the key problems of representing and reasoning about motivational attitudes is which propositions are the desirable ones. The answer based on classical logic is that the propositions that logically imply the goal are desirable and the others are not. We argue that this criterion is inadequate for the incomplete knowledge about environments for an agent. In this paper, we present a simple and intuitive semantics—partial implication—for the characterization of desirable propositions. In this semantics, Proposition P is a desirable one with respect to a given goal Q if and only if P is \"useful\" and \"harmless\" to Q in any situation. Partial implication is an extension of classical implication. We investigate some fundamental properties of partial implication and discuss some of the potential applications.\\nIncomplete knowledge\\nIntelligent agent\\nProposition\\nComputer science\\nAlgorithm\\nClassical logic\\nIf and only if\\nArtificial intelligence\\nSemantics',\n",
       " 1543088: 'Teaching Project Management Skills: An Example of Collaboration between a University and the Local PMI Chapter\\nYear: 2010\\n#Citations: 2\\nConference\\n\\nThe demand for project management skills in industry is increasing; however the number of individuals who can meet the demand is decreasing. Universities are addressing these changes by developing project management degree programs. In this paper we describe the experience of a collaborative effort between one University and a local chapter of the Project Management Institute (PMI). The result is a popular and highly successful program in which project management professionals from the PMI are engaged in student learning by providing a guest lecture series, serving as mentors for class projects, providing actual organizational projects for students to analyze and apply class concepts, and serving as judges on student team project competitions. The results are students who receive a rigorous education, hands on experience in industry, form relationships with, and learn practical skills from PMI volunteers; grounding their formal education in practical industry experience.\\nProject management 2.0\\nComputer science\\nKnowledge management\\nProgram management\\nOPM3\\nProject charter\\nStudent learning\\nProject management',\n",
       " 1544043: 'An Application of Knowledge Discovery Techniques on Stock Market.\\nYear: 2004\\n#Citations: 0\\nConference\\n\\nData science\\nComputer science\\nKnowledge extraction\\nStock market\\nDistributed computing',\n",
       " 1546088: 'An automatic music transcription based on translation of spectrum and sound path estimation\\nYear: 2011\\n#Citations: 1\\nConference\\nSpringer, Berlin, Heidelberg\\nAn automatic music transcription method is proposed. The method is based on a generative model that takes into account the translation of spectrum for an instrument and the sound path from the instrument to a microphone. The fundamental frequency (note), the spectrum of the instrument (basis pattern) and the sound path are estimated simultaneously using an extended complex nonnegative matrix factorization. The effectiveness of the proposed method is confirmed by synthetic data.\\nFundamental frequency\\nPattern recognition\\nComputer science\\nSpeech recognition\\nSynthetic data\\nNon-negative matrix factorization\\nArtificial intelligence\\nMicrophone\\nGenerative model',\n",
       " 1546718: 'Fixed point multistage DS-CDMA receivers *\\nYear: 1999\\n#Citations: 2\\nJournal\\nSpringer\\nA travers une etude analytique de la suppression parallele des brouillages, des methodes de decorrelation et de detection basee sur lu0027erreur quadratique moyenne, dans un systeme CDMA, lu0027article propose des ameliorations simples du0027une precedente structure de reception, permettant lu0027obtention de meilleures performances. Ces structures sont ensuite comparees avec la suppression seuillee, des brouillages, via des resultats de simulation et differents modeles de canaux. Le traitement de signal mis en œuvre presente la particularite du0027etre quantifie (signaux en bande de base et calculs en virgule fixe) et la synchronisation est acquise de maniere dynamique comme une structure realiste le ferait.\\nDecorrelation\\nElectronic engineering\\nFixed point\\nCode division multiple access\\nMathematics\\nSpread spectrum\\nBit error rate',\n",
       " 1547416: 'Linking Expert-Systems and Interactive Video for Medical Education\\nYear: 1991\\n#Citations: 0\\nConference\\nSpringer, Berlin, Heidelberg\\nExpert systems are potentially valuable tools in teaching medical decision making. Their potential in this field was identified early in the history of the technology (Clancey u0026 Letsinger 1981). In areas where decisions depend on visual clues, the addition of a store of illustrative video sequences greatly enhances the educational potential of an expert system. A system is described which combines an expert system on surgical management of lumps in the head and neck, with a videodisc containing patient examinations, and illustrative animations. The current system is aimed at students in their first year of clinical studies. Further developments required to make the system useful to more advanced students are identified.\\nInteractive video\\nMedical decision making\\nExpert system\\nPatient examination\\nMedicine\\nMultimedia',\n",
       " 1549638: 'Collaborative Facial Landmark Localization for Transferring Annotations Across Datasets\\nYear: 2014\\n#Citations: 23\\nConference\\nSpringer, Cham\\nIn this paper we make the first effort, to the best of our knowledge, to combine multiple face landmark datasets with different landmark definitions into a super dataset, with a union of all landmark types computed in each image as output. Our approach is flexible, and our system can optionally use known landmarks in the target dataset to constrain the localization. Our novel pipeline is built upon variants of state-of-the-art facial landmark localization methods. Specifically, we propose to label images in the target dataset jointly rather than independently and exploit exemplars from both the source datasets and the target dataset. This approach integrates nonparametric appearance and shape modeling and graph matching together to achieve our goal.\\nComputer vision\\nPattern recognition\\nComputer science\\nMatching (graph theory)\\nNonparametric statistics\\nExploit\\nActive appearance model\\nArtificial intelligence\\nLandmark\\nMachine learning',\n",
       " 1552205: 'A Course-Grain Multicomputer Algorithm for the Minimum Cost Parenthesization Problem.\\nYear: 2009\\n#Citations: 1\\nConference\\n\\nComputer science\\nParallel computing\\nDistributed computing',\n",
       " 1555134: 'Personalized context-aware presentation of information to mobile users\\nYear: 2003\\n#Citations: 0\\nConference\\n\\nMobile technology\\nMobile computing\\nMobile search\\nWorld Wide Web\\nComputer science\\nMobile Web\\nMultimedia',\n",
       " 1557874: 'Agents and Clinical Guidelines: Filling the Semantic Gap\\nYear: 2007\\n#Citations: 1\\nConference\\nIOS Press\\nMedical ontologies are developed to solve problems such as the demand for reusing, sharing and transmitting data. The unambiguous communication of complex and detailed medical concepts is a crucial feature in current medical information systems. In these systems, several agents must interact in order to share their results and, thus, they must use a medical terminology with a clear and non-confusing meaning. The paper presents the inclusion of an especially designed medical ontology in the HECASE2 multi-agent system. HECASE2 has been developed to help doctors in applying clinical guidelines to their patients in a semi-automatic fashion. In addition, it shows how intelligent agents may take profit from the modelled medical knowledge to coordinate their activities in the enactment of clinical guidelines.\\nInformation system\\nOntology (information science)\\nOntology\\nIntelligent agent\\nKnowledge representation and reasoning\\nMedical terminology\\nComputer science\\nSemantic gap\\nKnowledge management\\nMulti-agent system',\n",
       " 1560863: 'Queue Management and QoS Routing for Traffic Differentiation.\\nYear: 2005\\n#Citations: 1\\nConference\\n\\nThis paper presents a simulation study of router mechanisms to provide differentiated levels of service to traffic with diverse performance requirements in IP networks. The paper focuses on queue management mechanisms and on Quality of Service routing. The performance of the Random Early detection dropper associated with the Weighted Round Robin scheduling discipline is compared with the Dynamic Degradation Distribution system. This system redistributes the resources among traffic classes according to the state of the route. Afterwards, the impact of Quality of Service routing in networks where there is class-based traffic differentiation is assessed. The results show that even though the queue management mechanisms actually deployed in commercial routers naturally support traffic differentiation and provide adequate levels of QoS, the Dynamic Degradation Distribution system is able to give better performance in situations of congestion. Moreover, the inclusion of Quality of Service routing capabilities clearly improves traffic performance and network utilization.\\nWeighted random early detection\\nLink-state routing protocol\\nDynamic Source Routing\\nPolicy-based routing\\nStatic routing\\nComputer science\\nComputer network\\nAdaptive quality of service multi-hop routing\\nQueue management system\\nRouting protocol\\nDistributed computing',\n",
       " 1562509: 'Development of portable electrocardiogram signal generator\\nYear: 2011\\n#Citations: 0\\nConference\\nSpringer, Berlin, Heidelberg\\nTo meet the rising popular demand on the treatment of diseases and health security, a portable medical electrocardiogram (ECG) signal generator is developed. With the integrated circuit design, microcomputer control technology, the communication technology and the corresponding software technology, the design utilizes Samsungu0027s ARM chip S3C2410 as the whole system master chip, including micro controller, Ethernet communication interface, serial communication interface, USB communication interface, power supply circuit, DA conversion circuit and signal processing circuit. It not only realizes the functions of normal ECG signal generator, but also filters out actual human signal in ECG data. It can also compare different manufacturers of ECG productsu0027 performance through standard of database of ECG data.\\nSerial communication\\nSignal processing\\nARM architecture\\nComputer science\\nSignal generator\\nChip\\nIntegrated circuit design\\nMicrocontroller\\nComputer hardware\\nUSB',\n",
       " 1565496: 'The CSTL processor: a tool for automated conceptual schema testing\\nYear: 2011\\n#Citations: 6\\nConference\\nSpringer, Berlin, Heidelberg\\nIn this demonstration paper, we present the CSTL Processor, a tool to support the validation of two fundamental quality properties of conceptual schemas (correctness and completeness) by testing. The CSTL Processor supports the management, execution and automatic computation of the verdicts of test cases which formalize stakeholdersu0027 needs and expectations.\\nData mining\\nConceptual schema\\nProgramming language\\nConceptual model\\nComputer science\\nCorrectness\\nTest case\\nCompleteness (statistics)\\nSchema (psychology)\\nDatabase\\nComputation',\n",
       " 1568722: 'Progress on X.25.\\nYear: 1984\\n#Citations: 1\\nConference\\n\\nComputer science\\nComputer network\\nComputational science\\nX.25',\n",
       " 1570380: 'Definability on finite structures and the existence of one-way functions\\nYear: 1994\\n#Citations: 9\\nConference\\nAblex Publishing Corp.\\nComplexity class\\nQuantum complexity theory\\nDiscrete mathematics\\nParameterized complexity\\nStructural complexity theory\\nCombinatorics\\nSparse language\\nDescriptive complexity theory\\nOne-way function\\nMathematics\\nFast-growing hierarchy',\n",
       " 1573833: 'Towards a Multilingual Medical Lexicon\\nYear: 2006\\n#Citations: 8\\nConference\\nAmerican Medical Informatics Association\\nWe present results of the collaboration of a multinational team of researchers from (computational) linguistics, medicine, and medical informatics with the goal of building a multilingual medical lexicon with high coverage and complete morpho-syntactic information. Monolingual lexical resources were collected and subsequently mapped between languages using a morpho-semantic term normalization engine, which captures intra- as well as interlingual synonymy relationships on the level of subwords.\\nNormalization (statistics)\\nMultilingualism\\nComputer science\\nCooperative behavior\\nLexicon\\nNatural language processing\\nArtificial intelligence\\nHealth informatics\\nUnified Medical Language System\\nSemantics',\n",
       " 1575397: 'Defeasible logic graphs: II. Implementation\\nYear: 1998\\n#Citations: 16\\nConference\\nElsevier Science Publishers B. V.\\nAbstract   We propose development of an argument based decision support system utilizing defeasible or nonmonotonic reasoning. Defeasible logic graphs (d-graphs) represent the knowledge contained in a defeasible theory. A method for propagating labels through d-graphs is developed as a means for reasoning about the theory from which the d-graph is generated. This method is proven to be sound with respect to Nuteu0027s defeasible logic and complete for finite, consistent theories with acyclic d-graphs.\\nGraph\\nComputer science\\nDefeasible logic\\nDecision support system\\nNon-monotonic logic\\nArtificial intelligence\\nDefeasible estate',\n",
       " 1577540: 'Planning with graded fluents and actions\\nYear: 2005\\n#Citations: 0\\nConference\\nMorgan Kaufmann Publishers Inc.\\nThis work can be seen as a first approach to a new planning model that takes into account the possibility to express actions and fluents with nonboolean values. According to this model, a planning problem is defned using both graded (multi-valued) and classical (boolean) fluents. Moreover, actions that can have different application degrees can be defined. In this work a PDDL extension allowing to describe such new problems is proposed and a planning algorithm for such problems is presented.\\nDiscrete mathematics\\nPlanning algorithms\\nComputer science\\nPlanning Domain Definition Language',\n",
       " 1581160: 'Analysis of chord progression by HPSG\\nYear: 2006\\n#Citations: 13\\nConference\\nACTA Press\\nIn this paper, we will present an analysis system of chord progression in HPSG (Head-Driven Phrase Structure Grammar). It is said that the structure of music is somewhat similar to that of natural language sentences. When we try to write rules for chord progression in context-free grammar, we need to add a lot of rules for trivial exceptions. However in HPSG, we can encapsulate such diversity in the feature structure of each category and can reduce the number of rules. In addition, we can utilize the notion of head, which is the prime constituent in lower concepts, to represent various hierarchical knowledge in musicology. We show that our system adequately resolves the mutual dependency between the key and the chord progression from a given sequences of chords, and that the system outputs the candidates of plausible harmony sequences. We evaluate the experimental results, and discuss the problems and the future extension of our method.\\nHead-driven phrase structure grammar\\nKnowledge representation and reasoning\\nComputer science\\nPhrase structure grammar\\nFeature structure\\nGrammar\\nNatural language\\nArtificial intelligence\\nNatural language processing\\nParsing\\nChord (music)',\n",
       " 1581815: \"Shaping Knowledge Within Artifacts - Guest Editors' Introduction.\\nYear: 1989\\n#Citations: 1\\nJournal\\n\\nData science\\nComputer science\\nKnowledge management\",\n",
       " 1586857: 'Manager: Superdistribution and the Economics of Bits.\\nYear: 1997\\n#Citations: 0\\nJournal\\n\\nSoftware engineering\\nComputer science',\n",
       " 1594417: 'Modular Verification of Distributed Systems.\\nYear: 1985\\n#Citations: 0\\nConference\\n\\nComputer science\\nIntelligent verification\\nModular design\\nDistributed computing',\n",
       " 1600357: '3D Ear Analysis by an EGI Representation\\nYear: 2014\\n#Citations: 2\\nJournal\\nSpringer, Cham\\nIn this paper, a new method to represent human ear for biometrics purposes is introduced. Even if ear has a uniform distribution of color, human external ear characteristics are considered unique to each individual and permanent during the lifetime of an adult. For these reasons ear biometrics approaches are relying on morphological ear properties. Even if ear biometrics is a young topic a variety of approaches have been proposed to characterize the ear geometry and topology. Moreover, note that the ear morphology is the biggest human head concavity, and that its convex hull complement is mainly convex. In this connection, the matching potential for ear discrimination can be effectively exploited through an Extended Gaussian Image (EGI) representation. The original EGI representation and its correspondent concrete data-structure are here applied to ear description and discussed for human authentication and identification purposes.\\nAnatomy\\nAuthentication\\nInorganic chemistry\\nUniform distribution (continuous)\\nChemistry\\nConvex hull\\nArtificial intelligence\\nHuman head\\nGeometry and topology\\nPattern recognition\\nRegular polygon\\nGaussian\\nBiometrics',\n",
       " 1601902: 'Random indexing distributional semantic models for Croatian language\\nYear: 2011\\n#Citations: 1\\nConference\\nSpringer, Berlin, Heidelberg\\nDistributional semantic models (DSMs) model semantic relations between expressions by comparing the contexts in which these expressions occur. This paper presents an extensive evaluation of distributional semantic models for Croatian language. We focus on random indexing models, an efficient and scalable approach to building DSMs. We build a number of models with different parameters (dimension, context type, and similarity measure) and compare them against human semantic similarity judgments. Our results indicate that even low-dimensional random indexing models may outperform the raw frequency models, and that the choice of the similarity measure is most important.\\nSemantic similarity\\nSimilarity measure\\nExpression (mathematics)\\nRandom indexing\\nComputer science\\nComputational semantics\\nArtificial intelligence\\nNatural language processing\\nSemantic computing\\nSemantic compression\\nScalability',\n",
       " 1603316: 'A System That Supports Using Student-Drawn Diagrams to Assess Comprehension of Mathematical Formulas\\nYear: 2002\\n#Citations: 7\\nJournal\\nSpringer, Berlin, Heidelberg\\nGraphical communication by students can provide important clues to teachers about misconceptions in fields like mathematics and computing. We have built a facility called INFACT-SKETCH that permits conducting experiments in the elicitation and analysis of student-drawn diagrams. A goal of our project is to achieve the integration of a construction-oriented image processing and programming system with a combination of automatic and manual assessment tools in order to have a highly effective learning environment for information technology concepts. Some of the diagrams we elicit from students represent image processing algorithms, and others represent predictions of what particular mathematical formulas will do to images. In order to serve its educational assessment and research purposes, INFACT-SKETCH provides an unusual combination of features: tight integration with a web-based textual communication system called INFACT-FORUM, administrative control of which drawing tools students will be permitted to use (freehand, rectangles, ovals, text labels, lines, etc.), complete event capture for timed playback of the drawing process for any sketch in the system, graphical quoting option in message replies, and structured annotations for educational assessment. We describe the rationale, intended use, design, and our experience so far with INFACT-SKETCH.\\nComputer science\\nCommunications system\\nImage processing\\nEducational assessment\\nHuman–computer interaction\\nLearning environment\\nArtificial intelligence\\nSketch\\nDistributed computing\\nGraphics\\nInformation technology\\nDigital image processing\\nMachine learning',\n",
       " 1604202: 'Generation and Reorganization of Subtype Hierarchies.\\nYear: 1996\\n#Citations: 13\\nJournal\\n\\nProgramming language\\nComputer science\\nHierarchy',\n",
       " 1605429: 'BACKGROUND MODELING WITH MOTION CRITERION AND MULTI-MODAL SUPPORT\\nYear: 2016\\n#Citations: 1\\nConference\\n\\nComputer vision\\nPattern recognition\\nComputer science\\nArtificial intelligence\\nModal',\n",
       " 1606389: 'On the Meaning Representation of Fuzzy Words\\nYear: 2013\\n#Citations: 1\\nConference\\nSpringer, Berlin, Heidelberg\\nThe basic characteristic of fuzzy language is the meaning uncertainty and fuzziness of the language units, such as words and sentences, and how to represent such fuzzy meaning formally is a problem that is worth studying. This paper attempts to analyze and explore the formal meaning representation of Chinese fuzzy words.\\nFuzzy logic\\nArtificial intelligence\\nNatural language processing\\nType-2 fuzzy sets and systems\\nMathematics',\n",
       " 1608965: 'Visual Modelling of Complex Systems: Towards an Abstract Machine for PORGY\\nYear: 2014\\n#Citations: 7\\nConference\\nSpringer, Cham\\nPORGY is a visual modelling tool, where a system is defined by a strategic graph program. In this paper, we provide an operational semantics for strategic graph programs by means of an abstract machine. The semantics specifies the valid transformation steps, providing a link between the model and its implementation in PORGY.\\nComplex system\\nGraph\\nOperational semantics\\nProgramming language\\nComputer science\\nTheoretical computer science\\nGraph rewriting\\nAbstract machine\\nSemantics',\n",
       " 1610527: 'Speech processing in car environment.\\nYear: 1989\\n#Citations: 0\\nConference\\n\\nSpeech processing\\nComputer science\\nVoice activity detection\\nSpeech recognition\\nSpeech technology',\n",
       " 1614943: 'Learning from human errors: Prediction of phoneme confusions based on modified ASR training\\nYear: 2010\\n#Citations: 1\\nConference\\n\\nIn an attempt to improve models of human perception, the recognition of phonemes in nonsense utterances was predicted with automatic speech recognition (ASR) in order to analyze its applicability for modeling human speech recognition (HSR) in noise. In the first experiments, several feature types are used as input for an ASR system; the resulting phoneme scores are compared to listening experiments using the same speech data. With conventional training, the highest correlation between predicted and measured recognition was observed for perceptual linear prediction features (r = 0:84). Secondly, a new training paradigm for ASR is proposed with the aim of improving the prediction of phoneme intelligibility. For this perceptual training, the original utterance labels are modified based on the confusions measured in HSR tests. The modified ASR training improved the overall prediction, with the best models (r = 0:89) exceeding those obtained with conventional training (r = 0:80). Index Terms: automatic speech recognition, human speech perception, phoneme recognition\\nPerceptual linear prediction\\nComputer science\\nUtterance\\nActive listening\\nSpeech recognition\\nCorrelation\\nArtificial intelligence\\nNatural language processing\\nSpeech perception\\nPhoneme recognition\\nPerception\\nIntelligibility (communication)',\n",
       " 1619002: 'Improved Arabic-French Machine Translation through Preprocessing Schemes and Language Analysis\\nYear: 2013\\n#Citations: 3\\nConference\\nSpringer, Berlin, Heidelberg\\nArabic is a morphologically rich and complex language, which presents significant challenges for natural language processing and machine translation. In this paper, we describe an ongoing effort to build a competitive Arabic–French statistical machine translation system using the Moses decoder and other tools. The results show a significant increase in terms of Bleu score by introducing some preprocessing schemes for Arabic in addition to other language analysis rules.\\nBLEU\\nArabic\\nLanguage analysis\\nComputer science\\nMachine translation\\nMachine translation system\\nParallel corpora\\nSpeech recognition\\nPreprocessor\\nArtificial intelligence\\nNatural language processing',\n",
       " 1626643: 'A multilingual medical thesaurus browser for patients and medical content managers.\\nYear: 2001\\n#Citations: 1\\nJournal\\nStud Health Technol Inform\\nWorld Wide Web\\nInformation retrieval\\nMedicine',\n",
       " 1627759: 'DIGITAL FX!32: combining emulation and binary translation\\nYear: 1997\\n#Citations: 191\\nJournal\\nDigital Equipment Corp.\\nVol. 9 No. 4 1997 3 Spike is a performance tool developed by DIGITAL to optimize Alpha executables on the Windows NT operating system. This optimization system has two main components: the Spike Optimizer and the Spike Optimization Environment. The Spike Optimizer reads in an executable, optimizes the code, and writes out the optimized version. The Optimizer uses profile feedback from previous runs of an application to guide its optimizations. Profile feedback is not commonly used in practice because it is difficult to collect, manage, and apply profile information. The Spike Optimization Environment provides a user-transparent profile feedback system that solves most of these problems, allowing a user to easily optimize large applications composed of many executables and dynamic link libraries (DLLs). Optimizing an executable image after it has been compiled and linked has several advantages. The Spike Optimizer can see the entire image and perform interprocedural optimizations, particularly with regard to code layout. The Optimizer can use profile feedback easily, because the executable that is profiled is the same executable that is optimized; no awkward mapping of profile data back to the source language takes place. Also, Spike can be used when the sources to an application are not available, which is beneficial when DIGITAL is working with independent software vendors (ISVs) to tune applications. Applications can be loosely classified into two categories: loop-intensive programs and call-intensive programs. Conventional compiler technology is well suited to loop-intensive programs. The important loops in a program in this category are within a single procedure, which is typically the unit of compilation. The control flow is predictable, and the compiler can use simple heuristics to determine the frequently executed parts of the procedure. Spike is designed for large, call-intensive programs; it uses interprocedural optimization and profile feedback. In call-intensive programs, the important loops span multiple procedures, and the loop bodies contain procedure calls. Consequently, optimizations on the loops must be interprocedural. The control flow is Optimizing Alpha Executables on Windows NT with Spike Robert S. Cohn David W. Goodwin P. Geoffrey Lowney\\nComputer architecture\\nInterprocedural optimization\\nWindows NT\\nComputer science\\nControl flow\\nParallel computing\\nCompiler\\nBinary translation\\nSoftware\\nEmulation\\nExecutable',\n",
       " 1630115: 'A face-to-muscle inversion of a biomechanical face model for audiovisual and motor control research\\nYear: 2001\\n#Citations: 0\\nConference\\n\\nMuscle-based models of the human face produce high quality animation but rely on recorded muscle activity signals or synthetic muscle signals often derived by trial and error. In this paper we present a dynamic inversion of a muscle-based model [1] that permits the animation to be created from kinematic recordings of facial movements. Using a nonlinear optimizer (Powell’s algorithm) the inversion produces a muscle activity set for 16 muscle groups in the lower face that minimize the root mean square error between kinematic data recorded with OPTOTRAK and the corresponding nodes of the modeled facial mesh. This inverted muscle activity is then used to animate the facial model. The results of a first experiment showed that the inversion-synthesis method can accurately reproduce a synthetic facial animation, even for a partial sampling of the face. The results of a second experiment showed that the method is as successful for OPTOTRAK recording of a talker uttering a sentence. The animation was of high quality.\\nMuscle activity\\nKinematics\\nComputer science\\nInversion (meteorology)\\nMean squared error\\nArtificial intelligence\\nComputer facial animation\\nComputer vision\\nTrial and error\\nPattern recognition\\nMotor control\\nSpeech recognition\\nAnimation',\n",
       " 1634188: 'A Solution for the Naming Problem for Name-Centric Services\\nYear: 2014\\n#Citations: 1\\nConference\\nSpringer, Cham\\nIn recent past name-centric or content-centric networking (CCN) has gained substantial attention in the networking community. In a further development step name-centric service architecture enables the flexible placement and distribution of services in the network especially in a heterogeneous environment of wired and wireless (sensor) networks. However, the problem of structuring and creating hierarchies for names in name-centric networks is not solved yet. E.g. there is no configuration of service names in name-centric service WSN, no concept of unsolicited names or link-local names in CCN. In IP networks, DHCP or IPv6 auto-configuration is available, but no equivalent technique exists for CCN. We analyze the naming problem in the software development life cycle for name-centric services in WSN and propose a structure, hierarchy, and configuration mechanism for names. The paper introduces the overall concept and preliminary steps of implementation.\\nIPv6\\nService management\\nWireless\\nComputer science\\nComputer network\\nDynamic Host Configuration Protocol\\nSystems development life cycle\\nContent centric networking\\nStructuring\\nService-oriented architecture',\n",
       " 1635677: 'A Multi-level Routing Algorithms Based on Fixed Radio Wave Radius.\\nYear: 2010\\n#Citations: 0\\nConference\\n\\nEqual-cost multi-path routing\\nMultipath routing\\nLink-state routing protocol\\nDynamic Source Routing\\nComputer science\\nPath vector protocol\\nStatic routing\\nDestination-Sequenced Distance Vector routing\\nComputer network\\nRouting table\\nDistributed computing',\n",
       " 1636364: 'Research Dimensions in Information Seeking of Music: A Plea for the Socio-technical Perspective\\nYear: 2014\\n#Citations: 1\\nConference\\nSpringer, Cham\\nThis paper presents an analytical matrix for the purpose of integrating findings from different disciplines in information science related to everyday life information seeking behavior. The matrix is based on already available theoretical models and it’s anchored in the emerging socio technical perspective on information behavior and information literacy research. The Proposed matrix provides a systemic view of five different dimensions: Socio Cognitive Information Experience, Information Seeking Process, Information Retrieval and Content Consumption and Analysis. Such a merged view of different research strings is essential to develop IS which will not determine human behavior but support it in an organic way.\\nEveryday life information seeking\\nSocial psychology\\nInformation behavior\\nInformation seeking\\nInformation science\\nKnowledge management\\nPsychology\\nInformation literacy\\nPlea\\nSociotechnical system\\nSocio-cognitive',\n",
       " 1638427: 'Focused Crawling Using Vision-Based Page Segmentation\\nYear: 2012\\n#Citations: 3\\nConference\\nSpringer, Berlin, Heidelberg\\nCrawling the web to find relevant pages of the desired topics is called focused crawling. In this paper we propose a focused crawling method based on vision-based page segmentation (VIPS) algorithm. VIPS determines related parts of a web page which is called page blocks. The proposed method considers the text of the block as the link contexts of containing links of the block. Link contexts are terms that appear around the hyperlinks within the text of the web page. Since VIPS algorithm utilizes visual clues in the page segmentation process and is independent from the HTML structure of the page, it can find link contexts in an accurate manner. Our empirical study show higher performance of the proposed focused crawling method in comparison with the existing state of the art results.\\nWeb mining\\nCrawling\\nInformation retrieval\\nWeb page\\nComputer science\\nSegmentation\\nVision based\\nHyperlink\\nEmpirical research',\n",
       " 1645932: 'Toward an Open Systems Architecture.\\nYear: 1989\\n#Citations: 3\\nConference\\n\\nComputer architecture\\nApplications architecture\\nThe Open Group Architecture Framework\\nComputer science\\nSolution architecture\\nReference architecture\\nOpen systems architecture\\nEnterprise architecture framework',\n",
       " 1649711: 'A virtual reality training system for helping disabled children to acquire skills in activities of daily living\\nYear: 2014\\n#Citations: 1\\nConference\\nSpringer, Cham\\nDeficiency of hand function presents difficulty to disabled people in various activities of daily living. While rehabilitation training in occupational therapy is helpful for them to cope with their deficiency, the paper presents a virtual realty based system in attempt to provide an alternative approach to complement the conventional methods. The system simulates tasks of daily living in virtual environments and produces real-time interactive graphics and forces to enable trainees to practise the skills in cyberspace. Currently, three tasks are simulated, namely, door opening, water pouring and meat cutting. Visual, audio and haptic cues are produced as guidance in response to user’s actions. The performance of the users is recorded automatically on the fly with quantifiable metrics to enable objective analysis of the learning progress. Findings from initial trials with disabled children show that they found it very interesting to use the system and could adapt to the virtual training environment for practicing the tasks. Further study will be conducted to improve system usability and to evaluate the training effectiveness.\\nActivities of daily living\\nVirtual reality\\nTraining system\\nComputer science\\nUsability\\nHuman–computer interaction\\nVirtual training\\nOccupational therapy\\nMultimedia\\nHaptic technology\\nCyberspace',\n",
       " 1653831: 'A Collaborative Composition System Based On A Service Oriented Architecture\\nYear: 2006\\n#Citations: 0\\nConference\\nMichigan Publishing, University of Michigan Library\\nWorld Wide Web\\nComputer science\\nMultimedia\\nService-oriented architecture',\n",
       " 1655456: 'Modeling Botnet Propagation Using Time Zones.\\nYear: 2006\\n#Citations: 325\\nConference\\n\\nCutwail botnet\\nZeroAccess botnet\\nRustock botnet\\nComputer science\\nBotnet\\nComputer security\\nSrizbi botnet\\nAsprox botnet\\nMariposa botnet',\n",
       " 1657854: 'Integrating Usability Practices into Agile Development: A Case Study\\nYear: 2014\\n#Citations: 6\\nConference\\nUniversity of Zagreb\\nWithin agile software development there is a growing concern with how development organizations can integrate usability work into agile practices. The concern occurs as frustration experienced in p ...\\nInformation system\\nAgile Unified Process\\nComputer science\\nUsability engineering\\nExtreme programming practices\\nUsability\\nLean software development\\nKnowledge management\\nAgile software development\\nAgile usability engineering\\nProcess management',\n",
       " 1658645: 'Thomas Jansen: Analyzing Evolutionary Algorithms: The Computer Science Perspective: Springer, 2013, 255 pp, ISBN: 978-3-642-17338-7\\nYear: 2013\\n#Citations: 1\\nJournal\\nSpringer US\\nEvolutionary algorithm\\nComputer science\\nArtificial intelligence\\nMachine learning',\n",
       " 1658827: 'Contextual design of management support systems\\nYear: 1998\\n#Citations: 4\\nConference\\nSpringer, Boston, MA\\nA model for contextual design of Management Support Systems (MSS) is presented. The model is based on Layder’s philosophy and four levels framework of social science. Self, situated activity, setting, and context comprise the framework. The model for contextual MSS design can be used to structure, describe, and analyze the context where a MSS is used or is to be used. It can also be used to increase designers as well as other stakeholders understanding of the context where MSS design takes place.\\nSituated\\nManagement support systems\\nComputer science\\nContextual design\\nKnowledge management\\nContextual inquiry',\n",
       " 1660303: 'Survey of vertical handoff models in heterogeneous wireless networks\\nYear: 2008\\n#Citations: 0\\nConference\\n\\nB.G. Kim and Hengky Susanto Hwang S. Lee Computer Science Dept. Electrical Eng. Dept. Univ. of Mass. Lowell KAIST {kim, hsusanto}@cs.uml.edu hwanglee@ee.kaist.ac.kr    Abstract  A vertical handoff technique switches a mobile station among wireless networks with different technologies. Since a different network may not support the same QoS, the vertical handoff technique has to consider user QoS. A few vertical handoff models are described and compared in this paper. The focus of comparison is placed on objectives of the models and handoff parameters considered for the models. All models are based on a cost or a score function, which is formulated to reflect desirable QoS connections. All functions involve some type of weighting factors in incorporating various QoS parameters. Weighting factors are an important component in the decision model and most of studies use empirical data.\\nWireless network\\nWeighting\\nMobile station\\nComputer science\\nComputer network\\nQuality of service\\nDecision model\\nScore\\nHandover\\nDistributed computing',\n",
       " 1664788: 'Stochastic dynamics of logistic tumor growth\\nYear: 2009\\n#Citations: 0\\nConference\\nSpringer, Berlin, Heidelberg\\nWe investigate the effect of Gaussian white noises on the logistic growth of tumors. The model consists of the logistic growth dynamics under the influence of two Gaussian white noises, one multiplicative and the other additive. Both noises are correlated with each other. We study diverse aspects of the probability distribution of the size of the growing tumour both in the transient and steady-state regime. The simulation is based on the solution of the time-dependent Fokker-Planck equation associated with stochastic dynamics using B-spline functions\\nApplied mathematics\\nMultiplicative function\\nStochastic dynamics\\nGaussian\\nProbability distribution\\nStatistics\\nLogistic function\\nMathematics',\n",
       " 1665332: 'Performance Comparison between TEA and Rijndael Encryption Algorithm for Wireless Sensor Networks.\\nYear: 2002\\n#Citations: 1\\nConference\\n\\nKey distribution in wireless sensor networks\\nComputer science\\nAdvanced Encryption Standard\\nComputer network\\nEncryption\\nMobile wireless sensor network\\nWireless sensor network',\n",
       " 1666515: 'Log File Analysis with Context-Free Grammars\\nYear: 2013\\n#Citations: 0\\nConference\\nSpringer, Berlin, Heidelberg\\nClassical intrusion analysis of network log files uses statistical machine learning or regular expressions. Where statistically machine learning methods are not analytically exact, methods based on regular expressions do not reach up very far in Chomsky’s hierarchy of languages. This paper focuses on parsing traces of network traffic using context-free grammars. “Green grammars” are used to describe acceptable log files while “red grammars” are used to represent known intrusion patterns. This technique can complement or augment existing approaches by providing additional precision. Analytically, the technique is also more powerful than existing techniques that use regular expressions.\\nTree-adjoining grammar\\nRule-based machine translation\\nDecision problem\\nRegular expression\\nContext-free grammar\\nL-attributed grammar\\nComputer science\\nTheoretical computer science\\nParsing\\nIntrusion detection system',\n",
       " 1547990: 'Verfeinerung in objektorientierten Spezifikationen: Von Aktionen zu Transaktionen\\nYear: 1998\\n#Citations: 5\\n\\nVieweg+Teubner Verlag, Wiesbaden\\nSoftwaresysteme sind heute in allen Bereichen des offentlichen Lebens anzutreffen. Informationssysteme sind eine spezielle Art von Softwaresystemen. Wir beschaftigen uns mit dem Entwurf von Informationssystemen unter Verwendung eines objektorientierten Ansatzes. Da der Entwurfsprozes schnell unubersichtlich wird, verwenden wir die Technik der Verfeinerung zur Strukturierung und Reduktion der Komplexitat mit dem Ziel, den Grad der Wiederverwendbarkeit zu erhohen. Der objektorientierte Ansatz erfordert es, sowohl die Struktur des beabsichtigten Systems als auch dessen Verhalten zu verfeinern. Unser Ansatz basiert auf einer temporalen Logik zur Formalisierung der Systemdynamik. Im Zusammenhang mit der Verfeinerungstechnik ergeben sich einige Probleme, die wir anhand von Beispielen erlautern. Ein Losungsansatz wird intuitiv beschrieben.\\nHumanities\\nPhysics',\n",
       " 1550618: 'Supply Chain Management System and Interoperability through EAI Platform\\nYear: 2007\\n#Citations: 0\\n\\nSpringer London\\nInteroperability\\nSupply chain management\\nBusiness\\nProcess management\\nAutomotive industry',\n",
       " 1553690: 'Generalized rough sets and implication lattices\\nYear: 2011\\n#Citations: 12\\n\\nSpringer, Berlin, Heidelberg\\nThis paper consists of an extensive survey of various generalized approaches to the lower and upper approximations of a set, the two approximations being first defined by Pawlak while introducing rough set theory. Particularly, relational, covering based and operator based approaches are considered. Categorization of various approaches in terms of implication lattices is shown. Significance of this categorization in rough logics is briefly mentioned.\\nCategorization\\nDiscrete mathematics\\nLattice (order)\\nAlgebra\\nBitwise operation\\nApproximations of π\\nRough set\\nModal logic\\nPartition (number theory)\\nMathematics\\nDominance-based rough set approach',\n",
       " 1557031: 'Improving the Performance and Reliability of Mobile Commerce in Developing Countries\\nYear: 2014\\n#Citations: 2\\n\\nSpringer, Cham\\nMobile commerce (m-commerce) is currently more widely adapted in developed countries than the developing countries. Developing countries lag behind due to inappropriate technological infrastructure for the provisioning of m-commerce services. Though there exist various obstacles of adapting m-commerce services in developing countries, this paper addresses the performance and reliability issues. In particular, it considers the limited bandwidth of wireless networks and the capacity of underlying web servers involved in processing m-commerce requests. If m-commerce requests are not processed efficiently then they are more likely to be dropped wherever the network connection can be intermittent as in developing countries. This paper proposes an approach which is based on the class-based priority scheme that distinguishes m-commerce requests from other requests. The idea is to give high priority to the requests coming from mobile devices (over wireless networks) as compared to requests coming from standard PC/laptops (over standard Internet (wired) connections) as the later can tolerate longer delay and are less susceptible to connection failures. The proposed approach is formally specified and is implemented as a prototype tool. Experimental results demonstrate that the proposed approach significantly improves the performance and reliability m-commerce requests.\\nWireless network\\nComputer science\\nComputer security\\nDeveloping country\\nProvisioning\\nMobile device\\nBandwidth (signal processing)\\nMobile commerce\\nWeb server\\nThe Internet',\n",
       " 1563857: 'The ORAC Model: A Unified View of Data Abstraction.\\nYear: 1991\\n#Citations: 6\\n\\n\\nProgramming language\\nAbstraction\\nComputer science',\n",
       " 1566896: 'On e-Vertical Generated Implications\\nYear: 2011\\n#Citations: 1\\n\\nSpringer, Berlin, Heidelberg\\nRecently, a new construction method of a fuzzy implication from two given ones, called e-generation method, has been introduced. This method allows to control, up to a certain level, the increasingness on the second variable of the fuzzy implication through an adequate scaling on that variable of the two given implications. In this paper, the main goal is to reproduce the same idea but now on the first variable of the fuzzy implication. The new implications, called e-vertical generated implications, are studied in detail focusing on the preservation of the most common properties of fuzzy implications from the initial ones to the constructed implication.\\nMathematical optimization\\nFuzzy implication\\nComputer science\\nFuzzy logic\\nConstruction method\\nScaling',\n",
       " 1576036: 'Human Factors Safety Assurance for Changing ATM Systems\\nYear: 2008\\n#Citations: 1\\n\\nSpringer, London\\nThe significant contribution of human error to overall system risk for air traffic management systems has been recognised for some time. It therefore follows that when changes are being made to an ATM system, an important part of the safety assurance for that system is the risk assessment and mitigation for the human element. NATS are in the process of making a number of significant changes to their ATM systems and have been applying formalised and structured techniques for the analysis of human error. One of these techniques, the human error reduction technique for evaluating systems (HERTES), is described with reference to its successful application on the recent implementation of a new control tower at Heathrow Airport. However, it is also recognised that whilst human error assessment is a necessary component of human factors assurance, in isolation it is not sufficient. A complete framework for human factors assurance has therefore been developed and is being applied across all NATS future ATM projects.\\nFlight plan\\nAir traffic management\\nComputer science\\nSituation awareness\\nRisk assessment\\nHazard analysis\\nHuman error\\nRisk analysis (engineering)\\nHuman error assessment and reduction technique\\nSafety assurance',\n",
       " 1581016: 'Modeling and Electrical Simulations of Thin-Film Gated SOI Lateral PIN Photodetectors for High Sensitivity and Speed Performances\\nYear: 2013\\n#Citations: 1\\n\\nSpringer, Berlin, Heidelberg\\nThin-film gated SOI lateral PIN (LPIN) photodetectors was proposed, with ITO deposited on topside as transparent gate electrode. This paper investigates performances of the photodetectors versus the P-doping level in the intrinsic region (I-region), with gate voltage applied. We present analytical model and two-dimensional Atlas simulations of the current characteristics, sensitivity and speed performance. At a 400 nm wavelength, the output photocurrent approximately reaches the available photocurrent, the internal quantum efficiencies yield over 90%, even nearly 100% with various dopings. In terms of speed performances, the total -3dB frequencies of the photodetectors are up to a few tens of MHz with the intrinsic length of 8 um. And dark currents as low as 10− 14 A can give a high ratio of more than 107 between illuminated to dark currents under low-voltage operation. With such advantageous electrical characteristics, thin-film gated SOI LPIN photodetectros appear highly suitable for optical storage systems and blue DVD applications.\\nSilicon on insulator\\nPhotocurrent\\nQuantum\\nElectronic engineering\\nPhotodetector\\nOptical storage\\nThin film\\nMaterials science\\nOptoelectronics\\nWavelength\\nElectrode',\n",
       " 1581934: 'Community Planning: A Computer Simulation\\nYear: 1994\\n#Citations: 1\\n\\nElsevier Science Inc.\\nSystems engineering\\nComputer science\\nSimulation',\n",
       " 1586710: 'A unifying Kleene theorem for weighted finite automata\\nYear: 2011\\n#Citations: 4\\n\\nSpringer Berlin Heidelberg\\nWe state two variants of the Theorem of Kleene-Schutzenberger: one for arbitrary semirings and proper finite automata; the other for Conway semirings and arbitrary finite automata. Considering finite automata over partial Conway semirings over an ideal, we show that these two variants are special cases of a unifying theorem.\\nKleene algebra\\nQuantum finite automata\\nAutomata theory\\nAlgebra\\nFinite-state machine\\nMathematics',\n",
       " 1588621: 'A Coordinate System for Behaviour Models (abstract).\\nYear: 2009\\n#Citations: 0\\n\\n\\nCoordinate system\\nEllipsoidal coordinates\\nMathematical analysis\\nCoordinate space\\nPhysics',\n",
       " 1596488: 'A Situational Awareness Architecture for the Smart Grid\\nYear: 2011\\n#Citations: 11\\n\\nSpringer, Berlin, Heidelberg\\nComponents of the electric power grid that were traditionally deployed in physically isolated networks, are now using IP based, interconnected networks to transmit Supervisory Control and Data Acquisition (SCADA) messages. SCADA protocols were not designed with security in mind. Therefore, in order to enhance security, access control and risk mitigation, operators need detailed and accurate information about the status, integrity, configuration and network topology of SCADA devices. This paper describes a comprehensive system architecture that provides situational awareness (SA) for SCADA devices and their operations in a Smart Grid environment. The proposed SA architecture collects and analyzes industrial traffic and stores relevant information, verifies the integrity and the status of field devices and reports identified anomalies to operators.\\nArchitecture\\nSmart grid\\nSituation awareness\\nComputer network\\nNetwork topology\\nRisk management\\nAccess control\\nSCADA\\nSystems architecture\\nEngineering',\n",
       " 1601845: 'Performance Improvement for the HSR Ring Protocol with Traffic Control in Smart Grid\\nYear: 2012\\n#Citations: 8\\n\\nSpringer, Berlin, Heidelberg\\nHigh-availability Seamless Redundancy (HSR) protocol is proposed to recover disconnection of network within a short time. An Intelligent Electronic Device (IED) within a ring topology transmits two identical frames to the destination IED through both of the ports. This means that even in the case of disconnection of network, there is no stoppage of network operations whatsoever. However, because two identical frames are circulated inside the network, HSR protocol has a problem that causes the unnecessary traffic. This problem will degrade the network performance and may cause network congestion or delays.\\nSmart grid\\nIntelligent electronic device\\nComputer science\\nComputer network\\nNetwork operations center\\nRedundancy (engineering)\\nNetwork congestion\\nRing network\\nNetwork performance\\nPerformance improvement',\n",
       " 1605645: 'Mnemosine: Improving Life Conditions of Alzheimer Patients and Caregivers.\\nYear: 2009\\n#Citations: 0\\n\\n\\nIt is estimated that by 2050 over 100 million people will be affected by the Alzheimer’s disease. It not only affects the patient but also the whole family and specially the caregiver, who is continuously under great stress conditions. We propose a software environment, called Mnemosine, designed to improve the quality of life of both Alzheimer patients and caregivers, trying to reduce progression of disease as much as possible. Mnemosine provides the neuropsychologist and the caregiver with resources that ease monitoring the disease evolution and controlling the patient’s daily activity. Some other characteristics of Mnemosine are portability for the patient, alarms system and agenda for the patient’s daily routine, GPS route guidance and location, and predefined reports to evaluate disease progression.\\nDisease\\nQuality of life\\nStress conditions\\nDisease progression\\nSoftware portability\\nMedical emergency\\nMedicine\\nNeuropsychology',\n",
       " 1614983: 'abcnet: Literacy Tool Based on Entities.\\nYear: 2004\\n#Citations: 0\\n\\n\\nIn the 21 century the demanding for reading and writing capabilities will increase not only in the children but also in the adult generation. For adults, their level of literacy will determine the job they may get, the way they will behave as citizens, the way they will grow up their own children, etc. Literacy is the basic key tool for a successful future. Information requires literacy information is being redirected to the internet, requiring not only additional investments but also additional skills. The skills to deal with new technologies is the new challenge for the 21 century. abcNet is a web based application which aims at teaching how to read and write.\\nLiteracy\\nComputer science\\nEmerging technologies\\nWeb application\\nMultimedia\\nThe Internet',\n",
       " 1619398: 'The planet-4D model: an original hypersymmetric music space based on graph theory\\nYear: 2011\\n#Citations: 10\\n\\nSpringer, Berlin, Heidelberg\\nBeside a geometrical part that has been calculated with the help of the graph theory, the Planet-4D model includes twelve ideograms that can either symbolize notes, chords or scales depending on the context. Based on symmetry principles, it presents the following innovations:\\nGraph theory\\nAlgebra\\nPitch space\\nQuaternion\\nPure mathematics\\nHypersphere\\nPlanet\\nChord (music)\\nTonnetz\\nMathematics',\n",
       " 1623823: 'Regionwise classification of building facade images\\nYear: 2011\\n#Citations: 18\\n\\nSpringer, Berlin, Heidelberg\\nIn recent years, the classification task of building facade images receives a great deal of attention in the photogrammetry community. In this paper, we present an approach for regionwise classification using an efficient randomized decision forest classifier and local features. A conditional random field is then introduced to enforce spatial consistency between neighboring regions. Experimental results are provided to illustrate the performance of the proposed methods using image from eTRIMS database, where our focus is the object classes building, car, door, pavement, road, sky, vegetation, and window.\\nConditional random field\\nComputer vision\\nData mining\\nPhotogrammetry\\nVegetation\\nSegmentation\\nSky\\nArtificial intelligence\\nFacade\\nClassifier (linguistics)\\nRandom forest\\nGeography',\n",
       " 1625323: 'Using LTAG-Based Features for Semantic Role Labeling\\nYear: 2006\\n#Citations: 5\\n\\n\\nSemantic role labeling (SRL) methods typically use features from syntactic parse trees. We propose a novel method that uses Lexicalized Tree-Adjoining Grammar (LTAG) based features for this task. We convert parse trees into LTAG derivation trees where the semantic roles are treated as hidden information learned by supervised learning on annotated data derived from PropBank. We extracted various features from the LTAG derivation trees and trained a discriminative decision list model to predict semantic roles. We present our results on the full CoNLL 2005 SRL task.\\nComputer science\\nDecision list\\nGrammar\\nPropBank\\nSupervised learning\\nArtificial intelligence\\nNatural language processing\\nParsing\\nDiscriminative model\\nSyntax\\nSemantic role labeling\\nMachine learning',\n",
       " 1632518: 'Space Charge Layer Model: Verification by UPS, Ionic Conductivity, and Photographic Effect of AgBr.\\nYear: 2000\\n#Citations: 0\\n\\n\\nChemical physics\\nIonic potential\\nAnalytical chemistry\\nIonic conductivity\\nDepletion region\\nMaterials science',\n",
       " 1633124: \"Parallelization of Lanczos' Method and its Application in Ocean Modeling.\\nYear: 1993\\n#Citations: 0\\n\\n\\nLanczos resampling\\nComputer science\\nParallel computing\\nOcean modeling\",\n",
       " 1636197: 'Managing Information Systems in Australia and New Zealand: Requirements for the 1990s.\\nYear: 1992\\n#Citations: 10\\n\\n\\nInformation system\\nComputer science\\nEngineering management',\n",
       " 1643295: 'Performance Management at an Earth Science Supercomputer Center.\\nYear: 2003\\n#Citations: 2\\n\\n\\nSupercomputer\\nComputer science\\nComputational science\\nPerformance management',\n",
       " 1645439: 'Computing OWL Ontology Decompositions Using Resolution.\\nYear: 2007\\n#Citations: 2\\n\\n\\nReasoning over large ontologies can be done more effectively if they can be decomposed into smaller parts which can be reasoned on independently. This requires identifying parts of the ontology relevant to the problem at hand. We present a novel algorithm, based on resolution calculus, for decomposing an OWL ontology into smaller, more manageable components, such that the union of reasoning over each of these components separately is the same as reasoning over the original ontology. We describe our computational experience using the algorithm, and demonstrate that it is indeed possible to efficiently solve the standard concept subsumption reasoning problem in four large real-world OWL ontologies: SNOMED-CT, NCI, SWEET-JPL and GALEN. We chose SNOMED-CT and NCI because of their size; Galen because it is highly interconnected; SWEET-JPL because it is expressive (containing negation, both existential and universal quantifiers and both intersections and unions).\\nOntology (information science)\\nOntology\\nInformation retrieval\\nNegation\\nComputer science\\nWeb Ontology Language',\n",
       " 1656258: 'Reformulating Resolution Problems by Tactics\\nYear: 1999\\n#Citations: 0\\n\\n\\nA straightforward formulation of a mathematical problem is mostly not ad-equate for resolution theorem proving. We present a method to optimize suchformulations by exploiting the variability of first-order logic. The optimizingtransformation is described as logic morphisms, whose operationalizations aretactics. The different behaviour of a resolution theorem prover for the sourceand target formulations is demonstrated by several examples. It is shown howtactical and resolution-style theorem proving can be combined.\\nDiscrete mathematics\\nAlgebra\\nAutomated theorem proving\\nFundamental theorem\\nMathematics\\nMorphism\\nMathematical problem',\n",
       " 1667187: 'Monitoring Movement Behavior by Means of a Large Area Proximity Sensor Array in the Floor.\\nYear: 2008\\n#Citations: 19\\n\\n\\nThis paper describes an innovative sensor system which can detect and track people in a room by means of an array of capacitive sensors beneath the floor covering. By combining cutting-edge technology from the domains of capacitive sensing, wireless data transmission, interconnecting technology between textiles and microelectronics and high level data processing it is possible to support various groundbreaking applications in the domains of Ambient Assisted Living, energy saving, comfort, marketing, healthcare and security.\\nData processing\\nProximity sensor\\nWireless data transmission\\nMicroelectronics\\nComputer science\\nCapacitive sensing\\nSensor system\\nElectro-optical sensor\\nElectrical engineering',\n",
       " 1668433: 'Optimal Control of Unsteady Flows Using a Discrete and a Continuous Adjoint Approach\\nYear: 2011\\n#Citations: 15\\nConference\\nSpringer, Berlin, Heidelberg\\nWhile active flow control is an established method for controlling flow separation on vehicles and airfoils, the design of the actuation is often done by trial and error. In this paper, the development of a discrete and a continuous adjoint flow solver for the optimal control of unsteady turbulent flows governed by the incompressible Reynolds-averaged Navier-Stokes equations is presented. Both approaches are applied to testcases featuring active flow control of the blowing and suction type and are compared in terms of accuracy of the computed gradient.\\nApplied mathematics\\nAdjoint equation\\nOptimal control\\nControl theory\\nFlow separation\\nTurbulence\\nFlow (psychology)\\nSolver\\nSuction\\nAirfoil\\nMathematics',\n",
       " 1669943: 'The Height Distribution of Nodes in Non-Crossing Trees.\\nYear: 2003\\n#Citations: 3\\nJournal\\n\\nDiscrete mathematics\\nCombinatorics\\nMathematics',\n",
       " 1670048: 'Modular Form Approach to Solving Lattice Problems\\nYear: 2014\\n#Citations: 0\\nConference\\nSpringer, Cham\\nWe construct new randomized algorithms to find the exact solutions to the shortest and closest vector problems (SVP and CVP) in l2-norm for integral lattices. Not only the minimal norm of non-zero lattice vectors in SVP and the minimal distance in CVP, but also how many lattice vectors reach those minimums can be simultaneously computed. Our approach is based on special properties of the generating function of lattice vectors’ l2-norms, the lattice-associated theta function. In computational complexity perspective and take our SVP solver as an example, for the integral lattice family {Λ n } of dimension dimΛ n = n and level h n = l(Λ n ) (the minimal positive integer such that the dual lattice \\\\(\\\\Lambda_{n}^{*}\\\\) scaled by \\\\(h_{n}^{1/2}\\\\) is integral), this algorithm can find the minimal l2-norm of non-zero lattice vectors and the number of such shortest vectors in Λ n with success probability 1-e in the space-complexity of polynomial in n and time-complexity of (loglogn 2 h n ) O(n)log(1/e).\\nModular form\\nInteger\\nGenerating function\\nDiscrete mathematics\\nCombinatorics\\nPolynomial\\nLattice (order)\\nComputer science\\nTheta function\\nLattice problem\\nTime complexity',\n",
       " 1671437: 'An Efficient Algorithm for the Generation of Z-Convex Polyominoes\\nYear: 2014\\n#Citations: 4\\nConference\\nSpringer, Cham\\nWe present a characterization of Z-convex polyominoes in terms of pairs of suitable integer vectors. This lets us design an algorithm which generates all Z-convex polyominoes of size n in constant amortized time.\\nInteger\\nTetromino\\nDiscrete mathematics\\nMathematical optimization\\nCombinatorics\\nComputer science\\nAmortized analysis\\nPolyomino\\nAlgorithm\\nRegular polygon',\n",
       " 1673282: 'Hardening Access Control and Data Protection in GFS-like File Systems\\nYear: 2012\\n#Citations: 1\\nConference\\nSpringer, Berlin, Heidelberg\\nThe Google File System (GFS) is a highly distributed, faulttolerant file system designed for large files and high throughput batch processing. We consider the first complete security analysis of GFS systems. We formalize desirable security properties with respect to the successful enforcement of access control mechanisms and data confidentiality by considering a threat model that is much stronger then in previous works. We propose extensions to the GFS protocols that satisfy these properties, and provide a comprehensive analysis of the extensions, both analytically and experimentally. In a proof-of-concept implementation, we demonstrate the practicality of the extensions by showing that they incur only a 12% slowdown while offering higher-assurance guarantees.\\nFile system\\nMessage authentication code\\nThreat model\\nComputer science\\nComputer security\\nComputer network\\nSecurity analysis\\nAccess control\\nThroughput\\nData Protection Act 1998\\nDatabase server\\nDistributed computing',\n",
       " 1676246: 'Conceptual Modeling of Fuzzy Object-Oriented Database Systems.\\nYear: 2001\\n#Citations: 0\\nConference\\n\\nData mining\\nData modeling\\nConceptual schema\\nConceptual model\\nDatabase model\\nComputer science\\nConceptual graph\\nDatabase schema\\nDatabase design\\nData model',\n",
       " 1677821: 'SMS: Sequence, Motif and Structure - A Database on the Structural Rigidity of Peptide Fragments in Non-Redundant Proteins\\nYear: 2006\\n#Citations: 5\\nJournal\\nIOS Press\\nStructure prediction methods aim to identify the relationship between the amino acid sequence of an unknown protein and information comprised in databases of known protein structures. Towards this end, we created a database by combining the amino acid sequences and the corresponding three-dimensional atomic coordinates for all the 25% non-redundant protein chains available in the Protein Data Bank. It contains information about the peptide fragments that are 5 to 10 residues long. In addition, options are provided for the users to visualize the individual motifs and the superposed fragments in the client machine. Further, useful functionalities are provided to look for similar sequence motifs in all the sequence databases like PDB, 90% non-redundant protein chains, Genome database, PIR and Swiss-Prot. The database is being updated at regular intervals and the same can be accessed over the World Wide Web interface at the following URL: http://pranag.physics.iisc.ernet.in/sms/.\\nProtein structure database\\nSequence database\\nBiology\\nSequence motif\\nPeptide\\nBioinformatics\\nProtein Data Bank\\nProtein Data Bank (RCSB PDB)\\nDatabase\\nPeptide sequence\\nProtein structure',\n",
       " 1679128: 'MIS-recognized utterance detection using hierarchical language model\\nYear: 2004\\n#Citations: 0\\nConference\\nInternational Speech Communication Association\\nIn this paper, a mis-recognized utterance detection and modification scheme is proposed to recover speech recognition errors in speech translation. In a speech recognition stage, mis-recognition is frequently observed. The most of mis-recognitions result from mis-match of acoustic models and out-of-vocabulary (OOV) words. To cope with both acoustic model mis-match and OOVs, we adopt a hierarchical language model to identify them. A hierarchical language model can generate both hypotheses with and without OOVs (or acoustic mis-matched words). Likelihood difference of these hypotheses is used as utterance confidence measure. To confirm the possibility of this scheme, as a first experiment, we have conducted speech recognition experiments and mis-recognized utterance detection. Experiment results showed 99% detection rate for utterances with OOVs. This rate is considerably higher than 94% of a conventional detection method using a-posteriori probability. The rate of 80%, which is comparable to a conventional method were obtained for the utterances without OOVs. These results support the possibility of the proposed error detection and modification scheme.\\nCache language model\\nComputer science\\nUtterance\\nError detection and correction\\nSpeech recognition\\nArtificial intelligence\\nNatural language processing\\nSpeech translation\\nLanguage model\\nAcoustic model',\n",
       " 1681560: 'Towards Improving Reliability of Computational RFID Based Smart Healthcare Monitoring Systems\\nYear: 2013\\n#Citations: 0\\nConference\\nSpringer, Berlin, Heidelberg\\nAdvances in networking and small sensors (motes, RFID tags, etc) have made it possible to monitor and provide medical assistance to people in need at their homes. Recently, WISP tags, one advanced technology of Radio Frequency Identification (RFID) tags, have been used to monitor indoor activity, vital signs, sleep quality, and health status remotely. These types of systems take collaborative decision based on the data collected from all the WISP tags of the system. Any missing tag data within the environment may introduce critical error in the system’s decision and this eventually may jeopardize system’s decision reliability. In order to maintain system’s reliability, a monitoring protocol needs to be executed frequently and it should be made efficient in terms of execution time. This paper studies the problem of monitoring a large set of WISP tags and identifying the missing ones. In this paper, based on probabilistic methods, we propose a monitoring protocol for WISP based Smart Healthcare Monitoring Systems. The goal of this protocol is to improve the security and reliability of a smart healthcare monitoring system by detecting missing tags and reporting back only the data of the existing tags.\\nHealth care\\nMonitoring system\\nComputer science\\nComputer security\\nComputer network\\nProbabilistic method\\nSleep quality\\nExecution time\\nRadio-frequency identification',\n",
       " 1682202: 'Countermeasures Against Stress: Dynamic Cognitive Induction\\nYear: 1999\\n#Citations: 1\\nConference\\nL. Erlbaum Associates Inc.\\nCountermeasure\\nComputer science\\nHuman–computer interaction\\nCognition',\n",
       " 1684067: 'Migration von BULL DPS-8 auf UNIX - Ein Erfahrungsbericht.\\nYear: 1997\\n#Citations: 0\\nJournal\\n\\nKnowledge management\\nUnix\\nEngineering\\nOperating system',\n",
       " 1688939: \"Improving Model Checking Stateful Timed CSP with non-Zenoness through Clock-Symmetry Reduction\\nYear: 2013\\n#Citations: 4\\nConference\\nSpringer, Berlin, Heidelberg\\nReal-time system verification must deal with a special notion of ‘fairness’, i.e., clocks must always be able to progress. A system run which prevents clocks from progressing unboundedly is known as Zeno. Zeno runs are infeasible in reality and thus must be pruned during system verification. Though zone abstraction is an effective technique for model checking real-time systems, it is known that zone graphs (e.g., those generated from Timed Automata models) are too abstract to directly infer time progress and hence non-Zenoness. As a result, model checking with non-Zenoness (i.e., existence of a non-Zeno counterexample) based on zone graphs only is infeasible. In our previous work [23], we show that model checking Stateful Timed CSP with non-Zenoness based on zone graphs only is feasible, due to the difference between Stateful Timed CSP and Timed Automata. Nonetheless, the algorithm proposed in [23] requires to associate each time process construct with a unique clock, which could enlarge the state space (compared to model checking without non-Zenoness) significantly. In this paper, we improve our previous work by combining the checking algorithm with a clock-symmetry reduction method. The proposed algorithm has been realized in the PAT model checker for model checking LTL properties with non-Zenoness. The experimental results show that the improved algorithm significantly outperforms the previous work.\\nZeno's paradoxes\\nModel checking\\nAbstraction\\nComputer science\\nAutomaton\\nReal-time computing\\nTheoretical computer science\\nStateful firewall\\nCounterexample\\nStrongly connected component\\nState space\",\n",
       " 1689283: 'An overview of state of the art and research in the fields of sensible, latent and thermo-chemical thermal energy storage\\nYear: 2013\\n#Citations: 5\\nJournal\\nSpringer Vienna\\nDue to the increase in volatile renewable power and heat generation (wind or solar), thermal energy storage (TES) has obtained growing importance and interest. The technology can be distinguished into three main types: sensible, latent and thermochemical storage. Apart from low and medium temperature heat applications, high temperature TES also is an attractive means to store power in the form of heat (before the thermodynamic transformation process). Thermochemical storage allows for long duration seasonal storage of energy.\\nProcess engineering\\nEnergy storage\\nThermodynamics\\nThermal energy storage\\nRenewable energy\\nControl engineering\\nEnergy recovery\\nEngineering',\n",
       " 1692687: 'Rational-function-valued Valuations on Polyhedra.\\nYear: 1990\\n#Citations: 20\\nJournal\\n\\nCombinatorics\\nPolyhedron\\nRational function\\nValuation (finance)\\nMathematics',\n",
       " 1693126: 'Reproductive Health Services Discrete-Event Simulation\\nYear: 2006\\n#Citations: 0\\nConference\\nAmerican Medical Informatics Association\\nLow resource healthcare environments are often characteristic of patient flow patterns with varying patient risks, extensive patient waiting times, uneven workload distributions, and inefficient service delivery. Models from industrial and systems engineering allow for a greater examination of processes by applying discrete-event computer simulation techniques to evaluate and optimize hospital performance.\\nHealth care\\nPatient waiting\\nWorkload\\nPatient flow\\nComputer science\\nReproductive health\\nSoftware\\nManagement science\\nOperations management\\nService delivery framework\\nDiscrete event simulation',\n",
       " 1693729: 'An analysis for the causes of the academic procrastination behaviour\\nYear: 2011\\n#Citations: 0\\nConference\\nSpringer, Berlin, Heidelberg\\nIn general, the academic procrastination behaviour is a problem for many college students. A student procrastinates with regard to starting an assignment, and is unable to devote enough time to complete the assignment. As a result, there is a risk of a decrease in the quality of the assignment or of missing the deadline. This paper makes the hypothesis that procrastination is related to the following factors: (1) the difficulty of each assignment, (2) the studentu0027s interest in the programming used and in each assignment, (3) the level of procrastination, and (4) the studentu0027s understanding of the programming. This paper also performs a covariance structure analysis to confirm the relationships. According to the result of the analysis, there are also some problems in the analysis and in the model. In the future, we will improve the model and develop a system to prevent procrastination based on this model.\\nStructure analysis\\nProcrastination\\nComputer science\\nCognitive psychology\\nCovariance',\n",
       " 1695053: 'The Corporate Software Bank\\nYear: 1993\\n#Citations: 10\\nConference\\nUSENIX Association\\nThe Corporate Software Bank is the implementation of an idea borne of many hours spent installing and maintaining public domain UNIX software tools and many hours spent trying to explain the process to other UNIX workstation administrators. The Corporate Software Bank is a company-wide computing resource which makes valuable public domain software available in working form avoiding the usual pitfalls of inexperience and lack of  :[65],\"Electronics Corporation is making the transition from mainframe based computing to workgroup computing utilizing UNIX client/server technology. This has created a need for many UNIX system administrators. Like any major corporation, these administrators can range in experience from someone with no public domain software experience to the guru class  :[115],\"decentralized system administration model requires that each system administrator have all the skills necessary to meet their usersu0027 needs. Due to external factors, many system administrators are unfamiliar with Usenet/Internet related functions. Of these functions, retrieving, installing, and maintaining public domain software has become more requested from the user community. The Corporate Software Bank is an attempt to solve this problem by changing the answer from a lengthy explanation of the installation process to a simple answer of \"retrieve a file and follow the instructions to get that program and many more already in working  :[211],\"paper describes the motivation behind the Corporate Software Bank. It presents a site-dependent implementation discussing the problems encountered and solutions, when applicable. Finally, the usage history is presented and some future enhancements are suggested.\\nSoftware deployment\\nWorkgroup\\nSoftware engineering\\nComputer science\\nComputer security\\nUnix\\nSoftware system\\nSoftware\\nSystem administrator\\nArt history\\nSoftware development\\nThe Internet',\n",
       " 1697457: 'Automatic Detection of the Prosodic Structures of Speech Utterances\\nYear: 2013\\n#Citations: 8\\nConference\\nSpringer, Cham\\nThis paper presents an automatic approach for the detection of the prosodic structures of speech utterances. The algorithm relies on a hierarchical representation of the prosodic organization of the speech utterances. The approach is applied on a corpus of radio French broadcast news and also on radio and TV shows which are more spontaneous speech data. The algorithm detects prosodic boundaries whether they are followed or not by pause. The detection of the prosodic boundaries and of the prosodic structures is based on an approach that integrates little linguistic knowledge and mainly uses the amplitude of the F0 slopes and the inversion of the slopes as described in [1], as well as phone durations. The automatic prosodic segmentation results are then compared to a manual prosodic segmentation made by an expert phonetician. Finally, the results obtained by this automatic approach provide an insight into the most frequently used prosodic structures in the broadcasting speech style as well as in a more spontaneous speech style.\\nBroadcasting\\nSegmentation\\nComputer science\\nSpeech recognition\\nPhone\\nNatural language processing\\nArtificial intelligence',\n",
       " 1698166: 'A Scalable Update Protocol for Peer-to-Peer Data Grids.\\nYear: 2008\\n#Citations: 1\\nConference\\n\\nPeer-to-peer\\nComputer science\\nScalability\\nDistributed computing',\n",
       " 1698766: 'Order between logic networks and stable neural networks.\\nYear: 1997\\n#Citations: 0\\nConference\\n\\nIntelligent control\\nPhysical neural network\\nActivation function\\nComputer science\\nStochastic neural network\\nRecurrent neural network\\nTypes of artificial neural networks\\nTime delay neural network\\nArtificial intelligence\\nCellular neural network\\nMachine learning',\n",
       " 1699467: 'Towards an Infrastructure for Domain-Specific Languages in a Multi-domain Cloud Platform\\nYear: 2014\\n#Citations: 3\\nConference\\nSpringer, Cham\\nRecently, cloud computing gained more and more traction, not only in fast moving domains such as private and enterprise software, but also in more traditional domains like industrial automation. However, for rolling out automation software as a service solutions to low-end, long-tail markets with thousands of small customers important aspects for cloud scalability such as easy self service for the customer are still missing. There exists a large gap between the engineering efforts required to configure an automation system and the effort automation companies and their customers can afford. At the same time, tools for implementing Domain-Specific Languages (DSLs) have recently become more and more efficient and easy to use. Tailored DSLs that make use of abstractions for the particular (sub-)domains and omitting other complexities would allow customers to handle their applications in a SaaS-oriented, self-service manner. In this paper, we present an approach towards a model-based infrastructure for engineering languages for a multi-domain automation cloud platform that make use of modern DSL frameworks. This will allow automation SaaS providers to rapidly design sub-domain specific engineering tools based on a common platform. End-customers can then use these tailored languages to engineer their specific applications in an efficient manner.\\nDomain-specific language\\nTotally integrated automation\\nProcess automation system\\nSystems engineering\\nSoftware engineering\\nComputer science\\nEnterprise software\\nAutomation\\nSoftware as a service\\nCloud computing\\nScalability',\n",
       " 1699834: 'The Dolphin D330 Cluster Adapter Card.\\nYear: 2000\\n#Citations: 2\\nJournal\\n\\nA description of the Dolphin D330 Cluster Adapter Card and its main components and features will be given. The focus will be on the differences between the previous D320 and the new D330.\\nComputer science\\nExpansion card\\nOperating system\\nDistributed computing',\n",
       " 1702607: 'An Integrated Test Environment Process Model to Control Software Failures.\\nYear: 2008\\n#Citations: 0\\nJournal\\n\\nSystem integration testing\\nTest Management Approach\\nComputer science\\nSoftware reliability testing\\nEmpirical process (process control model)\\nSoftware construction\\nSoftware verification and validation\\nTest strategy\\nReliability engineering\\nGoal-Driven Software Development Process',\n",
       " 1705089: 'Webs, Grids and Knowledge Spaces: Programmes, Projects and Prospects.\\nYear: 2002\\n#Citations: 8\\nJournal\\n\\nMany believe that today’s Web has not yet reached the full potential which globally distributed systems may achieve in terms of information access and use. Realizing this potential may indeed turn the Web into a vast knowledge and service space. We discuss some of the issues involved and present a number of activities initiated and supported by the European Commission that are likely to make significant contributions towards attaining this goal.\\nCommission\\nComputer science\\nInformation access\\nKnowledge management',\n",
       " 1707342: 'A New Covert Image Communication Approach with HVS and GFCM\\nYear: 2009\\n#Citations: 2\\nConference\\nSpringer, Berlin, Heidelberg\\nA novel digital image covert communication algorithm is proposed to use the generalized fuzzy c-means clustering (GFCM), human visual system (HVS) and discrete cosine transform (DCT). The original image blocks are classified into two classes based on several characteristic parameters with HVS. One is suited for embedding security information, the other is not. So we can select the appropriate blocks in an image to embed the security information. The information is embedded in the original image by selectively modifying the middle-frequency part of the original image in conjunction with HVS and DCT. The maximal information strength is fixed according to the frequency masking. In the same time, for the good performance, the security information is modulated into the chaotic modulation array. The simulation results show that we can remarkably extract the hiding security information and can achieve good robustness with common signal distortion or geometric distortion and the quality of the embedded image is guaranteed.\\nComputer vision\\nEmbedding\\nComputer science\\nHuman visual system model\\nDiscrete cosine transform\\nFuzzy logic\\nDigital image\\nRobustness (computer science)\\nArtificial intelligence\\nCluster analysis\\nDistortion',\n",
       " 1708665: 'Handling Infinitely Branching WSTS\\nYear: 2014\\n#Citations: 5\\nConference\\nSpringer, Berlin, Heidelberg\\nMost decidability results concerning well-structured transition systems apply to the finitely branching variant. Yet some models (inserting automata, ω-Petri nets, ...) are naturally infinitely branching. Here we develop tools to handle infinitely branching WSTS by exploiting the crucial property that in the (ideal) completion of a well-quasi-ordered set, downward-closed sets are finite unions of ideals. Then, using these tools, we derive decidability results and we delineate the undecidability frontier in the case of the termination, the control-state maintainability and the coverability problems. Coverability and boundedness under new effectivity conditions are shown decidable.\\nDiscrete mathematics\\nForward algorithm\\nComputer science\\nAutomaton\\nDecidability\\nMaintainability\\nBranching (version control)',\n",
       " 1709287: 'Relational Structures and Dynamics of Certain Discrete Systems.\\nYear: 1973\\n#Citations: 9\\nConference\\n\\nDiscrete mathematics\\nAlgebra\\nComputer science\\nDiscrete event dynamic system\\nDiscrete modelling\\nDiscrete system',\n",
       " 1712050: 'Real-Time Smoke Rendering and Light Interaction.\\nYear: 2010\\n#Citations: 2\\nConference\\nThe Eurographics Association\\nComputer graphics (images)\\nComputer science\\nSmoke\\nRendering (computer graphics)',\n",
       " 1713610: 'Data refinement in Isabelle/HOL\\nYear: 2013\\n#Citations: 38\\nConference\\nSpringer, Berlin, Heidelberg\\nThe paper shows how the code generator of Isabelle/HOL supports data refinement, i.e., providing efficient code for operations on abstract types, e.g., sets or numbers. This allows all tools that employ code generation, e.g., Quickcheck or proof by evaluation, to compute with these abstract types. At the core is an extension of the code generator to deal with data type invariants. In order to automate the process of setting up specific data refinements, two packages for transferring definitions and theorems between types are exploited.\\nHOL\\nProgramming language\\nComputer science\\nAlgorithm\\nCode generation\\nTheoretical computer science\\nData type\\nInvariant (mathematics)',\n",
       " 1715145: 'Incorporating coverage criteria in bounded exhaustive black box test generation of structural inputs\\nYear: 2011\\n#Citations: 4\\nConference\\nSpringer, Berlin, Heidelberg\\nThe automated generation of test cases for heap allocated, complex, structures is particularly difficult. Various state of the art tools tackle this problem by bounded exhaustive exploration of potential test cases, using constraint solving mechanisms based on techniques such as search, model checking, symbolic execution and combinations of these. In this article we present a technique for improving the bounded exhaustive constraint based test case generation of structurally complex inputs, for \"filtering\" approaches. The technique works by guiding the search considering a given black box test criterion. Such a test criterion is incorporated in the constraint based mechanism so that the exploration of potential test cases can be pruned without missing coverable classes of inputs, corresponding to the test  present the :[119],\"technique, together with some case studies illustrating its performance for some black box testing criteria. The experimental results associated with these case studies are shown in the context of Korat, a state of the art tool for constraint based test case generation, but the approach is applicable in other contexts using a filtering approach to test generation.\\nBlack-box testing\\nModel checking\\nComputer science\\nSimulation\\nAlgorithm\\nWhite-box testing\\nTheoretical computer science\\nHeap (data structure)\\nTest case\\nSymbolic execution\\nEquivalence class\\nBounded function',\n",
       " 1716356: 'Passive-Aggressive Sequence Labeling with Discriminative Post-Editing for Recognising Person Entities in Tweets\\nYear: 2014\\n#Citations: 6\\nConference\\n\\nRecognising entities in social media text is difficult. NER on newswire text is conventionally cast as a sequence labeling problem. This makes implicit assumptions regarding its textual structure. Social media text is rich in disfluency and often has poor or noisy structure, and intuitively does not always satisfy these assumptions. We explore noise-tolerant methods for sequence labeling and apply discriminative post-editing to exceed state-of-the-art performance for person recognition in tweets, reaching an F1 of 84%.\\nPerson recognition\\nSocial media\\nSequence labeling\\nComputer science\\nArtificial intelligence\\nNatural language processing\\nDiscriminative model',\n",
       " 1721622: \"Personalized Recommendation by Exploring Social Users' Behaviors\\nYear: 2014\\n#Citations: 7\\nConference\\nSpringer, Cham\\nWith the popularity and rapid development of social network, more and more people enjoy sharing their experiences, such as reviews, ratings and moods. And there are great opportunities to solve the cold start and sparse data problem with the new factors of social network like interpersonal influence and interest based on circles of friends. Some algorithm models and social factors have been proposed in this domain, but have not been fully considered. In this paper, two social factors: interpersonal rating behaviors similarity and interpersonal interest similarity, are fused into a consolidated personalized recommendation model based on probabilistic matrix factorization. And the two factors can enhance the inner link between features in the latent space. We implement a series of experiments on Yelp dataset. And experimental results show the outperformance of proposed approach.\\nData science\\nSocial network\\nComputer science\\nPopularity\\nArtificial intelligence\\nInterpersonal influence\\nSparse matrix\\nRecommender system\\nProbabilistic matrix factorization\\nWorld Wide Web\\nInterpersonal communication\\nPattern recognition\\nRecommendation model\",\n",
       " 1724306: 'Classes of languages proof against regular pumping\\nYear: 1980\\n#Citations: 2\\nJournal\\nEDP Sciences\\nCombinatorics\\nComputer science\\nTheoretical computer science\\nArtificial intelligence',\n",
       " 1732060: 'Achieving Scalability and Expressivity in an RDF Knowledge Base by Implementing Contexts.\\nYear: 2006\\n#Citations: 1\\nConference\\n\\nIn this paper we are presenting the context architecture implemented on top of the RDFCore system. With this extended Knowledge Representation framework we are trying to overcome some of the limitations of RDF and OWL as they are today, without losing sight of performance and scalability issues. We are illustrating motivations – partly based on requirements in the VIKEF project – as well as theoretical background, implementation details and test-results of our latest works.\\nKnowledge representation and reasoning\\nWorld Wide Web\\nSoftware engineering\\nComputer science\\nKnowledge-based systems\\nKnowledge management\\nKnowledge extraction\\nKnowledge base\\nRDF Schema\\nRDF\\nOpen Knowledge Base Connectivity\\nScalability',\n",
       " 1736531: 'On a BPX-preconditioner for P1 elements\\nYear: 1993\\n#Citations: 44\\nJournal\\nSpringer Science and Business Media LLC\\nWe derive an optimal multilevel preconditioner for nonconforming P1 element discretizations of second order elliptic boundary value problems.\\nDiscretization\\nBoundary value problem\\nPreconditioner\\nMathematical analysis\\nMathematics\\nElliptic curve',\n",
       " 1738682: 'An algorithm for sample and data dimensionality reduction using fast simulated annealing\\nYear: 2011\\n#Citations: 9\\nConference\\nSpringer, Berlin, Heidelberg\\nThis paper deals with dimensionality and sample length reduction applied to the tasks of exploratory data analysis. Proposed technique relies on distance preserving linear transformation of given dataset to the lower dimensionality feature space. Coefficients of feature transformation matrix are found using Fast Simulated Annealing - an algorithm inspired by physical annealing of solids. Furthermore the elimination or weighting of data elements which, as an effect of above mentioned transformation, were moved significantly from the rest of the dataset can be performed. Presented method was positively verified in routines of clustering, classification and outlier detection. It ensures proper efficiency of those procedures in compact feature space and with reduced data sample length at the same time.\\nAnomaly detection\\nData mining\\nWeighting\\nDimensionality reduction\\nComputer science\\nArtificial intelligence\\nCluster analysis\\nExploratory data analysis\\nSimulated annealing\\nFeature vector\\nPattern recognition\\nAlgorithm\\nCurse of dimensionality\\nMachine learning',\n",
       " 1747233: \"Story Generation in PDDL Using Character Moods: A Case Study on Iliad's First Book\\nYear: 2014\\n#Citations: 0\\nConference\\nSpringer Verlag\\nIn this paper we look into a simple approach for generating character-based stories using planning and the language of PDDL. A story often involves modalities over properties and objects, such as what the characters believe, desire, request, etc. We look into a practical approach that reifies such modalities into normal objects of the planning domain, and relies on a “mood” predicate to represent the disposition of characters based on these objects. A short story is then generated by specifying a goal for the planning problem expressed in terms of the moods of the characters of the story. As a case study of how such a domain for story generation is modeled, we investigate the story of the first book of Homer’s Iliad as a solution of an appropriate PDDL domain and problem description.\\nModalities\\nComputer science\\nNatural language processing\\nArtificial intelligence\\nProblem description\\nPredicate (grammar)\\nMachine learning\\nPlanning Domain Definition Language\",\n",
       " 1748574: 'Simulating Working Memory Guiding Visual Attention for Capturing Target by Computational Cognitive Model\\nYear: 2011\\n#Citations: 0\\nConference\\nSpringer, Berlin, Heidelberg\\nThere are two opposite views on whether working memory can guide visual attention. Some researchers have reported that the contents of working memory guide visual attention for capturing target efficiently. However, others reported that they could not find any evidence of attention capture by working memory. In this study, it tried to find evidence for the first view with computer simulation. Two models based on two hypotheses were set up in simulating the simplified 4×4 Sudoku problem solving by which an fMRI (functional Magnetic Resonance Imaging) experiment was performed at the same time. One model is based on working memory guiding visual selective attention assumption while the other is based on no guiding random attention assumption. Both of the models predict the response time (RT) and blood oxygenation level-dependent (BOLD) response. Cognitive cost analysis on the predictions shows that more cost was occupied on no guiding model resulting in more differences between fMRI real data and predictions while the other can reduce the cost and get good fitness. This study confirms the first view and shows that working memory guiding visual search for capturing target is the intelligence of human brain in reducing the cognitive cost.\\nVisual search\\nFunctional magnetic resonance imaging\\nComputer science\\nWorking memory\\nCognitive psychology\\nResponse time\\nVisual attention\\nArtificial intelligence\\nCognitive model\\nCost analysis\\nCognition',\n",
       " 1752984: \"Prefix Table Construction and Conversion\\nYear: 2013\\n#Citations: 11\\nConference\\nSpringer, Berlin, Heidelberg\\nThe prefix table of a string x = x[1..n] is an array π = π[1..n] such that π[i] is the length of the longest substring beginning at i that equals a prefix of x. In this paper we describe and evaluate algorithms for prefix table construction, some previously proposed, others designed by us. We also describe and evaluate new linear-time algorithms for transformations between π and the border array.\\nDiscrete mathematics\\nSubstring\\nPrefix\\nKraft's inequality\\nPrefix code\\nMathematics\",\n",
       " 1766615: 'Democratic citizenship community: a social network to promote e-deliberative process\\nYear: 2009\\n#Citations: 10\\nConference\\nDigital Government Society of North America\\nSocial networks, such as virtual communities, permit connections between citizen and government. Integrating consultative and deliberative environments for popular participation in democratic issues and creating virtual communities for warranting better relationship among members make it possible to model decision-making processes. For this reason, the Democratic Citizenship Community (DCC) was developed, based on the Government-Citizen Interactive Model. The DCC has interaction and communication resources such as citizensu0027 profiles, debate, voting, information library, socialization space and usersu0027 help. This research analyzes the DCC social network in a pilot case study and presents initial discussions about this system.\\nSocial network\\nPolitical science\\nE-Government\\nVoting\\nPublic relations\\nSocialization\\nDemocracy\\nCitizenship\\nGovernment\\nVirtual community',\n",
       " 1766746: 'Nonlinear H ∞ State Feedback Control of Rigid Robot Manipulators\\nYear: 2004\\n#Citations: 3\\nConference\\nSpringer, Berlin, Heidelberg\\nIn this paper, nonlinear H ∞ control strategy is applied to control of a two-degree-of-freedom rigid robot manipulator. In order to obtain the nonlinear H ∞ control law, some inequalities so-called Hamilton-Jacobi-Isaacs (HJI) should be solved. It is so difficult, if not impossible, to find an explicit solution for HJI inequalities. However, there are some approximate solutions. One of these possible solutions is the use of Taylor Series expansion of nonlinear terms, which will be used in this paper. Using the obtained nonlinear robust controller, the response of the closed-loop system for tracking of fixed point and oscillating reference signals are obtained. Simulation results show better performance for higher order approximated controller than that of lower order one.\\nControl theory\\nNonlinear system\\nNonlinear control\\nControl theory\\nSeries expansion\\nArtificial intelligence\\nFixed point\\nRobust control\\nRobotics\\nMathematics\\nTaylor series',\n",
       " 1768292: 'On the existence of Aperiodic Perfect Maps for 2 x 2 Windows.\\nYear: 2002\\n#Citations: 1\\nJournal\\n\\nDiscrete mathematics\\nCombinatorics\\nAperiodic graph\\nMathematics',\n",
       " 1769274: 'Prosodic manifestations of confidence and uncertainty in spoken language.\\nYear: 2008\\n#Citations: 20\\nConference\\n\\nWe present a project aimed at understanding the acoustic and prosodic correlates of confidence and uncertainty in spoken language. We elicited speech produced under varying levels of certainty and performed perceptual and statistical analyses on the speech data to determine which prosodic features (e.g., pitch, energy, timing) are associated with a speaker’s level of certainty and where these prosodic manifestations occur relative to the location of the word or phrase that the speaker is confident or uncertain about. Our findings suggest that prosodic manifestations of confidence and uncertainty occur both in the local region that causes the uncertainty as well as in its surrounding context.\\nCertainty\\nComputer science\\nPhrase\\nSpeech recognition\\nArtificial intelligence\\nNatural language processing\\nPerception\\nSpoken language',\n",
       " 1770975: 'Experiments in machine learning and thinking.\\nYear: 1959\\n#Citations: 11\\nConference\\n\\nRobot learning\\nActive learning (machine learning)\\nComputer science\\nArtificial intelligence\\nError-driven learning\\nMachine learning',\n",
       " 1772954: 'Temporal Entities in the Context of Cross-Cultural Meetings and Negotiations.\\nYear: 2008\\n#Citations: 0\\nJournal\\n\\nDiscrete mathematics\\nCross-cultural\\nMathematics education\\nMathematics\\nNegotiation',\n",
       " 1776275: 'Impact of Varying Vocabularies on Controlling Motion of a Virtual Actor\\nYear: 2013\\n#Citations: 2\\nConference\\nSpringer, Berlin, Heidelberg\\nAn ideal verbally controlled virtual actor would allow the same interaction as instructing a real actor with a few words. Our goal is to create virtual actors that can be controlled with natural language instead of a predefined set of commands. In this paper, we present results related to a questionnaire where people described videos of human locomotion using verbs and modifiers. The verbs were used almost unanimously for many motions, while modifiers had more variation. The descriptions from only one person were found to cover less than half of the vocabulary of other participants. Further analysis of the vocabularies against the numerical descriptors calculated from the captured motions shows that verbs appeared in closed areas while modifiers could be scattered to disconnected clusters. Based on these findings, we propose modeling verbs with a hierarchical vocabulary and modifiers as transitions in the space defined by the numerical qualities of motions.\\nHuman locomotion\\nMotion capture\\nComputer science\\nNatural language\\nVirtual actor\\nMultimedia\\nVocabulary\\nNumerical descriptors',\n",
       " 1777938: 'Information Retrieval: Concepts and Practical Considerations for Teaching a Rising Topic.\\nYear: 2009\\n#Citations: 2\\nJournal\\n\\nThe last two decades have seen an enormous increase in the amount of information available, in the form of text documents as well as multimedia data such as images, speech and video. As a result, information retrieval (IR) has become a central topic of computer science and related disciplines and is now part of many curricula for bachelor and master programs. In this article, we outline which concepts should be integral part of IR courses depending on the orientation of the degree program (e.g. business vs. research). In addition to the theoretical content of IR courses, we also address practical considerations, based on the authors’ extensive experience in teaching IR. We comment on the suitability of a number of tools and systems and of different forms of teaching, including e-learning, in the IR classroom.\\nData mining\\nCognitive models of information retrieval\\nHuman–computer information retrieval\\nInformation retrieval\\nComputer science\\nCurriculum\\nRelevance (information retrieval)\\nBachelor',\n",
       " 1781265: 'Occlusion Invariant Face Recognition Using Two-Dimensional PCA\\nYear: 2007\\n#Citations: 13\\nConference\\nSpringer, Berlin, Heidelberg\\nSubspace analysis such as the Principal Component Analysis (PCA) and Linear Discriminant Analysis (LDA) are widely used feature extraction methods for face recognition. However, since most of them employ holistic basis, local information can not be represented in the subspace. Therefore, in general, they cannot cope with the occlusion problem in face recognition. In this paper, we propose a new method that uses the two-dimensional principal component analysis (2D PCA) for occlusion invariant face recognition. In contrast to 1D PCA, 2D PCA projects a 2D image directly onto the 2D PCA subspace, and each row of the resulting feature matrix exhibits the distribution of corresponding row of the image. Therefore by classifying each row of the feature matrix independently, we can easily identify the locally occluded parts in a face image. The proposed occlusion invariant face recognition algorithm consists of two parts: occlusion detection and partial matching. To detect occluded regions, we apply a novel combined k-NN and 1-NN classifier to each row of the feature matrix of the test face. And for partial matching, similarity between feature matrices is evaluated after removing the rows identified as the occluded parts. Experimental results on AR face database demonstrate that the proposed algorithm outperforms other existing approaches.\\nRow\\nComputer vision\\nFacial recognition system\\nEigenface\\nPattern recognition\\nSubspace topology\\nComputer science\\nFeature extraction\\nArtificial intelligence\\nInvariant (mathematics)\\nLinear discriminant analysis\\nPrincipal component analysis',\n",
       " 1782287: 'More Accurate Semantics Defining Constraint Combination for Software Systems Having Client-Server Relationships.\\nYear: 2003\\n#Citations: 1\\nConference\\n\\nIn this paper we present a new method of combining multiple precedence constraints for a single task to support software systems having client-server relationships. In these types of software systems, the combination of the precedence constraints must support the dynamic job structure of the system. Existing formalisms do not offer this support while accurately representing the desired behavior of the software. Additionally, the application of existing formalisms to software systems having periodic clients is ill defined. The new semantics presented here can be applied at the task graph level of description, support the underlying dynamic job structure of these systems, accurately represent the desired behavior of these software systems including those with periodic workloads, and easily map to commercial-off-the-shelf, asynchronous, event-driven, priority-based scheduling environments.\\nAsynchronous communication\\nComputer science\\nScheduling (computing)\\nSoftware system\\nSoftware\\nRotation formalisms in three dimensions\\nPeriodic graph (geometry)\\nSemantics\\nClient–server model\\nDistributed computing',\n",
       " 1788602: 'Semantic relatedness using salient semantic analysis\\nYear: 2011\\n#Citations: 97\\nConference\\nAAAI Press\\nThis paper introduces a novel method for measuring semantic relatedness using semantic profiles constructed from salient encyclopedic features. The model is built on the notion that the meaning of a word can be characterized by the salient concepts found in its immediate context. In addition to being computationally efficient, the new model has superior performance and remarkable consistency when compared to both knowledge-based and corpus-based state-of-the-art semantic relatedness models.\\nSemantic similarity\\nComputer science\\nSemantic equivalence\\nArtificial intelligence\\nNatural language processing\\nSemantic computing\\nSalient',\n",
       " 1789024: 'Algorithms for replace-add based paracomputers.\\nYear: 1982\\n#Citations: 5\\nConference\\n\\nComputer science\\nParallel computing\\nAnalysis of algorithms\\nProbabilistic analysis of algorithms\\nRandomized algorithms as zero-sum games',\n",
       " 1792112: 'An Efficient Heuristic for Solving an Extended Capacitated Concentrator Location Problem\\nYear: 2003\\n#Citations: 4\\nJournal\\nKluwer Academic Publishers\\nIn this paper, a mathematical model and a solution algorithm are developed for solving an extended capacitated concentrator location problem. Our model extends the conventional formulation by simultaneously addressing the two capacity constraints, total connection ports and maximum data processing rate, on each concentrator to be selected for satisfying the communication demands of the given end-user nodes. Since the problem is NP-complete, an efficient and effective Lagrangian heuristic is developed and tested by solving 100 randomly generated test problems with sizes ranging from 30(nodes)×30(concentrators) to150×30. Altogether 58% of the tested problems are solved optimally with an average solution gap 0.36% from the optimality and average solution times are from a few seconds to one half of a minute.\\nData processing\\nMathematical optimization\\nHeuristic\\nComputer science\\nLagrangian heuristic\\nInteger programming\\nRanging\\nConcentrator\\nOne half',\n",
       " 1794591: 'Speech Generation from Concept for Realizing Conversation with an Agent in a Virtual Room\\nYear: 2003\\n#Citations: 4\\nConference\\n\\nA concept to speech generation was realized in an agent dialogue system, where an agent (a stuffed animal) walked around in a small room constructed on a computer display to complete some jobs with instructions from a user. The communication between the user and the agent was done through speech. If the agent could not complete the job because of some difficulties, it tried to solve the problems through conversations with the user. Different from other spoken dialogue systems, the speech output from the agent was generated directly from the concept, and was synthesized using higher linguistic information. This scheme could largely improve the prosodic quality of speech output. In order to realize the concept to speech conversion, the linguistic information was handled as a tree structure in the whole dialogue process.\\nRule-based machine translation\\nConversation\\nSpeech output\\nComputer science\\nSpeech recognition\\nTree structure',\n",
       " 1796824: 'XI Brazilian Conference on Mathematical Logic.\\nYear: 1997\\n#Citations: 0\\nJournal\\n\\nComputer science\\nCalculus\\nMathematical logic',\n",
       " 1798268: 'Evaluating Software From a Learning-Theory Perspective\\nYear: 2002\\n#Citations: 0\\nJournal\\nACM\\nEducational gaming software is extremely adaptable to almost any teaching environment--from elementary school to college, novice to expert, cognitive to behavioral, and from the physical classroom to the virtual classroom. Presented is a review of just one of these gaming software products: RollerCoaster Tycoon.\\nComputer science\\nLearning theory\\nVirtual classroom\\nSoftware\\nDreyfus model of skill acquisition\\nCognition\\nMultimedia',\n",
       " 1803942: 'Reference Model in Design Science Research to Gather and Model Information\\nYear: 2012\\n#Citations: 8\\nConference\\n\\nDesign science research, at its current stage, does not offer consistent and detailed phases to guide researchers to manage information systems projects. In this paper we introduce a reference model that covers its phase of creating artefacts. This model serves as a base to gather relevant information in producing solutions to business’ problems in design science context. One aspect of the model is the capability to represent and reuse knowledge. In the domain context, it reflects the relevant knowledge based on domain-specific concepts and relations. This is achieved thanks to activities responsible for literature review, collaboration with practitioners, and information-modelling. The contribution of the paper is that application of the reference model helps improve the quality of design science artefacts, and provides researchers with choices of techniques that might be appropriate for most design science projects.\\nInformation system\\nReference model\\nComputer science\\nReuse\\nKnowledge management\\nDesign science research\\nDesign science\\nManagement science',\n",
       " 1807000: 'Statistical model checking, refinement checking, optimization, … for stochastic hybrid systems\\nYear: 2012\\n#Citations: 5\\nConference\\nSpringer, Berlin, Heidelberg\\nStatistical Model Checking (SMC) [19,16,21,23,15] is an approach that has recently been proposed as new validation technique for large-scale, complex systems. The core idea of SMC is to conduct some simulations of the system, monitor them, and then use statistical methods (including sequential hypothesis testing or Monte Carlo simulation) in order to decide with some degree of confidence whether the system satisfies the property or not. By nature, SMC is a compromise between testing and classical formal method techniques. Simulation-based methods are known to be far less memory and time intensive than exhaustive ones, and are some times the only option.\\nComplex system\\nMonte Carlo method\\nComputer science\\nAlgorithm\\nStatistical model checking\\nTheoretical computer science\\nFormal methods\\nSequential analysis\\nHybrid system',\n",
       " 1807198: 'A MapReduce-Based Method for Learning Bayesian Network from Massive Data\\nYear: 2013\\n#Citations: 13\\nConference\\nSpringer, Berlin, Heidelberg\\nBayesian network (BN) is the popular and important probabilistic graphical model for representing and inferring uncertain knowledge. Learning BN from massive data is the basis for uncertain-knowledge-centered inferences, prediction and decision. The inherence of massive data makes BN learning be adjusted to the large data volume and executed in parallel. In this paper, we proposed a MapReduce-based approach for learning BN from massive data by extending the traditional scoring u0026 search algorithm. First, in the scoring process, we developed map and reduce algorithms for obtaining the required parameters in parallel. Second, in the search process, for each node we developed map and reduce algorithms for scoring all the candidate local structures in parallel and selecting the local optimal structure with the highest score. Thus, the local optimal structures of each node are merged to the global optimal one. Experimental result indicates our proposed method is effective and efficient.\\nData mining\\nSearch algorithm\\nComputer science\\nInherence\\nBayesian network\\nArtificial intelligence\\nGraphical model\\nProbabilistic logic\\nDatabase\\nMachine learning',\n",
       " 1810017: 'A transition function based characterization of actions with delayed and continuous effects\\nYear: 2002\\n#Citations: 22\\nConference\\n\\nComputer science\\nAlgorithm\\nTheoretical computer science\\nTransition function',\n",
       " 1810403: 'Personality Profiling from Text and Grammar\\nYear: 2014\\n#Citations: 0\\nConference\\nSpringer, Cham\\nPersonality assessment can be used to predict subjects’ use of products and services, thriving in academic programs, and performance in work environments. To avoid the costs and inconvenience of administering personality questionnaires, researchers have inferred author personality from their writings. Extending such methods will enable marketing, interface adaptation, and a variety of data mining applications. The proposed program of research examines elements of syntax, addressing the following questions: does authors’ usage of English grammatical structures reflect their personalities? What methodology extracts and predicts personality from grammar usage? Key to this approach is the use of locally defined grammatical structures as described by Part of Speech n-grams.\\nAlternative five model of personality\\nWorld Wide Web\\nPersonality Assessment Inventory\\nPsychology\\nBig Five personality traits and culture\\nCognitive psychology\\nGrammar\\nSelf-report inventory\\nPersonality development\\nPersonality psychology\\nPersonality',\n",
       " 1813111: 'Assessing OpenMP tasking implementations on NUMA architectures\\nYear: 2012\\n#Citations: 14\\nConference\\nSpringer, Berlin, Heidelberg\\nThe introduction of task-level parallelization promises to raise the level of abstraction compared to thread-centric expression of parallelism. However, tasks might exhibit poor performance on NUMA systems if locality cannot be maintained. In contrast to traditional OpenMP worksharing constructs for which threads can be bound, the behavior of tasks is much less predetermined by the OpenMP specification and implementations have a high degree of freedom implementing task  :[67],\"different approaches to express task-parallelism, namely the single-producer and parallel-producer patterns with :[67],\"different data initialization strategies, we compare the behavior and quality of OpenMP implementations with task-parallel codes on NUMA architectures. For the programmer, we propose recipies to express parallelism with tasks allowing to preserve data locality while optimizing the degree of parallelism. Our proposals are evaluated on reasonably large NUMA systems with both important application kernels as well as a real-world simulation code.\\nComputer architecture\\nLocality\\nProgrammer\\nAbstraction\\nComputer science\\nDegree of parallelism\\nScheduling (computing)\\nParallel computing\\nThread (computing)\\nImplementation\\nInitialization',\n",
       " 1814947: 'How to prevent reinventing the wheel?: design principles for project knowledge management systems\\nYear: 2013\\n#Citations: 8\\nConference\\nSpringer, Berlin, Heidelberg\\nToday, many companies still struggle in documenting and reusing the knowledge gained by project teams. However, knowledge only creates value if it is applied. There exists a vast amount of research in the field of knowledge management focusing on documentation, storage and exchange of knowledge, but knowledge reuse is often omitted by researchers. The presented work aims to close this gap by developing a project knowledge management system enabling project teams to apply company-internal knowledge. We followed an action design research approach to explore meta-requirements in a case company, translate these requirements into design principles and test the design principles by evaluating an artifact of a project knowledge management system. By our work, the knowledge management research field can benefit since our design theory extends the existing body of knowledge. Furthermore, our research results are instantiated in a concrete artifact which can be directly transferred into practice.\\nBody of knowledge\\nKnowledge integration\\nDomain knowledge\\nPersonal knowledge management\\nKnowledge management\\nKnowledge value chain\\nProject management triangle\\nOrganizational learning\\nKnowledge engineering\\nEngineering',\n",
       " 1815792: 'Unsupervised spoken-term detection with spoken queries using segment-based dynamic time warping.\\nYear: 2010\\n#Citations: 41\\nConference\\n\\nDynamic time warping\\nPattern recognition\\nComputer science\\nSpeech recognition\\nArtificial intelligence',\n",
       " 1817027: 'A Spoken Dialogue System for Noisy Environment\\nYear: 2014\\n#Citations: 0\\nConference\\nSpringer, Cham\\nOne of the important challenges for achieving a spoken dialogue system in noisy environments is to make the system’s speech audible for the user. Although there have been many studies on speech recognition in noisy environments, very few attempts to improve the audibility of the system’s speech. In this paper, we develop a spoken dialogue system that has three functions: real-time volume adjustment, utterance delay, and re-utterance. Experimental results have shown that these three functions improve the audibility of the system’s utterances.\\nComputer science\\nUtterance\\nHuman–computer interaction',\n",
       " 1819050: 'Evolutionary Speciation Using Minimal Representation Size Clustering.\\nYear: 1995\\n#Citations: 9\\nJournal\\n\\nComputer science\\nSpeciation\\nArtificial intelligence\\nCluster analysis\\nMachine learning',\n",
       " ...}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "papers_text = pickle.load(open(\"../data/DBLP_v12/papers_text2.pkl\", \"rb\"))\n",
    "papers_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1388)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item2id = pickle.load(open(\"../data/DBLP_v12/item2id.pkl\", \"rb\"))\n",
    "min(item2id.values()), min(map(lambda x : abs(x), item2id.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rctejon/.cache/torch/hub/huggingface_pytorch-transformers_main\n",
      "Using cache found in /home/rctejon/.cache/torch/hub/huggingface_pytorch-transformers_main\n",
      "100%|██████████| 2447040/2447040 [16:12:57<00:00, 41.92it/s]  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', '../transformers/BERT/tokenizer/')\n",
    "model = torch.hub.load('huggingface/pytorch-transformers', 'model', '../transformers/BERT/model/')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "paper_embeddings = np.load(\"../data/DBLP_v12/paper_embeddings.npy\")\n",
    "\n",
    "for paper, text in tqdm(papers_text.items()):\n",
    "    model.to(device)\n",
    "    tokenization = tokenizer(text, max_length=512, padding='max_length', truncation=True, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        embedding = model(**tokenization).pooler_output.to('cpu')\n",
    "    if paper in item2id.keys():\n",
    "        paper_embeddings[item2id[paper]] = embedding\n",
    "np.save(\"../data/DBLP_v12/paper_embeddings.npy\", paper_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2942027, 768)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "paper_embeddings = np.load(\"../data/DBLP_v12/paper_embeddings.npy\")\n",
    "\n",
    "paper_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "users = pickle.load(open(f'../data/DBLP_v12/train_users_{4}.pkl', 'rb'))\n",
    "items = pickle.load(open(f'../data/DBLP_v12/train_items_{4}.pkl', 'rb'))\n",
    "ratings = pickle.load(open(f'../data/DBLP_v12/train_ratings_{4}.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "users = np.array(users)\n",
    "items = np.array(items)\n",
    "ratings = np.array(ratings)\n",
    "\n",
    "np.save(f'../data/DBLP_v12/train_users_{4}.npy', users)\n",
    "np.save(f'../data/DBLP_v12/train_items_{4}.npy', items)\n",
    "np.save(f'../data/DBLP_v12/train_ratings_{4}.npy', ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "users = np.load(f'../data/DBLP_v12/train_users_{4}.npy')\n",
    "items = np.load(f'../data/DBLP_v12/train_items_{4}.npy')\n",
    "ratings = np.load(f'../data/DBLP_v12/train_ratings_{4}.npy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
