{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "dir2 = os.path.abspath('')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: sys.path.append(dir1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rctejon/.cache/torch/hub/huggingface_pytorch-transformers_main\n",
      "/home/rctejon/Documents/tesis/Multimodal-RecSys/venv38/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using cache found in /home/rctejon/.cache/torch/hub/huggingface_pytorch-transformers_main\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-base-uncased')    # Download vocabulary from S3 and cache.\n",
    "tokenizer.save_pretrained('../transformers/BERT/tokenizer/')\n",
    "\n",
    "model = torch.hub.load('huggingface/pytorch-transformers', 'model', 'bert-base-uncased')    # Download model and configuration from S3 and cache.# tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', './test/bert_saved_model/')  # E.g. tokenizer was saved using `save_pretrained('./test/saved_model/')`\n",
    "model.save_pretrained('../transformers/BERT/model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rctejon/.cache/torch/hub/huggingface_pytorch-transformers_main\n",
      "Using cache found in /home/rctejon/.cache/torch/hub/huggingface_pytorch-transformers_main\n"
     ]
    }
   ],
   "source": [
    "tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', '../transformers/BERT/tokenizer/')\n",
    "model = torch.hub.load('huggingface/pytorch-transformers', 'model', '../transformers/BERT/model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.tokenization_utils_base.BatchEncoding"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BatchEncoding\n",
    "\n",
    "text1 = \"I really like the movie Titanic.\"\n",
    "text2 = \"I really like the book the Da Vinci Code.\"\n",
    "encoded_inputs = tokenizer([text1, text2], return_tensors='pt', max_length=16, padding='max_length', truncation=True)\n",
    "type(encoded_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input1 = tokenizer(text1, return_tensors='pt', max_length=16, padding='max_length', truncation=True)\n",
    "encoded_input2 = tokenizer(text2, return_tensors='pt', max_length=16, padding='max_length', truncation=True)\n",
    "\n",
    "encoded_inputs_list = [encoded_input1, encoded_input2]\n",
    "\n",
    "\n",
    "input_ids = torch.cat(tuple(map(lambda x: x['input_ids'], encoded_inputs_list)), dim=0)\n",
    "attention_mask = torch.cat(tuple(map(lambda x: x['attention_mask'], encoded_inputs_list)), dim=0)\n",
    "token_type_ids = torch.cat(tuple(map(lambda x: x['token_type_ids'], encoded_inputs_list)), dim=0)\n",
    "\n",
    "encoded_inputs = BatchEncoding({'input_ids': input_ids, 'attention_mask': attention_mask, 'token_type_ids': token_type_ids})\n",
    "encoded_inputs.input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0 device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9141, -0.4043, -0.8202,  ..., -0.7174, -0.6313,  0.9061],\n",
       "        [-0.9036, -0.3730, -0.6548,  ..., -0.5355, -0.6265,  0.9074]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "encoded_inputs = encoded_inputs.to(device)\n",
    "model = model.to(device)\n",
    "output = model(**encoded_inputs)\n",
    "output.pooler_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2100e+00,  1.7972e+00,  8.3262e-01,  ...,  1.3088e+00,\n",
       "          8.3779e-01, -1.3769e+00],\n",
       "        [ 7.6178e-02,  5.9780e-01, -4.7973e-02,  ...,  2.5567e-01,\n",
       "         -8.1189e-01,  7.5764e-02],\n",
       "        [ 2.5063e-02,  7.6688e-01, -6.1524e-01,  ..., -9.7178e-01,\n",
       "         -1.1545e-01, -1.4916e-01],\n",
       "        ...,\n",
       "        [-2.0185e+00, -1.0795e+00, -3.1225e-01,  ...,  1.3692e-03,\n",
       "         -6.8215e-01, -1.3954e-01],\n",
       "        [-1.0053e+00, -7.6392e-01,  3.1799e-01,  ..., -7.2641e-03,\n",
       "         -8.7118e-02, -3.6104e-01],\n",
       "        [-8.4138e-01, -8.0648e-01,  8.8313e-02,  ..., -1.9819e+00,\n",
       "         -7.0850e-01, -6.3064e-03]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = torch.randn(256, 1, 768).reshape(256, 768)\n",
    "v2 = torch.randn(256, 8)\n",
    "v3 = torch.randn(256, 32)\n",
    "\n",
    "v = torch.cat((v1, v2, v3), dim=1)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0 device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rctejon/.cache/torch/hub/huggingface_pytorch-transformers_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/MOOCCubeX/train.feather\n",
      "     id  course_id  rating\n",
      "0  U_24     597214       1\n",
      "1  U_24     605512       1\n",
      "2  U_24     597211       1\n",
      "3  U_24     597314       1\n",
      "4  U_24     597208       1\n",
      "id           object\n",
      "course_id     int64\n",
      "rating        int64\n",
      "dtype: object\n",
      "Begin Tokenization\n",
      "   course_id                                       tokenization\n",
      "0     584313  {'input_ids': [[tensor(101), tensor(8476), ten...\n",
      "1     584329  {'input_ids': [[tensor(101), tensor(8476), ten...\n",
      "2     584381  {'input_ids': [[tensor(101), tensor(8476), ten...\n",
      "3     597208  {'input_ids': [[tensor(101), tensor(8476), ten...\n",
      "4     597225  {'input_ids': [[tensor(101), tensor(6412), ten...\n",
      "course_id        int64\n",
      "tokenization    object\n",
      "dtype: object\n",
      "{'input_ids': tensor([[ 101, 6412, 1024,  102,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from metrics.metrics import metrics\n",
    "from architectures.BertMF.bert_mf import BertMF\n",
    "from loaders.create_dataloader import CreateDataloader\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "def tokenize(text, tokenizer, max_length):\n",
    "    \"\"\"\n",
    "    Tokenize the text\n",
    "    \"\"\"\n",
    "    tokenization = tokenizer(text, max_length=max_length, padding='max_length', truncation=True, return_tensors='pt')\n",
    "\n",
    "    tokenization = {\n",
    "        'input_ids': tokenization['input_ids'],\n",
    "        'attention_mask': tokenization['attention_mask'],\n",
    "        'token_type_ids': tokenization['token_type_ids']\n",
    "    }\n",
    "    return tokenization\n",
    "\n",
    "\n",
    "def create_text_df(tokenizer, max_length):\n",
    "    \"\"\"\n",
    "    Create a dataframe from the text dictionary\n",
    "    \"\"\"\n",
    "    course_texts = pickle.load(open('../pickles/course_texts.pkl', 'rb'))\n",
    "    text_df = pd.DataFrame.from_dict(course_texts, orient='index')\n",
    "    text_df.reset_index(inplace=True)\n",
    "    text_df.columns = ['course_id', 'text']\n",
    "    text_df['course_id'] = text_df['course_id'].apply(lambda x: x.split('_')[-1])\n",
    "    text_df['course_id'] = text_df['course_id'].astype(int)\n",
    "    text_df['text'] = text_df['text'].astype(str)\n",
    "    text_df['tokenization'] = text_df['text'].apply(lambda x: tokenize(x, tokenizer, max_length))\n",
    "    text_df.drop(columns=['text'], inplace=True)\n",
    "    return text_df\n",
    "\n",
    "def _reindex(ratings):\n",
    "    \"\"\"\n",
    "    Process dataset to reindex userID and itemID, also set rating as binary feedback\n",
    "    \"\"\"\n",
    "    user2id = pickle.load(open(MAIN_PATH + 'user2id.pkl', 'rb'))\n",
    "\n",
    "    item2id = pickle.load(open(MAIN_PATH + 'item2id.pkl', 'rb'))\n",
    "\n",
    "    ratings['user_id'] = ratings['user_id'].apply(lambda x: user2id[x])\n",
    "    ratings['item_id'] = ratings['item_id'].apply(lambda x: item2id[x])\n",
    "    ratings['rating'] = ratings['rating'].apply(lambda x: float(x > 0))\n",
    "    return ratings\n",
    "\n",
    "DATASET_NAME = 'MOOCCubeX'\n",
    "MODEL_NAME = 'BertMF'\n",
    "TRAIN_DATASET_FILE = 'train.feather'\n",
    "TEST_DATASET_FILE = 'test.feather'\n",
    "MAIN_PATH = f'../data/{DATASET_NAME}/'\n",
    "TRAIN_DATA_PATH = MAIN_PATH + TRAIN_DATASET_FILE\n",
    "TEST_DATA_PATH = MAIN_PATH + TEST_DATASET_FILE\n",
    "MODEL_PATH = f'../models/{DATASET_NAME}/'\n",
    "MODEL = f'{DATASET_NAME}-{MODEL_NAME}'\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "\n",
    "# set device and parameters\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# seed for Reproducibility\n",
    "seed_everything(51)\n",
    "\n",
    "tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', '../transformers/BERT/tokenizer/')\n",
    "\n",
    "# load data\n",
    "print(TRAIN_DATA_PATH)\n",
    "train_rating_data = pd.read_feather(TRAIN_DATA_PATH)\n",
    "test_rating_data = pd.read_feather(TEST_DATA_PATH)\n",
    "print(train_rating_data.head())\n",
    "print(train_rating_data.dtypes)\n",
    "print('Begin Tokenization')\n",
    "text_df = create_text_df(tokenizer=tokenizer, max_length=16)\n",
    "print(text_df.head())\n",
    "print(text_df.dtypes)\n",
    "\n",
    "train_rating_data = train_rating_data.merge(text_df, how='left', on='course_id')\n",
    "test_rating_data = test_rating_data.merge(text_df, how='left', on='course_id')\n",
    "\n",
    "default_tokenization = tokenize('Description: ', tokenizer, 16)\n",
    "\n",
    "print(default_tokenization)\n",
    "\n",
    "train_rating_data['tokenization'] = train_rating_data['tokenization'].apply(lambda x: default_tokenization if type(x) == float else x)\n",
    "test_rating_data['tokenization'] = test_rating_data['tokenization'].apply(lambda x: default_tokenization if type(x) == float else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>course_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>tokenization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U_24</td>\n",
       "      <td>597214</td>\n",
       "      <td>1</td>\n",
       "      <td>{'input_ids': [[tensor(101), tensor(6412), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U_24</td>\n",
       "      <td>605512</td>\n",
       "      <td>1</td>\n",
       "      <td>{'input_ids': [[tensor(101), tensor(6412), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U_24</td>\n",
       "      <td>597211</td>\n",
       "      <td>1</td>\n",
       "      <td>{'input_ids': [[tensor(101), tensor(6412), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U_24</td>\n",
       "      <td>597314</td>\n",
       "      <td>1</td>\n",
       "      <td>{'input_ids': [[tensor(101), tensor(8476), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U_24</td>\n",
       "      <td>597208</td>\n",
       "      <td>1</td>\n",
       "      <td>{'input_ids': [[tensor(101), tensor(8476), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6683569</th>\n",
       "      <td>U_34712108</td>\n",
       "      <td>782490</td>\n",
       "      <td>1</td>\n",
       "      <td>{'input_ids': [[tensor(101), tensor(6412), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6683570</th>\n",
       "      <td>U_34712115</td>\n",
       "      <td>883345</td>\n",
       "      <td>1</td>\n",
       "      <td>{'input_ids': [[tensor(101), tensor(6412), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6683571</th>\n",
       "      <td>U_34712115</td>\n",
       "      <td>770738</td>\n",
       "      <td>1</td>\n",
       "      <td>{'input_ids': [[tensor(101), tensor(6412), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6683572</th>\n",
       "      <td>U_34712115</td>\n",
       "      <td>676937</td>\n",
       "      <td>1</td>\n",
       "      <td>{'input_ids': [[tensor(101), tensor(8476), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6683573</th>\n",
       "      <td>U_34712115</td>\n",
       "      <td>694136</td>\n",
       "      <td>1</td>\n",
       "      <td>{'input_ids': [[tensor(101), tensor(6412), ten...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6683574 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  course_id  rating  \\\n",
       "0              U_24     597214       1   \n",
       "1              U_24     605512       1   \n",
       "2              U_24     597211       1   \n",
       "3              U_24     597314       1   \n",
       "4              U_24     597208       1   \n",
       "...             ...        ...     ...   \n",
       "6683569  U_34712108     782490       1   \n",
       "6683570  U_34712115     883345       1   \n",
       "6683571  U_34712115     770738       1   \n",
       "6683572  U_34712115     676937       1   \n",
       "6683573  U_34712115     694136       1   \n",
       "\n",
       "                                              tokenization  \n",
       "0        {'input_ids': [[tensor(101), tensor(6412), ten...  \n",
       "1        {'input_ids': [[tensor(101), tensor(6412), ten...  \n",
       "2        {'input_ids': [[tensor(101), tensor(6412), ten...  \n",
       "3        {'input_ids': [[tensor(101), tensor(8476), ten...  \n",
       "4        {'input_ids': [[tensor(101), tensor(8476), ten...  \n",
       "...                                                    ...  \n",
       "6683569  {'input_ids': [[tensor(101), tensor(6412), ten...  \n",
       "6683570  {'input_ids': [[tensor(101), tensor(6412), ten...  \n",
       "6683571  {'input_ids': [[tensor(101), tensor(6412), ten...  \n",
       "6683572  {'input_ids': [[tensor(101), tensor(8476), ten...  \n",
       "6683573  {'input_ids': [[tensor(101), tensor(6412), ten...  \n",
       "\n",
       "[6683574 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rating_data['tokenization'] = train_rating_data['tokenization'].apply(lambda x: default_tokenization if type(x) == float else x)\n",
    "train_rating_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id  course_id  rating                                       tokenization\n",
      "0  U_24     597214       1  {'input_ids': [[tensor(101), tensor(6412), ten...\n",
      "1  U_24     605512       1  {'input_ids': [[tensor(101), tensor(6412), ten...\n",
      "2  U_24     597211       1  {'input_ids': [[tensor(101), tensor(6412), ten...\n",
      "3  U_24     597314       1  {'input_ids': [[tensor(101), tensor(8476), ten...\n",
      "4  U_24     597208       1  {'input_ids': [[tensor(101), tensor(8476), ten...\n",
      "694530 4701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../transformers/BERT/model/'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_rating_data.head())\n",
    "\n",
    "train_rating_data = train_rating_data.rename(columns={'id': 'user_id', 'course_id': 'item_id'})\n",
    "test_rating_data = test_rating_data.rename(columns={'id': 'user_id', 'course_id': 'item_id'})\n",
    "\n",
    "ratings = pd.concat([train_rating_data, test_rating_data], ignore_index=True)\n",
    "\n",
    "tokenizations = None\n",
    "\n",
    "if not os.path.exists(f'{MAIN_PATH}/test_tokenizations_{100}.pkl') and not os.path.exists(f'{MAIN_PATH}/train_tokenizations_{4}.pkl'):\n",
    "    tokenizations = ratings[['item_id', 'tokenization']].drop_duplicates(subset=['item_id'])\n",
    "    tokenizations.set_index('item_id', inplace=True)\n",
    "\n",
    "# set the num_users, items\n",
    "num_users = ratings['user_id'].nunique()+1\n",
    "num_items = ratings['item_id'].nunique()+1\n",
    "\n",
    "print(num_users, num_items)\n",
    "\n",
    "train_rating_data = _reindex(train_rating_data)\n",
    "test_rating_data = _reindex(test_rating_data)\n",
    "\n",
    "\n",
    "# construct the train and test datasets\n",
    "class Args:\n",
    "    def __init__(self, num_ng, num_ng_test, batch_size, seed, factor_num, layers, dropout, lr, token_size, bert_path):\n",
    "        self.num_ng = num_ng\n",
    "        self.num_ng_test = num_ng_test\n",
    "        self.batch_size = batch_size\n",
    "        self.seed = seed\n",
    "        self.factor_num = factor_num\n",
    "        self.layers = layers\n",
    "        self.dropout = dropout\n",
    "        self.lr = lr\n",
    "        self.token_size = token_size\n",
    "        self.bert_path = bert_path\n",
    "args = Args(4, 100, 256, 51, 32, [64,32,16,8], 0.1, 0.001, 768, '../transformers/BERT/model/')\n",
    "\n",
    "args.bert_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6683574, 4) (1983584, 4) (8667158, 4)\n",
      "Create Train Data Loader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rctejon/.cache/torch/hub/huggingface_pytorch-transformers_main\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "130539"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "data = CreateDataloader(args, train_rating_data, test_rating_data, MAIN_PATH, True, tokenizations)\n",
    "print('Create Train Data Loader')\n",
    "train_loader = data.get_train_instance()\n",
    "\n",
    "# set model and loss, optimizer\n",
    "model = BertMF(args, num_users, num_items)\n",
    "# model = torch.load('{}{}.pth'.format(MODEL_PATH, MODEL))\n",
    "model = model.to(device)\n",
    "# print(model)\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "it = iter(train_loader)\n",
    "len(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.007116079330444336 seconds\n",
      "Time: 0.1030416488647461 seconds\n",
      "Time: 0.10625696182250977 seconds\n",
      "Time: 0.11337614059448242 seconds\n",
      "Time: 0.11348271369934082 seconds\n",
      "Time: 0.11427831649780273 seconds\n",
      "Time: 0.1149754524230957 seconds\n",
      "Time: 0.12044954299926758 seconds\n",
      "Time: 0.11875534057617188 seconds\n",
      "Time: 0.11550736427307129 seconds\n",
      "Time: 0.11506247520446777 seconds\n",
      "Time: 0.11113834381103516 seconds\n",
      "Time: 0.11017680168151855 seconds\n",
      "Time: 0.11149883270263672 seconds\n",
      "Time: 0.10703921318054199 seconds\n",
      "Time: 0.11527228355407715 seconds\n",
      "Time: 0.11738753318786621 seconds\n",
      "Time: 0.11019325256347656 seconds\n",
      "Time: 0.1103053092956543 seconds\n",
      "Time: 0.11354207992553711 seconds\n",
      "Time: 0.1093144416809082 seconds\n",
      "Time: 0.11489200592041016 seconds\n",
      "Time: 0.11279964447021484 seconds\n",
      "Time: 0.11248922348022461 seconds\n",
      "Time: 0.12108135223388672 seconds\n",
      "Time: 0.1065976619720459 seconds\n",
      "Time: 0.11140894889831543 seconds\n",
      "Time: 0.10970830917358398 seconds\n",
      "Time: 0.11317229270935059 seconds\n",
      "Time: 0.10523509979248047 seconds\n",
      "Time: 0.11643409729003906 seconds\n",
      "Time: 0.11367678642272949 seconds\n",
      "Time: 0.11499977111816406 seconds\n",
      "Time: 0.1153414249420166 seconds\n",
      "Time: 0.10905647277832031 seconds\n",
      "Time: 0.11140012741088867 seconds\n",
      "Time: 0.11136031150817871 seconds\n",
      "Time: 0.11364912986755371 seconds\n",
      "Time: 0.1062784194946289 seconds\n",
      "Time: 0.11713814735412598 seconds\n",
      "Time: 0.1137242317199707 seconds\n",
      "Time: 0.11281251907348633 seconds\n",
      "Time: 0.11426663398742676 seconds\n",
      "Time: 0.11278867721557617 seconds\n",
      "Time: 0.1108705997467041 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      6\u001b[0m user, item, label, tokenization \u001b[38;5;241m=\u001b[39m t\n\u001b[0;32m----> 8\u001b[0m user \u001b[38;5;241m=\u001b[39m \u001b[43muser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m item \u001b[38;5;241m=\u001b[39m item\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     10\u001b[0m label \u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "\n",
    "t = next(it, None)\n",
    "while t is not None:\n",
    "    start_time = time.time()\n",
    "    user, item, label, tokenization = t\n",
    "\n",
    "    user = user.to(device)\n",
    "    item = item.to(device)\n",
    "    label = label.to(device)\n",
    "    tokenization = tokenization.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    prediction = model(user, item, tokenization)\n",
    "    loss = loss_function(prediction, label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    end_time = time.time()\n",
    "    t = next(it, None)\n",
    "    print(f\"Time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/130539 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 163/130539 [00:27<6:08:51,  5.89it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 11\u001b[0m\n\u001b[1;32m      5\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m user, item, label, tokenization \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# print(user.size(), item.size(), label.size())\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# print(user, item, label)\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     user \u001b[38;5;241m=\u001b[39m \u001b[43muser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     item \u001b[38;5;241m=\u001b[39m item\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m     label \u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# train, evaluation\n",
    "best_hr = 0\n",
    "for epoch in range(1, 1+1):\n",
    "    model.train() # Enable dropout (if have).\n",
    "    start_time = time.time()\n",
    "\n",
    "    for user, item, label, tokenization in tqdm(train_loader):\n",
    "        # print(user.size(), item.size(), label.size())\n",
    "        # print(user, item, label)\n",
    "        \n",
    "        user = user.to(device)\n",
    "        item = item.to(device)\n",
    "        label = label.to(device)\n",
    "        tokenization = tokenization.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # print('Zero Grad')\n",
    "        prediction = model(user, item, tokenization)\n",
    "        # print('Prediction')\n",
    "        loss = loss_function(prediction, label)\n",
    "        # print('Loss')\n",
    "        loss.backward()\n",
    "        # print('Backward')\n",
    "        optimizer.step()\n",
    "        # print('Step')\n",
    "        time.sleep(0.03)\n",
    "\n",
    "    print('Epoch: {}, Loss: {:.4f}'.format(epoch, loss.item()))\n",
    "    print('epoch time: {:.4f}s'.format(time.time()-start_time))\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    os.mkdir(MODEL_PATH)\n",
    "torch.save(model,\n",
    "    '{}{}.pth'.format(MODEL_PATH, MODEL))\n",
    "\n",
    "print('Train done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
