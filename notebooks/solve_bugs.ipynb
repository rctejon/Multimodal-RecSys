{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "dir2 = os.path.abspath('')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: sys.path.append(dir1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from tensorboardX import SummaryWriter\n",
    "from architectures.NeuMF.neu_mf import NeuMF\n",
    "from loaders.create_dataloader import CreateDataloader\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'MOOCCubeX'\n",
    "MODEL_NAME = 'NeuMF'\n",
    "TRAIN_DATASET_FILE = 'train.feather'\n",
    "TEST_DATASET_FILE = 'test.feather'\n",
    "MAIN_PATH = f'../data/{DATASET_NAME}/'\n",
    "TRAIN_DATA_PATH = MAIN_PATH + TRAIN_DATASET_FILE\n",
    "TEST_DATA_PATH = MAIN_PATH + TEST_DATASET_FILE\n",
    "MODEL = f'{DATASET_NAME}-{MODEL_NAME}'\n",
    "MODEL_PATH = f'../models/{DATASET_NAME}/{MODEL}.pth'\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reindex(ratings):\n",
    "    \"\"\"\n",
    "    Process dataset to reindex userID and itemID, also set rating as binary feedback\n",
    "    \"\"\"\n",
    "    user2id = pickle.load(open(MAIN_PATH + 'user2id.pkl', 'rb'))\n",
    "\n",
    "    item2id = pickle.load(open(MAIN_PATH + 'item2id.pkl', 'rb'))\n",
    "\n",
    "    ratings['user_id'] = ratings['user_id'].apply(lambda x: user2id[x])\n",
    "    ratings['item_id'] = ratings['item_id'].apply(lambda x: item2id[x])\n",
    "    ratings['rating'] = ratings['rating'].apply(lambda x: float(x > 0))\n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0 device\n"
     ]
    }
   ],
   "source": [
    "# set device and parameters\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# seed for Reproducibility\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/MOOCCubeX/train.feather\n",
      "     id  course_id  rating\n",
      "0  U_24     948415       1\n",
      "1  U_24     948410       1\n",
      "2  U_24    1808023       1\n",
      "3  U_24    1906706       1\n",
      "4  U_24     681414       1\n",
      "694530 4506\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "print(TRAIN_DATA_PATH)\n",
    "train_rating_data = pd.read_feather(TRAIN_DATA_PATH)\n",
    "test_rating_data = pd.read_feather(TEST_DATA_PATH)\n",
    "print(test_rating_data.head())\n",
    "\n",
    "train_rating_data = train_rating_data.rename(columns={'id': 'user_id', 'course_id': 'item_id'})\n",
    "test_rating_data = test_rating_data.rename(columns={'id': 'user_id', 'course_id': 'item_id'})\n",
    "\n",
    "# set the num_users, items\n",
    "num_users = train_rating_data['user_id'].nunique()+1\n",
    "num_items = train_rating_data['item_id'].nunique()+1\n",
    "\n",
    "print(num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>419025</td>\n",
       "      <td>2878</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>419025</td>\n",
       "      <td>2873</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>419025</td>\n",
       "      <td>3599</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>419025</td>\n",
       "      <td>3890</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>419025</td>\n",
       "      <td>681</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983579</th>\n",
       "      <td>627567</td>\n",
       "      <td>2415</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983580</th>\n",
       "      <td>627567</td>\n",
       "      <td>2453</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983581</th>\n",
       "      <td>627568</td>\n",
       "      <td>2331</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983582</th>\n",
       "      <td>627569</td>\n",
       "      <td>3135</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983583</th>\n",
       "      <td>627569</td>\n",
       "      <td>1691</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1983584 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  item_id  rating\n",
       "0         419025     2878     1.0\n",
       "1         419025     2873     1.0\n",
       "2         419025     3599     1.0\n",
       "3         419025     3890     1.0\n",
       "4         419025      681     1.0\n",
       "...          ...      ...     ...\n",
       "1983579   627567     2415     1.0\n",
       "1983580   627567     2453     1.0\n",
       "1983581   627568     2331     1.0\n",
       "1983582   627569     3135     1.0\n",
       "1983583   627569     1691     1.0\n",
       "\n",
       "[1983584 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rating_data = _reindex(train_rating_data)\n",
    "test_rating_data = _reindex(test_rating_data)\n",
    "test_rating_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=256, dropout=0.2, epochs=10, factor_num=32, layers=[64, 32, 16, 8], lr=0.001, num_ng=4, num_ng_test=100, out=True, seed=42, top_k=10)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--seed\",\n",
    "\ttype=int,\n",
    "\tdefault=42,\n",
    "\thelp=\"Seed\")\n",
    "parser.add_argument(\"--lr\",\n",
    "\ttype=float,\n",
    "\tdefault=0.001,\n",
    "\thelp=\"learning rate\")\n",
    "parser.add_argument(\"--dropout\",\n",
    "\ttype=float,\n",
    "\tdefault=0.2,\n",
    "\thelp=\"dropout rate\")\n",
    "parser.add_argument(\"--batch_size\",\n",
    "\ttype=int,\n",
    "\tdefault=256,\n",
    "\thelp=\"batch size for training\")\n",
    "parser.add_argument(\"--epochs\",\n",
    "\ttype=int,\n",
    "\tdefault=10,\n",
    "\thelp=\"training epoches\")\n",
    "parser.add_argument(\"--top_k\",\n",
    "\ttype=int,\n",
    "\tdefault=10,\n",
    "\thelp=\"compute metrics@top_k\")\n",
    "parser.add_argument(\"--factor_num\",\n",
    "\ttype=int,\n",
    "\tdefault=32,\n",
    "\thelp=\"predictive factors numbers in the model\")\n",
    "parser.add_argument(\"--layers\",\n",
    "    nargs='+',\n",
    "    default=[64,32,16,8],\n",
    "    help=\"MLP layers. Note that the first layer is the concatenation of user \\\n",
    "    and item embeddings. So layers[0]/2 is the embedding size.\")\n",
    "parser.add_argument(\"--num_ng\",\n",
    "\ttype=int,\n",
    "\tdefault=4,\n",
    "\thelp=\"Number of negative samples for training set\")\n",
    "parser.add_argument(\"--num_ng_test\",\n",
    "\ttype=int,\n",
    "\tdefault=100,\n",
    "\thelp=\"Number of negative samples for test set\")\n",
    "parser.add_argument(\"--out\",\n",
    "\tdefault=True,\n",
    "\thelp=\"save model or not\")\n",
    "args = parser.parse_args(\"\")\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative sampling\n",
      "done\n",
      "Create Train Data Loader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6683574/6683574 [00:09<00:00, 708980.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Test Data Loader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1983584/1983584 [00:35<00:00, 55529.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# construct the train and test datasets\n",
    "\n",
    "data = CreateDataloader(args, train_rating_data, test_rating_data)\n",
    "print('Create Train Data Loader')\n",
    "train_loader = data.get_train_instance()\n",
    "print('Create Test Data Loader')\n",
    "test_loader = data.get_test_instance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def hit(ng_items, pred_items):\n",
    "\tfor ng_item in ng_items:\n",
    "\t\tif ng_item in pred_items:\n",
    "\t\t\treturn 1\n",
    "\treturn 0\n",
    "\n",
    "\n",
    "def idcg(ng_items):\n",
    "\tidcg = 0\n",
    "\tfor i in range(len(ng_items)):\n",
    "\t\tidcg += np.reciprocal(np.log2(i+2))\n",
    "\treturn idcg\n",
    "\n",
    "\n",
    "def ndcg(ng_items, pred_items):\n",
    "\tdcg = 0\n",
    "\tfor ng_item in ng_items:\n",
    "\t\tif ng_item in pred_items:\n",
    "\t\t\tindex = pred_items.index(ng_item)\n",
    "\t\t\tdcg += np.reciprocal(np.log2(index+2))\n",
    "\treturn dcg / idcg(ng_items)\n",
    "\n",
    "\n",
    "def mrr(ng_items, pred_items):\n",
    "\tmin_index = 999\n",
    "\tfor ng_item in ng_items:\n",
    "\t\tif ng_item in pred_items:\n",
    "\t\t\tindex = pred_items.index(ng_item)\n",
    "\t\t\tif index < min_index:\n",
    "\t\t\t\tmin_index = index\n",
    "\tif min_index != 999:\n",
    "\t\treturn np.reciprocal(float(min_index+1))\n",
    "\treturn 0\n",
    "\n",
    "\n",
    "def metrics(model, test_loader, top_k, device):\n",
    "\tHR, NDCG, MRR = [], [], []\n",
    "\t\n",
    "\tprint(len(test_loader))\n",
    "\tfor user, item, label in tqdm(test_loader, total=len(test_loader)):\n",
    "\t\tuser = user.to(device)\n",
    "\t\titem = item.to(device)\n",
    "\n",
    "\t\tpredictions = model(user, item)\n",
    "\t\t_, indices = torch.topk(predictions, top_k)\n",
    "\t\trecommends = torch.take(\n",
    "\t\t\t\titem, indices).cpu().numpy().tolist()\n",
    "\n",
    "\t\tng_items = []\n",
    "\n",
    "\t\tfor i in range(user.size(0)):\n",
    "\t\t\tif label[i].item() != 0:\n",
    "\t\t\t\tng_item = item[i].item()\n",
    "\t\t\t\tng_items.append(ng_item)\n",
    "\t\t\t\n",
    "\t\tHR.append(hit(ng_items, recommends))\n",
    "\t\tNDCG.append(ndcg(ng_items, recommends))\n",
    "\t\tMRR.append(mrr(ng_items, recommends))\n",
    "\treturn np.mean(HR), np.mean(NDCG), np.mean(MRR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuMF(\n",
      "  (embedding_user_mlp): Embedding(694530, 32)\n",
      "  (embedding_item_mlp): Embedding(4701, 32)\n",
      "  (embedding_user_mf): Embedding(694530, 32)\n",
      "  (embedding_item_mf): Embedding(4701, 32)\n",
      "  (fc_layers): ModuleList(\n",
      "    (0): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=16, out_features=8, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (affine_output): Linear(in_features=40, out_features=1, bias=True)\n",
      "  (logistic): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# set model and loss, optimizer\n",
    "model = torch.load(MODEL_PATH)\n",
    "model = model.to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([652087, 652087, 652087, 652087, 652087, 652087, 652087, 652087, 652087,\n",
      "        652087, 652087, 652087, 652087, 652087, 652087, 652087, 652087, 652087,\n",
      "        652087, 652087, 652087, 652087, 652087, 652087, 652087, 652087, 652087,\n",
      "        652087, 652087, 652087, 652087, 652087, 652087, 652087, 652087, 652087,\n",
      "        652087, 652087, 652087, 652087, 652087, 652087, 652087, 652087, 652087,\n",
      "        652087, 652087, 652087, 652087, 652087, 652087, 652087, 652087, 652087,\n",
      "        652087, 652087, 652087, 652087, 652087, 652087, 652087, 652087, 652087,\n",
      "        652087, 652087, 652087, 652087, 652087, 652087, 652087, 652087, 652087,\n",
      "        652087, 652087, 652087, 652087, 652087, 652087, 652087, 652087, 652087,\n",
      "        652087, 652087, 652087, 652087, 652087, 652087, 652087, 652087, 652087,\n",
      "        652087, 652087, 652087, 652087, 652087, 652087, 652087, 652087, 652087,\n",
      "        652087, 652087])\n",
      "12\n",
      "tensor([6.4101e-01, 5.1673e-04, 1.3970e-01, 4.0576e-01, 1.0045e-01, 1.0794e-02,\n",
      "        2.1156e-01, 4.3691e-01, 8.4826e-01, 9.1424e-01, 8.9499e-01, 1.4134e-03,\n",
      "        7.5308e-01, 2.0841e-04, 2.3119e-03, 1.6305e-01, 7.6935e-01, 8.6364e-03,\n",
      "        3.2205e-04, 7.7417e-04, 1.4988e-02, 7.9206e-01, 4.8024e-01, 4.7530e-01,\n",
      "        1.6163e-01, 1.1651e-01, 9.3966e-01, 9.4525e-01, 1.8122e-03, 5.1407e-01,\n",
      "        1.1417e-04, 1.0954e-01, 3.7199e-03, 1.1690e-01, 4.2560e-04, 2.8211e-01,\n",
      "        2.7527e-03, 4.0099e-01, 5.5968e-01, 8.2539e-01, 6.1011e-04, 1.7286e-02,\n",
      "        4.1441e-01, 7.9090e-01, 8.2403e-03, 6.5029e-03, 1.3253e-01, 2.7076e-01,\n",
      "        2.0845e-04, 2.7556e-01, 1.2019e-04, 3.7048e-03, 4.6759e-03, 9.5354e-04,\n",
      "        9.4994e-01, 2.0360e-03, 3.3831e-04, 7.3351e-04, 1.2458e-01, 7.4565e-03,\n",
      "        4.8817e-01, 2.0074e-01, 3.9188e-03, 7.1843e-01, 8.5116e-01, 3.4333e-01,\n",
      "        2.0392e-01, 5.4793e-04, 9.8410e-03, 8.5067e-02, 1.8739e-04, 2.2150e-01,\n",
      "        8.3343e-02, 4.3528e-01, 2.3373e-01, 2.4984e-04, 9.1726e-01, 9.7735e-01,\n",
      "        1.3268e-01, 4.4737e-02, 2.1309e-01, 3.4090e-01, 3.8090e-01, 2.0200e-01,\n",
      "        2.5575e-02, 5.5366e-03, 1.4933e-02, 1.7518e-01, 9.2077e-01, 5.5421e-02,\n",
      "        2.6325e-01, 9.3179e-01, 4.0656e-01, 4.2047e-01, 6.6351e-01, 1.4498e-03,\n",
      "        1.2674e-04, 7.8775e-01, 4.4817e-03, 2.9110e-04, 1.2526e-02],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "user_iter = iter(test_loader)\n",
    "users, items, labels = next(user_iter)   \n",
    "cusers, citems, clabels = next(user_iter)   \n",
    "\n",
    "count = 0\n",
    "while users.numpy()[0] == 419025:\n",
    "   # print(count)\n",
    "   users, items, labels = next(user_iter)\n",
    "   count += 1\n",
    "print(users)\n",
    "print(count)\n",
    "user = users.to(device)\n",
    "item = items.to(device)\n",
    "\n",
    "predictions = model(user, item)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([202])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_iter = iter(test_loader)\n",
    "users, items, labels = next(user_iter)   \n",
    "torch.cat((cusers, users), 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1983584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 51347/1983584 [01:09<43:38, 738.04it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m HR, NDCG, MRR \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPerfomance/HR@\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mtop_k,\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, HR, \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      3\u001b[0m writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPerfomance/NDCG@\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mtop_k,\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, NDCG, \u001b[38;5;241m10\u001b[39m)\n",
      "Cell \u001b[0;32mIn[11], line 45\u001b[0m, in \u001b[0;36mmetrics\u001b[0;34m(model, test_loader, top_k, device)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(test_loader))\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m user, item, label \u001b[38;5;129;01min\u001b[39;00m tqdm(test_loader, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(test_loader)):\n\u001b[0;32m---> 45\u001b[0m \tuser \u001b[38;5;241m=\u001b[39m \u001b[43muser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \titem \u001b[38;5;241m=\u001b[39m item\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     48\u001b[0m \tpredictions \u001b[38;5;241m=\u001b[39m model(user, item)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "HR, NDCG, MRR = metrics(model, test_loader, args.top_k, device)\n",
    "writer.add_scalar(f'Perfomance/HR@{args.top_k,}', HR, 10)\n",
    "writer.add_scalar(f'Perfomance/NDCG@{args.top_k,}', NDCG, 10)\n",
    "writer.add_scalar(f'Perfomance/MRR@{args.top_k,}', MRR, 10)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"The time elapse of epoch {:03d}\".format(10) + \" is: \" +\n",
    "        time.strftime(\"%H: %M: %S\", time.gmtime(elapsed_time)))\n",
    "print(\"HR: {:.3f}\\tNDCG: {:.3f}\\tNDCG: {:.3f}\".format(np.mean(HR), np.mean(NDCG), np.mean(MRR)))\n",
    "\n",
    "\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
